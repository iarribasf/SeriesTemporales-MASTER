<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Iván Arribas (Depto. Análisis Económico. Universitat de València)" />


<title>Series Temporales: Alisado Exponencial</title>

<script src="site_libs/header-attrs-2.5/header-attrs.js"></script>
<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cerulean.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<script src="site_libs/navigation-1.1/codefolding.js"></script>
<script src="site_libs/navigation-1.1/sourceembed.js"></script>
<link href="site_libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="site_libs/anchor-sections-1.0/anchor-sections.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
#rmd-source-code {
  display: none;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->
<style type="text/css">
.code-folding-btn { margin-bottom: 4px; }
</style>



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row-fluid">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-inverse  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Series Temporales</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">
    <span class="fa fa-home"></span>
     
  </a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="01-Guia-curso.html">
    <span class="fa fa-graduation-cap"></span>
     
    Guía del curso
  </a>
</li>
<li>
  <a href="02-Logistica.html">
    <span class="fa fa-laptop"></span>
     
    Logística
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-book"></span>
     
    Diapos
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Teoría</li>
    <li>
      <a href="03-01-Tema1.html">Tema 1: Introducción</a>
    </li>
    <li>
      <a href="03-02-Tema2.html">Tema 2: Alisado</a>
    </li>
    <li>
      <a href="03-03-Tema3.html">Tema 3: Procesos estocásticos</a>
    </li>
    <li>
      <a href="03-04-Tema4.html">Tema 4: ARIMA</a>
    </li>
    <li>
      <a href="03-05-Tema5.html">Tema 5: SARIMA</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Ejemplo de aplicación</li>
    <li>
      <a href="03-06-Ejemplo1.html">Ejemplo Tema 1</a>
    </li>
    <li>
      <a href="03-07-Ejemplo2.html">Ejemplo Tema 2</a>
    </li>
    <li>
      <a href="03-08-Ejemplo3.html">Ejemplo Tema 3</a>
    </li>
    <li>
      <a href="03-09-Ejemplo4.html">Ejemplo Tema 4</a>
    </li>
    <li>
      <a href="03-10-Ejemplo5.html">Ejemplo Tema 5</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Otro ejemplo</li>
    <li>
      <a href="03-11-Ejemplo-Pasajeros.html">Ejemplo de Pasajeros</a>
    </li>
  </ul>
</li>
<li>
  <a href="04-Recursos-R.html">
    <span class="fa fa-code"></span>
     
    Recursos de R
  </a>
</li>
<li>
  <a href="05-Practica.html">
    <span class="fa fa-edit"></span>
     
    Practica
  </a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    <span class="fa fa-download"></span>
     
    Más
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">R</li>
    <li>
      <a href="https://cran.r-project.org">Dónde está R</a>
    </li>
    <li>
      <a href="https://rstudio.com">Donde está RStudio</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Markdown</li>
    <li>
      <a href="https://bookdown.org/yihui/rmarkdown/">Markdown</a>
    </li>
    <li>
      <a href="https://rmarkdown.rstudio.com/lesson-1.html">R Markdown</a>
    </li>
    <li class="divider"></li>
    <li class="dropdown-header">Otros</li>
    <li>
      <a href="https://www.r-bloggers.com">Blog sobre R</a>
    </li>
    <li>
      <a href="https://bookdown.org">Libros online que debes conocer</a>
    </li>
  </ul>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">

<div class="btn-group pull-right">
<button type="button" class="btn btn-default btn-xs dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"><span>Code</span> <span class="caret"></span></button>
<ul class="dropdown-menu" style="min-width: 50px;">
<li><a id="rmd-download-source" href="#">Download Rmd</a></li>
</ul>
</div>



<h1 class="title toc-ignore">Series Temporales: Alisado Exponencial</h1>
<h3 class="subtitle">Máster de Bioestadística (Modelización Estadística)</h3>
<h4 class="author">Iván Arribas (Depto. Análisis Económico. Universitat de València)</h4>

</div>


<div id="introducción" class="section level1" number="1">
<h1 number="1"><span class="header-section-number">1</span> Introducción</h1>
<p>En muchos casos es preciso aplicar un método de predicción rápido y sencillo:</p>
<ul>
<li>A causa del elevado número de series que tienen que ser analizadas.</li>
<li>Debido a la rapidez con que las predicciones se han de dar.</li>
</ul>
<p>Actualmente existen muchos métodos sencillos de predicción, entre lo que cabe destacar dos:</p>
<ul>
<li><strong>Métodos de media móvil</strong> (no los veremos en este curso pero puedes aprender sobre ellos <a href="http://uc-r.github.io/ts_moving_averages">aqui</a> y <a href="https://cran.r-project.org/web/packages/smooth/vignettes/sma.html">aqui</a>).</li>
<li><strong>Métodos de alisado exponencial</strong>.</li>
</ul>
<p>Estas técnicas, a pesar de su sencillez, son bastante adecuadas cuando la previsión es a corto plazo:</p>
<blockquote>
<p>“Statistically sophisticated or complex methods do not necessarily produce more accurate forecasts than simpler ones.” Makridakis y Hibon (2000).</p>
</blockquote>
<p>Veremos en detalle los métodos de alisado exponencial por ser muy versátiles, pudiéndose aplicar a cualquier serie, independientemente de sus componentes, y haber demostrado una gran capacidad de ajuste y calidad de predicción. En ellos se hace uso de datos pasados para obtener una nueva serie más <em>suave</em> o alisada, a partir de la cual se realizarán las predicciones. Existe un amplio menú de métodos de alisado alternativos y la elección del más adecuado dependerá de las componentes que presenta la serie y del tipo de esquema.</p>
<p><br />
<br />
</p>
</div>
<div id="criterios-de-calidad" class="section level1" number="2">
<h1 number="2"><span class="header-section-number">2</span> Criterios de calidad</h1>
<p>En este tema y en los siguientes se verán diferentes métodos para predecir una serie temporal. Así, es preciso definir criterios de bondad de ajuste que permitan estimar tanto la calidad del ajuste como de las predicciones de un método.</p>
<blockquote>
<p>“The rankings of the performance of the various methods vary according to the accuracy measure being used.” Makridakis y Hibon (2000).</p>
</blockquote>
<p><br />
</p>
<div id="notación-y-definiciones" class="section level2" number="2.1">
<h2 number="2.1"><span class="header-section-number">2.1</span> Notación y definiciones</h2>
<p>Dada una serie temporal <span class="math inline">\(\{y_t\}_{t=1}^T\)</span>, se define:</p>
<ul>
<li><strong>Previsión <span class="math inline">\(h\)</span> periodos adelante</strong>, como la previsión de la serie para el periodo <span class="math inline">\(t+h\)</span> disponiendo de información hasta el periodo <span class="math inline">\(t\)</span>, y se denota por <span class="math inline">\(\hat{y}_{t+h|t}\)</span>. Por simplicidad lo escribiremos también como <span class="math inline">\(\hat{y}_{t+h}\)</span>.</li>
</ul>
<ul>
<li>Así, <span class="math inline">\(\hat{y}_{t+1|t}\)</span> es la <strong>previsión un periodo adelante</strong> o a un periodo vista. Es decir, la previsión de la serie en <span class="math inline">\(t+1\)</span> desde el periodo <span class="math inline">\(t\)</span>.</li>
</ul>
<ul>
<li>De nuevo, por simplicidad denotaremos a <span class="math inline">\(\hat{y}_{t+1|t}\)</span> como <span class="math inline">\(\hat{y}_{t+1}\)</span>; y como <span class="math inline">\(\hat{y}_{t}\)</span> a la previsión en <span class="math inline">\(t\)</span>, con datos hasta el periodo <span class="math inline">\(t-1\)</span> (<span class="math inline">\(\hat{y}_{t} = \hat{y}_{t|t-1}\)</span>).</li>
</ul>
<p>Se define como <strong>error de previsión</strong> a un periodo vista a <span class="math display">\[\hat{e}_t=y_t-\hat{y}_t,\]</span> de forma que la serie <span class="math inline">\(\{\hat{e}_t\}_{t=1}^T\)</span> nos permitirá definir varios criterios de calidad de ajuste.</p>
<p><br />
</p>
</div>
<div id="medidas-de-precisión-de-la-predicción" class="section level2" number="2.2">
<h2 number="2.2"><span class="header-section-number">2.2</span> Medidas de precisión de la predicción</h2>
<p>Dada una serie <span class="math inline">\(\{y_t\}_{t=1}^T\)</span>, un método de predicción y su vector de errores asociado <span class="math inline">\(\{\hat{e}_t\}_{t=1}^T\)</span>, podemos definir múltiples medidas de calidad del método de predicción que hacen referencia a la presencia de sesgo en las predicciones, la magnitud del error cometido y la calidad del intervalo de confianza de las predicciones. Las más habituales son (siglas en inglés):</p>
<ul>
<li>Error medio (ME): <span class="math inline">\(\frac{1}{T}\sum_{t=1}^T \hat{e}_t\)</span></li>
</ul>
<ul>
<li><strong>Raíz del error cuadrático medio (RMSE)</strong>: <span class="math inline">\(\sqrt{\frac{1}{T}\sum_{t=1}^T \hat{e}^2_t}\)</span></li>
</ul>
<ul>
<li>Error absoluto medio (MAE): <span class="math inline">\(\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|\)</span></li>
</ul>
<ul>
<li>Error porcentual medio (MPE): <span class="math inline">\(\frac{100}{T}\sum_{t=1}^T \frac{\hat{e}_t}{y_t}\)</span></li>
</ul>
<ul>
<li><strong>Error porcentual absoluto medio (MAPE)</strong>: <span class="math inline">\(\frac{100}{T}\sum_{t=1}^T \big|\frac{\hat{e}_t}{y_t}\big|\)</span></li>
</ul>
<ul>
<li>Error porcentual absoluto medio simétrico (sMAPE): <span class="math inline">\(\frac{200}{T}\sum_{t=1}^T \Big|\frac{\hat{e}_t}{y_t + \hat{y}_t}\Big|\)</span></li>
</ul>
<ul>
<li>Error escalado absoluto medio (MASE): <span class="math inline">\(\big(\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|\big)/q\)</span>, donde <span class="math inline">\(q\)</span> es el error absoluto medio para un método ingenuo de predicción:
<ul>
<li><span class="math inline">\(q=\frac{1}{T-1}\sum_{t=2}^T |y_t-y_{t-1}|\)</span> para series <em>sin</em> estacionalidad</li>
<li><span class="math inline">\(q=\frac{1}{T-m}\sum_{t=m+1}^T |y_t-y_{t-m}|\)</span> para series <em>con</em> estacionalidad</li>
</ul></li>
</ul>
<ul>
<li>Correlación entre <span class="math inline">\(\hat{e}_t\)</span> y <span class="math inline">\(\hat{e}_{t-1}\)</span> (ACF1).</li>
</ul>
<p><br />
</p>
<p>ME y MPE permiten valorar el sesgo de las predicciones (que estas estén sistemáticamente por encima o por debajo de los valores reales).</p>
<ul>
<li>Lo esperado es un valor cercano a cero (con relación al valor medio de la serie). Valores muy alejados de cero son indicadores de sesgo de predicción.</li>
</ul>
<p>RMSE y MAE indican el error medio cometido, medido en las mismas unidades que la serie temporal.</p>
<ul>
<li>Están acotadas inferiormente por el valor óptimo de 0, pero no hay cota superior.</li>
</ul>
<p>MAPE y sMAPE indican el error porcentual medio cometido.</p>
<ul>
<li>Están acotadas inferiormente por el valor óptimo de 0%, y la cota superior natural es 100%, aunque podría sobrepasarse.</li>
<li>Si <span class="math inline">\(y_t\)</span> puede valer 0, entonces MAPE no se puede calcular. Además, MAPE penaliza más los errores negativos frente a los errores positivos. La medida de precisión sMAPE se define a fin de corregir estos problemas.</li>
</ul>
<p>MASE es la ratio entre el error del método usado y el error de un método ingenuo de predicción. Permite saber cuánto ganamos en capacidad predictiva al pasar de un método ingenuo a otro más complicado.</p>
<ul>
<li>Un valor cercano a 1 indica que el método usado no es mejor que el método ingenuo</li>
<li>Cuanto más cercano a 0, mejor es el método usado respecto del método ingenuo</li>
<li>Su complementario a 1 se puede interpretar como la tasa de mejora</li>
</ul>
<p>ACF1 evalúa la capacidad de mejora que hay en la estimación del intervalo de confianza de las predicciones. Lo veremos con más detalle en el tema de modelos ARIMA. Por ahora basta saber que:</p>
<ul>
<li>Un valor muy cercano a 0 indica que hay poca capacidad de mejora.</li>
<li>Un valor cercano a 1 o -1 indica que hay mucha capacidad de mejora.</li>
</ul>
<p>Las <em>medias</em> se pueden sustituir por <em>medianas</em>. Esto es especialmente útil cuando para algunas observaciones hay errores atípicamente altos.</p>
<p><br />
</p>
<p>Si para realizar la predicción del periodo <span class="math inline">\(t\)</span> se usa una metodología que utiliza datos hasta dicho periodo, se hablará de <strong>predicción y error intra-muestral</strong>. En caso contrario, la predicción del periodo <span class="math inline">\(t\)</span> usa una metodología que solo necesita de datos hasta el periodo <span class="math inline">\(t-1\)</span>, se hablará de <strong>predicción y error extra-muestral</strong>.</p>
<p>Si los indicadores de calidad se basan en predicciones intra-muestrales a un periodo vista, presentan dos problemas. Primero, evalúan el error de predicción a un periodo vista, cuando en muchas situaciones reales las predicciones se realizan sobre un horizonte temporal más amplio. Segundo, son errores intra-muestrales, resultantes de predecir los mismos datos que se ha usado el método para calcular la predicción y, por tanto, sobre-estiman la capacidad predictiva del modelo.</p>
<p>Veremos durante en este tema métodos de evaluación de la calidad de las predicciones que superan estas limitaciones.</p>
<p><br />
<br />
</p>
</div>
</div>
<div id="métodos-sencillos-de-predicción" class="section level1" number="3">
<h1 number="3"><span class="header-section-number">3</span> Métodos sencillos de predicción</h1>
<p>Algunos métodos de predicción son extremadamente sencillos y sorprendentemente eficaces, son los denominados métodos ingenuos. Estos métodos:</p>
<ul>
<li>posibilitan realizar predicciones prácticamente sin realizar ningún cálculo.</li>
<li>como son muy sencillos, dan las previsiones con mayor error (menos precisas). El error de un método ingenuo sirve de punto de referencia (<em>benchmark</em>) para valorar la necesidad de aplicar otros métodos más complicados con el objetivo de mejorar la calidad de las predicciones.</li>
</ul>
<p>Veamos algunos métodos ingenuos y sus funciones en el paquete <code>forecast</code>.</p>
<p><br />
</p>
<div id="métodos-sencillos-de-predicción-1" class="section level2" number="3.1">
<h2 number="3.1"><span class="header-section-number">3.1</span> Métodos sencillos de predicción</h2>
<div id="series-sin-tendencia-y-sin-estacionalidad" class="section level3 unnumbered">
<h3 class="unnumbered">Series <em>sin</em> tendencia y <em>sin</em> estacionalidad</h3>
<p><strong>Método de la Media</strong>: <span class="math inline">\(\hat{y}_{T+h}=(y_1+\ldots,y_T)/T\)</span>.</p>
<ul>
<li>La predicción para cualquier periodo futuro es la <strong>media</strong> de las observaciones disponibles previas.</li>
<li>Función de <code>R</code>: <code>meanf(y, h)</code></li>
</ul>
<p><strong>Método ingenuo I</strong>: <span class="math inline">\(\hat{y}_{T+h}=y_T\)</span>.</p>
<ul>
<li>La predicción para cualquier periodo futuro es la <strong>última</strong> observación disponible.</li>
<li>Función de <code>R</code>: <code>naive(y, h)</code> o <code>rwf(y, h)</code> (<em>rw</em> de random walk)</li>
</ul>
</div>
<div id="series-con-tendencia-y-sin-estacionalidad" class="section level3 unnumbered">
<h3 class="unnumbered">Series <em>con</em> tendencia y <em>sin</em> estacionalidad</h3>
<p><strong>Método ingenuo II</strong>: <span class="math inline">\(\hat{y}_{T+h}=y_T + h(y_T-y_{T-1})\)</span>.</p>
<ul>
<li>La predicción <span class="math inline">\(h\)</span> periodos adelante es la <strong>última observación</strong> disponible más <span class="math inline">\(h\)</span> veces el <strong>último incremento</strong> observado.</li>
<li>No tiene función en <code>R</code>, pero se podría emular mediante la función <code>holt</code> (véase epígrafe de 4.5 Alisado exponencial de Holt).</li>
</ul>
<p><strong>Método de la deriva</strong>: <span class="math inline">\(\hat{y}_{T+h}=y_T+h\frac{y_T - y_1}{T-1}\)</span>.</p>
<ul>
<li>La predicción <span class="math inline">\(h\)</span> periodos adelante es la <strong>última observación</strong> disponible más <span class="math inline">\(h\)</span> veces el <strong>incremento medio</strong> observado.</li>
<li>Función de <code>R</code>: <code>rwf(y, h, drift = TRUE)</code></li>
</ul>
</div>
<div id="series-sin-tendencia-y-con-estacionalidad" class="section level3 unnumbered">
<h3 class="unnumbered">Series <em>sin</em> tendencia y <em>con</em> estacionalidad</h3>
<p><strong>Método ingenuo con estacionalidad</strong>: <span class="math inline">\(\hat{y}_{T+h}=y_{T-m(k+1)}\)</span>.</p>
<ul>
<li><span class="math inline">\(k\)</span> es la parte entera de <span class="math inline">\((h-1)/m\)</span>, es decir, el número de años completos en el periodo de predicción previo al periodo <span class="math inline">\(T+h\)</span>.</li>
<li>La predicción para un periodo es la <strong>última observación disponible de la misma estación que la fecha que se desea predecir</strong>.</li>
<li>Función de <code>R</code>: <code>snaive(y, h)</code></li>
</ul>
<p><strong>No hay métodos ingenuos cuando la serie tiene tendencia y estacionalidad</strong>, aunque la aplicación del método ingenuo con estacionalidad suele ser muy efectiva.</p>
<p><br />
</p>
</div>
</div>
<div id="ejemplo-de-aplicación" class="section level2" number="3.2">
<h2 number="3.2"><span class="header-section-number">3.2</span> Ejemplo de aplicación</h2>
<div id="serie-libros" class="section level3 unnumbered">
<h3 class="unnumbered">Serie Libros</h3>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>libros <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">&quot;./series/libros.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>libros <span class="ot">&lt;-</span> <span class="fu">ts</span>(libros[ ,<span class="dv">2</span>], <span class="at">start =</span> <span class="dv">1993</span>, <span class="at">frequency  =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>En la figura 1 se muestra el resultado gráfico de la aplicación de algunos de estos métodos sencillos a la serie Libros (número de títulos publicados anualmente en España desde 1993 hasta 2018), con independencia de su adecuación dadas las componentes de esta serie. Se ha fijado un horizonte de previsión de cinco años (<code>h = 5</code>). El argumento <code>PI = FALSE</code> hace que no se impriman los intervalos de confianza de las predicciones.</p>
<p>Los métodos de la Media e Ingenuo I realizan una predicción constante, el primero la media de títulos en el periodo de análisis (61786) y el segundo el último dato observado (62180). El método de deriva ofrece una predicción creciente porque la serie Libros tiene una pendiente media positiva en el periodo de análisis.</p>
<p>Recuerda que debes cargar las librerías <code>forecast</code> y <code>ggplot2</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>(mediaLibros <span class="ot">&lt;-</span> <span class="fu">meanf</span>(libros, <span class="at">h =</span> <span class="dv">5</span>))</span></code></pre></div>
<pre><code>     Point Forecast   Lo 80    Hi 80    Lo 95    Hi 95
2019       61786.23 47291.7 76280.76 39108.25 84464.21
2020       61786.23 47291.7 76280.76 39108.25 84464.21
2021       61786.23 47291.7 76280.76 39108.25 84464.21
2022       61786.23 47291.7 76280.76 39108.25 84464.21
2023       61786.23 47291.7 76280.76 39108.25 84464.21</code></pre>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>(naiveLibros <span class="ot">&lt;-</span> <span class="fu">naive</span>(libros, <span class="at">h =</span> <span class="dv">5</span>))</span></code></pre></div>
<pre><code>     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
2019          62180 54474.50 69885.50 50395.46 73964.54
2020          62180 51282.78 73077.22 45514.14 78845.86
2021          62180 48833.68 75526.32 41768.57 82591.43
2022          62180 46769.00 77591.00 38610.91 85749.09
2023          62180 44949.98 79410.02 35828.96 88531.04</code></pre>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>(derivaLibros <span class="ot">&lt;-</span> <span class="fu">rwf</span>(libros,  <span class="at">h =</span> <span class="dv">5</span>, <span class="at">drift =</span> <span class="cn">TRUE</span>))</span></code></pre></div>
<pre><code>     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
2019       63036.88 55252.76 70821.00 51132.10 74941.66
2020       63893.76 52667.34 75120.18 46724.44 81063.08
2021       64750.64 50739.23 78762.05 43322.03 86179.25
2022       65607.52 49131.65 82083.39 40409.84 90805.20
2023       66464.40 47717.76 85211.04 37793.89 95134.91</code></pre>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(libros, <span class="at">series =</span> <span class="st">&quot;Libros&quot;</span>,</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>                <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                <span class="at">main =</span> <span class="st">&quot;Figura 1. Libros y predicción por métodos sencillos&quot;</span>) <span class="sc">+</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(mediaLibros, <span class="at">series=</span><span class="st">&quot;Media&quot;</span>, <span class="at">PI =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(naiveLibros, <span class="at">series=</span><span class="st">&quot;Ingenuo&quot;</span>, <span class="at">PI =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">autolayer</span>(derivaLibros, <span class="at">series=</span><span class="st">&quot;Deriva&quot;</span>, <span class="at">PI =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_colour_discrete</span>(<span class="at">limits=</span><span class="fu">c</span>(<span class="st">&quot;Libros&quot;</span>, <span class="st">&quot;Media&quot;</span>, <span class="st">&quot;Ingenuo&quot;</span>, <span class="st">&quot;Deriva&quot;</span>)) <span class="sc">+</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">colour =</span> <span class="fu">guide_legend</span>(<span class="at">title =</span> <span class="st">&quot;Métodos&quot;</span>)) <span class="sc">+</span> </span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position=</span><span class="fu">c</span>(<span class="fl">0.02</span>,<span class="fl">0.98</span>), <span class="at">legend.justification=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-2-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Con la función <code>accuracy</code> se puede obtener el error de predicción intra-muestral a un periodo vista de cada método:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(mediaLibros)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(naiveLibros)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(derivaLibros)</span></code></pre></div>
<pre><code>              ME     RMSE     MAE   MPE  MAPE MASE  ACF1
Media       0.00 10595.53 8155.92 -3.17 14.03 1.76  0.77
Ingenuo I 856.88  6012.63 4626.40  1.27  7.30 1.00 -0.04
Deriva      0.00  5951.26 4364.46 -0.13  6.87 0.94 -0.04</code></pre>
<p>Podemos destacar que:</p>
<ul>
<li>El método de <em>Media</em> presenta una baja capacidad predictiva debido a que la serie Libros tiene tendencia (MAPE = 14%). Además, el intervalo de confianza de las predicciones no es fiable (ACF1 = 0.77).</li>
<li>El método de <em>Deriva</em> tiene la mejor calidad de ajuste, con un error porcentual del 6.9% (MAPE), y un error medio aproximado de 6,000 títulos (RMSE). No presenta sesgo (ME = 0) y el intervalo de confianza de las predicciones es fiable (ACF1 = -0.04).</li>
<li>El método <em>Ingenuo I</em> tiene buena calidad de ajuste, pero las previsiones están muy sesgadas (ME = 857).</li>
<li>Para series sin estacionalidad el método sencillo de comparación usado en el cálculo del MASE es el <em>Ingenuo I</em>. Es por ello que este indicador vale 1 para este método.</li>
<li>El error medio (ME) siempre será nulo para el método de la <em>Media</em> y de la <em>Deriva</em>, lo que indica que nos equivocamos tanto por exceso como por defecto. Esta es una buena propiedad, que el método <em>Ingenuo I</em> no verifica.</li>
</ul>
</div>
<div id="serie-nacimientos" class="section level3 unnumbered">
<h3 class="unnumbered">Serie Nacimientos</h3>
<p>Podemos usar el método ingenuo con estacionalidad con la serie Nacimientos para obtener una previsión a dos años vista. El error absoluto porcentual medio es del 3.6%. Es decir, aplicando algo tan simple como predecir el número de nacimientos para un mes como los nacimientos del mismo mes del año previo, tenemos ya un error de predicción muy bajo. La figura 2 muestra la serie y la predicción que, debido al método usado, no incorpora la tendencia decreciente de los últimos años.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>nacimientos <span class="ot">&lt;-</span> <span class="fu">read.csv2</span>(<span class="st">&quot;./series/nacimientos.csv&quot;</span>, <span class="at">header =</span> <span class="cn">TRUE</span>)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>nacimientos <span class="ot">&lt;-</span> <span class="fu">ts</span>(nacimientos[, <span class="dv">2</span>],</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                  <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">1975</span>, <span class="dv">1</span>),</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                  <span class="at">frequency =</span> <span class="dv">12</span>)</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>(snaive.nacimientos <span class="ot">&lt;-</span> <span class="fu">snaive</span>(nacimientos, <span class="at">h =</span> <span class="dv">24</span>, <span class="at">level =</span> <span class="dv">95</span>))</span></code></pre></div>
<pre><code>         Point Forecast   Lo 95   Hi 95
Jan 2019          31772 28378.6 35165.4
Feb 2019          28211 24817.6 31604.4
Mar 2019          30340 26946.6 33733.4
Apr 2019          29436 26042.6 32829.4
May 2019          31061 27667.6 34454.4
Jun 2019          30546 27152.6 33939.4
Jul 2019          32521 29127.6 35914.4
Aug 2019          33059 29665.6 36452.4
Sep 2019          31406 28012.6 34799.4
Oct 2019          33059 29665.6 36452.4
Nov 2019          30696 27302.6 34089.4
Dec 2019          30670 27276.6 34063.4
Jan 2020          31772 26973.0 36571.0
Feb 2020          28211 23412.0 33010.0
Mar 2020          30340 25541.0 35139.0
Apr 2020          29436 24637.0 34235.0
May 2020          31061 26262.0 35860.0
Jun 2020          30546 25747.0 35345.0
Jul 2020          32521 27722.0 37320.0
Aug 2020          33059 28260.0 37858.0
Sep 2020          31406 26607.0 36205.0
Oct 2020          33059 28260.0 37858.0
Nov 2020          30696 25897.0 35495.0
Dec 2020          30670 25871.0 35469.0</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(snaive.nacimientos)</span></code></pre></div>
<pre><code>                    ME     RMSE      MAE       MPE     MAPE MASE      ACF1
Training set -574.8081 1731.361 1396.684 -1.456378 3.647108    1 0.7179587</code></pre>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(snaive.nacimientos,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Nacimientos&quot;</span>,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 2. Nacimientos y predicción por el método Ingenuo con estacionalidad&quot;</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-5-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
<br />
</p>
</div>
</div>
</div>
<div id="evaluación-de-las-predicciones" class="section level1" number="4">
<h1 number="4"><span class="header-section-number">4</span> Evaluación de las predicciones</h1>
<p>Las medidas que hemos usado hasta ahora para valorar la calidad de las predicciones son realmente medidas de bondad de ajuste, es decir, medidas de la calidad de <strong>previsiones intra-muestrales a un periodo vista</strong>. Valoran en que medida los datos se ajustan a un patrón o modelo, pero no evalúan la calidad de la previsiones ante nuevos datos.</p>
<p>En este epígrafe vamos a ver dos metodologías que podemos usar para valorar la calidad de las <strong>previsiones extra-muestrales</strong>, que es realmente los que nos interesa. Estas dos metodologías están relacionadas con los métodos de <em>Training set/Test set</em> y <em>Cross-validation</em> usuales en el análisis de las predicciones con datos transversales, pero adaptadas a datos temporales.</p>
<div id="validación-por-la-metodología-de-training-settest-set-para-series-temporales" class="section level2" number="4.1">
<h2 number="4.1"><span class="header-section-number">4.1</span> Validación por la metodología de <em>Training set/Test set</em> para Series Temporales</h2>
<p>Vamos a mejorar la estimación de la calidad de las predicciones obteniendo las medidas de error para <strong>previsiones extra-muestrales a varios periodos vista</strong> usando la filosofía del método <em>training set/test set</em>. Dividimos la serie temporal <span class="math inline">\(\{y_t\}_{t=1}^T\)</span> en dos subseries, los primeros datos <span class="math inline">\(\{y_t\}_{t=1}^{T_0}\)</span>, <span class="math inline">\(T_0 &lt; T\)</span> se usarán para estimar el modelo, y los últimos datos <span class="math inline">\(\{y_t\}_{t={T_0+1}}^{T}\)</span> para validar el modelo.</p>
<p>Esta metodología, muy efectiva para datos de corte transversal, genera dos problemas cuando se aplica a series temporales: <em>i</em>) el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar; <em>ii</em>) los resultados dependen tremendamente del punto de corte temporal seleccionado.</p>
<div id="serie-libros-1" class="section level3 unnumbered">
<h3 class="unnumbered">Serie Libros</h3>
<p>Vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Definimos las observaciones intra- y extra-muestrales</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>librosIntra <span class="ot">&lt;-</span> <span class="fu">subset</span>(libros, <span class="at">end =</span> <span class="fu">length</span>(libros) <span class="sc">-</span> <span class="dv">6</span>)</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>librosExtra <span class="ot">&lt;-</span> <span class="fu">subset</span>(libros, <span class="at">start =</span> <span class="fu">length</span>(libros) <span class="sc">-</span> <span class="dv">5</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimamos el modelo con todos los datos menos los 6 ultimos y</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="co"># predecimos los 6 años que hemos quitado de la serie </span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>librosExtraPre <span class="ot">&lt;-</span> <span class="fu">rwf</span>(librosIntra,  <span class="at">h =</span> <span class="dv">6</span>, <span class="at">drift =</span> <span class="cn">TRUE</span>)</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Vemos la calidad del ajuste. Primero la predicción y luego los datos reales</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(librosExtraPre, librosExtra)</span></code></pre></div>
<pre><code>                    ME     RMSE      MAE    MPE  MAPE MASE  ACF1 Theil&#39;s U
Training set      0.00  5863.85  4279.52  -0.05  6.53 0.87 -0.19        NA
Test set     -15759.36 15817.29 15759.36 -26.65 26.65 3.22 -0.24      6.19</code></pre>
<p>Atendiendo al MAPE se tiene que el error de <strong>previsión a un periodo vista</strong> en el <strong>periodo intra-muestral</strong> de <strong>1993 a 2012</strong> es del 6.5%; mientras que el error de <strong>previsión a largo plazo</strong> en el <strong>periodo extra-muestral</strong> de <strong>2013 a 2018</strong> es del 26.6%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas (sobre-estiman la realidad). En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas.</p>
<p>Un gráfico puede ayudar a entender este proceso de validación. En la figura 3:</p>
<ul>
<li>La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.</li>
<li>La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.</li>
<li>La previsión <em>intra</em>-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.</li>
<li>La línea en rojo es la previsión <em>extra</em>-muestral a largo plazo. Observa que todas las previsiones están por encima del valor real de la serie.</li>
<li>Al lado de cada previsión (intra- y extra-muestral) se ha indicado el error estimado (MAPE).</li>
</ul>
<p>Claramente estos resultados dependen del punto de corte seleccionado.</p>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-8-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="serie-nacimientos-1" class="section level3 unnumbered">
<h3 class="unnumbered">Serie Nacimientos</h3>
<p>Calculamos de nuevo los diferentes criterios de bondad de ajuste para valorar la calidad de las previsiones extra-muestrales a largo plazo. En este caso vamos a reservar los últimos 36 meses como periodo extra-muestral.</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>nacimientosIntra <span class="ot">&lt;-</span> <span class="fu">subset</span>(nacimientos, <span class="at">end =</span> <span class="fu">length</span>(nacimientos) <span class="sc">-</span> <span class="dv">36</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>nacimientosExtra <span class="ot">&lt;-</span> <span class="fu">subset</span>(nacimientos, <span class="at">start =</span> <span class="fu">length</span>(nacimientos) <span class="sc">-</span> <span class="dv">35</span>)</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>nacimientosExtraPre <span class="ot">&lt;-</span> <span class="fu">snaive</span>(nacimientosIntra, <span class="at">h =</span> <span class="dv">36</span>)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(nacimientosExtraPre, nacimientosExtra)</span></code></pre></div>
<pre><code>                   ME    RMSE     MAE   MPE MAPE MASE ACF1 Theil&#39;s U
Training set  -518.93 1742.83 1394.96 -1.26 3.59 1.00 0.72        NA
Test set     -2342.47 2783.26 2440.75 -7.37 7.66 1.75 0.68      1.68</code></pre>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-11-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Las previsiones extra-muestrales muestran una menor pendiente que los casos reales de nacimientos. Así, conforme se avanza en el horizonte temporal las previsiones se van alejando de la realidad y el error extra-muestral es del 7.7%, reducido pero que duplica el error de estimación intra-muestral (3.6%).</p>
<p><br />
</p>
</div>
</div>
<div id="validación-cruzada-para-series-temporales" class="section level2" number="4.2">
<h2 number="4.2"><span class="header-section-number">4.2</span> Validación cruzada para Series Temporales</h2>
<p>Hemos visto dos alternativas para evaluar la calidad de un método de predicción de series temporales, uno basado en predicciones intra-muestrales a un periodo vista y otro basado en predicciones extra-muestrales a largo plazo, ambas con sus inconvenientes.</p>
<p>Veamos ahora una técnica, basada en el concepto de validación cruzada (<em>cross validation</em>) que permite obtener de forma individualizada los errores de previsión extra-muestral a un periodo vista, a dos periodos vista, etc.</p>
<p>Supongamos que para estimar el modelo se necesita un mínimo de <span class="math inline">\(k\)</span> observaciones y que se desea predecir hasta un horizonte temporal <span class="math inline">\(h\)</span>.</p>
<ul>
<li><p>Seleccionamos las observaciones <span class="math inline">\(1,2,...,k\)</span> para estimar el modelo y predecimos las observaciones desde <span class="math inline">\(k+1\)</span> hasta <span class="math inline">\(k+h\)</span>. Tenemos, por tanto, <span class="math inline">\(h\)</span> predicciones.</p></li>
<li><p>Calculamos el error de predicción para las predicciones desde <span class="math inline">\(k+1\)</span> hasta <span class="math inline">\(k+h\)</span>.</p></li>
<li><p>Repetimos este proceso desplazando el número de observaciones seleccionadas para la estimación un periodo adelante. Es decir, ahora usamos las observaciones <span class="math inline">\(2,3,...,k+1\)</span> para estimar el modelo, predecimos las observaciones desde <span class="math inline">\(k+2\)</span> hasta <span class="math inline">\(k+1+h\)</span> y calculamos el error de predicción.</p></li>
<li><p>Iteramos el proceso, desplazando cada vez las observaciones de la estimación un periodo adelante.</p></li>
<li><p>En general para <span class="math inline">\(i=0,1,...,T-k-h\)</span>, donde <span class="math inline">\(T\)</span> es el número total de observaciones:</p>
<ol style="list-style-type: decimal">
<li>Seleccionamos las observaciones <span class="math inline">\(i+1,i+2,...,i+k\)</span> para estimar el modelo.</li>
<li>Predecimos las observaciones desde <span class="math inline">\(i+k+1\)</span> hasta <span class="math inline">\(i+k+h\)</span>.</li>
<li>Calculamos el error de predicción para las observaciones desde <span class="math inline">\(i+k+1\)</span> hasta <span class="math inline">\(i+k+h\)</span>.</li>
<li>Para cada horizonte temporal de predicción se calcula la medida de error deseada.</li>
</ol></li>
</ul>
<p><br />
<br />
</p>
<p><img src="imagenes/RollingWindows.png" /></p>
<p>Este procedimiento se denomina <strong>origen de predicción móvil</strong> (<em>rolling forecast origin</em>) o <em>rolling windows</em>.</p>
<p>Cuando se aplica esta metodología hay que tener en cuenta que los resultados pueden depender del número <span class="math inline">\(k\)</span> de datos usados para la estimación del modelo.</p>
<div id="ejemplo-de-aplicación-con-nacimientos" class="section level3 unnumbered">
<h3 class="unnumbered">Ejemplo de aplicación con Nacimientos</h3>
<p>Vamos a aplicar la metodología previa a la serie anual de Nacimientos. Asumimos que se precisan veinte años para hacer una buena estimación, <span class="math inline">\(k=20\)</span>, y que el horizonte temporal es de cinco años, <span class="math inline">\(h = 5\)</span> meses. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a cinco años.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>nacAnual <span class="ot">&lt;-</span> <span class="fu">aggregate</span>(nacimientos, <span class="at">FUN =</span> sum)</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">20</span>                   <span class="co">#Minimo numero de datos para estimar</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="dv">5</span>                    <span class="co">#Horizonte de las prediciciones</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">length</span>(nacAnual)    <span class="co">#Longitud serie</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> TT <span class="sc">-</span> k <span class="sc">-</span> h           <span class="co">#Total de estimaciones</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>mapeRwf <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, s <span class="sc">+</span> <span class="dv">1</span>, h)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">0</span><span class="sc">:</span>s) {</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>  train.set <span class="ot">&lt;-</span> <span class="fu">subset</span>(nacAnual, <span class="at">start =</span> i <span class="sc">+</span> <span class="dv">1</span>, <span class="at">end =</span> i <span class="sc">+</span> k)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>  test.set <span class="ot">&lt;-</span>  <span class="fu">subset</span>(nacAnual, <span class="at">start =</span> i <span class="sc">+</span> k <span class="sc">+</span> <span class="dv">1</span>, <span class="at">end =</span> i <span class="sc">+</span> k <span class="sc">+</span> h)</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>  fcast <span class="ot">&lt;-</span> <span class="fu">rwf</span>(train.set, <span class="at">h =</span> h, <span class="at">drift =</span> <span class="cn">TRUE</span>)</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>  mapeRwf[i <span class="sc">+</span> <span class="dv">1</span>,] <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">*</span><span class="fu">abs</span>(test.set <span class="sc">-</span> fcast<span class="sc">$</span>mean)<span class="sc">/</span>test.set</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>mapeRwf <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(mapeRwf)</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(mapeRwf, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>[1]  4.21  8.16 12.15 16.20 20.42</code></pre>
<p>El error de previsión extra-muestral crece linealmente con el horizonte de previsión. Para el primer año el error de predicción se mantiene en un moderado 4.2%. Sin embargo, para el segundo año de predicción el MAPE salta al 8.2% y para los restantes años sigue creciendo rápidamente. Predecir usando la tendencia media solo es un buen método para predecir a un año vista.</p>
<p><br />
<br />
</p>
</div>
</div>
</div>
<div id="métodos-de-alisado-exponencial" class="section level1" number="5">
<h1 number="5"><span class="header-section-number">5</span> Métodos de Alisado Exponencial</h1>
<div id="introducción-1" class="section level2" number="5.1">
<h2 number="5.1"><span class="header-section-number">5.1</span> Introducción</h2>
<p>Los métodos de alisado exponencial aparecen en los años 50 de la mano de Brown, Holt y Winters y han sido la raíz de uno de los métodos de predicción más sencillos y eficaces. La idea básica es predecir usando una media ponderada de los datos pasados, donde los más recientes tienen un peso mayor y este decae exponencialmente conforme usamos observaciones más antiguas.</p>
<p>El alisado exponencial es una familia de métodos de ajuste y previsión que ofrece muy buenos resultados para predicciones a corto plazo o para predecir series con pocos datos o <em>sencillas</em> (sin mucho <em>ruido</em>).</p>
<p>Suponen un grado de modelización mayor que los métodos sencillos vistos previamente, pero sin alcanzar la complejidad de otras metodologías (modelos ARIMA).</p>
<p>En origen, son métodos descriptivos con el único objetivo de producir <strong>predicciones puntuales</strong>. Sin embargo, su enfoque como modelos de <em>espacio de estados</em> posibilita un marco teórico para obtener <strong>intervalos de predicción</strong>.</p>
<p><br />
</p>
</div>
<div id="componentes-de-una-serie-en-el-contexto-del-alisado-exponencial" class="section level2" number="5.2">
<h2 number="5.2"><span class="header-section-number">5.2</span> Componentes de una serie en el contexto del alisado exponencial</h2>
<p>Para obtener una predicción en el periodo <span class="math inline">\(t+1\)</span> con datos hasta el periodo <span class="math inline">\(t\)</span> necesitamos tres componentes:</p>
<ul>
<li>La estimación del nivel de la serie en el periodo <span class="math inline">\(t\)</span>: <span class="math inline">\(l_t\)</span></li>
<li>La estimación de la pendiente de la serie en el periodo <span class="math inline">\(t\)</span>: <span class="math inline">\(b_t\)</span></li>
<li>La estimación de la estacionalidad en el mes correspondiente al periodo <span class="math inline">\(t+1\)</span> con datos hasta <span class="math inline">\(t\)</span>: <span class="math inline">\(s_{t + 1 - m}\)</span> (recuerda, <span class="math inline">\(m\)</span> es el orden estacional</li>
</ul>
<p>A partir de estas componentes, obtenidas en el periodo <span class="math inline">\(t\)</span> y para un esquema aditivo, se tendría que la predicción en el periodo <span class="math inline">\(t+1\)</span> es: <span class="math display">\[\widehat{y}_{t+1} = l_t+b_t+s_{t+1-m}.\]</span> En general, las componentes pueden <strong>existir o no</strong> y se pueden combinar entre ellas <strong>aditiva o multiplicativamente</strong>. Veamos algunos casos:</p>
<ul>
<li>Existen todas y son multiplicativas: <span class="math display">\[\widehat{y}_{t+1}=l_t \cdot b_t \cdot s_{t + 1 - m}\]</span></li>
<li>Existen todas, nivel y pendiente aditivas, y estacionalidad multiplicativa: <span class="math display">\[\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}\]</span></li>
<li>No hay pendiente y la estacionalidad es aditiva: <span class="math display">\[\widehat{y}_{t+1}=l_t+s_{t + 1 - m}\]</span></li>
</ul>
<p>¿Como obtenemos los valores de <span class="math inline">\(l_t\)</span>, <span class="math inline">\(b_t\)</span> y <span class="math inline">\(s_{t + 1 - m}\)</span>? Mediante <strong>expresiones recursivas</strong>, donde cada componente se calcula a partir de los valores hasta <span class="math inline">\(t\)</span> de la serie y de las componentes: <span class="math display">\[
\begin{aligned}
l_t&amp; = f_l(y_t,y_{t-1}\ldots, l_{t-1},l_{t-2}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
b_t&amp; = f_b(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
s_t&amp; = f_s(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t},b_{t-1}\ldots,s_{t-1},s_{t-2}\ldots)
\end{aligned}
\]</span> Por ejemplo, el <em>método ingenuo I</em> se puede interpretar dentro de este contexto como un método de alisado donde <span class="math inline">\(l_t = y_t\)</span> y no hay ni pendiente ni estacionalidad. Por tanto, <span class="math inline">\(\widehat{y}_{T+1} = l_{T} = y_{T}\)</span>.</p>
<p>De la misma forma, el <em>método ingenuo II</em> se puede interpretar como un método de alisado donde <span class="math inline">\(l_t = y_t\)</span>, <span class="math inline">\(b_t = y_t - y_{t-1}\)</span> y no hay estacionalidad. Entonces, <span class="math inline">\(\widehat{y}_{T+1}=l_T + b_T = y_T + (y_T - y_{T-1})\)</span>.</p>
<p>En las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista (<span class="math inline">\(\widehat{y}_{t+1}\)</span>). Si el objetivo es estimar una previsión <span class="math inline">\(h\)</span> periodos hacia delante desde el periodo <span class="math inline">\(t\)</span>, <span class="math inline">\(\widehat{y}_{t+h}\)</span>, hay que realizar algunas modificaciones. Por ejemplo, para el caso aditivo se tendría que <span class="math display">\[\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}\]</span> donde <span class="math inline">\(k = \lfloor (h-1)/m\rfloor\)</span>.</p>
<p>El concepto de componentes aquí visto no coincide con el definido en el Tema 1. Sin embargo, podemos asimilar la tendencia de una serie como la suma (multiplicación) del nivel y la pendiente <span class="math inline">\(T_{t+1} = l_t + b_t\)</span> (<span class="math inline">\(T_{t+1} = l_t \cdot b_t\)</span>) y de esta forma ambas definiciones de componentes de una serie se hacen compatibles.</p>
<p><br />
<br />
</p>
</div>
<div id="casos-posibles" class="section level2" number="5.3">
<h2 number="5.3"><span class="header-section-number">5.3</span> Casos posibles</h2>
<p>Todas las series tiene nivel, pero dependiendo del tipo de pendiente y estacionalidad hay 15 casos posibles, mostrados en la tabla siguiente.</p>
<table>
<thead>
<tr class="header">
<th align="left">Tendencia</th>
<th align="center"></th>
<th align="center">Estacionalidad</th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="center">Ninguna (N)</td>
<td align="center">Aditiva (A)</td>
<td align="center">Multiplicativa (M)</td>
</tr>
<tr class="even">
<td align="left">Ninguna (N)</td>
<td align="center"><strong>N, N</strong></td>
<td align="center">N, A</td>
<td align="center">N, M</td>
</tr>
<tr class="odd">
<td align="left">Aditiva (A)</td>
<td align="center"><strong>A, N</strong></td>
<td align="center"><strong>A, A</strong></td>
<td align="center"><strong>A, M</strong></td>
</tr>
<tr class="even">
<td align="left">Aditiva Amortiguada (Ad)</td>
<td align="center"><strong>Ad, N</strong></td>
<td align="center">Ad, A</td>
<td align="center">Ad, M</td>
</tr>
<tr class="odd">
<td align="left">Multiplicativa (M)</td>
<td align="center">M, N</td>
<td align="center">M, A</td>
<td align="center">M, M</td>
</tr>
<tr class="even">
<td align="left">Multiplicativa Amortiguada (Md)</td>
<td align="center">Md, N</td>
<td align="center">Md, A</td>
<td align="center">Md, M</td>
</tr>
</tbody>
</table>
<p>Cada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.</p>
<p>Si se añade que el error puede ser aditivo o multiplicativo, da 30 posibilidades. <strong>El tipo de error (aditivo o multiplicativo) no afecta ni a la estimación ni a la previsión puntual, sólo es relevante en el cálculo del intervalo de confianza de las predicciones.</strong></p>
<p>Los modelos más usuales son:</p>
<ul>
<li>(N, N): Alisado exponencial simple</li>
<li>(A, N): Alisado de Holt</li>
<li>(Ad, N): Alisado con tendencia amortiguada (d de <em>damped</em>)</li>
<li>(A, A): Alisado de Holt-Winters aditivo</li>
<li>(A, M): Alisado de Holt-Winters multiplicativo</li>
</ul>
<p>Acude al artículo de <a href="http://www.jstatsoft.org/v27/i03/paper">Rob J. Hyndman y Yeasmin Khandakar (2008)</a> para saber más de cada modelo, o al libro <em>Forecasting with Exponential Smoothing: the State Space Approach</em> (2008) de Hyndman y otros autores.</p>
<p><br />
</p>
</div>
<div id="alisado-exponencial-simple-n-n" class="section level2" number="5.4">
<h2 number="5.4"><span class="header-section-number">5.4</span> Alisado exponencial simple (N, N)</h2>
<div id="definición" class="section level3 unnumbered">
<h3 class="unnumbered">Definición</h3>
<p>El alisado exponencial simple es adecuado para una serie estacionaria y sin estacionalidad. Es decir, una serie que se mueve alrededor de un nivel constante.</p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> es <span class="math display">\[\hat{y}_{t+1} = \alpha y_t + \alpha (1-\alpha) y_{t-1} + \alpha (1-\alpha)^2 y_{t-2} + \alpha (1-\alpha)^3 y_{t-3} + \ldots =  \alpha y_t + (1-\alpha)\hat{y}_{t},\]</span> donde <span class="math inline">\(0 \leq \alpha \leq 1\)</span> es el parámetro de suavizado. La primera <strong>predicción extra-muestral</strong> queda <span class="math display">\[\hat{y}_{T+1}=\alpha y_T + (1-\alpha)\hat{y}_{T}\]</span> y para las restantes <span class="math display">\[\hat{y}_{T+h} = \hat{y}_{T+1}.\]</span></p>
</div>
<div id="formulas-interactivas-de-sus-componentes" class="section level3 unnumbered">
<h3 class="unnumbered">Formulas interactivas de sus componentes</h3>
<p>En el alisado exponencial simple solo hay una componente, el nivel <span class="math inline">\(l_t\)</span>.</p>
<ul>
<li>La <strong>ecuación recursiva</strong> de suavizado es <span class="math inline">\(l_t=\alpha y_t + (1-\alpha)l_{t-1}\)</span></li>
<li>La ecuación de <strong>predicción intra-muestral</strong> es <span class="math inline">\(\hat{y}_{t+1} = l_t\)</span></li>
<li>La ecuación de <strong>predicción extra-muestral</strong> es <span class="math inline">\(\hat{y}_{T+h} = \hat{y}_{T+1} = l_T\)</span></li>
</ul>
<p>Dos estimaciones razonables de <span class="math inline">\(l_t\)</span>, el nivel de la serie en el periodo <span class="math inline">\(t\)</span>, son el valor observado para la serie en ese periodo <span class="math inline">\(y_t\)</span> y el nivel del periodo previo <span class="math inline">\(l_{t-1}\)</span>. La estimación final de <span class="math inline">\(l_t\)</span> es una media ponderada de ambas y esta estimación final es la previsión de la serie para el periodo siguiente.</p>
</div>
<div id="estimación-de-los-parámetros-del-modelo" class="section level3 unnumbered">
<h3 class="unnumbered">Estimación de los parámetros del modelo</h3>
<p>Dado el proceso iterativo para el cálculo de <span class="math inline">\(l_t\)</span> se necesita un <strong>valor inicial</strong> de arranque <span class="math inline">\(l_0\)</span>. Cada programa estadístico usa su propio método para obtener <span class="math inline">\(l_0\)</span>.</p>
<p>Respecto de <span class="math inline">\(\alpha\)</span>, usualmente se estima el valor <strong>optimo</strong> según un criterio de precisión de la predicción. El parámetro <span class="math inline">\(\alpha\)</span> <strong>se puede interpretar</strong> como:</p>
<ul>
<li>Si <span class="math inline">\(\alpha = 1\)</span> se tiene el <em>método ingenuo I</em> (<span class="math inline">\(\hat{y}_{t+1}=y_t\)</span>), óptimo cuando el nivel de la serie varía constantemente en el tiempo.</li>
<li>Si <span class="math inline">\(\alpha = 0\)</span> se tiene <span class="math inline">\(\hat{y}_{t} =l_0\)</span>, óptimo cuando el nivel permanece constante en el tiempo.</li>
</ul>
</div>
<div id="ejemplo" class="section level3 unnumbered">
<h3 class="unnumbered">Ejemplo</h3>
<p>Vamos a usar el método de alisado exponencial simple para predecir la serie Libros. Usaremos para ello la función <code>ses</code> (<em>simple exponential smoothing</em>) con una previsión a 5 años vista (<code>h = 5</code>). Esta función estima los valores de <span class="math inline">\(l_0\)</span> y <span class="math inline">\(\alpha\)</span> que maximizan la función de verosimilitud, pero se pueden elegir otros criterios con el parámetro <code>opt.crit</code>.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>librosf <span class="ot">&lt;-</span> <span class="fu">ses</span>(libros, <span class="at">h =</span> <span class="dv">5</span>, <span class="at">level =</span> <span class="dv">95</span>)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosf)</span></code></pre></div>
<pre><code>
Forecast method: Simple exponential smoothing

Model Information:
Simple exponential smoothing 

Call:
 ses(y = libros, h = 5, level = 95) 

  Smoothing parameters:
    alpha = 0.9756 

  Initial states:
    l = 40846.9233 

  sigma:  6135.033

     AIC     AICc      BIC 
542.1615 543.2524 545.9358 

Error measures:
                   ME     RMSE      MAE      MPE     MAPE     MASE        ACF1
Training set 839.0525 5894.349 4452.239 1.240605 7.032466 0.962355 -0.01829562

Forecasts:
     Point Forecast    Lo 95    Hi 95
2019       62131.07 50106.63 74155.52
2020       62131.07 45331.71 78930.44
2021       62131.07 41640.83 82621.32
2022       62131.07 38520.03 85742.12
2023       62131.07 35766.08 88496.07</code></pre>
<p>Veamos la salida en detalle:</p>
<ul>
<li>El valor de <span class="math inline">\(\alpha\)</span> que optimiza el criterio usado para medir la calidad del ajuste es <span class="math inline">\(\alpha =\)</span> 0.98, un valor muy cercano a 1. Esto es un indicativo de que: i) la serie Libros cambia de nivel de forma constante, un rasgo en los procesos puramente estocásticos como el paseo aleatorio; ii) y el método de alisado exponencial simple se aproxima al método Ingenuo I.</li>
<li>El valor de arranque <span class="math inline">\(l_0\)</span> óptimo es 40846.92.</li>
<li><em>sigma</em> es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular sigma en lugar de dividir por <span class="math inline">\(T\)</span> se divide por <span class="math inline">\(T\)</span> menos el número de parámetros estimados (en este caso 3, <span class="math inline">\(l_0\)</span>, <span class="math inline">\(\alpha\)</span> y <em>sigma</em>).</li>
<li>La calidad de ajuste es razonable, como evidencia el error porcentual medio del 7%.</li>
<li>Las predicciones son las mismas para los 5 años, como cabe esperar (recuerda que <span class="math inline">\(\hat{y}_{T+h} = \hat{y}_{T+1}\)</span>).</li>
</ul>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(librosf<span class="sc">$</span>model<span class="sc">$</span>states, <span class="at">n =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>Time Series:
Start = 2015 
End = 2018 
Frequency = 1 
            l
[1,] 60887.22
[2,] 59599.15
[3,] 60170.73
[4,] 62131.07</code></pre>
<p>En el objeto <code>librosf</code> la matriz <code>librosf$model$states</code> guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluidos el valor de arranque, así que es una matriz con <span class="math inline">\(T+1\)</span> filas. Puedes ver el valor de <span class="math inline">\(l_{2018}\)</span> en su última fila, que vale 62131.07. Así, la predicción para <span class="math inline">\(2019\)</span> es <span class="math inline">\(\widehat{y}_{2019}=l_{2018}=\)</span> 62131.07. Igualmente <span class="math inline">\(\widehat{y}_{2020}=l_{2018}=\)</span> 62131.07. Es decir, todas las previsiones son iguales a <span class="math inline">\(l_{2018}\)</span>.</p>
<p>La figura 6 muestra la serie Libros y las previsiones extra-muestrales, que son constantes, y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosf,</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 6. Libros y predicción con alisado simple&quot;</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-15-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
</p>
</div>
</div>
<div id="alisado-exponencial-de-holt-a-n" class="section level2" number="5.5">
<h2 number="5.5"><span class="header-section-number">5.5</span> Alisado exponencial de Holt (A, N)</h2>
<p>El alisado exponencial de Holt es adecuado para una serie no estacionaria y sin estacionalidad.</p>
<div id="formulas-interactivas-de-sus-componentes-1" class="section level3 unnumbered">
<h3 class="unnumbered">Formulas interactivas de sus componentes</h3>
<p>Las <strong>ecuaciones recursivas</strong> son <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} 
\end{aligned}
\]</span> La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\hat{y}_{t+1} = l_t + b_t,\]</span> de forma que la ecuación de <strong>predicción extra-muestral</strong> es <span class="math display">\[\hat{y}_{T+h}=l_T + h b_T.\]</span></p>
<p>Dos estimaciones razonables del nivel de la serie en el periodo <span class="math inline">\(t\)</span> son el valor observado para la serie en ese periodo <span class="math inline">\(y_t\)</span>, y una estimación del nivel del periodo <span class="math inline">\(t\)</span> realizada desde el periodo <span class="math inline">\(t-1\)</span>: <span class="math inline">\(l_{t-1} + b_{t-1}\)</span>. Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo <span class="math inline">\(t\)</span> son el último cambio de nivel observado <span class="math inline">\(l_t-l_{t-1}\)</span>, y el valor de la pendiente en el periodo previo, <span class="math inline">\(b_{t-1}\)</span>. En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por <span class="math inline">\(0 \leq \alpha, \: \beta \leq 1\)</span>.</p>
</div>
<div id="estimación-de-los-parámetros-del-modelo-1" class="section level3 unnumbered">
<h3 class="unnumbered">Estimación de los parámetros del modelo</h3>
<p>Para aplicar este método es necesario estimar unos valores iniciales <span class="math inline">\(l_0\)</span> y <span class="math inline">\(b_0\)</span> de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\beta\)</span>. Los <strong>valores óptimos</strong> de estos cuatro parámetros se obtienen optimizando una medida de precisión de las predicciones.</p>
<p>La interpretación del parámetro <span class="math inline">\(\alpha\)</span> es similar al caso del alisado exponencial simple.</p>
<p><strong>Interpretación del parámetro <span class="math inline">\(\beta\)</span></strong>:</p>
<ul>
<li>Si <span class="math inline">\(\beta = 1\)</span>, <span class="math inline">\(b_t = l_t - l_{t-1}\)</span>, la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).</li>
<li>Si <span class="math inline">\(\beta = 0\)</span>, <span class="math inline">\(b_t = b_{t-1}= \ldots = b_0\)</span>, la pendiente se mantiene constante en el tiempo.</li>
</ul>
<p>El <em>método ingenuo II</em> es un caso concreto de Alisado de Holt. Si hacemos <span class="math inline">\(\alpha=\beta = 1\)</span>, queda <span class="math inline">\(l_t=y_t\)</span> y <span class="math inline">\(b_t=y_t-y_{t-1}\)</span>, por tanto <span class="math display">\[\hat{y}_{T+h}=l_T + h \cdot b_T = y_T + h(y_T - y_{T-1}).\]</span></p>
</div>
<div id="ejemplo-1" class="section level3 unnumbered">
<h3 class="unnumbered">Ejemplo</h3>
<p>Vamos a usar el método de alisado de Holt para predecir de nuevo la serie Libros. Usaremos para ello la función <code>holt</code> con una previsión a 5 años vista (<code>h = 5</code>).</p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>librosf <span class="ot">&lt;-</span> <span class="fu">holt</span>(libros, <span class="at">h =</span> <span class="dv">5</span>, <span class="at">level =</span> <span class="dv">95</span>)</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosf)</span></code></pre></div>
<pre><code>
Forecast method: Holt&#39;s method

Model Information:
Holt&#39;s method 

Call:
 holt(y = libros, h = 5, level = 95) 

  Smoothing parameters:
    alpha = 0.9513 
    beta  = 0.0001 

  Initial states:
    l = 41061.2751 
    b = 808.0212 

  sigma:  6342.639

     AIC     AICc      BIC 
545.6297 548.6297 551.9202 

Error measures:
                   ME    RMSE      MAE        MPE     MAPE      MASE       ACF1
Training set 1.059887 5834.38 4235.524 -0.1683705 6.717033 0.9155118 0.00362974

Forecasts:
     Point Forecast    Lo 95    Hi 95
2019       62930.86 50499.52 75362.21
2020       63738.89 46580.48 80897.29
2021       64546.91 43706.74 85387.08
2022       65354.93 41391.54 89318.33
2023       66162.96 39438.34 92887.57</code></pre>
<p>Los valores óptimos de los cuatro parámetros son <span class="math inline">\(\alpha=\)</span> 0.95, <span class="math inline">\(\beta=\)</span> 0, <span class="math inline">\(l_0 =\)</span> 41061.28 y <span class="math inline">\(b_0 =\)</span> 808.02. Observa que <span class="math inline">\(\alpha\)</span> es prácticamente 1 y que <span class="math inline">\(\beta\)</span> es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extra-muestral, obtenemos <span class="math inline">\(y_{T+h}=y_T + hb_0\)</span>: la predicción es el último valor observado más la primera pendiente estimada.</p>
<p>La calidad de las predicciones es razonable, con un error porcentual medio del 6.7%, y se ha mejorado respecto del alisado exponencial simple.</p>
<div class="sourceCode" id="cb29"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(librosf<span class="sc">$</span>model<span class="sc">$</span>states, <span class="at">n =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>Time Series:
Start = 2015 
End = 2018 
Frequency = 1 
            l        b
2015 60809.31 808.1407
2016 59666.92 807.9356
2017 60199.13 807.9066
2018 62122.84 808.0240</code></pre>
<p>De nuevo, en el objeto <code>librosf</code> la matriz <code>librosf$model$states</code> guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de <span class="math inline">\(l_{2018}\)</span> y <span class="math inline">\(b_{2018}\)</span> en su última fila, que valen respectivamente 62122.84, 808.02. Así, la predicción para <span class="math inline">\(2019\)</span> es <span class="math inline">\(\widehat{y}_{2019}=l_{2018} + b_{2018}=\)</span> 62122.84 <span class="math inline">\(+\)</span> 808.02 <span class="math inline">\(=\)</span> 62930.86. Igualmente <span class="math inline">\(\widehat{y}_{2020}=l_{2018} + 2\cdot b_{2018}=\)</span> 63738.89. Es decir, el incremento entre previsiones es contante e igual a <span class="math inline">\(b_{2018}\)</span> que, por ser <span class="math inline">\(\beta\)</span> prácticamente nulo, coincide con <span class="math inline">\(b_0\)</span>.</p>
<p>La figura 7 muestra la serie Libros y las previsiones extra-muestrales que muestran una ligera tendencia creciente.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosf,</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 7. Libros y predicción con alisado de Holt&quot;</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-18-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
</p>
</div>
</div>
<div id="alisado-exponencial-con-pendiente-amortiguada-ad-n" class="section level2" number="5.6">
<h2 number="5.6"><span class="header-section-number">5.6</span> Alisado exponencial con pendiente amortiguada (Ad, N)</h2>
<p>Las previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por Gardner y McKenzie en 1985, es introducir un nuevo parámetro <span class="math inline">\(0 \leq \phi \leq 1\)</span> que <em>amortigua</em> la tendencia hasta hacerla plana en el largo plazo.</p>
<div id="formulas-interactivas-de-sus-componentes-2" class="section level3 unnumbered">
<h3 class="unnumbered">Formulas interactivas de sus componentes</h3>
<p>Las <strong>ecuaciones recursivas</strong> son <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)\phi b_{t-1} 
\end{aligned}
\]</span> La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\hat{y}_{t+1} = l_t + \phi b_t,\]</span> de forma que la ecuación de <strong>predicción extra-muestral</strong> es <span class="math display">\[\hat{y}_{T+h}=l_T + (\phi + \phi^2 + \ldots + \phi^h) b_T.\]</span></p>
<p>Si <span class="math inline">\(\phi = 1\)</span> se tiene el alisado de Holt y si <span class="math inline">\(\phi = 0\)</span> se tiene el alisado simple. Para valores entre <span class="math inline">\(0\)</span> y <span class="math inline">\(1\)</span> en el corto plazo las predicciones tienen pendiente y en el largo plazo se hacen constantes e iguales a <span class="math inline">\(l_T + \phi b_T/(1 - \phi)\)</span>.</p>
</div>
<div id="ejemplo-2" class="section level3 unnumbered">
<h3 class="unnumbered">Ejemplo</h3>
<p>Vamos a usar el método de alisado con amortiguamiento para predecir, una vez más, la serie Libros añadiendo a la función <code>holt</code> el argumento <code>damped = TRUE</code>. Por razones prácticas el rango de búsqueda de <span class="math inline">\(\phi\)</span> queda en el intervalo <span class="math inline">\([0.8, 0.98]\)</span>. En este caso, para ver el efecto del <em>amortiguamiento</em> vamos a fijar el valor de <span class="math inline">\(\phi\)</span> a <span class="math inline">\(0.9\)</span> y vamos a pedir un horizonte temporal más largo.</p>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>librosfd <span class="ot">&lt;-</span> <span class="fu">holt</span>(libros, <span class="at">damped =</span> <span class="cn">TRUE</span>, <span class="at">h =</span> <span class="dv">15</span>, <span class="at">phi =</span> <span class="fl">0.9</span>)</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosfd)</span></code></pre></div>
<pre><code>
Forecast method: Damped Holt&#39;s method

Model Information:
Damped Holt&#39;s method 

Call:
 holt(y = libros, h = 15, damped = TRUE, phi = 0.9) 

  Smoothing parameters:
    alpha = 0.8885 
    beta  = 0.0001 
    phi   = 0.9 

  Initial states:
    l = 39515.4609 
    b = 4345.5669 

  sigma:  6337.754

     AIC     AICc      BIC 
544.3801 547.3801 550.6706 

Error measures:
                    ME     RMSE      MAE       MPE     MAPE      MASE
Training set -610.6056 5695.848 3943.135 -1.422026 6.229522 0.8523118
                   ACF1
Training set 0.00189887

Forecasts:
     Point Forecast    Lo 80    Hi 80    Lo 95     Hi 95
2019       62238.63 54116.47 70360.79 49816.86  74660.40
2020       62465.35 51599.92 73330.77 45848.12  79082.58
2021       62669.39 49625.05 75713.74 42719.79  82619.00
2022       62853.04 47944.62 77761.45 40052.58  85653.49
2023       63018.31 46454.06 79582.57 37685.47  88351.16
2024       63167.06 45097.88 81236.24 35532.64  90801.49
2025       63300.94 43842.72 82759.15 33542.17  93059.71
2026       63421.42 42666.80 84176.05 31679.96  95162.89
2027       63529.86 41555.06 85504.67 29922.30  97137.43
2028       63627.46 40496.65 86758.26 28251.94  99002.97
2029       63715.29 39483.49 87947.10 26655.95 100774.64
2030       63794.34 38509.37 89079.32 25124.31 102464.38
2031       63865.49 37569.42 90161.56 23649.12 104081.86
2032       63929.52 36659.77 91199.28 22224.03 105635.01
2033       63987.15 35777.26 92197.05 20843.84 107130.47</code></pre>
<p>La figura 8 muestra la serie Libros, su estimación (intra-muestral) y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se <em>amortigua</em> en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años.</p>
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosfd,</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 8. Libros y predicción con alisado exponencial con amortiguamiento&quot;</span>,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">PI =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-20-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
</p>
</div>
</div>
<div id="alisado-de-holt-winters-aditivo-a-a-y-multiplicativo-a-m" class="section level2" number="5.7">
<h2 number="5.7"><span class="header-section-number">5.7</span> Alisado de Holt-Winters aditivo (A, A) y multiplicativo (A, M)</h2>
<p>El método de alisado exponencial de Holt-Winters es adecuado para una serie con tendencia y con estacionalidad. Existen dos versiones según que el esquema sea aditivo o multiplicativo.</p>
<div id="alisado-de-holt-winters-aditivo-a-a" class="section level3 unnumbered">
<h3 class="unnumbered">Alisado de Holt-Winters aditivo (A, A)</h3>
<p>Las <strong>ecuaciones recursivas</strong> de actualización son: <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha (y_t - s_{t-m} ) + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t &amp; =\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \gamma)s_{t-m}
\end{aligned}
\]</span> con <span class="math inline">\(0 \leq \alpha, \beta, \gamma \leq 1\)</span>.</p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\hat{y}_{t+1}  = l_t + b_t + s_{t+1-m},\]</span> de forma que la ecuación de <strong>predicción extra-muestral es</strong>: <span class="math display">\[\hat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},\]</span> con <span class="math inline">\(k = \lfloor(h-1)/m\rfloor\)</span>.</p>
</div>
<div id="alisado-de-holt-winters-multiplicativo-a-m" class="section level3 unnumbered">
<h3 class="unnumbered">Alisado de Holt-Winters multiplicativo (A, M)</h3>
<p>Las <strong>ecuaciones recursivas</strong> de actualización son: <span class="math display">\[
\begin{aligned}
l_t &amp; =\alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t &amp; =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t &amp; =\gamma \frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \gamma)s_{t-m}
\end{aligned}
\]</span></p>
<p>La ecuación de la <strong>predicción intra-muestral</strong> a un periodo vista es <span class="math display">\[\hat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},\]</span> de forma que la ecuación de <strong>predicción extra-muestral es</strong>: <span class="math display">\[\hat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.\]</span></p>
</div>
<div id="ejemplo-3" class="section level3 unnumbered">
<h3 class="unnumbered">Ejemplo</h3>
<p>Vamos a usar el método de Holt-Winters para predecir la serie Nacimientos, que presentaba un esquema multiplicativo. Para ello usaremos la función <code>hw</code> con el argumento <code>seasonal = "multiplicative"</code> (que sería <code>seasonal = "additive"</code> en caso de esquema aditivo). Vamos a considerar la serie Nacimientos desde enero de 2000 y pedir una previsión a dos años vista.</p>
<div class="sourceCode" id="cb35"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>nacimientosb <span class="ot">&lt;-</span> <span class="fu">window</span>(nacimientos, <span class="at">start =</span> <span class="dv">2000</span>)</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a>nacimientosbf <span class="ot">&lt;-</span> <span class="fu">hw</span>(nacimientosb, <span class="at">seasonal =</span> <span class="st">&quot;mult&quot;</span>, <span class="at">h =</span> <span class="dv">24</span>)</span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nacimientosbf)</span></code></pre></div>
<pre><code>
Forecast method: Holt-Winters&#39; multiplicative method

Model Information:
Holt-Winters&#39; multiplicative method 

Call:
 hw(y = nacimientosb, h = 24, seasonal = &quot;mult&quot;) 

  Smoothing parameters:
    alpha = 0.3892 
    beta  = 0.0148 
    gamma = 0.0425 

  Initial states:
    l = 33009.2785 
    b = 145.6544 
    s = 1.0025 0.9974 1.0527 1.0436 1.0281 1.0366
           0.9722 1.0146 0.9623 0.9901 0.9043 0.9958

  sigma:  0.023

     AIC     AICc      BIC 
4329.668 4332.583 4387.967 

Error measures:
                    ME     RMSE     MAE        MPE    MAPE      MASE      ACF1
Training set -74.07627 832.4718 662.566 -0.2262176 1.79118 0.4718897 0.0605442

Forecasts:
         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
Jan 2019       30514.76 29617.09 31412.44 29141.88 31887.64
Feb 2019       27577.35 26701.93 28452.78 26238.50 28916.20
Mar 2019       30121.05 29094.43 31147.67 28550.97 31691.14
Apr 2019       29081.10 28021.40 30140.80 27460.42 30701.78
May 2019       30487.72 29304.26 31671.17 28677.78 32297.66
Jun 2019       29290.89 28083.51 30498.26 27444.37 31137.40
Jul 2019       31030.75 29676.27 32385.24 28959.25 33102.26
Aug 2019       30723.23 29306.62 32139.85 28556.71 32889.76
Sep 2019       30978.00 29472.49 32483.50 28675.53 33280.47
Oct 2019       31294.54 29694.70 32894.37 28847.80 33741.28
Nov 2019       29527.19 27942.21 31112.16 27103.17 31951.20
Dec 2019       29549.08 27886.35 31211.81 27006.15 32092.00
Jan 2020       29307.40 27570.10 31044.70 26650.43 31964.37
Feb 2020       26482.60 24842.63 28122.56 23974.48 28990.71
Mar 2020       28921.35 27052.66 30790.03 26063.44 31779.25
Apr 2020       27918.96 26038.95 29798.96 25043.73 30794.18
May 2020       29265.29 27213.70 31316.88 26127.65 32402.92
Jun 2020       28112.50 26062.87 30162.14 24977.86 31247.15
Jul 2020       29778.17 27522.36 32033.99 26328.20 33228.14
Aug 2020       29478.88 27160.65 31797.11 25933.45 33024.31
Sep 2020       29719.07 27294.94 32143.21 26011.68 33426.47
Oct 2020       30018.43 27480.73 32556.12 26137.36 33899.49
Nov 2020       28319.03 25839.72 30798.35 24527.25 32110.82
Dec 2020       28335.89 25768.57 30903.21 24409.51 32262.27</code></pre>
<p>Los valores óptimos de los parámetros son <span class="math inline">\(\alpha=\)</span> 0.39, <span class="math inline">\(\beta=\)</span> 0.01 y <span class="math inline">\(\gamma=\)</span> 0.04. Los valores tan bajos para <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> indican que ambas, la pendiente y la estacionalidad, modifican su valor muy lentamente. Es decir, hay pendiente y hay efecto estacional, pero permanecen constantes en el tiempo.</p>
<p>La calidad de las predicciones es notable, con un error porcentual medio del 1.8%. Recuerda que con el método ingenuo con estacionalidad el error era del 3.6%.</p>
<p>Los últimos valores de las componentes son</p>
<div class="sourceCode" id="cb37"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">nrow</span>(nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT,]</span></code></pre></div>
<pre><code>        l         b        s1        s2        s3        s4        s5        s6 
30722.451  -100.998     1.001     0.997     1.053     1.039     1.027     1.034 
       s7        s8        s9       s10       s11       s12 
    0.973     1.009     0.959     0.990     0.904     0.997 </code></pre>
<p>Como el último dato de la serie es diciembre de 2018, los valores del nivel <span class="math inline">\(l\)</span> y la pendiente <span class="math inline">\(b\)</span> mostrados corresponden a ese periodo. Sin embargo, la componente estacional tiene un orden muy peculiar: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, s3 de octubre, hasta s11 que sería febrero y s12 que es enero. Podemos reproducir las predicciones para los primeros 12 meses de enero a diciembre con (ojo, el etiquetado de la salida no es correcto):</p>
<div class="sourceCode" id="cb39"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>(nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT, <span class="dv">1</span>] <span class="sc">+</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>)<span class="sc">*</span>nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT, <span class="dv">2</span>]) <span class="sc">*</span> </span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>  nacimientosbf<span class="sc">$</span>model<span class="sc">$</span>states[TT, <span class="dv">14</span><span class="sc">:</span><span class="dv">3</span>]</span></code></pre></div>
<pre><code>     s12      s11      s10       s9       s8       s7       s6       s5 
30514.76 27577.35 30121.05 29081.10 30487.72 29290.89 31030.75 30723.23 
      s4       s3       s2       s1 
30978.00 31294.54 29527.19 29549.08 </code></pre>
<p>La figura 9 muestra la serie Nacimientos y las previsiones extra-muestrales.</p>
<div class="sourceCode" id="cb41"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(nacimientosbf,</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Nacimientos&quot;</span>,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 9. Nacimientos y predicción con alisado de Holt-Winters multiplicativo&quot;</span>,</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">PI =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-25-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="ejemplo-con-transformación-logarítmica" class="section level2" number="5.8">
<h2 number="5.8"><span class="header-section-number">5.8</span> Ejemplo con transformación logarítmica</h2>
<p>Una alternativa a predecir la serie Nacimientos, que tiene esquema multiplicativo, es predecir la transformación logarítmica de la serie, que tendrá un esquema aditivo. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original.</p>
<p>Este proceso se puede realizar de forma sencilla y transparente con cualquiera de las funciones de alisado exponencial que hemos visto a partir de los argumentos <code>lambda</code> y <code>biasadj</code>.</p>
<ul>
<li><code>lambda = 0</code> indica a la función de alisado que se ha de realizar la transformación logarítmica de la serie. Es un parámetro de la transformación Box-Cox que veremos en detalle en el tema 3.</li>
<li><code>biasadj = TRUE</code> es necesario si tras una transformación de la serie original queremos que las predicciones sean insesgadas. Sea <span class="math inline">\(y_t\)</span> la serie original y <span class="math inline">\(z_t=log(y_t)\)</span> su transformación logarítmica. Si obtenemos una predicción <span class="math inline">\(\hat{y}_t\)</span> de la serie original, esta será insesgada <span class="math inline">\(E[\hat{y}_t]=y_t\)</span>. Ahora bien, si obtenemos una predicción <span class="math inline">\(\hat{z}_t\)</span> de la serie transformada, podemos pensar que <span class="math inline">\(e^{\hat{z}_t}\)</span> es una predicción insesgada de la serie original, pero resulta que <span class="math inline">\(E[e^{\hat{z}_t}] \neq y_t\)</span>. Es decir, la exponencial de la predicción de la serie transformada logarítmicamente no es insesgada. Si el argumento <code>biasadj</code> es fijado a FALSE, las predicciones se calcularan de forma directa deshaciendo la transformación y serán sesgadas; si es fijado a TRUE, las predicciones se calcularan por medio de una fórmula alternativa y serán insesgadas. En ambos casos las estimaciones son consistentes, así que para series largas no debería observarse mucha diferencia entre las dos alternativas.</li>
</ul>
<p>Vamos a practicar el uso de estos argumentos con la serie Nacimientos. Como se va a predecir el logaritmo de la serie, se debe indicar a la función <code>hw</code> que use el modelo Holt-Winters aditivo.</p>
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>nacimientosbfl <span class="ot">&lt;-</span> <span class="fu">hw</span>(nacimientosb, </span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>                     <span class="at">seasonal =</span> <span class="st">&quot;addit&quot;</span>, </span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>                     <span class="at">h =</span> <span class="dv">24</span>, </span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>                     <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>                     <span class="at">biasadj =</span> <span class="cn">TRUE</span>)</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nacimientosbfl)</span></code></pre></div>
<pre><code>
Forecast method: Holt-Winters&#39; additive method

Model Information:
Holt-Winters&#39; additive method 

Call:
 hw(y = nacimientosb, h = 24, seasonal = &quot;addit&quot;, lambda = 0,  

 Call:
     biasadj = TRUE) 

  Box-Cox transformation: lambda= 0 

  Smoothing parameters:
    alpha = 0.2611 
    beta  = 0.0478 
    gamma = 0.0001 

  Initial states:
    l = 10.4305 
    b = 0.0097 
    s = 0.0043 -0.0008 0.0526 0.0381 0.0245 0.0318
           -0.0282 0.01 -0.0338 -0.0047 -0.0961 0.0023

  sigma:  0.0246

      AIC      AICc       BIC 
-435.1078 -432.1936 -376.8090 

Error measures:
                    ME     RMSE     MAE        MPE     MAPE     MASE      ACF1
Training set -50.30465 885.6888 713.322 -0.1715636 1.929063 0.508039 0.2646609

Forecasts:
         Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
Jan 2019       30643.42 29685.38 31613.34 29195.06 32144.27
Feb 2019       27694.28 26788.35 28611.96 26325.44 29115.08
Mar 2019       30259.54 29214.19 31319.20 28681.11 31901.31
Apr 2019       29309.36 28231.72 30402.72 27683.51 31004.78
May 2019       30537.11 29335.00 31758.03 28725.20 32432.21
Jun 2019       29309.90 28069.48 30571.20 27442.29 31269.90
Jul 2019       31036.27 29620.72 32477.54 28907.57 33278.76
Aug 2019       30724.51 29212.67 32266.04 28454.02 33126.32
Sep 2019       31060.84 29411.90 32744.77 28588.01 33688.47
Oct 2019       31427.98 29629.37 33267.80 28734.81 34303.48
Nov 2019       29715.86 27885.00 31591.96 26978.83 32653.07
Dec 2019       29785.78 27813.47 31810.58 26842.30 32961.51
Jan 2020       29646.88 27541.13 31812.87 26509.83 33050.47
Feb 2020       26799.16 24761.67 28899.17 23769.40 30105.59
Mar 2020       29288.00 26909.63 31744.51 25758.10 33163.67
Apr 2020       28375.09 25919.20 30917.19 24737.31 32394.33
May 2020       29571.25 26849.15 32395.21 25547.33 34045.98
Jun 2020       28390.55 25616.78 31274.77 24298.78 32971.15
Jul 2020       30071.41 26959.40 33315.04 25490.46 35234.88
Aug 2020       29778.39 26520.45 33182.40 24993.09 35210.21
Sep 2020       30114.00 26637.35 33755.60 25018.83 35939.32
Oct 2020       30480.19 26773.45 34372.72 25060.14 36722.70
Nov 2020       28829.86 25142.93 32711.70 23451.24 35071.41
Dec 2020       28908.35 25026.90 33005.90 23259.27 35514.24</code></pre>
<p>Observa que en este caso la calidad de las predicciones (MAPE = 1.9%) es inferior a la obtenida con la serie sin transformar.</p>
<p>La figura 10 muestra la serie Nacimientos y las previsiones extra-muestrales obtenidas con y sin la transformación logarítmica.</p>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-27-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>La siguiente tabla muestra las predicciones de Nacimientos obtenidas sin transformar la serie, con transformación logarítmica y predicciones insesgadas (<code>biasadj = TRUE</code>), y con transformación logarítmica y predicciones sesgadas (<code>biasadj = FALSE</code>).</p>
<pre><code>         Sin transformar log(Nac) insesgadas log(Nac) sesgadas
Jan 2019        30514.76            30643.42          30634.19
Feb 2019        27577.35            27694.28          27685.14
Mar 2019        30121.05            30259.54          30248.39
Apr 2019        29081.10            29309.36          29297.12
May 2019        30487.72            30537.11          30522.48
Jun 2019        29290.89            29309.90          29293.65
Jul 2019        31030.75            31036.27          31016.26
Aug 2019        30723.23            30724.51          30701.42
Sep 2019        30978.00            31060.84          31033.63
Oct 2019        31294.54            31427.98          31395.92
Nov 2019        29527.19            29715.86          29680.66
Dec 2019        29549.08            29785.78          29744.96</code></pre>
<p>Observa que las predicciones sesgadas son menores que las insesgadas. Esto siempre es así. La diferencia depende fundamentalmente de la varianza del error, <em>sigma</em> al cuadrado en la salida de los métodos de alisado exponencial. Cuanto mayor es la varianza del error, mayores son las diferencias.</p>
<p>Por otro lado, las predicciones obtenidas sin y con la transformación logarítmica no guardan ninguna relación.</p>
<p><strong>Ni la transformación logarítmica ni el uso de predicciones insesgadas aseguran mejores predicciones respecto de otras opciones</strong>, como pueden ser trabajar con predicciones sesgadas o no realizar la transformación logarítmica.</p>
<p><br />
</p>
</div>
<div id="casos-generales-de-alisado-exponencial" class="section level2" number="5.9">
<h2 number="5.9"><span class="header-section-number">5.9</span> Casos generales de alisado exponencial</h2>
<p>En los epígrafes previos hemos visto cinco de los casos expuestos en la taxonomía del epígrafe 4.3, y las funciones de <code>R</code> asociadas. Veamos ahora como estimar cualquiera de los quince modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md) y de la estacionalidad (N, A y M).</p>
<p>Recordemos que al añadir el error, aditivo o multiplicativo, estos quince modelos se convierten en treinta. Sin embargo, el tipo de error no influye en el cálculo de las previsiones, solo influye en el cálculo del intervalo de confianza de estas.</p>
<div id="la-función-ets" class="section level3 unnumbered">
<h3 class="unnumbered">La función <code>ets</code></h3>
<p>Podemos estimar cualquiera de los treinta modelos usando la función <code>ets</code> del paquete <code>forecast</code>. A diferencia de las funciones previas <code>ses</code>, <code>holt</code> y <code>hw</code>, la función <code>ets</code> solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función <code>forecast</code> sobre un modelo estimado con <code>ets</code>. Mira la ayuda para ver una explicación detallada de los argumentos de estas funciones.</p>
<ul>
<li>El tipo de modelo en <code>ets</code> se especifica con el argumento <code>model</code>, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, <code>model = "ANN"</code> indica un modelo con error aditivo, sin tendencia ni estacionalidad, es decir, el alisado exponencial simple; <code>model = "AAN"</code> indica un modelo con error aditivo, pendiente aditiva, pero sin estacionalidad, el alisado exponencial de Holt. El alisado exponencial de Holt-Winters multiplicativo sería <code>model = "AAM"</code>.</li>
<li>Si se desea incluir amortiguamiento, hay que incluir el argumento <code>damped = TRUE</code>.</li>
<li>Por defecto <code>ets</code> no considera modelos con tendencia multiplicativa (últimas dos líneas de la taxonomía del epígrafe 5.3). Debes fijar el parámetro <code>allow.multiplicative.trend=TRUE</code> para contemplar esta opción.</li>
<li>Además, se sigue disponiendo de los argumentos <code>lambda</code> y <code>biasadj</code>.</li>
</ul>
<p><strong>Criterios de optimización</strong></p>
<p>Fijado un modelo, <code>ets</code> estima por defecto sus parámetros maximizando la función de verosimilitud. Esta búsqueda esta restringida a <span class="math inline">\(0 &lt; \beta &lt; \alpha &lt; 1\)</span>, <span class="math inline">\(0 &lt; \gamma &lt; 1 - \alpha\)</span> y <span class="math inline">\(0.8 &lt; \phi &lt; 0.98\)</span>. Es decir, los tres primeros parámetros nunca pueden ser 0 o 1, y en la práctica sus valores límite son 0.0001 y 0.9999.</p>
<p>Puedes cambiar el criterio de optimización con el argumento <code>opt.crit</code>. Por defecto vale “lik”, pero si lo fijas a <code>opt.crit = "mse"</code> se estiman los parámetros que minimizan el error cuadrático medio. Otra opción interesante es <code>opt.crit = "amse"</code> que minimiza la media de los errores cuadráticos medios obtenido sobre las previsiones a <code>nmse</code> periodos vista. En este caso usa el argumento <code>nmse</code> para fijar el valor numérico del horizonte temporal.</p>
<p><strong>Selección de modelos</strong></p>
<p>Lo más habitual es no saber cual es el mejor modelo, entendiendo como tal, el que mejor se ajusta a la serie temporal. De hecho, si lo que buscamos es predecir bien, más que entender la naturaleza del proceso generador de datos, el mejor modelo será el que mejor prediga.</p>
<p>Si en una de las tres letras del código del modelo se indica “Z”, la función <code>ets</code> selecciona de entre los modelos posibles el que mejor se ajusta. Por ejemplo, <code>model = "AAZ"</code> indica un modelo con error y pendiente aditivos y dejaría a <code>ets</code> la búsqueda de la mejor opción para la estacionalidad (nula, aditiva o multiplicativa). Si se especifica <code>model = "ZZZ</code> junto con <code>damped = NULL</code> (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos (excepto aquellos con pendiente multiplicativa). Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar <code>damped = FALSE</code> y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento <code>additive.only = TRUE</code>.</p>
<p>Queda pendiente saber que criterio se usa para seleccionar el modelo cuando se ofrece esta opción. Esto se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son: <span class="math display">\[aic = -2log(L) + 2k\]</span> <span class="math display">\[aicc = aic + \frac{k(k+1)}{T-k-1}\]</span> <span class="math display">\[bic=aic + k(log(T) - 2)\]</span> donde <span class="math inline">\(L\)</span> es la verosimilitud, <span class="math inline">\(T\)</span> el número de datos y <span class="math inline">\(k\)</span> el de parámetros (incluidos los puntos iniciales de arranque y la varianza residual).</p>
<p>Por defecto se usa Akaike corregido para pequeñas muestras, pero el argumento <code>ic</code> permite cambiar de criterio.</p>
</div>
<div id="una-reflexión-sobre-los-métodos-automáticos-de-selección-de-modelos" class="section level3 unnumbered">
<h3 class="unnumbered">Una reflexión sobre los métodos automáticos de selección de modelos</h3>
<p>Con el comando <code>forecast(ets(nacimientos), h = 24)</code> obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?</p>
<p>Parémonos a reflexionar sobre lo que hemos hecho –más bien lo que el algoritmo ha hecho– y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.</p>
<p>Si consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intra-muestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.</p>
<p>Pero no es esto lo que hacemos.</p>
<p>Nada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por <em>mejores</em> quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea que el minimiza nuestro criterio de calidad de las predicciones.</p>
<p>Ahora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.</p>
<p>Alguien dirá que casi seguro entre las predicciones sub-óptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo sub-óptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.</p>
<p>Esta reflexión realizada en el contexto de series temporales y para la función <code>ets</code> es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados.</p>
<p>A pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir tu propio código, seguiremos trabajando con modelos sub-óptimos y obteniendo estimaciones sub-óptimas, pero diciendo que son las mejores.</p>
<p><br />
</p>
</div>
<div id="residuo-aditivo-versus-residuo-multiplicativo" class="section level3 unnumbered">
<h3 class="unnumbered">Residuo aditivo versus residuo multiplicativo</h3>
<p>En los modelos de alisado estimados por la función <code>ets</code> la fórmula para el cálculo del residuo estimado depende de su naturaleza aditiva o multiplicativa.</p>
<p>Si el <strong>residuo es aditivo</strong>, entonces el modelo es <span class="math inline">\(y_t = \hat{y}_t + \hat{\varepsilon}_t\)</span> y el residuo se define de la forma usual <span class="math display">\[\hat{\varepsilon}_t = y_t - \hat{y}_t.\]</span> Ahora bien, si el <strong>residuo es multiplicativo</strong>, entonces el modelo es <span class="math inline">\(y_t = \hat{y}_t \cdot (1 + \hat{\varepsilon}_t)\)</span>, y no <span class="math inline">\(y_t = \hat{y}_t \cdot \hat{\varepsilon}_t\)</span>, como se podría esperar. Por tanto, el residuo multiplicativo se define como <span class="math display">\[\varepsilon_t = (y_t - \hat{y}_t)/\hat{y}_t.\]</span> De esta forma en ambos casos el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco.</p>
<p>La función <code>residual</code> permite extraer de un objeto <code>ets</code> el residuo del modelo. Si el modelo tiene residuo multiplicativo y se desea obtener el residuo aditivo, se debe usar con el argumento <code>type = "response"</code>.</p>
<p><br />
<br />
</p>
</div>
</div>
</div>
<div id="ejemplo-de-aplicación-libros" class="section level1" number="6">
<h1 number="6"><span class="header-section-number">6</span> Ejemplo de aplicación: Libros</h1>
<p><br />
</p>
<div id="identificación-y-estimación-del-mejor-modelo" class="section level2" number="6.1">
<h2 number="6.1"><span class="header-section-number">6.1</span> Identificación y estimación del mejor modelo</h2>
<p>Si estimamos el mejor modelo de alisado exponencial para la serie Libros sin ningún tipo de restricción, nos encontramos:</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>librosEts <span class="ot">&lt;-</span> <span class="fu">ets</span>(libros)</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(librosEts) </span></code></pre></div>
<pre><code>ETS(M,N,N) 

Call:
 ets(y = libros) 

  Smoothing parameters:
    alpha = 0.9999 

  Initial states:
    l = 40449.9278 

  sigma:  0.0919

     AIC     AICc      BIC 
536.4611 537.5520 540.2354 

Training set error measures:
                   ME     RMSE      MAE      MPE    MAPE      MASE       ACF1
Training set 835.8489 5896.169 4460.311 1.251566 7.04867 0.9640998 -0.0393776</code></pre>
<p>El modelo estimado es ETS(M,N,N) o “MNN”, un modelo sin pendiente ni estacionalidad y con error multiplicativo. Es decir, <span class="math inline">\(y_{t+1} = l_t \cdot (1 + \varepsilon_{t+1})\)</span>.</p>
<p>El valor de <span class="math inline">\(\alpha\)</span> técnicamente es 1, indicando que el nivel de la serie varia en el tiempo y que realmente estamos usando para las previsiones el método ingenuo I.</p>
<p>Respecto de la calidad del modelo, el valor de MAPE= <span class="math inline">\(7\)</span>% evidencia que estamos ante un modelo que ajusta razonablemente bien a los datos, y MASE= <span class="math inline">\(0.96\)</span> indica que el modelo de alisado exponencial simple reduce en solo un <span class="math inline">\(4\)</span>% el error del método ingenuo I.</p>
</div>
<div id="predicción" class="section level2" number="6.2">
<h2 number="6.2"><span class="header-section-number">6.2</span> Predicción</h2>
<p>Mediante la función <code>forecast</code> podemos predecir los casos de Libros. Por tratarse de un modelo de alisado exponencial simple, la predicción es constante en el tiempo (véase figura 11).</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a>librosEtsPre <span class="ot">&lt;-</span> <span class="fu">forecast</span>(librosEts, <span class="at">h =</span> <span class="dv">5</span>)</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>librosEtsPre</span></code></pre></div>
<pre><code>     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95
2019        62179.8 54859.93 69499.66 50985.03 73374.56
2020        62179.8 51806.66 72552.93 46315.46 78044.14
2021        62179.8 49448.76 74910.83 42709.36 81650.24
2022        62179.8 47448.33 76911.26 39649.96 84709.63
2023        62179.8 45674.75 78684.84 36937.51 87422.08</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(librosEtsPre,</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Títulos&quot;</span>,</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 11. Libros y predicción a 5 años vista&quot;</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-30-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="análisis-del-error" class="section level2" number="6.3">
<h2 number="6.3"><span class="header-section-number">6.3</span> Análisis del error</h2>
<p>El error de un modelo de alisado <em>contiene</em> la componente de <strong>Intervención</strong> y el propio término de <strong>Error</strong>. Ver numérica o gráficamente el error permite identificar fácilmente la presencia de valores atípicos (intervención).</p>
<p>El modelo de alisado tiene error multiplicativo así que debemos usar el argumento <code>type = "response"</code> para obtener el error aditivo con <code>residuals</code>.</p>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">residuals</span>(librosEts, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>sderror <span class="ot">&lt;-</span> <span class="fu">sd</span>(error)</span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(error, <span class="at">series=</span><span class="st">&quot;Error&quot;</span>,</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Periodo&quot;</span>,</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Error&quot;</span>,</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 12: Error + Intervención&quot;</span>) <span class="sc">+</span></span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span> ,<span class="dv">3</span>)<span class="sc">*</span>sderror, </span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span> <span class="fu">seq</span>(<span class="dv">1993</span>, <span class="dv">2019</span>, <span class="dv">2</span>)) </span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-31-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>La figura 12 muestra que aunque algún error supera las dos desviaciones típicas, ninguno puede ser considerado como claramente atípico.</p>
</div>
<div id="validación-error-extra-muestral" class="section level2" number="6.4">
<h2 number="6.4"><span class="header-section-number">6.4</span> Validación: error extra-muestral</h2>
<p>Vamos a mejorar la estimación de la calidad de las predicciones obteniendo el MAPE para <strong>previsiones extra-muestrales a varios periodos vista</strong>. Para ello vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie Libros.</p>
<p>Recordemos que los resultados dependen tremendamente del punto de corte temporal seleccionado.</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Definimos las observaciones intra- y extra-muestrales</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>librosIntra <span class="ot">&lt;-</span> <span class="fu">subset</span>(libros, <span class="at">end =</span> <span class="fu">length</span>(libros) <span class="sc">-</span> <span class="dv">6</span>)</span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>librosExtra <span class="ot">&lt;-</span> <span class="fu">subset</span>(libros, <span class="at">start =</span> <span class="fu">length</span>(libros) <span class="sc">-</span> <span class="dv">5</span>)</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Estimamos el modelo con todos los datos menos los 6 ultimos</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>librosIntraEts <span class="ot">&lt;-</span> <span class="fu">ets</span>(librosIntra, <span class="at">model =</span> <span class="st">&quot;MNN&quot;</span>)</span>
<span id="cb51-7"><a href="#cb51-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-8"><a href="#cb51-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Predecimos los 7 años que hemos quitado de la serie y </span></span>
<span id="cb51-9"><a href="#cb51-9" aria-hidden="true" tabindex="-1"></a><span class="co"># vemos la calidad del ajuste.</span></span>
<span id="cb51-10"><a href="#cb51-10" aria-hidden="true" tabindex="-1"></a>librosExtraPre <span class="ot">&lt;-</span> <span class="fu">forecast</span>(librosIntraEts, <span class="at">h =</span> <span class="dv">6</span>)</span>
<span id="cb51-11"><a href="#cb51-11" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(librosExtraPre, librosExtra)</span></code></pre></div>
<pre><code>                     ME     RMSE       MAE        MPE      MAPE      MASE
Training set   1462.163  5905.05  4665.937   2.339602  7.216588 0.9533584
Test set     -10434.291 10678.54 10434.291 -17.790750 17.790750 2.1319661
                   ACF1 Theil&#39;s U
Training set -0.1925569        NA
Test set      0.2260149  3.937573</code></pre>
<p>Atendiendo al MAPE se tiene que el error de <strong>previsión a un periodo vista</strong> en el <strong>periodo intra-muestral</strong> de <strong>1993 a 2012</strong> es del 7.2%; mientras que el error de <strong>previsión a largo plazo</strong> en el <strong>periodo extra-muestral</strong> de <strong>2013 a 2018</strong> es del 17.8%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas. En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas.</p>
<p>Un gráfico puede ayudar a entender este proceso de validación. En la figura 13:</p>
<ul>
<li>La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.</li>
<li>La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.</li>
<li>La previsión <em>intra</em>-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.</li>
<li>La línea en rojo es la previsión <em>extra</em>-muestral a largo plazo: <span class="math inline">\(\hat{y}_{T+h}=l_T\)</span>, donde <span class="math inline">\(T=2012\)</span>. Observa que todas las previsiones están por encima del valor real de la serie.</li>
<li>Al lado de cada previsión se ha indicado el error estimado (MAPE).</li>
</ul>
<p>Claramente estos resultados dependen del punto de corte seleccionado.</p>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-34-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p><br />
<br />
</p>
<p><strong>Nota:</strong> La presencia de tendencia, primero creciente y luego decreciente, en la serie Libros puede hacernos pensar que un modelo más adecuado para su ajuste y predicción sería ETS(M,A,N), forzando a que haya pendiente. De hecho, el error de estimación de este modelo es del 6.2%, frente al 7% para el modelo ETS(M,N,N). Sin embargo, el error de previsión extra-muestral a largo plazo para el modelo ETS(M,A,N) es del 31.5%, frente al 17.8% para el modelo ETS(M,N,N). De nuevo, incidir en que mayor calidad de ajuste no implica mayor calidad de predicción; y en que estos resultados dependen del punto de corte seleccionado.</p>
</div>
</div>
<div id="ejemplo-de-aplicación-nacimientos" class="section level1" number="7">
<h1 number="7"><span class="header-section-number">7</span> Ejemplo de aplicación: Nacimientos</h1>
<p>Veamos un segundo ejemplo con la serie Nacimientos (desde el año 2000).</p>
<div id="identificación-y-estimación-del-mejor-modelo-1" class="section level2" number="7.1">
<h2 number="7.1"><span class="header-section-number">7.1</span> Identificación y estimación del mejor modelo</h2>
<p>Si damos total libertad al proceso de selección del mejor modelo, el óptimo tiene tendencia amortiguada con un parámetro <span class="math inline">\(\phi = 0.98\)</span>, su máximo valor permitido. Este resultado aconseja repetir el proceso de selección del modelo restringido a aquellos sin amortiguamiento.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>nacimientosEts <span class="ot">&lt;-</span> <span class="fu">ets</span>(nacimientosb, <span class="at">damped =</span> <span class="cn">FALSE</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(nacimientosEts) </span></code></pre></div>
<pre><code>ETS(M,A,A) 

Call:
 ets(y = nacimientosb, damped = FALSE) 

  Smoothing parameters:
    alpha = 0.453 
    beta  = 0.0129 
    gamma = 0.0001 

  Initial states:
    l = 33060.0131 
    b = 133.8359 
    s = 186.0139 -23.5386 1964.614 1476.782 838.1165 1139.429
           -1049.547 364.3884 -1322.119 -197.631 -3356.247 -20.2609

  sigma:  0.0226

     AIC     AICc      BIC 
4323.210 4326.124 4381.509 

Training set error measures:
                   ME     RMSE      MAE        MPE     MAPE      MASE
Training set -78.9317 819.2494 647.6997 -0.2429001 1.751808 0.4613018
                    ACF1
Training set -0.01764952</code></pre>
<p>El modelo estimado es ETS(M,A,A), es decir, <span class="math inline">\(y_{t+1} = (l_t + b_t + s_{t+1-m}) \cdot (1+ \varepsilon_{t+1})\)</span>.</p>
<p>El bajo valor de <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la figura 14).</p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(nacimientosEts,</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Periodo&quot;</span>,</span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 14. Componentes del modelo óptimo para Nacimientos&quot;</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-36-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Respecto de la calidad del modelo, el MAPE de 1.8% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a 0.46 indica que este modelo reduce en un 54% el error del método ingenuo con estacionalidad, el más sencillo posible, que ya utilizamos en el epígrafe 3 (aunque para la serie nacimientos completa).</p>
<p>Podemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">nrow</span>(nacimientosEts<span class="sc">$</span>states)</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>nacimientosEts<span class="sc">$</span>states[TT,]</span></code></pre></div>
<pre><code>       l        b       s1       s2       s3       s4       s5 
30579.27   -97.62   185.84   -23.71  1964.49  1476.46   838.07 </code></pre>
<pre><code>      s6       s7       s8       s9      s10      s11      s12 
 1139.30 -1049.77   364.26 -1322.26  -197.71 -3356.56   -20.23 </code></pre>
<p>También podemos usarlos para predecir un año:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a>nacimientosEts<span class="sc">$</span>states[TT, <span class="dv">1</span>] <span class="sc">+</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">12</span>) <span class="sc">*</span> nacimientosEts<span class="sc">$</span>states[TT, <span class="dv">2</span>] <span class="sc">+</span> </span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>  nacimientosEts<span class="sc">$</span>states[TT, <span class="dv">14</span><span class="sc">:</span><span class="dv">3</span>]</span></code></pre></div>
<pre><code>     s12      s11      s10       s9       s8       s7       s6       s5 
30461.42 27027.46 30088.70 28866.53 30455.42 28943.77 31035.22 30636.37 
      s4       s3       s2       s1 
31177.13 31567.54 29481.72 29593.65 </code></pre>
<p>Febrero es el mes con menor número de nacimientos: nacen 3356 bebés menos, respecto de la media anual. En octubre es cuando más niños nacen: 1964 más que la media anual.</p>
<p>Nuestra predicción para enero de 2019 es de 30461 bebés y para diciembre de 2019 de 29593 bebés.</p>
</div>
<div id="predicción-1" class="section level2" number="7.2">
<h2 number="7.2"><span class="header-section-number">7.2</span> Predicción</h2>
<p>Si pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):</p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>nacimientosEtsPre <span class="ot">&lt;-</span> <span class="fu">forecast</span>(nacimientosEts, <span class="at">h =</span> <span class="dv">24</span>, <span class="at">level =</span> <span class="dv">95</span>)</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>nacimientosEtsPre</span></code></pre></div>
<pre><code>         Point Forecast    Lo 95    Hi 95
Jan 2019       30461.42 29110.45 31812.39
Feb 2019       27027.46 25673.56 28381.37
Mar 2019       30088.70 28504.04 31673.36
Apr 2019       28866.53 27194.30 30538.76
May 2019       30455.42 28611.33 32299.52</code></pre>
<p>Gráficamente,</p>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(nacimientosEtsPre,</span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Bebés&quot;</span>,</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 15. Nacimientos y predicción&quot;</span>)</span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-43-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
<div id="análisis-del-error-1" class="section level2" number="7.3">
<h2 number="7.3"><span class="header-section-number">7.3</span> Análisis del error</h2>
<p>El modelo de alisado tiene error multiplicativo así que debemos usar el argumento <code>type = "response"</code> para obtener el error aditivo con <code>residuals</code>.</p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>error <span class="ot">&lt;-</span> <span class="fu">residuals</span>(nacimientosEts, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>sderror <span class="ot">&lt;-</span> <span class="fu">sd</span>(error)</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="fu">autoplot</span>(error, <span class="at">series=</span><span class="st">&quot;Error&quot;</span>,</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">colour =</span> <span class="st">&quot;black&quot;</span>,</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">xlab =</span> <span class="st">&quot;Periodo&quot;</span>,</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">ylab =</span> <span class="st">&quot;Error&quot;</span>,</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">main =</span> <span class="st">&quot;Figura 16: Error + Intervención&quot;</span>) <span class="sc">+</span></span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">2</span> ,<span class="dv">3</span>)<span class="sc">*</span>sderror, </span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>             <span class="at">colour =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="at">lty =</span> <span class="dv">2</span>) <span class="sc">+</span> </span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks=</span> <span class="fu">seq</span>(<span class="dv">2000</span>, <span class="dv">2019</span>, <span class="dv">2</span>)) </span></code></pre></div>
<p><img src="03-02-Tema2_files/figure-html/unnamed-chunk-44-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Se identifica un valor claramente atípico –supera las 4 desviaciones típicas– que corresponde a enero de 2011. Abril de 2008 es otro candidato a intervención por alcanzar las 3 desviaciones típicas.</p>
</div>
<div id="validación-error-extra-muestral-1" class="section level2" number="7.4">
<h2 number="7.4"><span class="header-section-number">7.4</span> Validación: error extra-muestral</h2>
<p>En este caso vamos a aplicar la metodología <strong>origen de predicción móvil</strong> (<em>rolling forecast origin</em>) o <em>rolling windows</em>. Asumimos que se precisan diez años para hacer una buena estimación, <span class="math inline">\(k=120\)</span>, y que el horizonte temporal es de 12 meses, <span class="math inline">\(h = 12\)</span>. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a doce meses.</p>
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>k <span class="ot">&lt;-</span> <span class="dv">120</span>                  <span class="co">#Minimo numero de datos para estimar</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>h <span class="ot">&lt;-</span> <span class="dv">12</span>                   <span class="co">#Horizonte de las prediciciones</span></span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>TT <span class="ot">&lt;-</span> <span class="fu">length</span>(nacimientosb)    <span class="co">#Longitud serie</span></span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>s <span class="ot">&lt;-</span> TT <span class="sc">-</span> k <span class="sc">-</span> h           <span class="co">#Total de estimaciones</span></span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>mapeEts <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="cn">NA</span>, s <span class="sc">+</span> <span class="dv">1</span>, h)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">0</span><span class="sc">:</span>s) {</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>  train.set <span class="ot">&lt;-</span> <span class="fu">subset</span>(nacimientosb, <span class="at">start =</span> i <span class="sc">+</span> <span class="dv">1</span>, <span class="at">end =</span> i <span class="sc">+</span> k)</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>  test.set <span class="ot">&lt;-</span>  <span class="fu">subset</span>(nacimientosb, <span class="at">start =</span> i <span class="sc">+</span> k <span class="sc">+</span> <span class="dv">1</span>, <span class="at">end =</span> i <span class="sc">+</span> k <span class="sc">+</span> h)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>  fit <span class="ot">&lt;-</span> <span class="fu">ets</span>(train.set,  <span class="at">model =</span> <span class="st">&quot;MAA&quot;</span>, <span class="at">damped =</span> <span class="cn">FALSE</span>)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>  fcast <span class="ot">&lt;-</span> <span class="fu">forecast</span>(fit, <span class="at">h =</span> h)</span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>  mapeEts[i <span class="sc">+</span> <span class="dv">1</span>,] <span class="ot">&lt;-</span> <span class="dv">100</span><span class="sc">*</span><span class="fu">abs</span>(test.set <span class="sc">-</span> fcast<span class="sc">$</span>mean)<span class="sc">/</span>test.set</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>mapeEts <span class="ot">&lt;-</span> <span class="fu">colMeans</span>(mapeEts)</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(mapeEts, <span class="dv">2</span>)</span></code></pre></div>
<pre><code> [1] 1.92 2.16 2.29 2.67 2.70 2.74 2.88 2.91 3.03 3.16 3.22 3.50</code></pre>
<p>El error extra-muestral a un periodo vista es comparable al error intra-muestral (1.9% frente a 1.8%). Aunque el error de previsión aumenta conforme lo hace el horizonte temporal, siempre se mantiene muy bajo. Por ejemplo, en las previsiones a 12 meses vista el error es del 3.5%.</p>
<p><br />
</p>
</div>
<div id="otras-alternativas-para-predecir-nacimientos" class="section level2" number="7.5">
<h2 number="7.5"><span class="header-section-number">7.5</span> Otras alternativas para predecir Nacimientos</h2>
<p>A la hora de predecir hay que ser un poco imaginativos, dedicarle tiempo y probar cosas. Por ejemplo, podríamos predecir los nacimientos a partir del ajuste de la transformación logarítmica. O podemos probar a cambiar el criterio de estimación de los parámetros o el de selección del modelo óptimo.</p>
<p>Yendo un poco más lejos, y dado que el número de nacimientos depende forzosamente del número de días del mes, podemos predecir los nacimientos medios por día (cociente entre los nacimientos de cada mes y el número de días del mes). Esta serie tendrá una componente estacional más suave, elimina el efecto de los febreros bisiestos y tendrá, previsiblemente un mejor ajuste.</p>
<p>También podemos mezclar varios de los enfoques previos o ser aún más imaginativos.</p>
<p>El siguiente código muestra el MAPE (para previsiones intra-muestrales a un periodo vista) para varias de estas opciones. Puedes deducir que se está haciendo en cada caso a partir del código. Sería más adecuado usar otro criterio de validación diferente, pero el objetivo de este epígrafe es recalcar que no hay que quedarse con lo inmediato (predecir Nacimientos con las opciones por defecto de las funciones), sino probar y probar.</p>
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Serie Nacimientos</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.751808</code></pre>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.757418</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformación logarítmica</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773713</code></pre>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773713</code></pre>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Transformación logarítmica insesgada</span></span>
<span id="cb75-2"><a href="#cb75-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb75-3"><a href="#cb75-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb75-4"><a href="#cb75-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">biasadj =</span> <span class="cn">TRUE</span>,</span>
<span id="cb75-5"><a href="#cb75-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773718</code></pre>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb, </span>
<span id="cb77-2"><a href="#cb77-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">lambda =</span> <span class="dv">0</span>, </span>
<span id="cb77-3"><a href="#cb77-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">biasadj =</span> <span class="cn">TRUE</span>,</span>
<span id="cb77-4"><a href="#cb77-4" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb77-5"><a href="#cb77-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.773718</code></pre>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Nacimientos por dia</span></span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb<span class="sc">/</span><span class="fu">monthdays</span>(nacimientosb), </span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.677256</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">accuracy</span>(<span class="fu">ets</span>(nacimientosb<span class="sc">/</span><span class="fu">monthdays</span>(nacimientosb), </span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>             <span class="at">damped =</span> <span class="cn">FALSE</span>, </span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>             <span class="at">opt.crit =</span> <span class="st">&quot;mse&quot;</span>))[<span class="dv">5</span>]</span></code></pre></div>
<pre><code>[1] 1.671269</code></pre>
<p>La principal conclusión en este caso es que salirse de la estimación directa sobre la serie original no reduce el error significativamente. Sin embargo, cabe destacar que,</p>
<ul>
<li>El error de estimación de los nacimientos por día es menor, al tratarse de una serie con mejor comportamiento, aunque la ganancia no es mucha. (Véanse los dos últimos modelos respecto de los dos primeros)</li>
<li>Usar la transformación logarítmica (con o sin predicciones insesgadas) no mejora la capacidad predictiva del modelo. (Véanse los modelos 3 a 6 respecto de los modelos 1 y 2)</li>
<li>El mejor modelo estima los nacimientos por día y estima los parámetros minimizando el error cuadrático medio (“mse”). Todo menos lo <em>directo</em>.</li>
</ul>
<p><br />
<br />
</p>
</div>
</div>
<div id="resumen-de-los-comandos-utilizados" class="section level1" number="8">
<h1 number="8"><span class="header-section-number">8</span> Resumen de los comandos utilizados</h1>
<table>
<colgroup>
<col width="18%" />
<col width="14%" />
<col width="66%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Función</th>
<th align="left">Paquete</th>
<th align="left">Descripción</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"><code>meanf</code></td>
<td align="left">forecast</td>
<td align="left">Predicción por media</td>
</tr>
<tr class="even">
<td align="left"><code>naive</code></td>
<td align="left">forecast</td>
<td align="left">Predicción por método ingenuo I</td>
</tr>
<tr class="odd">
<td align="left"><code>rwf</code></td>
<td align="left">forecast</td>
<td align="left">Predicción con tendencia media</td>
</tr>
<tr class="even">
<td align="left"><code>snaive</code></td>
<td align="left">forecast</td>
<td align="left">Predicción por método ingenuo con estacionalidad</td>
</tr>
<tr class="odd">
<td align="left"><code>accuracy</code></td>
<td align="left">forecast</td>
<td align="left">Calculo de la precisión del modelo</td>
</tr>
<tr class="even">
<td align="left"><code>forecast</code></td>
<td align="left">forecast</td>
<td align="left">Predice valores extra-muestrales futuros de la serie</td>
</tr>
<tr class="odd">
<td align="left"><code>ses</code></td>
<td align="left">forecast</td>
<td align="left">Estimación del modelo de alisado exponencial simple</td>
</tr>
<tr class="even">
<td align="left"><code>holt</code></td>
<td align="left">forecast</td>
<td align="left">Estimación del modelo de alisado exponencial de Holt</td>
</tr>
<tr class="odd">
<td align="left"><code>hw</code></td>
<td align="left">forecast</td>
<td align="left">Estimación del modelo de alisado exponencial de Holt-Winters</td>
</tr>
<tr class="even">
<td align="left"><code>ets</code></td>
<td align="left">forecast</td>
<td align="left">Estimación de una amplia familia de métodos de alisado exponencial</td>
</tr>
<tr class="odd">
<td align="left"><code>residuals</code></td>
<td align="left">stats</td>
<td align="left">Obtiene el residuo de un modelo estimado</td>
</tr>
<tr class="even">
<td align="left"><code>fitted</code></td>
<td align="left">stats</td>
<td align="left">Obtiene las predicciones a un periodo vista intra-muestrales</td>
</tr>
</tbody>
</table>
<p><br />
<br />
</p>
</div>
<div id="referencias" class="section level1" number="9">
<h1 number="9"><span class="header-section-number">9</span> Referencias</h1>
<ul>
<li><p>Brown, R. G. (1959). <em>Statistical forecasting for inventory control</em>. Ed. McGraw/Hill.</p></li>
<li><p>Gardner, Jr, E. S. y McKenzie, E. (1985) <em>Forecasting trends in time series</em>, Management Science, 31(10), pp. 1237–1246. <a href="doi:10.1287/mnsc.31.10.1237" class="uri">doi:10.1287/mnsc.31.10.1237</a></p></li>
<li><p>Holt, C. E. (1957). <em>Forecasting seasonals and trends by exponentially weighted averages</em> O.N.R. Memorandum No. 52. Carnegie Institute of Technology, Pittsburgh USA. <a href="doi:10.1016/j.ijforecast.2003.09.015" class="uri">doi:10.1016/j.ijforecast.2003.09.015</a></p></li>
<li><p>Hyndman, R. J. y Khandakar, Y. (2008) <em>Automatic Time Series Forecasting: The forecast Package for R</em>. Journal of Statistical Software, 27(3), pp. 1-22. <a href="doi:10.18637/jss.v027.i03" class="uri">doi:10.18637/jss.v027.i03</a></p></li>
<li><p>Hyndman, R. J., Koehler, A., B., Ord, J. K. y Snyder, R. D. (2008) <em>Forecasting with Exponential Smoothing: the State Space Approach</em>. Ed. Springer.</p></li>
<li><p>Makridakis, S. y Hibon, M. (2000). <em>The M3-Competition: results, conclusions and implications</em>. International Journal of Forecasting, 16(4), pp. 451–476. <a href="doi:10.1016/S0169-2070(00)00057-1" class="uri">doi:10.1016/S0169-2070(00)00057-1</a></p></li>
<li><p>Winters, P. R. (1960). <em>Forecasting sales by exponentially weighted moving averages</em>. Management Science, 6, pp. 324–342. <a href="doi:10.1287/mnsc.6.3.324" class="uri">doi:10.1287/mnsc.6.3.324</a></p></li>
</ul>
<p><br />
<br />
<br />
<br />
</p>
</div>

<div id="rmd-source-code">---
title: "Series Temporales: Alisado Exponencial"
subtitle: "Máster de Bioestadística (Modelización Estadística)"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
output: 
  html_document:
    theme: cerulean
    highlight: pygments 
    fig_caption: false
    df_print: kable
    toc: true
    toc_depth: 2
    toc_float: 
      collapsed: true
    number_sections: true
    self_contained: true
    code_download: true
---

```{r chunk_setup, echo = FALSE}
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```

```{r options_setup, echo = FALSE}
options(scipen = 999) #- para quitar la notacion cientifica
```

```{r librerias, echo = FALSE}
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(gridExtra)
library(grid)
```

# Introducción

En muchos casos es preciso aplicar un método de predicción rápido y sencillo:

* A causa del elevado número de series que tienen que ser analizadas.
* Debido a la rapidez con que las predicciones se han de dar.
      
Actualmente existen muchos métodos sencillos de predicción, entre lo que cabe destacar dos:

* __Métodos de media móvil__ (no los veremos en este curso pero puedes aprender sobre ellos [aqui](http://uc-r.github.io/ts_moving_averages) y [aqui](https://cran.r-project.org/web/packages/smooth/vignettes/sma.html)).
* __Métodos de alisado exponencial__.
    
Estas técnicas, a pesar de su sencillez, son bastante adecuadas cuando la previsión es a corto plazo:

>"Statistically sophisticated or complex methods do not necessarily produce more accurate forecasts than simpler ones." Makridakis y Hibon (2000).
      
Veremos en detalle los métodos de alisado exponencial por ser muy versátiles, pudiéndose aplicar a cualquier serie, independientemente de sus componentes, y haber demostrado una gran capacidad de ajuste y calidad de predicción. En ellos se hace uso de datos pasados para obtener una nueva serie más _suave_ o alisada, a partir de la cual se realizarán las predicciones. Existe un amplio menú de métodos de alisado alternativos y la elección del más adecuado dependerá de las componentes que presenta la serie y del tipo de esquema.

\
\

# Criterios de calidad

En este tema y en los siguientes se verán diferentes métodos para predecir una serie temporal. Así, es preciso definir criterios de bondad de ajuste que permitan estimar tanto la calidad del ajuste como de las predicciones de un método.

> "The rankings of the performance of the various methods vary according to the accuracy measure being used."  Makridakis y Hibon (2000).
     
\

## Notación y definiciones


 
Dada una serie temporal $\{y_t\}_{t=1}^T$, se define:

* __Previsión $h$ periodos adelante__, como la previsión de la serie para el periodo $t+h$ disponiendo de información hasta el periodo $t$, y se denota por $\hat{y}_{t+h|t}$. Por simplicidad lo escribiremos también como $\hat{y}_{t+h}$.

\vspace{0.3cm}

* Así, $\hat{y}_{t+1|t}$ es la __previsión un periodo adelante__ o a un periodo vista. Es decir, la previsión de la serie en $t+1$ desde el periodo $t$.

\vspace{0.3cm}

* De nuevo, por simplicidad denotaremos a $\hat{y}_{t+1|t}$ como $\hat{y}_{t+1}$; y como $\hat{y}_{t}$ a la previsión en $t$, con datos hasta el periodo $t-1$ ($\hat{y}_{t} = \hat{y}_{t|t-1}$).

Se define como __error de previsión__ a un periodo vista a 
$$\hat{e}_t=y_t-\hat{y}_t,$$
de forma que la serie $\{\hat{e}_t\}_{t=1}^T$ nos permitirá definir varios criterios de calidad de ajuste. 
  
\

## Medidas de precisión de la predicción
 
Dada una serie $\{y_t\}_{t=1}^T$, un método de predicción y su vector de errores asociado $\{\hat{e}_t\}_{t=1}^T$, podemos definir múltiples medidas de calidad del método de predicción que hacen referencia a la presencia de sesgo en las predicciones, la magnitud del error cometido y la calidad del intervalo de confianza de las predicciones. Las más habituales son (siglas en inglés):

* Error medio (ME): $\frac{1}{T}\sum_{t=1}^T \hat{e}_t$

\vspace{0.3cm}

* __Raíz del error cuadrático medio (RMSE)__: $\sqrt{\frac{1}{T}\sum_{t=1}^T \hat{e}^2_t}$

\vspace{0.3cm}

* Error absoluto medio (MAE): $\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|$

\vspace{0.3cm}

* Error porcentual medio (MPE): $\frac{100}{T}\sum_{t=1}^T \frac{\hat{e}_t}{y_t}$

\vspace{0.3cm}

* __Error porcentual absoluto medio (MAPE)__: $\frac{100}{T}\sum_{t=1}^T \big|\frac{\hat{e}_t}{y_t}\big|$

\vspace{0.3cm}

* Error porcentual absoluto medio simétrico (sMAPE): $\frac{200}{T}\sum_{t=1}^T \Big|\frac{\hat{e}_t}{y_t + \hat{y}_t}\Big|$

\vspace{0.3cm}

* Error escalado absoluto medio (MASE): $\big(\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|\big)/q$, donde $q$ es el error absoluto medio para un método ingenuo de predicción:
  * $q=\frac{1}{T-1}\sum_{t=2}^T |y_t-y_{t-1}|$ para series _sin_ estacionalidad
  * $q=\frac{1}{T-m}\sum_{t=m+1}^T |y_t-y_{t-m}|$ para series _con_ estacionalidad

\vspace{0.3cm}

* Correlación entre $\hat{e}_t$ y $\hat{e}_{t-1}$ (ACF1).

\

ME y MPE permiten valorar el sesgo de las predicciones (que estas estén sistemáticamente por encima o por debajo de los valores reales).

* Lo esperado es un valor cercano a cero (con relación al valor medio de la serie). Valores muy alejados de cero son indicadores de sesgo de predicción.

RMSE y MAE indican el error medio cometido, medido en las mismas unidades que la serie temporal.

* Están acotadas inferiormente por el valor óptimo de 0, pero no hay cota superior.

MAPE y sMAPE indican el error porcentual medio cometido.

* Están acotadas inferiormente por el valor óptimo de 0%, y la cota superior natural es 100%, aunque podría sobrepasarse.
* Si $y_t$ puede valer 0, entonces MAPE no se puede calcular. Además, MAPE penaliza más los errores negativos frente a los errores positivos. La medida de precisión sMAPE se define a fin de corregir estos problemas.
      
MASE es la ratio entre el error del método usado y el error de un método ingenuo de predicción. Permite saber cuánto ganamos en capacidad predictiva al pasar de un método ingenuo a otro más complicado.

* Un valor cercano a 1 indica que el método usado no es mejor que el método ingenuo
* Cuanto más cercano a 0, mejor es el método usado respecto del método ingenuo
* Su complementario a 1 se puede interpretar como la tasa de mejora

ACF1 evalúa la capacidad de mejora que hay en la estimación del intervalo de confianza de las predicciones. Lo veremos con más detalle en el tema de modelos ARIMA. Por ahora basta saber que:

* Un valor muy cercano a 0 indica que hay poca capacidad de mejora.
* Un valor cercano a 1 o -1 indica que hay mucha capacidad de mejora.

Las _medias_ se pueden sustituir por _medianas_. Esto es especialmente útil cuando para algunas observaciones hay errores atípicamente altos.

\

Si para realizar la predicción del periodo $t$ se usa una metodología que utiliza datos hasta dicho periodo, se hablará de **predicción y error intra-muestral**. En caso contrario, la predicción del periodo $t$ usa una metodología que solo necesita de datos hasta el periodo $t-1$, se hablará de **predicción y error extra-muestral**.

Si los indicadores de calidad se basan en predicciones intra-muestrales a un periodo vista, presentan dos problemas. Primero, evalúan el error de predicción a un periodo vista, cuando en muchas situaciones reales las predicciones se realizan sobre un horizonte temporal más amplio. Segundo, son errores intra-muestrales, resultantes de predecir los mismos datos que se ha usado el método para calcular la predicción y, por tanto, sobre-estiman la capacidad predictiva del modelo.

Veremos durante en este tema métodos de evaluación de la calidad de las predicciones que superan estas limitaciones.

\
\

# Métodos sencillos de predicción

Algunos métodos de predicción son extremadamente sencillos y sorprendentemente eficaces, son los denominados métodos ingenuos. Estos métodos:

* posibilitan realizar predicciones prácticamente sin realizar ningún cálculo. 
* como son muy sencillos, dan las previsiones con mayor error (menos precisas). El error de un método ingenuo sirve de punto de referencia (_benchmark_) para valorar la necesidad de aplicar otros métodos más complicados con el objetivo de mejorar la calidad de las predicciones. 

Veamos algunos métodos ingenuos y sus funciones en el paquete `forecast`.

\

## Métodos sencillos de predicción

### Series _sin_ tendencia y _sin_ estacionalidad {-}

**Método de la Media**: $\hat{y}_{T+h}=(y_1+\ldots,y_T)/T$.

* La predicción para cualquier periodo futuro es la __media__ de las observaciones disponibles previas.
* Función de `R`: `meanf(y, h)`
    
**Método ingenuo I**: $\hat{y}_{T+h}=y_T$.

* La predicción para cualquier periodo futuro es la __última__ observación disponible.
* Función de `R`: `naive(y, h)` o `rwf(y, h)` (_rw_ de random walk)


### Series _con_ tendencia y _sin_ estacionalidad {-}

**Método ingenuo II**: $\hat{y}_{T+h}=y_T + h(y_T-y_{T-1})$.

* La predicción $h$ periodos adelante es la __última observación__ disponible más $h$ veces el __último incremento__ observado. 
* No tiene función en `R`, pero se podría emular mediante la función `holt` (véase epígrafe de 4.5 Alisado exponencial de Holt).
      
**Método de la deriva**: $\hat{y}_{T+h}=y_T+h\frac{y_T - y_1}{T-1}$.

* La predicción $h$ periodos adelante es la __última observación__ disponible más $h$ veces el __incremento medio__ observado.
* Función de `R`: `rwf(y, h, drift = TRUE)`  


### Series _sin_ tendencia y _con_ estacionalidad {-}

**Método ingenuo con estacionalidad**: $\hat{y}_{T+h}=y_{T-m(k+1)}$.

* $k$ es la parte entera de $(h-1)/m$, es decir, el número de años completos en el periodo de predicción previo al periodo $T+h$.
* La predicción para un periodo es la __última observación disponible de la misma estación que la fecha que se desea predecir__.
* Función de `R`: `snaive(y, h)`
    
__No hay métodos ingenuos cuando la serie tiene tendencia y estacionalidad__, aunque la aplicación del método ingenuo con estacionalidad suele ser muy efectiva.

\

## Ejemplo de aplicación

### Serie Libros {-}
 
```{r}
libros <- read.csv2("./series/libros.csv", header = TRUE)
libros <- ts(libros[ ,2], start = 1993, frequency  = 1)
```

En la figura 1 se muestra el resultado gráfico de la aplicación de algunos de estos métodos sencillos a la serie Libros (número de títulos publicados anualmente en España desde 1993 hasta 2018), con independencia de su adecuación dadas las componentes de esta serie. Se ha fijado un horizonte de previsión de cinco años (`h = 5`). El argumento `PI = FALSE` hace que no se impriman los intervalos de confianza de las predicciones.

Los métodos de la Media e Ingenuo I realizan una predicción constante, el primero la media de títulos en el periodo de análisis (`r as.integer(mean(libros))`) y el segundo el último dato observado (`r tail(as.integer(libros), n=1)`). El método de deriva ofrece una predicción creciente porque la serie Libros tiene una pendiente media positiva en el periodo de análisis.

Recuerda que debes cargar las librerías `forecast` y `ggplot2`.

```{r}
(mediaLibros <- meanf(libros, h = 5))
(naiveLibros <- naive(libros, h = 5))
(derivaLibros <- rwf(libros,  h = 5, drift = TRUE))
 

autoplot(libros, series = "Libros",
                xlab = "",
                ylab = "Títulos",
                main = "Figura 1. Libros y predicción por métodos sencillos") +
  autolayer(mediaLibros, series="Media", PI = FALSE) +
  autolayer(naiveLibros, series="Ingenuo", PI = FALSE) +
  autolayer(derivaLibros, series="Deriva", PI = FALSE) +
  scale_colour_discrete(limits=c("Libros", "Media", "Ingenuo", "Deriva")) +
  guides(colour = guide_legend(title = "Métodos")) + 
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1))
```

Con la función `accuracy` se puede obtener el error de predicción intra-muestral a un periodo vista de cada método:

```{r, eval = FALSE}
accuracy(mediaLibros)
accuracy(naiveLibros)
accuracy(derivaLibros)
```

```{r, echo=FALSE}
tmp <- rbind(
  accuracy(mediaLibros),
  accuracy(naiveLibros),
  accuracy(derivaLibros)
)
tmp <- round(tmp,2)
rownames(tmp) <- c("Media","Ingenuo I","Deriva")
tmp
```

Podemos destacar que:

* El método de _Media_ presenta una baja capacidad predictiva debido a que la serie Libros tiene tendencia (MAPE =  14%). Además, el intervalo de confianza de las predicciones no es fiable (ACF1 = 0.77).
* El método de _Deriva_ tiene la mejor calidad de ajuste, con un error porcentual del 6.9% (MAPE), y un error medio aproximado de 6,000 títulos (RMSE). No presenta sesgo (ME = 0) y el intervalo de confianza de las predicciones es fiable (ACF1 = -0.04).
* El método _Ingenuo I_ tiene buena calidad de ajuste, pero las previsiones están muy sesgadas (ME = 857).
* Para series sin estacionalidad el método sencillo de comparación usado en el cálculo del MASE es el _Ingenuo I_. Es por ello que este indicador vale 1 para este método.
* El error medio (ME) siempre será nulo para el método de la _Media_ y de la _Deriva_, lo que indica que nos equivocamos tanto por exceso como por defecto. Esta es una buena propiedad, que el método _Ingenuo I_ no verifica.

### Serie Nacimientos {-}

Podemos usar el método ingenuo con estacionalidad con la serie Nacimientos para obtener una previsión a dos años vista. El error absoluto porcentual medio es del 3.6%. Es decir, aplicando algo tan simple como predecir el número de nacimientos para un mes como los nacimientos del mismo mes del año previo, tenemos ya un error de predicción muy bajo. La figura 2 muestra la serie y la predicción que, debido al método usado, no incorpora la tendencia decreciente de los últimos años.

```{r}
nacimientos <- read.csv2("./series/nacimientos.csv", header = TRUE)
nacimientos <- ts(nacimientos[, 2],
                  start = c(1975, 1),
                  frequency = 12)

(snaive.nacimientos <- snaive(nacimientos, h = 24, level = 95))
accuracy(snaive.nacimientos)

autoplot(snaive.nacimientos,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 2. Nacimientos y predicción por el método Ingenuo con estacionalidad")
```


\
\

# Evaluación de las predicciones

Las medidas que hemos usado hasta ahora para valorar la calidad de las predicciones son realmente medidas de bondad de ajuste, es decir, medidas de la calidad de __previsiones intra-muestrales a un periodo vista__. Valoran en que medida los datos se ajustan a un patrón o modelo, pero no evalúan la calidad de la previsiones ante nuevos datos.

En este epígrafe vamos a ver dos metodologías que podemos usar para valorar la calidad de las __previsiones extra-muestrales__, que es realmente los que nos interesa. Estas dos metodologías están relacionadas con los métodos de _Training set/Test set_ y _Cross-validation_ usuales en el análisis de las predicciones con datos transversales, pero adaptadas a datos temporales.

## Validación por la metodología de _Training set/Test set_ para Series Temporales

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo las medidas de error para __previsiones extra-muestrales a varios periodos vista__ usando la filosofía del método _training set/test set_. Dividimos la serie temporal $\{y_t\}_{t=1}^T$ en dos subseries, los primeros datos $\{y_t\}_{t=1}^{T_0}$, $T_0 < T$ se usarán para estimar el modelo, y los últimos datos $\{y_t\}_{t={T_0+1}}^{T}$ para validar el modelo.

Esta metodología, muy efectiva para datos de corte transversal, genera dos problemas cuando se aplica a series temporales: _i_) el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar; _ii_) los resultados dependen tremendamente del punto de corte temporal seleccionado.

### Serie Libros {-}

Vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie. 

```{r, eval = FALSE}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 6 años que hemos quitado de la serie 
librosExtraPre <- rwf(librosIntra,  h = 6, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
accuracy(librosExtraPre, librosExtra)
```

```{r, echo = FALSE}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 7 años que hemos quitado de la serie 
librosExtraPre <- rwf(librosIntra,  h = 6, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
round(accuracy(librosExtraPre, librosExtra), 2)

error.muestral.1 <- round(accuracy(librosExtraPre, librosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(librosExtraPre, librosExtra)[2,5],1)
```

Atendiendo al MAPE se tiene que el error de __previsión a un periodo vista__ en el __periodo intra-muestral__ de __1993 a 2012__ es del `r error.muestral.1`%; mientras que el error de __previsión a largo plazo__ en el __periodo extra-muestral__ de __2013 a 2018__ es del `r error.extramuestral.n`%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas (sobre-estiman la realidad). En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas. 

Un gráfico puede ayudar a entender este proceso de validación. En la figura 3:

* La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.
* La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.
* La previsión _intra_-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.
* La línea en rojo es la previsión _extra_-muestral a largo plazo. Observa que todas las previsiones están por encima del valor real de la serie.
* Al lado de cada previsión (intra- y extra-muestral) se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r,echo=FALSE}
autoplot(libros, series = "Libros",
         main="Figura 3. Libros, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(librosExtraPre), series = "Libros (ajustada)") + 
  autolayer(librosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2012.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Libros"="black",
                               "Libros (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=1999, y=65000, label="6.5%", colour = "blue") +
  annotate("text", x=2016, y=72000, label="26.7%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

### Serie Nacimientos {-}

Calculamos de nuevo los diferentes criterios de bondad de ajuste para valorar la calidad de las previsiones extra-muestrales a largo plazo. En este caso vamos a reservar los últimos 36 meses como periodo extra-muestral.
  
```{r, eval = FALSE}
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

accuracy(nacimientosExtraPre, nacimientosExtra)
```

```{r, echo = FALSE}
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

round(accuracy(nacimientosExtraPre, nacimientosExtra), 2)
```

```{r, echo = FALSE}
autoplot(nacimientos, series = "Nacimientos",
         main="Figura 4. Nacimientos, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Nacimientos"
         ) +
  autolayer(fitted(nacimientosExtraPre), series = "Nacimientos (ajustada)") + 
  autolayer(nacimientosExtraPre$mean, series = "Predicción") + 
  scale_colour_manual(values=c("Nacimientos"="black",
                               "Nacimientos (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=2012, y=45000, label="3.6%", colour = "blue") +
  annotate("text", x=2018, y=40000, label="7.7%", colour = "red") + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

Las previsiones extra-muestrales muestran una menor pendiente que los casos reales de nacimientos. Así, conforme se avanza en el horizonte temporal las previsiones se van alejando de la realidad y el error extra-muestral es del 7.7%, reducido pero que duplica el error de estimación intra-muestral (3.6%).

\

## Validación cruzada para Series Temporales

Hemos visto dos alternativas para evaluar la calidad de un método de predicción de series temporales, uno basado en predicciones intra-muestrales a un periodo vista y otro basado en predicciones extra-muestrales a largo plazo, ambas con sus inconvenientes.

Veamos ahora una técnica, basada en el concepto de validación cruzada (_cross validation_) que permite obtener de forma individualizada los errores de previsión extra-muestral a un periodo vista, a dos periodos vista, etc.

Supongamos que para estimar el modelo se necesita un mínimo de $k$ observaciones y que se desea predecir hasta un horizonte temporal $h$.

* Seleccionamos las observaciones $1,2,...,k$ para estimar el modelo y predecimos las observaciones desde $k+1$ hasta $k+h$. Tenemos, por tanto, $h$ predicciones.
* Calculamos el error de predicción para las predicciones desde $k+1$ hasta $k+h$.
* Repetimos este proceso desplazando el número de observaciones seleccionadas para la estimación un periodo adelante. Es decir, ahora usamos las observaciones $2,3,...,k+1$ para estimar el modelo, predecimos las observaciones desde $k+2$ hasta $k+1+h$ y calculamos el error de predicción.
* Iteramos el proceso, desplazando cada vez las observaciones de la estimación un periodo adelante.
* En general para $i=0,1,...,T-k-h$, donde $T$ es el número total de observaciones:
  
  1. Seleccionamos las observaciones $i+1,i+2,...,i+k$ para estimar el modelo.
  2. Predecimos las observaciones desde $i+k+1$ hasta $i+k+h$.
  3. Calculamos el error de predicción para las observaciones desde $i+k+1$ hasta $i+k+h$.
  4. Para cada horizonte temporal de predicción se calcula la medida de error deseada.

\
\

![](./imagenes/RollingWindows.png)

Este procedimiento se denomina __origen de predicción móvil__ (_rolling forecast origin_) o _rolling windows_.

Cuando se aplica esta metodología hay que tener en cuenta que los resultados pueden depender del número $k$ de datos usados para la estimación del modelo.

### Ejemplo de aplicación con Nacimientos {-}

Vamos a aplicar la metodología previa a la serie anual de Nacimientos. Asumimos que se precisan veinte años para hacer una buena estimación, $k=20$, y que el horizonte temporal es de cinco años, $h = 5$ meses. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a cinco años.
  
```{r}  
nacAnual <- aggregate(nacimientos, FUN = sum)
k <- 20                   #Minimo numero de datos para estimar
h <- 5                    #Horizonte de las prediciciones
TT <- length(nacAnual)    #Longitud serie
s <- TT - k - h           #Total de estimaciones

mapeRwf <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacAnual, start = i + 1, end = i + k)
  test.set <-  subset(nacAnual, start = i + k + 1, end = i + k + h)
  
  fcast <- rwf(train.set, h = h, drift = TRUE)
  mapeRwf[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

mapeRwf <- colMeans(mapeRwf)
round(mapeRwf, 2)
```

El error de previsión extra-muestral crece linealmente con el horizonte de previsión. Para el primer año el error de predicción se mantiene en un moderado 4.2%. Sin embargo, para el segundo año de predicción el MAPE salta al 8.2% y para los restantes años sigue creciendo rápidamente. Predecir usando la tendencia media solo es un buen método para predecir a un año vista.

\
\

# Métodos de Alisado Exponencial

## Introducción

Los métodos de alisado exponencial aparecen en los años 50 de la mano de Brown, Holt y Winters y han sido la raíz de uno de los métodos de predicción más sencillos y eficaces. La idea básica es predecir usando una media ponderada de los datos pasados, donde los más recientes tienen un peso mayor y este decae exponencialmente conforme usamos observaciones más antiguas.

El alisado exponencial es una familia de métodos de ajuste y previsión que ofrece muy buenos resultados para predicciones a corto plazo o para predecir series con pocos datos o _sencillas_ (sin mucho _ruido_).

Suponen un grado de modelización mayor que los métodos sencillos vistos previamente, pero sin alcanzar la complejidad de otras metodologías (modelos ARIMA).  

En origen, son métodos descriptivos con el único objetivo de producir __predicciones puntuales__. Sin embargo, su enfoque como modelos de _espacio de estados_ posibilita un marco teórico para obtener __intervalos de predicción__.

\

## Componentes de una serie en el contexto del alisado exponencial

Para obtener una predicción en el periodo $t+1$ con datos hasta el periodo $t$ necesitamos tres componentes:

* La estimación del nivel de la serie en el periodo $t$: $l_t$
* La estimación de la pendiente de la serie en el periodo $t$: $b_t$
* La estimación de la estacionalidad en el mes correspondiente al periodo $t+1$ con datos hasta $t$: $s_{t + 1 - m}$ (recuerda, $m$ es el orden estacional

A partir de estas componentes, obtenidas en el periodo $t$ y para un esquema aditivo, se tendría que la predicción en el periodo $t+1$ es:
$$\widehat{y}_{t+1} = l_t+b_t+s_{t+1-m}.$$
En general, las componentes pueden __existir o no__ y se pueden combinar entre ellas __aditiva o multiplicativamente__. Veamos algunos casos:

* Existen todas y son multiplicativas:
$$\widehat{y}_{t+1}=l_t \cdot b_t \cdot s_{t + 1 - m}$$
* Existen todas, nivel y pendiente aditivas, y estacionalidad multiplicativa:
$$\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}$$
* No hay pendiente y la estacionalidad es aditiva:
$$\widehat{y}_{t+1}=l_t+s_{t + 1 - m}$$

¿Como obtenemos los valores de $l_t$, $b_t$ y $s_{t + 1 - m}$? Mediante __expresiones recursivas__, donde cada componente se calcula a partir de los valores hasta $t$ de la serie y de las componentes:
$$
\begin{aligned}
l_t& = f_l(y_t,y_{t-1}\ldots, l_{t-1},l_{t-2}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
b_t& = f_b(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
s_t& = f_s(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t},b_{t-1}\ldots,s_{t-1},s_{t-2}\ldots)
\end{aligned}
$$
Por ejemplo, el _método ingenuo I_ se puede interpretar dentro de este contexto como un método de alisado donde $l_t = y_t$ y no hay ni pendiente ni estacionalidad. Por tanto, $\widehat{y}_{T+1} = l_{T} = y_{T}$.

De la misma forma, el _método ingenuo II_ se puede interpretar como un método de alisado donde $l_t = y_t$, $b_t = y_t - y_{t-1}$ y no hay estacionalidad. Entonces, $\widehat{y}_{T+1}=l_T + b_T = y_T + (y_T - y_{T-1})$.
    
En las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista ($\widehat{y}_{t+1}$). Si el objetivo es estimar una previsión $h$ periodos hacia delante desde el periodo $t$, $\widehat{y}_{t+h}$, hay que realizar algunas modificaciones. Por ejemplo, para el caso aditivo se tendría que 
$$\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}$$
donde $k = \lfloor (h-1)/m\rfloor$.

El concepto de componentes aquí visto no coincide con el definido en el Tema 1. Sin embargo, podemos asimilar la tendencia de una serie como la suma (multiplicación) del nivel y la pendiente $T_{t+1} = l_t + b_t$ ($T_{t+1} = l_t \cdot b_t$) y de esta forma ambas definiciones de componentes de una serie se hacen compatibles.

\
\

## Casos posibles

Todas las series tiene nivel, pero dependiendo del tipo de pendiente y estacionalidad hay 15 casos posibles, mostrados en la tabla siguiente.

|    Tendencia          |           | Estacionalidad |                  |
|:----------------------|:---------:|:--------------:|:----------------:|
|                       | Ninguna (N) | Aditiva (A) | Multiplicativa (M)        |
| Ninguna (N)           |__N, N__   |       N, A     |        N, M      |
| Aditiva (A)           |__A, N__   |   __A, A__     |    __A, M__      |
| Aditiva Amortiguada (Ad)  |__Ad, N__  |      Ad, A     |       Ad, M      |
| Multiplicativa (M)    |    M, N   |       M, A     |        M, M      |
| Multiplicativa Amortiguada (Md) |    Md, N  |      Md, A     |       Md, M      |


Cada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.

Si se añade que el error puede ser aditivo o multiplicativo, da 30 posibilidades. **El tipo de error (aditivo o multiplicativo) no afecta ni a la estimación ni a la previsión puntual, sólo es relevante en el cálculo del intervalo de confianza de las predicciones.**

Los modelos más usuales son:

* (N, N):   Alisado exponencial simple
* (A, N):   Alisado de Holt
* (Ad, N):  Alisado con tendencia amortiguada (d de _damped_)
* (A, A):   Alisado de Holt-Winters aditivo
* (A, M):   Alisado de Holt-Winters multiplicativo

Acude al artículo de [Rob J. Hyndman y Yeasmin Khandakar (2008)](http://www.jstatsoft.org/v27/i03/paper) para saber más de cada modelo, o al libro _Forecasting with Exponential Smoothing: the State Space Approach_ (2008) de Hyndman y otros autores.

\

## Alisado exponencial simple (N, N)

### Definición {-}

El alisado exponencial simple es adecuado para una serie estacionaria y sin estacionalidad. Es decir, una serie que se mueve alrededor de un nivel constante.

La ecuación de la __predicción intra-muestral__ es 
$$\hat{y}_{t+1} = \alpha y_t + \alpha (1-\alpha) y_{t-1} + \alpha (1-\alpha)^2 y_{t-2} + \alpha (1-\alpha)^3 y_{t-3} + \ldots =  \alpha y_t + (1-\alpha)\hat{y}_{t},$$
donde $0 \leq \alpha \leq 1$ es el parámetro de suavizado. La primera __predicción extra-muestral__ queda 
$$\hat{y}_{T+1}=\alpha y_T + (1-\alpha)\hat{y}_{T}$$
y para las restantes
$$\hat{y}_{T+h} = \hat{y}_{T+1}.$$

### Formulas interactivas de sus componentes {-}

En el alisado exponencial simple solo hay una componente, el nivel $l_t$.

* La __ecuación recursiva__ de suavizado es $l_t=\alpha y_t + (1-\alpha)l_{t-1}$
* La ecuación de __predicción intra-muestral__ es $\hat{y}_{t+1} = l_t$
* La ecuación de __predicción extra-muestral__ es $\hat{y}_{T+h} = \hat{y}_{T+1} = l_T$

Dos estimaciones razonables de $l_t$, el nivel de la serie en el periodo $t$, son el valor observado para la serie en ese periodo $y_t$ y el nivel del periodo previo $l_{t-1}$. La estimación final de $l_t$ es una media ponderada de ambas y esta estimación final es la previsión de la serie para el periodo siguiente. 

### Estimación de los parámetros del modelo {-}
    
Dado el proceso iterativo para el cálculo de $l_t$ se necesita un __valor inicial__ de arranque $l_0$. Cada programa estadístico usa su propio método para obtener $l_0$.
    
Respecto de $\alpha$, usualmente se estima el valor __optimo__ según un criterio de precisión de la predicción. El parámetro $\alpha$ __se puede interpretar__ como:

* Si $\alpha = 1$ se tiene el _método ingenuo I_ ($\hat{y}_{t+1}=y_t$), óptimo cuando el nivel de la serie varía constantemente en el tiempo.
* Si $\alpha = 0$ se tiene $\hat{y}_{t} =l_0$, óptimo cuando el nivel permanece constante en el tiempo.

### Ejemplo {-}

Vamos a usar el método de alisado exponencial simple para predecir la serie Libros. Usaremos para ello la función `ses` (_simple exponential smoothing_) con una previsión a 5 años vista (`h = 5`). Esta función estima los valores de $l_0$ y $\alpha$ que maximizan la función de verosimilitud, pero se pueden elegir otros criterios con el parámetro `opt.crit`.

```{r}
librosf <- ses(libros, h = 5, level = 95)
summary(librosf)
```

Veamos la salida en detalle:

* El valor de $\alpha$ que optimiza el criterio usado para medir la calidad del ajuste es $\alpha =$ `r round(librosf$model$par[1],2)`, un valor muy cercano a 1. Esto es un indicativo de que: i) la serie Libros cambia de nivel de forma constante, un rasgo en los procesos puramente estocásticos como el paseo aleatorio; ii) y el método de alisado exponencial simple se aproxima al método Ingenuo I. 
* El valor de arranque $l_0$ óptimo es `r round(librosf$model$par[2],2)`. 
* _sigma_ es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular sigma en lugar de dividir por $T$ se divide por $T$ menos el número de parámetros estimados (en este caso 3, $l_0$, $\alpha$ y _sigma_).
* La calidad de ajuste es razonable, como evidencia el error porcentual medio del 7%.
* Las predicciones son las mismas para los 5 años, como cabe esperar (recuerda que $\hat{y}_{T+h} = \hat{y}_{T+1}$).

```{r}
tail(librosf$model$states, n = 4)
```

En el objeto `librosf` la matriz `librosf$model$states` guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluidos el valor de arranque, así que es una matriz con $T+1$ filas. Puedes ver el valor de $l_{2018}$ en su última fila, que vale `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Así, la predicción para $2019$ es $\widehat{y}_{2019}=l_{2018}=$ `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Igualmente $\widehat{y}_{2020}=l_{2018}=$ `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Es decir, todas las previsiones son iguales a $l_{2018}$.

La figura 6 muestra la serie Libros y las previsiones extra-muestrales, que son constantes, y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.
 
```{r}
autoplot(librosf,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 6. Libros y predicción con alisado simple")
```

\

## Alisado exponencial de Holt (A, N)

El alisado exponencial de Holt es adecuado para una serie no estacionaria y sin estacionalidad.

### Formulas interactivas de sus componentes {-}

Las __ecuaciones recursivas__ son
$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} 
\end{aligned}
$$
La ecuación de la __predicción intra-muestral__ a un periodo vista es
$$\hat{y}_{t+1} = l_t + b_t,$$
\noindent de forma que la ecuación de __predicción extra-muestral__ es 
$$\hat{y}_{T+h}=l_T + h b_T.$$ 
 
Dos estimaciones razonables del nivel de la serie en el periodo $t$ son el valor observado para la serie en ese periodo $y_t$, y una estimación del nivel del periodo $t$ realizada desde el periodo $t-1$: $l_{t-1} + b_{t-1}$. Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo $t$ son el último cambio de nivel observado $l_t-l_{t-1}$, y el valor de la pendiente en el periodo previo, $b_{t-1}$. En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por $0 \leq \alpha, \: \beta \leq 1$.

### Estimación de los parámetros del modelo {-}

Para aplicar este método es necesario estimar unos valores iniciales $l_0$ y $b_0$ de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros $\alpha$ y $\beta$. Los __valores óptimos__ de estos cuatro parámetros se obtienen optimizando una medida de precisión de las predicciones.

La interpretación del parámetro $\alpha$ es similar al caso del alisado exponencial simple.

__Interpretación del parámetro $\beta$__:

* Si $\beta = 1$, $b_t  = l_t - l_{t-1}$, la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).
* Si $\beta = 0$, $b_t = b_{t-1}= \ldots = b_0$, la pendiente se mantiene constante en el tiempo.

El _método ingenuo II_ es un caso concreto de Alisado de Holt. Si hacemos $\alpha=\beta = 1$, queda $l_t=y_t$ y $b_t=y_t-y_{t-1}$, por tanto
$$\hat{y}_{T+h}=l_T + h \cdot b_T = y_T + h(y_T - y_{T-1}).$$

### Ejemplo {-}

Vamos a usar el método de alisado de Holt para predecir de nuevo la serie Libros. Usaremos para ello la función `holt` con una previsión a 5 años vista (`h = 5`).

```{r}
librosf <- holt(libros, h = 5, level = 95)
summary(librosf)
```

Los valores óptimos de los cuatro parámetros son $\alpha=$ `r round(librosf$model$par[1],2)`, $\beta=$ `r round(librosf$model$par[2],2)`, $l_0 =$ `r round(librosf$model$par[3],2)` y $b_0 =$ `r round(librosf$model$par[4],2)`. Observa que $\alpha$ es prácticamente 1 y que $\beta$ es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extra-muestral, obtenemos $y_{T+h}=y_T + hb_0$: la predicción es el último valor observado más la primera pendiente estimada.

La calidad de las predicciones es razonable, con un error porcentual medio del 6.7%, y se ha mejorado respecto del alisado exponencial simple.

```{r}
tail(librosf$model$states, n = 4)
```

De nuevo, en el objeto `librosf` la matriz `librosf$model$states` guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de $l_{2018}$ y $b_{2018}$ en su última fila, que valen respectivamente `r formatC(librosf$model$states[27,], format = "f", digits = 2)`. Así, la predicción para $2019$ es $\widehat{y}_{2019}=l_{2018} + b_{2018}=$ `r formatC(librosf$model$states[27, 1], format = "f", digits = 2)` $+$ `r formatC(librosf$model$states[27, 2], format = "f", digits = 2)` $=$ `r formatC(sum(librosf$model$states[27,]), format = "f", digits = 2)`. Igualmente $\widehat{y}_{2020}=l_{2018} + 2\cdot b_{2018}=$ `r formatC(librosf$model$states[27,1] + 2* librosf$model$states[27,2], format = "f", digits = 2)`. Es decir, el incremento entre previsiones es contante e igual a $b_{2018}$ que, por ser $\beta$ prácticamente nulo, coincide con $b_0$.

La figura 7 muestra la serie Libros y las previsiones extra-muestrales que muestran una ligera tendencia creciente.
 
```{r}
autoplot(librosf,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 7. Libros y predicción con alisado de Holt")
```

\

## Alisado exponencial con pendiente amortiguada (Ad, N)

Las previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por Gardner y McKenzie en 1985, es introducir un nuevo parámetro $0 \leq \phi \leq 1$ que _amortigua_ la tendencia hasta hacerla plana en el largo plazo.


### Formulas interactivas de sus componentes {-}

Las __ecuaciones recursivas__ son
$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)\phi b_{t-1} 
\end{aligned}
$$
La ecuación de la __predicción intra-muestral__ a un periodo vista es
$$\hat{y}_{t+1} = l_t + \phi b_t,$$
\noindent de forma que la ecuación de __predicción extra-muestral__ es 
$$\hat{y}_{T+h}=l_T + (\phi + \phi^2 + \ldots + \phi^h) b_T.$$ 
 
Si $\phi = 1$ se tiene el alisado de Holt y si $\phi = 0$ se tiene el alisado simple. Para valores entre $0$ y $1$ en el corto plazo las predicciones tienen pendiente y en el largo plazo se hacen constantes e iguales a $l_T + \phi b_T/(1 - \phi)$.

### Ejemplo {-}

Vamos a usar el método de alisado con amortiguamiento para predecir, una vez más, la serie Libros añadiendo a la función `holt` el argumento `damped = TRUE`. Por razones prácticas el rango de búsqueda de $\phi$ queda en el intervalo $[0.8, 0.98]$. En este caso, para ver el efecto del _amortiguamiento_ vamos a fijar el valor de $\phi$ a $0.9$ y vamos a pedir un horizonte temporal más largo.

```{r}
librosfd <- holt(libros, damped = TRUE, h = 15, phi = 0.9)
summary(librosfd)
```

La figura 8 muestra la serie Libros, su estimación (intra-muestral) y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se _amortigua_ en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años.
 
```{r}
autoplot(librosfd,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 8. Libros y predicción con alisado exponencial con amortiguamiento",
         PI = FALSE)
```

\

## Alisado de Holt-Winters aditivo (A, A) y multiplicativo (A, M)

El método de alisado exponencial de Holt-Winters es adecuado para una serie con tendencia y con estacionalidad. Existen dos versiones según que el esquema sea aditivo o multiplicativo.

### Alisado de Holt-Winters aditivo (A, A) {-}

Las __ecuaciones recursivas__ de actualización son:
$$
\begin{aligned}
l_t & =\alpha (y_t - s_{t-m} ) + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \gamma)s_{t-m}
\end{aligned}
$$
con $0 \leq \alpha, \beta, \gamma \leq 1$.

La ecuación de la __predicción intra-muestral__ a un periodo vista es 
$$\hat{y}_{t+1}  = l_t + b_t + s_{t+1-m},$$
\noindent de forma que la ecuación de __predicción extra-muestral es__:
$$\hat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},$$ 
\noindent con $k = \lfloor(h-1)/m\rfloor$.

### Alisado de Holt-Winters multiplicativo (A, M) {-}

Las __ecuaciones recursivas__ de actualización son:
$$
\begin{aligned}
l_t & =\alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma \frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \gamma)s_{t-m}
\end{aligned}
$$

La ecuación de la __predicción intra-muestral__ a un periodo vista es 
$$\hat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},$$
de forma que la ecuación de __predicción extra-muestral es__:
$$\hat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.$$ 

### Ejemplo {-}

Vamos a usar el método de Holt-Winters para predecir la serie Nacimientos, que presentaba un esquema multiplicativo. Para ello usaremos la función `hw` con el argumento `seasonal = "multiplicative"` (que sería `seasonal = "additive"` en caso de esquema aditivo). Vamos a considerar la serie Nacimientos desde enero de 2000 y pedir una previsión a dos años vista.

```{r}
nacimientosb <- window(nacimientos, start = 2000)
nacimientosbf <- hw(nacimientosb, seasonal = "mult", h = 24)
summary(nacimientosbf)
```

Los valores óptimos de los parámetros son $\alpha=$ `r round(nacimientosbf$model$par[1],2)`, $\beta=$ `r round(nacimientosbf$model$par[2],2)` y $\gamma=$ `r round(nacimientosbf$model$par[3],2)`. Los valores tan bajos para $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, modifican su valor muy lentamente. Es decir, hay pendiente y hay efecto estacional, pero permanecen constantes en el tiempo.

La calidad de las predicciones es notable, con un error porcentual medio del 1.8%. Recuerda que con el método ingenuo con estacionalidad el error era del 3.6%.

Los últimos valores de las componentes son 
```{r, eval = FALSE}
TT <- nrow(nacimientosbf$model$states)
nacimientosbf$model$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(nacimientosbf$model$states)
round(nacimientosbf$model$states[TT,], 3)
```

Como el último dato de la serie es diciembre de 2018, los valores del nivel $l$ y la pendiente $b$ mostrados corresponden a ese periodo. Sin embargo, la componente estacional tiene un orden muy peculiar: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, s3 de octubre, hasta s11 que sería febrero y s12 que es enero. Podemos reproducir las predicciones para los primeros 12 meses de enero a diciembre con (ojo, el etiquetado de la salida no es correcto):

```{r}
(nacimientosbf$model$states[TT, 1] + (1:12)*nacimientosbf$model$states[TT, 2]) * 
  nacimientosbf$model$states[TT, 14:3]
```

La figura 9 muestra la serie Nacimientos y las previsiones extra-muestrales.
 
```{r}
autoplot(nacimientosbf,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 9. Nacimientos y predicción con alisado de Holt-Winters multiplicativo",
         PI = FALSE)
```

## Ejemplo con transformación logarítmica

Una alternativa a predecir la serie Nacimientos, que tiene esquema multiplicativo, es predecir la transformación logarítmica de la serie, que tendrá un esquema aditivo. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original.

Este proceso se puede realizar de forma sencilla y transparente con cualquiera de las funciones de alisado exponencial que hemos visto a partir de los argumentos `lambda` y `biasadj`.

* `lambda = 0` indica a la función de alisado que se ha de realizar la transformación logarítmica de la serie. Es un parámetro de la transformación Box-Cox que veremos en detalle en el tema 3. 
* `biasadj = TRUE` es necesario si tras una transformación de la serie original queremos que las predicciones sean insesgadas. Sea $y_t$ la serie original y $z_t=log(y_t)$ su transformación logarítmica. Si obtenemos una predicción $\hat{y}_t$ de la serie original, esta será insesgada $E[\hat{y}_t]=y_t$. Ahora bien, si obtenemos una predicción $\hat{z}_t$ de la serie transformada, podemos pensar que $e^{\hat{z}_t}$ es una predicción insesgada de la serie original, pero resulta que $E[e^{\hat{z}_t}] \neq y_t$. Es decir, la exponencial de la predicción de la serie transformada logarítmicamente no es insesgada. Si el argumento `biasadj` es fijado a FALSE, las predicciones se calcularan de forma directa deshaciendo la transformación y serán sesgadas; si es fijado a TRUE, las predicciones se calcularan por medio de una fórmula alternativa y serán insesgadas. En ambos casos las estimaciones son consistentes, así que para series largas no debería observarse mucha diferencia entre las dos alternativas.

Vamos a practicar el uso de estos argumentos con la serie Nacimientos. Como se va a predecir el logaritmo de la serie, se debe indicar a la función `hw` que use el modelo Holt-Winters aditivo.

```{r}
nacimientosbfl <- hw(nacimientosb, 
                     seasonal = "addit", 
                     h = 24, 
                     lambda = 0, 
                     biasadj = TRUE)
summary(nacimientosbfl)
```

Observa que en este caso la calidad de las predicciones (MAPE = 1.9%) es inferior a la obtenida con la serie sin transformar.

La figura 10 muestra la serie Nacimientos y las previsiones extra-muestrales obtenidas con y sin la transformación logarítmica.
 
```{r, echo = FALSE}
autoplot(nacimientosb,
         xlab = "",
         ylab = "Nacimientos",
         main = "Figura 10. Nacimientos y dos predicciones con alisado de Holt-Winters") + 
  autolayer(nacimientosbf, series = "Nacimientos", PI = FALSE) + 
  autolayer(nacimientosbfl, series = "Nacimientos (log)", PI = FALSE) + 
  guides(colour = guide_legend(title = "Predicción")) + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

La siguiente tabla muestra las predicciones de Nacimientos obtenidas sin transformar la serie, con transformación logarítmica y predicciones insesgadas (`biasadj = TRUE`), y con transformación logarítmica y predicciones sesgadas (`biasadj = FALSE`).

```{r, echo = FALSE}
nacimientosbfl2 <- hw(nacimientosb, seasonal = "addit", h=24, lambda = 0, biasadj = FALSE)
datos <- cbind(
  `Sin transformar` = nacimientosbf$mean,
  `log(Nac) insesgadas` = nacimientosbfl$mean,
  `log(Nac) sesgadas` = nacimientosbfl2$mean
  )
head(datos, 12)
```

Observa que las predicciones sesgadas son menores que las insesgadas. Esto siempre es así. La diferencia depende fundamentalmente de la varianza del error, _sigma_ al cuadrado en la salida de los métodos de alisado exponencial. Cuanto mayor es la varianza del error, mayores son las diferencias.

Por otro lado, las predicciones obtenidas sin y con la transformación logarítmica no guardan ninguna relación.

**Ni la transformación logarítmica ni el uso de predicciones insesgadas aseguran mejores predicciones respecto de otras opciones**, como pueden ser trabajar con predicciones sesgadas o no realizar la transformación logarítmica.

\

## Casos generales de alisado exponencial

En los epígrafes previos hemos visto cinco de los casos expuestos en la taxonomía del epígrafe 4.3, y las funciones de `R` asociadas. Veamos ahora como estimar cualquiera de los quince modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md) y de la estacionalidad (N, A y M). 

Recordemos que al añadir el error, aditivo o multiplicativo, estos quince modelos se convierten en treinta. Sin embargo, el tipo de error no influye en el cálculo de las previsiones, solo influye en el cálculo del intervalo de confianza de estas.

### La función `ets` {-}

Podemos estimar cualquiera de los treinta modelos usando la función `ets` del paquete `forecast`. A diferencia de las funciones previas `ses`, `holt` y `hw`, la función `ets` solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función `forecast` sobre un modelo estimado con `ets`. Mira la ayuda para ver una explicación detallada de los argumentos de estas funciones.

* El tipo de modelo en `ets` se especifica con el argumento `model`, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, `model = "ANN"` indica un modelo con error aditivo, sin tendencia ni estacionalidad, es decir, el alisado exponencial simple; `model = "AAN"` indica un modelo con error aditivo, pendiente aditiva, pero sin estacionalidad, el alisado exponencial de Holt. El alisado exponencial de Holt-Winters multiplicativo sería `model = "AAM"`.
* Si se desea incluir amortiguamiento, hay que incluir el argumento `damped = TRUE`. 
* Por defecto `ets` no considera modelos con tendencia multiplicativa (últimas dos líneas de la taxonomía del epígrafe 5.3). Debes fijar el parámetro `allow.multiplicative.trend=TRUE` para contemplar esta opción.
* Además, se sigue disponiendo de los argumentos `lambda` y `biasadj`.

__Criterios de optimización__

Fijado un modelo, `ets` estima por defecto sus parámetros maximizando la función de verosimilitud. Esta búsqueda esta restringida a $0 < \beta < \alpha < 1$, $0 < \gamma < 1 - \alpha$ y $0.8 < \phi < 0.98$. Es decir, los tres primeros parámetros nunca pueden ser 0 o 1, y en la práctica sus valores límite son 0.0001 y 0.9999.

Puedes cambiar el criterio de optimización con el argumento `opt.crit`. Por defecto vale "lik", pero si lo fijas a `opt.crit = "mse"` se estiman los parámetros que minimizan el error cuadrático medio. Otra opción interesante es `opt.crit = "amse"` que minimiza la media de los errores cuadráticos medios obtenido sobre las previsiones a `nmse` periodos vista. En este caso usa el argumento `nmse` para fijar el valor numérico del horizonte temporal.

__Selección de modelos__

Lo más habitual es no saber cual es el mejor modelo, entendiendo como tal, el que mejor se ajusta a la serie temporal. De hecho, si lo que buscamos es predecir bien, más que entender la naturaleza del proceso generador de datos, el mejor modelo será el que mejor prediga.

Si en una de las tres letras del código del modelo se indica "Z", la función `ets` selecciona de entre los modelos posibles el que mejor se ajusta. Por ejemplo, `model = "AAZ"` indica un modelo con error y pendiente aditivos y dejaría a `ets` la búsqueda de la mejor opción para la estacionalidad (nula, aditiva o multiplicativa). Si se especifica `model = "ZZZ` junto con `damped = NULL` (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos (excepto aquellos con pendiente multiplicativa). Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar `damped = FALSE` y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento `additive.only = TRUE`.

Queda pendiente saber que criterio se usa para seleccionar el modelo cuando se ofrece esta opción. Esto se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son:
$$aic = -2log(L) + 2k$$
$$aicc = aic + \frac{k(k+1)}{T-k-1}$$
$$bic=aic + k(log(T) - 2)$$
\noindent donde $L$ es la verosimilitud, $T$ el número de datos y $k$ el de parámetros (incluidos los puntos iniciales de arranque y la varianza residual).

Por defecto se usa Akaike corregido para pequeñas muestras, pero el argumento `ic` permite cambiar de criterio. 

### Una reflexión sobre los métodos automáticos de selección de modelos {-}

Con el comando `forecast(ets(nacimientos), h = 24)` obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?

Parémonos a reflexionar sobre lo que hemos hecho --más bien lo que el algoritmo ha hecho-- y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.

Si consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intra-muestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.

Pero no es esto lo que hacemos. 

Nada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por _mejores_ quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea que el minimiza nuestro criterio de calidad de las predicciones.

Ahora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.

Alguien dirá que casi seguro entre las predicciones sub-óptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo sub-óptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.

Esta reflexión realizada en el contexto de series temporales y para la función `ets` es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados.

A pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir tu propio código, seguiremos trabajando con modelos sub-óptimos y obteniendo estimaciones sub-óptimas, pero diciendo que son las mejores.

\

### Residuo aditivo versus residuo multiplicativo {-}

En los modelos de alisado estimados por la función `ets` la fórmula para el cálculo del residuo estimado depende de su naturaleza aditiva o multiplicativa.

Si el __residuo es aditivo__, entonces el modelo es $y_t = \hat{y}_t + \hat{\varepsilon}_t$ y el residuo se define de la forma usual 
$$\hat{\varepsilon}_t = y_t - \hat{y}_t.$$
Ahora bien, si el __residuo es multiplicativo__, entonces el modelo es $y_t = \hat{y}_t \cdot (1 + \hat{\varepsilon}_t)$, y no $y_t = \hat{y}_t \cdot \hat{\varepsilon}_t$, como se podría esperar. Por tanto, el residuo multiplicativo se define como 
$$\varepsilon_t = (y_t - \hat{y}_t)/\hat{y}_t.$$
De esta forma en ambos casos el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco. 

La función `residual` permite extraer de un objeto `ets` el residuo del modelo. Si el modelo tiene residuo multiplicativo y se desea obtener el residuo aditivo, se debe usar con el argumento `type = "response"`.

\
\

# Ejemplo de aplicación: Libros

\

## Identificación y estimación del mejor modelo

Si estimamos el mejor modelo de alisado exponencial para la serie Libros sin ningún tipo de restricción, nos encontramos:

```{r}
librosEts <- ets(libros)
summary(librosEts) 
```

El modelo estimado es ETS(M,N,N) o "MNN", un modelo sin pendiente ni estacionalidad y con error multiplicativo. Es decir, $y_{t+1} = l_t \cdot (1 + \varepsilon_{t+1})$. 

El valor de $\alpha$ técnicamente es 1, indicando que el nivel de la serie varia en el tiempo y que realmente estamos usando para las previsiones el método ingenuo I.

Respecto de la calidad del modelo, el valor de MAPE= $`r round(accuracy(librosEts)[5],1)`$% evidencia que estamos ante un modelo que ajusta razonablemente bien a los datos, y MASE= $`r round(accuracy(librosEts)[6],2)`$ indica que el modelo de alisado exponencial simple reduce en solo un $`r 100 - round(100*accuracy(librosEts)[6],0)`$% el error del método ingenuo I.


## Predicción

Mediante la función `forecast` podemos predecir los casos de Libros. Por tratarse de un modelo de alisado exponencial simple, la predicción es constante en el tiempo (véase figura 11).

```{r}
librosEtsPre <- forecast(librosEts, h = 5)
librosEtsPre
autoplot(librosEtsPre,
         xlab = "",
         ylab = "Títulos",
         main = "Figura 11. Libros y predicción a 5 años vista")
```

## Análisis del error

El error de un modelo de alisado _contiene_ la componente de __Intervención__ y el propio término de __Error__. Ver numérica o gráficamente el error permite identificar fácilmente la presencia de valores atípicos (intervención).

El modelo de alisado tiene error multiplicativo así que debemos usar el argumento `type = "response"` para obtener el error aditivo con `residuals`.

```{r}
error <- residuals(librosEts, type = "response")
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "Figura 12: Error + Intervención") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(1993, 2019, 2)) 
```

La figura 12 muestra que aunque algún error supera las dos desviaciones típicas, ninguno puede ser considerado como claramente atípico.

## Validación: error extra-muestral

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo el MAPE para __previsiones extra-muestrales a varios periodos vista__. Para ello vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Libros y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie Libros. 

Recordemos que los resultados dependen tremendamente del punto de corte temporal seleccionado.


```{r}
# Definimos las observaciones intra- y extra-muestrales
librosIntra <- subset(libros, end = length(libros) - 6)
librosExtra <- subset(libros, start = length(libros) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos
librosIntraEts <- ets(librosIntra, model = "MNN")

# Predecimos los 7 años que hemos quitado de la serie y 
# vemos la calidad del ajuste.
librosExtraPre <- forecast(librosIntraEts, h = 6)
accuracy(librosExtraPre, librosExtra)
```

```{r, echo=FALSE}
error.muestral.1 <- round(accuracy(librosExtraPre, librosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(librosExtraPre, librosExtra)[2,5],1)
```
Atendiendo al MAPE se tiene que el error de __previsión a un periodo vista__ en el __periodo intra-muestral__ de __1993 a 2012__ es del `r error.muestral.1`%; mientras que el error de __previsión a largo plazo__ en el __periodo extra-muestral__ de __2013 a 2018__ es del `r error.extramuestral.n`%. Ademas, para el periodo extra-muestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas. En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas. 

Un gráfico puede ayudar a entender este proceso de validación. En la figura 13:

* La línea de puntos vertical separa el periodo muestral (1993-2012) usado para estimar el modelo, del periodo extra-muestral (2013-2018) usado sólo para hacer las previsiones.
* La serie Libros aparece como una línea sólida en negro, desde 1993 hasta 2018.
* La previsión _intra_-muestral (a un periodo vista) de la serie Libros aparece como una línea azul.
* La línea en rojo es la previsión _extra_-muestral a largo plazo: $\hat{y}_{T+h}=l_T$, donde $T=2012$. Observa que todas las previsiones están por encima del valor real de la serie.
* Al lado de cada previsión se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r,echo=FALSE}
autoplot(libros, series = "Libros",
         main="Figura 13. Libros, predicción intra- y extra-muestral",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(librosIntraEts), series = "Libros (ajustada)") + 
  autolayer(librosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2012.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Libros"="black",
                               "Libros (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=1999, y=65000, label="7.2%", colour = "blue") +
  annotate("text", x=2016, y=72000, label="17.8%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

\
\

__Nota:__ La presencia de tendencia, primero creciente y luego decreciente, en la serie Libros puede hacernos pensar que un modelo más adecuado para su ajuste y predicción sería ETS(M,A,N), forzando a que haya pendiente. De hecho, el error de estimación de este modelo es del 6.2%, frente al 7% para el modelo ETS(M,N,N). Sin embargo, el error de previsión extra-muestral a largo plazo para el modelo ETS(M,A,N) es del 31.5%, frente al 17.8% para el modelo ETS(M,N,N). De nuevo, incidir en que mayor calidad de ajuste no implica mayor calidad de predicción; y en que estos resultados dependen del punto de corte seleccionado.

# Ejemplo de aplicación: Nacimientos

Veamos un segundo ejemplo con la serie Nacimientos (desde el año 2000).

## Identificación y estimación del mejor modelo

Si damos total libertad al proceso de selección del mejor modelo, el óptimo tiene tendencia amortiguada con un parámetro $\phi = 0.98$, su máximo valor permitido. Este resultado aconseja repetir el proceso de selección del modelo restringido a aquellos sin amortiguamiento.

```{r}
nacimientosEts <- ets(nacimientosb, damped = FALSE)
summary(nacimientosEts) 
```

El modelo estimado es ETS(M,A,A), es decir, $y_{t+1} = (l_t + b_t +  s_{t+1-m}) \cdot (1+ \varepsilon_{t+1})$.

El bajo valor de $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la figura 14). 

```{r}
autoplot(nacimientosEts,
         xlab = "Periodo",
         main = "Figura 14. Componentes del modelo óptimo para Nacimientos")
```

Respecto de la calidad del modelo, el MAPE de `r round(accuracy(nacimientosEts)[5],1)`% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a `r round(summary(nacimientosEts)[6],2)` indica que este modelo reduce en un `r 100 - round(100*summary(nacimientosEts)[6],0)`% el error del método ingenuo con estacionalidad, el más sencillo posible, que ya utilizamos en el epígrafe 3 (aunque para la serie nacimientos completa).
      
Podemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos.

```{r, eval = FALSE}
TT <- nrow(nacimientosEts$states)
nacimientosEts$states[TT,]
```

```{r, echo = FALSE}
TT <- nrow(nacimientosEts$states)
round(nacimientosEts$states[TT,],2)[1:7]
round(nacimientosEts$states[TT,],2)[8:14]
```

También podemos usarlos para predecir un año:
```{r, eval = FALSE}
nacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + 
  nacimientosEts$states[TT, 14:3]
```

```{r, echo = FALSE}
nacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + nacimientosEts$states[TT, 14:3]
```

Febrero es el mes con menor número de nacimientos: nacen `r abs(trunc(nacimientosEts$states[TT,13]))` bebés menos, respecto de la media anual. En octubre es cuando más niños nacen: `r trunc(nacimientosEts$states[TT,5])` más que la media anual.

Nuestra predicción para enero de 2019 es de `r as.integer((nacimientosEts$states[TT, 1] +  nacimientosEts$states[TT, 2]) + nacimientosEts$states[TT, 14])` bebés y para diciembre de 2019 de `r as.integer((nacimientosEts$states[TT, 1] + 12 * nacimientosEts$states[TT, 2]) + nacimientosEts$states[TT, 3])` bebés.

## Predicción

Si pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):
```{r, eval = FALSE}
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
nacimientosEtsPre
```

```{r, echo = FALSE}
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
forecast(nacimientosEts, h = 5, level = 95)
```

Gráficamente,
```{r}
autoplot(nacimientosEtsPre,
         xlab = "",
         ylab = "Bebés",
         main = "Figura 15. Nacimientos y predicción")
```

## Análisis del error

El modelo de alisado tiene error multiplicativo así que debemos usar el argumento `type = "response"` para obtener el error aditivo con `residuals`.

```{r}
error <- residuals(nacimientosEts, type = "response")
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "Figura 16: Error + Intervención") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(2000, 2019, 2)) 
```

Se identifica un valor claramente atípico --supera las 4 desviaciones típicas-- que corresponde a enero de 2011. Abril de 2008 es otro candidato a intervención por alcanzar las 3 desviaciones típicas.

## Validación: error extra-muestral

En este caso vamos a aplicar la metodología __origen de predicción móvil__ (_rolling forecast origin_) o _rolling windows_. Asumimos que se precisan diez años para hacer una buena estimación, $k=120$, y que el horizonte temporal es de 12 meses, $h = 12$. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a doce meses.
  
```{r}  
k <- 120                  #Minimo numero de datos para estimar
h <- 12                   #Horizonte de las prediciciones
TT <- length(nacimientosb)    #Longitud serie
s <- TT - k - h           #Total de estimaciones

mapeEts <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacimientosb, start = i + 1, end = i + k)
  test.set <-  subset(nacimientosb, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set,  model = "MAA", damped = FALSE)
  fcast <- forecast(fit, h = h)
  mapeEts[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

mapeEts <- colMeans(mapeEts)
round(mapeEts, 2)
```

El error extra-muestral a un periodo vista es comparable al error intra-muestral (1.9% frente a 1.8%). Aunque el error de previsión aumenta conforme lo hace el horizonte temporal, siempre se mantiene muy bajo. Por ejemplo, en las previsiones a 12 meses vista el error es del 3.5%.

\

## Otras alternativas para predecir Nacimientos

A la hora de predecir hay que ser un poco imaginativos, dedicarle tiempo y probar cosas. Por ejemplo, podríamos predecir los nacimientos a partir del ajuste de la transformación logarítmica. O podemos probar a cambiar el criterio de estimación de los parámetros o el de selección del modelo óptimo.

Yendo un poco más lejos, y dado que el número de nacimientos depende forzosamente del número de días del mes, podemos predecir los nacimientos medios por día (cociente entre los nacimientos de cada mes y el número de días del mes). Esta serie tendrá una componente estacional más suave, elimina el efecto de los febreros bisiestos y tendrá, previsiblemente un mejor ajuste.

También podemos mezclar varios de los enfoques previos o ser aún más imaginativos.

El siguiente código muestra el MAPE (para previsiones intra-muestrales a un periodo vista) para varias de estas opciones. Puedes deducir que se está haciendo en cada caso a partir del código. Sería más adecuado usar otro criterio de validación diferente, pero el objetivo de este epígrafe es recalcar que no hay que quedarse con lo inmediato (predecir Nacimientos con las opciones por defecto de las funciones), sino probar y probar.

```{r}
# Serie Nacimientos
accuracy(ets(nacimientosb, 
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Transformación logarítmica
accuracy(ets(nacimientosb, 
             lambda = 0, 
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             lambda = 0, 
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Transformación logarítmica insesgada
accuracy(ets(nacimientosb, 
             lambda = 0, 
             biasadj = TRUE,
             damped = FALSE))[5]
accuracy(ets(nacimientosb, 
             lambda = 0, 
             biasadj = TRUE,
             damped = FALSE, 
             opt.crit = "mse"))[5]

# Nacimientos por dia
accuracy(ets(nacimientosb/monthdays(nacimientosb), 
             damped = FALSE))[5]
accuracy(ets(nacimientosb/monthdays(nacimientosb), 
             damped = FALSE, 
             opt.crit = "mse"))[5]
```

La principal conclusión en este caso es que salirse de la estimación directa sobre la serie original no reduce el error significativamente. Sin embargo, cabe destacar que, 

* El error de estimación de los nacimientos por día es menor, al tratarse de una serie con mejor comportamiento, aunque la ganancia no es mucha. (Véanse los dos últimos modelos respecto de los dos primeros)
* Usar la transformación logarítmica (con o sin predicciones insesgadas) no mejora la capacidad predictiva del modelo. (Véanse los modelos 3 a 6 respecto de los modelos 1 y 2)
* El mejor modelo estima los nacimientos por día y estima los parámetros minimizando el error cuadrático medio ("mse"). Todo menos lo _directo_.


\
\

# Resumen de los comandos utilizados


|Función  |Paquete | Descripción                                           |
|:--------------|:-----------|:-----------------------------------------------------|
|`meanf`        |forecast  |Predicción por media |
|`naive`        |forecast  |Predicción por método ingenuo I |
|`rwf`          |forecast  |Predicción con tendencia media |
|`snaive`	      |forecast  |Predicción por método ingenuo con estacionalidad |
|`accuracy`	    |forecast  |Calculo de la precisión del modelo |
|`forecast`     |forecast  |Predice valores extra-muestrales futuros de la serie |
|`ses`          |forecast  |Estimación del modelo de alisado exponencial simple|
|`holt`         |forecast   |Estimación del modelo de alisado exponencial de Holt|
|`hw`           |forecast |Estimación del modelo de alisado exponencial de Holt-Winters|
|`ets`          |forecast  |Estimación de una amplia familia de métodos de alisado exponencial|
|`residuals`    |stats   |Obtiene el residuo de un modelo estimado|
|`fitted`       |stats     |Obtiene las predicciones a un periodo vista intra-muestrales|

\
\

# Referencias

* Brown, R. G. (1959). _Statistical forecasting for inventory control_. Ed. McGraw/Hill.

* Gardner, Jr, E. S. y McKenzie, E. (1985) _Forecasting trends in time series_, Management Science, 31(10), pp. 1237–1246. doi:10.1287/mnsc.31.10.1237

* Holt, C. E. (1957). _Forecasting seasonals and trends by exponentially weighted averages_ O.N.R. Memorandum No. 52. Carnegie Institute of Technology, Pittsburgh USA. doi:10.1016/j.ijforecast.2003.09.015

* Hyndman, R. J. y Khandakar, Y. (2008) _Automatic Time Series Forecasting: The forecast Package for R_. Journal of Statistical Software, 27(3), pp. 1-22. doi:10.18637/jss.v027.i03

* Hyndman, R. J., Koehler, A., B., Ord, J. K. y Snyder, R. D. (2008) _Forecasting with Exponential Smoothing: the State Space Approach_. Ed. Springer.

* Makridakis, S. y  Hibon, M. (2000). _The M3-Competition: results, conclusions and implications_. International Journal of Forecasting, 16(4), pp. 451–476. doi:10.1016/S0169-2070(00)00057-1

* Winters, P. R. (1960). _Forecasting sales by exponentially weighted moving averages_. Management Science, 6, pp. 324–342.  doi:10.1287/mnsc.6.3.324

\
\
\
\
</div>
<footer class="footer">
  
<a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-sa/4.0/88x31.png" /></a>
<br>
This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.  <div class="text-muted">Website created by Iv&aacute;n Arribas. &copy;  2020. If you find any bugs please report them to <a href="mailto:ivan.arribas@uv.es"> ivan.arribas@uv.es</a>.</div>
  
</footer>




</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->
<script>
$(document).ready(function () {
  window.initializeSourceEmbed("03-02-Tema2.Rmd");
});
</script>

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
