---
title: "Bootstrapping para obtener intervalos de predicción"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
subtitle: "Máster de Bioestadística (Modelización Estadística)"
toc: false
number-sections: true
bibliography: references.bib
crossref:
  fig-title: Figura
  tbl-title: Tabla
  fig-prefix: Figura
  tbl-prefix: Tabla
---

```{r}
#| label: chunk_setup
#| echo: false
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      error = FALSE,
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%")
```

```{r}
#| echo: false
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(tidyverse)
```

\
\

# Antecedentes

En el curso hemos aprendido como obtener predicciones puntuales con diferentes métodos: Ingenuo I, Deriva, Ingenuo con estacionalidad, Alisado Exponencial... Por *aprendido* quiero decir que conocemos la fórmula para calcular la predicción, que sabríamos hacer las predicciones a mano y que en algunas clases de práctica así lo hemos hecho.

También hemos aprendido a obtener intervalos de predicción, aunque nunca hemos visto las fórmulas que hay detrás de estos intervalos. De forma general, si $\hat y_{T+h|T}$ es la predicción a $h$ periodos vista, su intervalo de predicción se puede escribir como

$$[\hat y_{T+h|T} - c\cdot \hat \sigma_h,\;\; \hat y_{T+h|T} + c\cdot \hat \sigma_h]$$ donde $c$ depende del nivel de confianza del intervalo de predicción, por ejemplo $c=1.96$ para un nivel de confianza del 95%; y $\hat \sigma_h$ es una estimación de la desviación típica del error de predicción $h$ periodos adelante. Observa que, por su forma de cálculo, estos intervalos siempre son simétricos en torno a la predicción.

Bajo ciertos supuestos sobre la serie temporal y su residuo, se puede obtener matemáticamente la expresión de $\hat \sigma_h$. Por ejemplo,

-   Método Ingenuo I: $\hat \sigma_h = \hat \sigma \sqrt{h}$, donde $\hat \sigma$ es la desviación típica del error del modelo.

-   Método Ingenuo con estacionalidad $\hat \sigma_h = \hat \sigma \sqrt{s +1}$, donde $s=\lfloor(h-1)/m\rfloor$.

-   Método de la deriva: $\hat \sigma_h = \hat \sigma \sqrt{h(1 + h/T)}$.

-   Alisado simple: $\hat \sigma_h = \hat \sigma \sqrt{1 + (h-1)\alpha^2}$.

-   Alisado de Holt: $\hat \sigma_h = \hat \sigma \sqrt{1 + (h-1)(\alpha^2 + \alpha\beta h + \frac{1}{6}\beta^2 h (2 h -1))}$.

-   Arima(0, 0, q): $\hat \sigma_h = \hat \sigma \sqrt{1 + \sum_{i=1}^h \theta_i^2}$, donde $\theta_i = 0$ para $i>q$.

Para otros métodos de alisado o ARIMA la fórmula es más compleja.

Entre los supuestos sobre el residuo necesarios para que estas formulas sean correctas están que se distribuya como una normal y que sea incorrelado (¿recuerdas el ACF1 de los indicadores de calidad?). Cuando alguno de estos dos supuestos no se da, el intervalo de confianza de las predicciones obtenido con estas fórmulas es incorrecto y, entonces, bootstrapping es una buena alternativa para obtener el intervalo de confianza de la predicción.

\

# Bootstrapping para obtener intervalos de predicción

Lo que viene a continuación no es del todo preciso porque para series temporales se usa algo denominado "block bootstrapping", pero aquí solo pretendo que tengáis una idea aproximada del procedimiento que se sigue para obtener un intervalo de predicción usando bootstrapping.

## Idea general {-}

Veamos primero la idea general y luego los detalles:

1.  Partimos de una serie temporal $\{y_t\}_{t=1}^T$ y un horizonte de predicción $h$.

2.  A partir de la serie original vamos a generar una nueva serie que es *similar* a la original. Luego veremos como.

3.  Ajustamos nuestro modelo a la nueva serie y obtenemos una predicción $h$ periodos hacia adelante, que llamaremos $\hat y_{T+h|T}^1$.

4.  Repetimos los pasos 2 y 3 un numero $n$ de veces (típicamente $n=5000$), de forma que al final del proceso tenemos $n$ predicciones $h$ periodos hacia adelante, $\hat y_{T+h|T}^1,\; \hat y_{T+h|T}^2,\; \ldots,\; \hat y_{T+h|T}^n$, obtenidas a partir de $n$ series similares a la original.

5.  Por último, obtenemos el intervalo de predicción calculando los percentiles correspondientes a partir de estas $n$ predicciones.

Este proceso hay que repetirlo para cada horizonte de predicción en que estemos interesados.

## Detalles {-}

La clave del proceso es el paso 2, donde se obtiene una *nueva serie similar a la original*. También vale la pena aclarar un poco más el paso 5.

**Paso 2: nueva serie**

En lo que viene a continuación no voy a ser riguroso para no perdernos en cuestiones matemáticas, pero sí suficientemente preciso para entender bien el proceso.

-   Dada la serie original, la descomponemos en sus tres componentes: tendencia, estacionalidad y error.

-   A continuación, obtenemos una versión barajada de la componente del error. (Aquí es donde no estoy siendo preciso porque el proceso de barajado se tiene que hacer por bloques y es con reemplazamiento.)

-   Ahora se combinan --sumando o multiplicando, según el esquema-- la tendencia, la estacionalidad y el **error barajado** para obtener una nueva serie que se parecerá a la original porque tiene la misma tendencia y estacionalidad, pero diferente error.

Veamos un ejemplo muy sencillo para una serie simulada de orden estacional 5.

-   La dos primeras columnas indican la estación de cada dato y el valor de la serie, para un total de 15 observaciones.

-   Las columnas *Tendencia*, *Estacionalidad* y *Error* han sido obtenidas aplicando el método de descomposición por regresiones locales ponderadas. Observa que cada dato de la serie es la suma de estas tres componentes.

-   La columna *ErrorBootstrapping* se ha obtenido como un muestreo con reemplazamiento de los datos de la columna *Error*. Como es una muestra con reemplazamiento, hay algunos errores repetidos.

-   Por último, la nueva serie (columna *NuevaSerie*) se ha obtenido sumando las columnas *Tendencia*, *Estacionalidad* y *ErrorBootstrapping*. Esta serie tiene la misma tendencia y estacionalidad que la serie original y solo se diferencia en el error, así que la nueva serie debería parecerse a la serie original.

```{r}
#| echo: false
set.seed(324535)
datos <- data.frame(
  Estacion = rep(1:5 ,3),
  Serie = round(5*(rep(1:5, 3) - 3  + rnorm(15))^2 + 11:25, 2)
)

serie <- ts(datos$Serie, start = 1, freq = 5)

des <- stl(serie, s.window="periodic")
datos$Tendencia <- trendcycle(des)
datos$Estacionalidad <- seasonal(des)
datos$Error <- remainder(des)

datos$ErrorBootstrapping <- sample(datos$Error, 15, replace = TRUE)
datos$NuevaSerie <- datos$Tendencia + datos$Estacionalidad + datos$ErrorBootstrapping
round(datos, 2)
```

**Paso 5: Predicción por intervalos**

Partimos de $n$ predicciones a $h$ periodos vista ($\hat y_{T+h|T}^1,\; \hat y_{T+h|T}^2,\; \ldots,\; \hat y_{T+h|T}^n$) y queremos obtener a partir de ellas el intervalo de confianza.

Supongamos que el nivel de confianza deseado es del 95%. Entonces, debemos calcular para las predicciones el percentil 2.5% y 97.5%. Recuerda que el percentil 2.5% es el valor numérico que deja un 2.5% de las predicciones por debajo de él; y que el percentil 97.5% es el valor numérico que deja un 97.5% de las predicciones por debajo de él. La función de `R` `quantile()` permite obtener estos valores.

Si denominamos $l_h$ al percentil 2.5% y $u_h$ al percentil 97.5%, el intervalo de confianza de la predicción a $h$ periodos vista es $[l_h,\; u_h]$.

**¿Y la prediccion puntual?**

Para la predicción puntual tenemos dos opciones: obtener la predicción a partir de la serie original (como hemos visto en clase); u obtenerla como media de las $n$ predicciones obtenidas

$$\frac{1}{n}\sum_{j=1}^n \hat y_{T+h|T}^j$$

Este segundo método es el usual y se denomina bagging de **b**ootstrap **agg**regat**ing**.

# Ejemplo

Vamos a ver un sencillo ejemplo con la serie de nacimientos desde el año 2000 y hasta el año 2019.

En primer lugar y con propósito meramente ilustrativo, hemos calculado 10 versiones de la serie original de nacimientos obtenidas por bootstraping (paso 2 de la idea general). La @fig-NacimientosBT muestra la serie original (en negro) y las 10 simulaciones.

```{r}
#| echo: false
nacimientos <- read.csv2("./series/nacimientos.csv", 
                         header = TRUE)

nacimientos <- ts(nacimientos[, 2],
                  start = c(1975, 1),
                  frequency = 12)

nacimientos <- window(nacimientos, start = 2000, end = c(2019, 12))
```

```{r}
#| label: fig-NacimientosBT
#| fig-cap: "Nacimientos y diez simulaciones"
bootseries <- bld.mbb.bootstrap(nacimientos, 10) %>%
  as.data.frame() %>% 
  ts(start=2000, frequency=12)

autoplot(bootseries, colour=TRUE) +
  autolayer(nacimientos, colour=FALSE) +
  ylab("Nacimientos") +
  xlab("") +
  guides(colour="none")
```

Ahora vamos a ajustar la serie por Alisado Exponencial y obtener las predicciones y sus intervalos a 12 meses vista. Vamos a realizar estos cálculos de dos formas, usando la fórmula teórica --que solo es correcta bajo ciertos supuestos sobre el residuo-- y por bootstrapping. Para el segundo caso necesitamos la función de `R` `baggedETS`, que por defecto genera 100 nuevas series por bootstrapping.

```{r}
#| echo: false
t1 <- Sys.time()
```

```{r}
nacimientosETS <- ets(nacimientos)

etsfc <- forecast(nacimientosETS,
                  h=12, 
                  level=95)

etsfc
```

```{r}
#| echo: false
t1 <- Sys.time() - t1
t2 <- Sys.time()
```

```{r}
nacimientosBagETS<- baggedETS(nacimientos)

baggedetsfc <- forecast(nacimientosBagETS,
                        h=12,
                        level=95)

baggedetsfc
```

```{r}
#| echo: false
t2 <- Sys.time() - t2
```

Observa que ni las predicciones puntuales ni sus intervalos coinciden. Las predicciones son muy parecidas, pero en este caso las obtenidas con bootstrapping son algo superiores a las obtenidas por Alisado (véase @fig-NacimientosPre a). Además, los intervalos de confianza obtenidos por bootstrapping no son simétricos respecto de la predicción y son más pequeños que los estimados usando las fórmulas clásicas (véase @fig-NacimientosPre b).

```{r}
#| echo: false
#| label: fig-NacimientosPre
#| fig-cap: "Nacimientos y predicciones puntuales y por intervalo con bootstrapping"
#| fig-subcap: 
#|   - "Nacimientos y predicciones puntuales para el año 2020"
#|   - "Intervalos de confianza"
#| layout-nrow: 2
autoplot(nacimientos) +
  ggtitle("") +
  xlab("Año") + 
  ylab("Bebés") +
  xlim(2015, 2021) + 
  autolayer(baggedetsfc, series="Bootstraping", PI = FALSE) +
  autolayer(etsfc, series="ETS", PI = FALSE) + 
  labs(colour = "Series") + 
  theme(legend.position=c(0.1,0.8))

autoplot(nacimientos) +
  ggtitle("") +
  xlab("Año") + 
  ylab("Bebés") +
  xlim(2019, 2021) + 
  autolayer(etsfc, series="ETS") +
  autolayer(baggedetsfc, series="Bootstraping") +
  labs(colour = "Series") + 
  theme(legend.position=c(0.1,0.8))
```

En media, bagging da mejores predicciones que la simple aplicación de `ets()` a la serie original. Pero como nada es gratis, esta mejora es a costa de un incremento significativo en los tiempos de computación. En concreto, por Alisado los cálculos tardan `r round(t1, 2)` segundos y por bootstrapping tardan `r round(t2, 2)` segundos, ¡y solo hemos pedido 100 simulaciones, no las habituales 5000!

\
\
\
\
