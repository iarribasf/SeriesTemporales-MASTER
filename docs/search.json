[
  {
    "objectID": "04-03-Redes_neuronales.html",
    "href": "04-03-Redes_neuronales.html",
    "title": "Autorregresión con redes neuronales",
    "section": "",
    "text": "1 Antecedentes\nEn las dos grandes familias de modelos que permiten ajustar y predecir series temporales –Alisado exponencial y modelos Arima– se ajusta un modelo a una serie temporal y el resultado del ajuste nos permite no solo predecir, sino aprender y entender el comportamiento de la serie. Por ejemplo, el resultado del ajuste por alisado nos permite saber si la pendiente de la serie cambia en el tiempo (parámetro \\(\\beta\\) del ajuste) o el tipo de esquema de la serie según que la estacionalidad sea aditiva o multiplicativa. Con los modelos Arima podemos estimar el impacto en la serie de un efecto calendario (Semana Santa, días laborables…).\nOtra familia de modelos muy versátiles que permiten predecir con todo tipo de datos –transversales, series temporales, imágenes, espacio-temporales…– son las redes neuronales. Estos modelos son el embrión del Deep Learning y el motor de muchas AI y los estudiaréis en detalle el próximo año en la asignatura Técnicas Avanzadas de Predicción en Negocios.\nVamos a ver muy, pero que muy por encima en que consisten las redes neuronales y como se pueden aplicar para predecir series temporales. Esto es una pequeña píldora.\n\n\n2 Arquitectura de una red neuronal de una capa\nUna red neuronal puede ser entendida como una red de neuronas dispuestas en capas. Siempre hay una capa de entrada de los datos y una capa de salida de la respuesta. Entre estas dos capas se puede disponer de tantas capas intermedias (ocultas) como se considere necesario.\nCada capa está formada por un número determinado y potencialmente diferente de neuronas o nodos. Los nodos de una capa están conectadas a los nodos de la siguiente. Por simplicidad asumiremos que todos los nodos de una capa se conectan con los nodos de la capa siguiente.\nAquí vamos a considerar solo redes neuronales con una capa intermedia y donde la capa de salida tiene solo una neurona. La Figura 1 es un ejemplo de este tipo de redes neuronales.\n\n\n\n\n\n\n\n\nFigura 1: Red neuronal con una sola capa intermedia\n\n\n\nEn esta red cada nodo de una capa recibe entradas de los nodos de la capa previa. Dicho de otra forma, las salidas de los nodos de una capa son las entradas de los nodos de la siguiente capa. Es lo que se denomina una multilayer feed-forward network.\nLas entradas que recibe cada nodo se combinan usando una función lineal ponderada. Por ejemplo, un nodo \\(j\\) de la capa intermedia recibe las dos entradas \\(x_1\\) y \\(x_2\\) de los nodos de la capa de entrada y los combina linealmente\n\\[z_j = b_j + \\sum_{i=1}^2 w_{i,j}x_i\\] Para los nodos de la capa intermedia el valor \\(z_j\\) se transforma usando una función no lineal, por ejemplo la sigmoidea:\n\\[s_j = \\frac{1}{1 + e^{-z_j}}\\] y este valor \\(s_j\\) es la salida del nodo \\(j\\) que va al nodo de la capa de salida.\nLos valores de los pesos \\(b_1\\), \\(b_2\\), \\(w_{1,1}\\), \\(w_{1,2}\\)…\\(w_{2,5}\\) se deben ajustar a partir de los datos. Estos valores suelen estar restringidos para evitar que sean demasiado grandes. El parámetro que restringe las ponderaciones se conoce como parámetro de decaimiento, y suele ser igual a \\(0.1\\).\nLos pesos toman valores aleatorios al principio y luego se actualizan con los datos observados en un proceso de aprendizaje. Por lo tanto, hay un elemento de aleatoriedad en las predicciones producidas por una red neuronal. Por este motivo, la red suele entrenarse varias veces utilizando diferentes puntos de partida aleatorios, y los resultados se promedian.\n\n\n3 Autoregresión de redes neuronales\nEn el contexto de series temporales, los valores de entrada pueden ser valores retardados de la serie y el valor de salida deseado el valor contemporáneo. De la misma forma que en un modelo AR usamos los datos pasados para predecir el futuro.\n\n\n\n\n\n\nFigura 2: Red neuronal para predecir una serie temporal. El dato del periodo \\(t\\) se predice a partir de los dos datos previos.\n\n\n\nVamos a extender estas ideas e ir añadiendo algo de notación.\nComo hemos indicado vamos a considerar solo redes simples con una capa intermedia y una capa de salida de un solo nodo, que denominaremos \\(NNAR\\). La notación \\(NNAR(p, k)\\) indica que hay \\(p\\) valores desfasados en la capa de entrada y \\(k\\) nodos en la capa intermedia. Por ejemplo, la red de la Figura 2 es modelo \\(NNAR(2,5)\\), donde \\(y_{t-1}\\) e \\(y_{t-2}\\) son usados para predecir \\(y_t\\). Así, un modelo \\(NNAR(p, 0)\\) sería equivalente a un modelo \\(ARIMA(p,0,0)\\).\nSi la serie tiene estacionalidad es conveniente que entre los datos de entrada estén las observaciones pasadas de la misma estación que se desea predecir. Por ejemplo, para la serie diaria de consumo eléctrico un modelo \\(NNAR(2, 1, k)\\) usaría como datos de entrada \\(y_{t-1}\\), \\(y_{t-2}\\) e \\(y_{t-7}\\) para predecir \\(y_t\\). En general, \\(NNAR(p,P,k)_m\\) usa como datos de entrada \\(y_{t-1}\\),\\(y_{t-2}\\),…,\\(y_{t-p}\\),\\(y_{t-m}\\), \\(y_{t-2m}\\),…,\\(y_{t-Pm}\\) y una capa intermedia de \\(k\\) neuronas. Por lo tanto, \\(NNAR(p,P,0)_m\\) es equivalente a \\(ARIMA(p,0,0)(P,0,0)_m\\).\n\n\n4 Aplicación\nLa función nnetar de la librería forecast permite estimar modelos \\(NNAR(p,P,k)_m\\). En su forma más sencilla el usuario no tiene que especificar los valor de los parámetros \\(p\\), \\(P\\) y \\(k\\) ya que la función los identifica según ciertos criterios.\nLa siguiente gráfica muestra el consumo eléctrico en España en GWh para 17 semanas desde febrero hasta mayo de 2023. Hay una fuerte componente estacional diaria de orden \\(7\\), donde el consumo es alto de lunes a viernes, algo mas reducido el sábado y aún menor el domingo.\n\nelectricidad &lt;- read.csv(\"./series/Consumo electrico.csv\", \n                         header = TRUE)\n\nelectricidad &lt;- ts(electricidad[, 1], \n                   start = c(1, 7),\n                   frequency = 7)\n\nelectricidad &lt;- window(electricidad,\n                       start = c(7, 1),\n                       end = c(23, 7))\n\nautoplot(electricidad) + \n  ggtitle(\"\") +\n  ylab(\"GWh\") + \n  xlab(\"Semana\")\n\n\n\n\n\n\n\nFigura 3: Consumo eléctrico (febrero a mayo de 2023)\n\n\n\n\n\nLa Figura 4 muestra la serie y su predicción para los siguientes 14 días. El modelo ajustado es \\(NNAR(1,1,2)_7\\). Es decir, la capa de entrada tiene 2 nodos porque para predecir el consumo del día \\(t\\), \\(y_t\\), se usa el consumo del día previo \\(y_{t-1}\\) y el consumo de hace una semana \\(y_{t-7}\\). La capa intermedia tiene dos nodos.\n\nfit &lt;- nnetar(electricidad)\n\naccuracy(fit)\n\n                       ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -0.003522209 31.02647 21.69363 -0.2674735 3.488865 0.7799231\n                  ACF1\nTraining set 0.4808039\n\n\nEl error de ajuste es de 3.5% o 31 GWh y el ajuste no presenta sesgo.\nPor otro lado, el ACF1 muestra una elevada autocorrelación de orden 1. Sin embargo, esto no afecta a la calidad de la predicción por intervalos porque con redes neuronales no se utiliza una fórmula cerrada que precise de la hipótesis de incorrelación. Se utiliza un proceso complejo y costoso temporalmente.\n\ntiempo &lt;- Sys.time()\n\npfit &lt;- forecast(fit, \n                 h = 14,\n                 level = 95,\n                 PI = TRUE)\n\nSys.time() - tiempo\n\nTime difference of 12.36857 secs\n\nautoplot(pfit) +\n  ylab(\"GWh\") + \n  xlab(\"Semana\")\n\n\n\n\n\n\n\nFigura 4: Consumo eléctrico (febrero a mayo de 2023) y predicción\n\n\n\n\n\n\npfit\n\n         Point Forecast    Lo 95    Hi 95\n24.00000       582.7681 521.0113 644.3734\n24.14286       609.8695 552.0627 670.9850\n24.28571       618.4790 555.2266 686.7446\n24.42857       629.3963 569.3561 691.9409\n24.57143       626.0324 562.4529 691.4722\n24.71429       578.3370 515.1470 646.6450\n24.85714       551.8244 488.1199 619.7140\n25.00000       561.5289 494.8116 637.0061\n25.14286       582.6359 507.6601 668.8267\n25.28571       594.8449 526.1968 680.7075\n25.42857       607.5927 527.2594 699.4689\n25.57143       608.2305 531.9688 692.8518\n25.71429       575.7486 509.4929 663.7323\n25.85714       555.1745 490.9350 640.7984\n\n\nLa función nnetar admite la inclusión de variables de intervención de la forma usual a través del argumento xreg."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html",
    "href": "03-20-Ejemplo-Pasajeros.html",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "",
    "text": "En este curso hemos aprendido a describir una serie temporal, estimar su proceso generador de datos y realizar predicciones, tanto puntuales como por intervalo. Para ello, hemos estudiado los principales aspectos teóricos relacionados con las series temporales, sus componentes, modelos de ajuste, predicción, criterios de calidad, etc. También hemos practicado la aplicación de estos conceptos a través de diferentes series temporales: Títulos publicados, Nacimientos, Aforo de vehículos, Consumo de alimentos per cápita, Exportaciones y Pernoctaciones de turistas extranjeros, entre otras.\nEl programa de estadística utilizado R ha servido con dos propósitos entremezclados durante el curso. En primer lugar, para ilustrar los aspectos teóricos que se iban presentando. En este caso, R tenía un uso más instrumental y en general se mostraba la salida obtenida sin enseñar el código. En segundo lugar, hemos aprendido a usar R para analizar y predecir una serie temporal real. Los ejemplos vistos en cada tema y el ejemplo transversal utilizado durante el curso de Pernoctaciones en alojamientos turísticos de turistas extranjeros son buenos exponentes de este uso de R.\nAhora bien, ambos usos de R –ilustrar aspectos teóricos y analizar una serie– han quedado distribuidos a lo largo de los temas. El ejemplo Pasajeros en transporte urbano, desarrollado aquí, tiene como objetivo disponer, en un único documento y de forma organizada, del análisis completo de una serie temporal. En este informe se mostrará siempre el código completo empleado para las salidas, se hará hincapié en la aplicación práctica de los conceptos teóricos, se insistirá en los diferentes enfoques que se pueden y deben emplear para analizar una serie temporal y se justificarán todas las decisiones adoptadas.\nEste es, por tanto, un ejemplo que se extiende más allá de lo que un informe de análisis de una serie temporal precisa.\nPara el código de este ejemplo se utilizarán funciones de las librerías básicas de R y de otras que se pueden encontrar en las siguientes librerías:\n\nlibrary(forecast)\nlibrary(ggplot2); theme_set(theme_bw())\nlibrary(seasonal)\nlibrary(lmtest)\nlibrary(timeDate)\nlibrary(knitr)"
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#análisis-de-la-tendencia",
    "href": "03-20-Ejemplo-Pasajeros.html#análisis-de-la-tendencia",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "2.1 Análisis de la tendencia",
    "text": "2.1 Análisis de la tendencia\nSi anualizamos la serie podemos, por un lado, identificar mejor en que años se producen los cambios en la tendencia y, por otro lado, poner cifras al volumen de pasajeros en transporte urbano.\n\nPasajerosAnual &lt;- aggregate(Pasajeros, FUN = sum)\n\nautoplot(PasajerosAnual, colour = \"darkblue\",\n         xlab = \"\",\n         ylab = \"Millones de pasajeros\",\n         main = \"\") +\n  scale_x_continuous(breaks= seq(1996, 2020, 2))\n\n\n\n\n\n\n\nFigura 2: Pasajeros en transporte urbano (datos anuales)\n\n\n\n\n\nLa Figura 2 muestra el volumen anual de pasajeros en transporte urbano. El crecimiento continuado, posiblemente iniciado antes de 1996 y que permitió superar los 3000 millones de pasajeros en 2007, se ve interrumpido con el inicio de la Gran Recesión. La caída en el número de pasajeros se interrumpe en 2014, año que marca la salida de esta crisis en España y el inicio de la recuperación en el serie. En 2019 se superaron los 3100 millones de pasajeros.\nEl incremento en el uso del transporte urbano observado antes y después de la crisis puede tener distintas causas: un uso más intensivo del transporte urbano en detrimento de otros medios de transporte, una reorganización de los servicios de transporte urbano que haya mejorado la conectividad dentro de los municipios, o un aumento en el número de líneas de autobús, tranvía o metro en determinadas ciudades.\nLa causa del repunte aislado observado el año 2011, en plena crisis, fue una ligera recuperación de la economía que tuvo lugar a finales de 2010 y principios de 2011."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#análisis-de-la-estacionalidad",
    "href": "03-20-Ejemplo-Pasajeros.html#análisis-de-la-estacionalidad",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "2.2 Análisis de la estacionalidad",
    "text": "2.2 Análisis de la estacionalidad\nLa principal causa de la estacionalidad observada en la serie es la estructura vacacional de la sociedad, especialmente caracterizada por las vacaciones de verano (julio a septiembre) y las vacaciones de Semana Santa (en marzo y/o abril, según el año). Además, debido a que el transporte urbano se usa principalmente para ir a trabajar o al centro de educación, también influye el número de días laborables del mes. Por ejemplo, en 2017 el mes de junio tuvo 22 días laborables, mientras que en 2019 tuvo 20 días laborables. Esta diferencia de dos días tendrá un efecto sobre el volumen de pasajeros.\nEl número de días laborables de un mes viene marcado por los fines de semana del mes y por las festividades nacionales. Es cierto que el sábado se trabaja en diversos sectores (comercio, ocio, distribución) pero la caída en el número de trabajadores respecto de los días entre semana (lunes a viernes) es muy notable. También es cierto que, además de las festividades nacionales, hay muchas festividades autonómicas o municipales que podrían afectar al volumen de pasajeros en transporte urbano. Por ejemplo, las festividades regionales en comunidades como Madrid o Cataluña pueden tener un efecto significativo sobre la serie Pasajeros. Sin embargo, las festividades no nacionales no se van a tener en cuenta.\nPor tanto, para realizar un análisis detallado de la estacionalidad, es necesario crear una serie con el número de días laborables de cada mes. Además, esta serie se usará más adelante para modelizar y predecir la serie Pasajeros.\n\nDías laborables de cada mes\nLa librería timeData proporciona una serie de funciones que permiten definir un calendario de festividades, identificar los fines de semana y, a partir de aquí, crear la serie de días laborables (véase código más abajo).\n\nCon timeCalendar se definen las festividades nacionales que vamos a considerar: Año nuevo (1 de enero), Reyes (6 de enero), Viernes Santo (fecha variable), Día del Trabajo (1 de mayo), Día de la Asunción (15 de agosto), Día de la Hispanidad (12 de octubre), Día de Todos los Santos (1 de noviembre), la Constitución (6 de diciembre) la Inmaculada Concepción (8 de diciembre) y Navidad (25 de diciembre).\nPor claridad, cada festivo se ha definido de forma independiente para después crear una variable con todas las festividades (FestivosNacionales).\nEl rango para todos los cálculos va desde 1996 hasta 2024, que incluye el rango de la serie Pasajeros más cinco años de predicción.\nLa función utilizada Easter de la librería timeDate difiere de la función easter de forecast.\n\n\nAnoNuevo &lt;- timeCalendar(d = 1, m = 1, y = 1996:2024)\nReyes &lt;- timeCalendar(d = 6, m = 1, y = 1996:2024)\nViernesSanto &lt;- Easter(1996:2024, shift = -2)\nDiaTrabajo &lt;- timeCalendar(d = 1, m = 5, y = 1996:2024)\nAsuncion &lt;- timeCalendar(d = 15, m = 8, y = 1996:2024)\nHispanidad &lt;- timeCalendar(d = 12, m = 10, y = 1996:2024)\nTodoSantos &lt;- timeCalendar(d = 1, m = 11, y = 1996:2024)\nConstitucion &lt;- timeCalendar(d = 6, m = 12, y = 1996:2024)\nInmaculada &lt;- timeCalendar(d = 8, m = 12, y = 1996:2024)\nNavidad &lt;- timeCalendar(d = 25, m = 12, y = 1996:2024)\n\nFestivosNacionales &lt;- c(AnoNuevo, Reyes, ViernesSanto,\n                        DiaTrabajo, Asuncion,  Hispanidad, TodoSantos, \n                        Constitucion, Inmaculada, Navidad)\n\n\nA continuación, con timeSequence se crea una serie diaria desde el 1 de enero de 1996 hasta el 31 de diciembre de 2024.\n\n\nfechaDiaria &lt;- timeSequence(from = \"1996-01-01\", to = \"2024-12-31\")\n\n\nLas siguientes líneas eliminan de la serie diaria los festivos y los fines de semana, (función isBizday), para después dar a esta nueva serie el formato año-mes eliminando el día. De esta forma, la serie de días laborales tendrá el mismo identificador para todos los días del mismo mes.\n\n\nbiz &lt;- fechaDiaria[isBizday(fechaDiaria, holidays = FestivosNacionales)]\nbizdays &lt;- format(biz, format = \"%Y-%m\")\n\n\nAhora se crea una tabla que, por la naturaleza de la serie de días laborales, tendrá para cada año-mes el numero de días laborables. Por último fechamos la tabla, que es nuestra serie de días laborables y mostramos algunos datos.\n\n\nDiasLaborables &lt;- table(bizdays)\n\n\nLas últimas líneas de código dividen la serie en el periodo muestral y el de predicción.\n\n\nDiasLaborables &lt;- ts(DiasLaborables, start = 1996, frequency = 12)\n\nsubset(DiasLaborables, start = 289) #Mostramos solo los 5 últimos años\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2020  21  20  22  21  20  22  23  21  22  21  21  21\n2021  19  20  23  21  21  22  22  22  22  20  21  21\n2022  20  20  23  20  22  22  21  22  22  20  21  20\n2023  21  20  23  19  22  22  21  22  21  21  21  18\n2024  22  21  20  22  22  20  23  21  21  23  20  20\n\npDiasLaborables &lt;- subset(DiasLaborables, start = length(DiasLaborables) - 59)\nDiasLaborables &lt;- subset(DiasLaborables, end = length(DiasLaborables) - 60)\n\nEs conveniente indicar que la identificación de las festividades nacionales dista de ser perfecta por varios motivos:\n\nalgunos festivos nacionales si caen en domingo, se pasan a lunes (por ejemplo Reyes y la Inmaculada de 2019), aspecto que no se ha tenido en cuenta.\nalgunos festivos nacionales pueden ser sustituidos por otros días por las Comunidades Autónomas, por ejemplo Reyes o Jueves Santo.\n\n\n\n\n\nAnálisis gráfico de la estacionalidad\nVeamos ahora una descriptiva detallada de la estacionalidad de la serie Pasajeros, haciendo especial hincapié en el efecto de las vacaciones (verano y Semana Santa) y el número de días laborables. Para ello, mostraremos gráficamente las subseries definidas por el mes tanto para Pasajeros como para Pasajeros por día laborable, esta segunda resultado de dividir Pasajeros por DiasLaborables.\n\nPasajerosDL &lt;- Pasajeros/DiasLaborables\n\nggsubseriesplot(Pasajeros) +\n  ylab(\"Millones de pasajeros\") +\n  xlab(\"\") +\n  ggtitle(\"\")\n\nggsubseriesplot(PasajerosDL) +\n  ylab(\"Millones de pasajeros\") +\n  xlab(\"\") +\n  ggtitle(\"\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Pasajeros\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Pasajeros por día laborable\n\n\n\n\n\n\n\nFigura 3: Estacionalidad de la serie Pasajeros\n\n\n\n\nLa Figura 3 muestra para cada mes la serie de pasajeros (total o por día laborable) y el valor medio (línea azul horizontal). En ambos paneles se identifica perfectamente el efecto de los periodos vacacionales sobre el transporte urbano de pasajeros. En las vacaciones de verano se observa una fuerte caída en el número de pasajeros, especialmente en agosto y, en menor medida, en julio y septiembre. Por otro lado, las subseries de marzo y abril muestran mucha más irregularidad que las de otros meses debido a que el volumen de pasajeros depende de cómo haya caído la Semana Santa. Cada año el mes en que caiga la Semana Santa presentará un volumen de pasajeros inferior al esperado. Diciembre, para ser un mes de 31 días, presenta también un reducido número de pasajeros debido a las vacaciones navideñas.\nLa Figura 3 a) muestra el efecto estacional total debido al número de días del mes y de días laborales. Por ejemplo, en febrero, el mes con menos días y por tanto con menos días laborales, en media se transportan menos pasajeros, comparado con enero o marzo. Octubre, un mes con 31 días, muestra un volumen medio de pasajeros mayor que noviembre de 30 días.\nEn la Figura 3 b) se ha eliminado el efecto de los días laborables al trabajar con la serie de pasajeros transportados por día laborable. Si la comparamos con la Figura 3 a), destaca que las diferencias entre las medias (lineas azules) se han reducido: prácticamente no hay diferencias entre los meses de enero a junio, o entre los meses de octubre a diciembre.\nCabría pensar que al excluir de la serie de días laborables la Semana Santa, en la Figura 3 b) las subseries de marzo y abril serían tan suaves como las observadas para otro meses, pero no es así. Claramente la simple exclusión de los festivos nacionales de Semana Santa no es suficiente para recoger bien su efecto sobre el transporte urbano. La razón hay que buscarla en las vacaciones escolares de este periodo, que en algunas comunidades autónomas tiene lugar durante la propia semana de Semana Santa, mientras que en otras comunidades tiene lugar en la semana posterior. De esta forma, el efecto sobre el transporte urbano de Semana Santa no es homogéneo en el territorio nacional y resulta difícil incluirlo en el análisis de la serie Pasajeros.\n\n\n\n\nDescomposición y estimación de la estacionalidad\nPodemos obtener la componente estacional para poder valorarla numéricamente y ver que efecto tiene el número de días laborables. Previamente, debemos determinar el esquema, aditivo o multiplicativo, de la serie.\nLa gráfica media-varianza (Figura 4) refuerza la impresión que se obtenía de la gráfica de la serie (Figura 1), que el esquema es aditivo.\n\nMediaAnual &lt;- aggregate(Pasajeros, FUN = sum)\nDesviacionAnual &lt;- aggregate(Pasajeros, FUN = sd)\n\nggplot() +\n  geom_point(aes(x = MediaAnual, y = DesviacionAnual), size = 2) +\n  xlab(\"Total pasajeros por año\") + \n  ylab(\"Desviación típica intraanual de pasajeros\") + \n  ggtitle(\"\")\n\n\n\n\n\n\n\nFigura 4: Identificación del tipo de esquema\n\n\n\n\n\nAhora vamos a proceder a descomponer tanto la serie original como la serie de pasajeros por día laboral. Dado que la serie presenta un esquema aditivo, usaremos el método de descomposición por regresiones locales ponderadas, asumiendo una componente estacional constante y considerando la presencia de posibles valores extremos.\nLa Tabla 1 pone en cifras el efecto estacional sobre los Pasajeros (primera columna): en agosto la caída en el número de pasajeros, respecto de la media anual, se cifra en 72 millones de pasajeros. En julio, septiembre y en menor medida abril también el uso del transporte urbano es inferior a la media anual, en el caso de los dos primeros meses por las vacaciones de verano y en abril debido a ser el mes en que con más frecuencia cae la Semana Santa. Por otro lado, destaca el elevado número de pasajeros en los meses de marzo, mayo y octubre, por tener 31 días.\n\nPasajerosStl &lt;- stl(Pasajeros, \n                    s.window = \"periodic\", \n                    robust = TRUE)\n\nPasajerosDLStl &lt;- stl(PasajerosDL, \n                    s.window = \"periodic\", \n                    robust = TRUE)\n\ndatos &lt;- cbind(seasonal(PasajerosStl)[1:12], seasonal(PasajerosDLStl)[1:12])\ncolnames(datos) &lt;- c(\"Pasajeros\", \"Pasajeros por día laborable\")\nrownames(datos) &lt;- meses\n\nkable(datos, \n      digits = 2)\n\n\n\nTabla 1: Efecto estacional\n\n\n\n\n\n\n\nPasajeros\nPasajeros por día laborable\n\n\n\n\nEne\n4.70\n0.41\n\n\nFeb\n0.34\n0.53\n\n\nMar\n24.02\n0.53\n\n\nAbr\n-2.17\n0.39\n\n\nMay\n19.67\n0.69\n\n\nJun\n6.45\n0.18\n\n\nJul\n-15.30\n-1.21\n\n\nAgo\n-71.82\n-3.52\n\n\nSep\n-8.31\n-0.53\n\n\nOct\n26.79\n1.02\n\n\nNov\n14.70\n0.94\n\n\nDic\n0.93\n0.55\n\n\n\n\n\n\n\n\nTras la corrección por el número de días laborales, el efecto estacional es más suave (véase la segunda columna en la Tabla 1). Ahora, los meses de febrero y marzo tienen un efecto similar, al igual que octubre y noviembre. También se observa que las diferencias entre marzo y abril se han reducido.\n\n\nAnálisis de la intervención\nYa hemos realizado una descripción detallada de las principales componentes de la serie, tendencia y estacionalidad. Ahora vamos a analizar, aunque sea de forma gráfica, el error y tener ya una primera impresión sobre la relevancia de la componente de intervención en Pasajeros.\n\nerror &lt;- remainder(PasajerosStl)\nsderror &lt;- sd(error)\n\nautoplot(error,\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\",\n         colour = \"darkblue\") +\n  geom_hline(yintercept = c(3, 2, -2, -3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"),\n             lty = 2) + \n  scale_x_continuous(breaks= seq(1996, 2020, 2))\n\nfechasMes &lt;- format(seq(from = as.Date(\"1996-01-01\"), \n                        to = as.Date(\"2019-12-01\"), \n                        \"month\"), \n                    \"%Y-%m\")\nfechasMes[abs(error) &gt; 3 * sderror]\n\n[1] \"1997-03\" \"1997-04\" \"2002-03\" \"2002-04\" \"2005-04\" \"2008-03\" \"2008-04\"\n[8] \"2013-03\" \"2013-04\"\n\n\n\n\n\n\n\n\nFigura 5: Error + Intervención. Descomposición de Pasajeros\n\n\n\n\n\nLa Figura 5 muestra el error de la descomposición y los intervalos de confianza al 95% (líneas verdes) y el 99.7% (líneas rojas). Se aprecian claramente múltiples valores extremos (superan las tres desviaciones típicas) en forma de compensación (dos errores extremos consecutivos de signo opuesto) que corresponden a los meses de marzo y abril de 1997, 2002, 2008 y 2013, y otro valor extremo en abril de 2005. Además, en marzo y abril de 2016 hay dos valores atípicos. Todos los valores identificados corresponden a los meses de marzo y abril, y en todos los casos el error negativo tiene lugar en marzo y el positivo en abril. Si miramos un calendario, veremos que tienen lugar en los años en que la Semana Santa cayó en marzo.\nLa prueba de Tukey solo identifica como meses atípicos los marzo de 2002 y 2008.\n\natipicos &lt;- tsoutliers(error)\nfechasMes[atipicos$index]\n\n[1] \"2002-03\" \"2008-03\"\n\n\nSi repetimos este análisis para la serie de Pasajeros por día laborable, los resultados son bien diferentes (véase Figura 6). Ahora solo se detectan dos valores extremos en diciembre de 2000 y 2006. También destaca el error de diciembre de 2017. Los errores en diciembre se dan cuando Navidad cae en lunes, de forma que la caída en el transporte urbano debida a la nochebuena coincide con la de cualquier domingo. Así, estos meses de diciembre presentan más transporte urbano que los meses de diciembre donde la nochebuena cae entre semana.\n\nerror &lt;- remainder(PasajerosDLStl)\nsderror &lt;- sd(error)\n\nautoplot(error,\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\",\n         colour = \"darkblue\") +\n  geom_hline(yintercept = c(3, 2, -2, -3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"),\n             lty = 2) + \n  scale_x_continuous(breaks= seq(1996, 2020, 2))\n\nfechasMes[abs(error) &gt; 3 * sderror]\n\n[1] \"2000-12\" \"2006-12\"\n\n\n\n\n\n\n\n\nFigura 6: Error + Intervención. Descomposición de Pasajeros por día laborable"
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#conclusión",
    "href": "03-20-Ejemplo-Pasajeros.html#conclusión",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "2.3 Conclusión",
    "text": "2.3 Conclusión\nLa serie de pasajeros en transporte urbano muestra una tendencia creciente solo interrumpida entre 2008 y 2014 debido a la Gran Recesión.\nLos principales determinantes de la estacionalidad de la serie Pasajeros son los grandes periodos vacacionales en España (Semana Santa y verano) y el número de días laborales del mes. Así, en la serie Pasajeros corregida por días laborables la componente estacional se ha suavizado y prácticamente queda determinada por las vacaciones.\nLa intervención tiene lugar en los meses de marzo y abril debido al carácter móvil de la Semana Santa, y en diciembre cuando el día de Navidad cae en lunes, de forma que la caída de pasajeros de nochebuena se solapa con la de cualquier domingo."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#análisis-de-la-serie-pasajeros",
    "href": "03-20-Ejemplo-Pasajeros.html#análisis-de-la-serie-pasajeros",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "4.1 Análisis de la serie Pasajeros",
    "text": "4.1 Análisis de la serie Pasajeros\n\n\n\nEstimación e interpretación\nEl modelo óptimo, estimado con la función ets sin imponer ninguna restricción, es ETS(M,Ad,A): pendiente aditiva con amortiguamiento, estacionalidad aditiva y residuo multiplicativo. \\[y_{t+1} = (l_t + \\phi b_t + s_{t+1-m}) \\cdot (1 + \\varepsilon_{t+1}).\\]\n\nPasajerosEts &lt;- ets(Pasajeros)\nsummary(PasajerosEts) \n\nETS(M,Ad,A) \n\nCall:\nets(y = Pasajeros)\n\n  Smoothing parameters:\n    alpha = 0.1374 \n    beta  = 0.017 \n    gamma = 1e-04 \n    phi   = 0.9438 \n\n  Initial states:\n    l = 203.1964 \n    b = -0.4508 \n    s = 2.0753 14.0423 27.0229 -8.7953 -72.369 -15.0625\n           6.6935 19.5129 4.2863 18.0168 0.373 4.2039\n\n  sigma:  0.0333\n\n     AIC     AICc      BIC \n2823.866 2826.408 2889.799 \n\nTraining set error measures:\n                    ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 0.5929553 7.492818 5.654414 0.1765693 2.447442 0.6844865\n                   ACF1\nTraining set -0.1434247\n\n\nEl valor de \\(\\phi=\\) 0.94 indica que la inclusión de amortiguamiento en el modelo mejora sensiblemente su ajuste a los datos. Por otro lado, \\(\\gamma\\) es técnicamente cero, indicando que el efecto estacional se mantiene constante en el tiempo. Sin embargo, el valor de \\(\\beta\\), reducido pero no nulo, indica que la pendiente cambia en el tiempo de forma muy lenta.\nLa calidad del ajuste es bastante buena, con un error porcentual del 2.4% o un error de 7.5 millones de pasajeros (RMSE). La aplicación del método de Alisado supone una reducción de un punto en el error porcentual respecto del método ingenuo, o una reducción del RMSE de 3.5 millones de pasajeros. Es decir, el modelo de Alisado exponencial supone una mejora en la calidad del ajuste del 32% respecto del método ingenuo con estacionalidad visto en el epígrafe previo (MASE). El indicador ACF1 revela que las fórmulas usadas para el intervalo de confianza no son válidas.\nEl efecto estacional, que recordemos se mantiene constante en el tiempo, es prácticamente idéntico al estimado en la descriptiva y viene determinado por los periodos vacacionales y el número de días laborables. Véase la Figura 8.\nEn verano (julio a septiembre) el uso del transporte urbano es inferior a la media anual, destacando agosto con un descenso de 72 millones de pasajeros. Por el contrario, octubre destaca por ser el mes con mayor incremento en el volumen de pasajeros (27 millones) respecto de la media anual.\n\nPasajerosEtsEst &lt;- PasajerosEts$states[nrow(PasajerosEts$states), 14:3]\nnames(PasajerosEtsEst) &lt;- meses\n\nround(PasajerosEtsEst, 2)\n\n   Ene    Feb    Mar    Abr    May    Jun    Jul    Ago    Sep    Oct    Nov \n  4.21   0.37  18.02   4.29  19.51   6.69 -15.06 -72.37  -8.79  27.02  14.04 \n   Dic \n  2.07 \n\nggplot() +\n  geom_line(aes(x = 1:12, y = PasajerosEtsEst), colour = \"darkblue\") + \n  geom_hline(yintercept = 0, colour = \"black\", lty = 2) +\n  ggtitle(\"\") +\n  xlab(\"\") +\n  ylab(\"Efecto estacional\") +\n  scale_x_continuous(breaks= 1:12, \n                     labels = meses)\n\n\n\n\n\n\n\nFigura 8: Componente estacional estimada con Alisado exponencial\n\n\n\n\n\n\n\n\n\nPredicción\nPodemos ahora pedir los valores de predicción para los próximos cinco años. No mostramos los resultados numéricos, pero si gráficos (Figura 9). Las predicciones muestran una tendencia creciente amortiguada y, por tanto, no tan acusada como la observada en los años precedentes.\n\nPasajerosEtsPre &lt;- forecast(PasajerosEts, \n                            h = 60)\n\nautoplot(PasajerosEtsPre,\n         xlab = \"\",\n         ylab = \"Millones de pasajeros\",\n         main = \"\") \n\n\n\n\n\n\n\nFigura 9: Pasajeros (1996-2019) y predicción (2020-2024). Método de Alisado exponencial\n\n\n\n\n\nEn el año 2020 se esperan 3153 millones de pasajeros, un 1.6% más que en 2019.2\n\n\n\n\nAnálisis del error\nEl residuo del modelo (Figura 10) muestra varios valores que pueden ser considerados como atípicos y que se dan siempre en los meses de marzo y abril para los años donde la Semana Santa recayó en marzo.\n\nerror &lt;- residuals(PasajerosEts)\nsderror &lt;- sd(error)\n\nautoplot(error,\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\",\n         colour = \"darkblue\") +\n  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), lty = 2) + \n  scale_x_continuous(breaks= seq(1996, 2020, 2))\n\nfechasMes[abs(error) &gt; 3 * sderror]\n\n[1] \"2008-03\"\n\n\n\n\n\n\n\n\nFigura 10: Error + Intervención. Método de Alisado exponencial"
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#otras-alternativas-de-análisis",
    "href": "03-20-Ejemplo-Pasajeros.html#otras-alternativas-de-análisis",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "4.2 Otras alternativas de análisis",
    "text": "4.2 Otras alternativas de análisis\nEn la descriptiva se ha visto que la serie de pasajeros por día laborable tiene un comportamiento más suave (la componente estacional era más plana) y presentaba un menor número de valores atípicos que la serie original Pasajeros. Cabe esperar, por tanto, que esta serie presente un mejor ajuste con el método de Alisado exponencial y ofrezca mejores predicciones.\nPor otro lado, siempre vale la pena analizar la transformación logarítmica de la serie y ver si ofrece mejores resultados que la serie original. La transformación logarítmica es especialmente eficaz para series no lineales, así que para Pasajeros posiblemente no suponga ningún mejora.\nLas transformaciones indicadas en los dos párrafos precedentes son solo dos de las posibles. También se pude analizar la serie de pasajeros por día del mes o la transformación óptima de Box-Cox. La idea es no quedarse con lo inmediato –la serie tal cual nos la han ofrecido–, sino probar otras alternativas. Por ejemplo, la serie de Pasajeros es el agregado del número de pasajeros que viajan en transporte urbano según el tipo de transporte (autobús, metro, tranvía…). Se podría proceder a analizar cada serie por separado (pasajeros en autobús, pasajeros en metro, etc.), para luego agregar los resultados y ver si este enfoque da mejores resultados que el análisis directo de la serie agregada Pasajeros.\nEn este epígrafe se analizarán tres de las transformaciones indicadas: la transformación logarítmica, los pasajeros por día laborable y los pasajeros por día del mes. El objetivo es ver si es posible mejorar la calidad de las predicciones obtenidas para Pasajeros. Se usará como criterio de bondad el error de las predicciones extramuestrales según el horizonte temporal, obtenido con el procedimiento origen de predicción móvil. Asumiremos que son necesarios 12 años para obtener una buena estimación del modelo y el horizonte temporal se fijará en 12 meses (\\(k = 144, h = 12\\)). Previamente, hay que crear la serie Pasajeros por día del mes, e identificar el mejor modelo para las series transformadas. Además, para evitar el efecto de meses atípicos sobre el cálculo de la precisión de las previsiones, usaremos como medida de calidad la mediana del error porcentual absoluto.\n\nPasajerosDM &lt;- Pasajeros/monthdays(Pasajeros)\nets(Pasajeros, lambda = 0)$method\n\n[1] \"ETS(A,Ad,A)\"\n\nets(PasajerosDL)$method\n\n[1] \"ETS(M,Ad,A)\"\n\nets(PasajerosDM)$method\n\n[1] \"ETS(A,Ad,A)\"\n\n\n\n\n\nk &lt;- 144                 \nh &lt;- 12                  \nTT &lt;- length(Pasajeros)  \ns &lt;- TT - k - h          \n\nmapeAlisadoPas &lt;- matrix(NA, s + 1, h)\nmapeAlisadoLogPas &lt;- matrix(NA, s + 1, h)\nmapeAlisadoPasDL &lt;- matrix(NA, s + 1, h)\nmapeAlisadoPasDM &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(Pasajeros, start = i + 1, end = i + k)\n  test.set &lt;-  subset(Pasajeros, start = i + k + 1, end = i + k + h)\n  \n  trainDL.set &lt;- subset(PasajerosDL, start = i + 1, end = i + k)\n  testDL.set &lt;-  subset(PasajerosDL, start = i + k + 1, end = i + k + h)\n  \n  trainDM.set &lt;- subset(PasajerosDM, start = i + 1, end = i + k)\n  testDM.set &lt;-  subset(PasajerosDM, start = i + k + 1, end = i + k + h)\n  \n  fit &lt;- ets(train.set, model = \"MAA\", damped = TRUE)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAlisadoPas[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n  fit &lt;- ets(train.set, model = \"AAA\", damped = TRUE, lambda = 0)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAlisadoLogPas[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n  fit &lt;- ets(trainDL.set, model = \"MAA\", damped = TRUE)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAlisadoPasDL[i + 1,] &lt;- 100*abs(testDL.set - fcast$mean)/testDL.set\n  \n  fit &lt;- ets(trainDM.set, model = \"AAA\", damped = TRUE)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAlisadoPasDM[i + 1,] &lt;- 100*abs(testDM.set - fcast$mean)/testDM.set\n}\n\nerrorAlisadoPas &lt;- apply(mapeAlisadoPas, MARGIN = 2, FUN = median)\nerrorAlisadoLogPas &lt;- apply(mapeAlisadoLogPas, MARGIN = 2, FUN = median)\nerrorAlisadoPasDL &lt;- apply(mapeAlisadoPasDL, MARGIN = 2, FUN = median)\nerrorAlisadoPasDM &lt;- apply(mapeAlisadoPasDM, MARGIN = 2, FUN = median)\n\ndatos &lt;- data.frame(\n  factor = c(rep(\"Pasajeros\", 12), \n             rep(\"Pasajeros por día laborable\", 12), \n             rep(\"Pasajeros por día del mes\", 12), \n             rep(\"Pasajeros (log)\", 12)),\n  x = c(1:12, 1:12, 1:12, 1:12),\n  y = c(errorAlisadoPas, errorAlisadoPasDL, errorAlisadoPasDM, errorAlisadoLogPas)\n)\n\n\nggplot(datos, aes(x = x, y = y,  colour= factor)) + \n  geom_line() +\n  ggtitle(\"\") +\n  xlab(\"Horizonte temporal de predicción\") +\n  ylab(\"%\") +\n  scale_x_continuous(breaks= 1:12) +\n  scale_y_continuous(breaks= seq(2, 4, .2)) +\n  labs(colour = \"Métodos\") + \n  theme(legend.position=c(0.15, 0.7))\n\n\n\n\n\n\n\nFigura 11: Error de predicción (MedAPE) según horizonte temporal y enfoque. Método de Alisado exponencial\n\n\n\n\n\nAntes de pasar al análisis de los resultados, indicar que en las predicciones sobre el logaritmo no se ha pedido corrección por sesgo, y que al trabajar con errores porcentuales no es necesario pasar la predicción de pasajeros por día (laborable o del mes) a predicción de pasajeros.\nLa Figura 11 muestra los errores de predicción según el horizonte temporal para las cuatro aproximaciones. En todos los casos el error aumenta con el horizonte temporal de predicción, de forma que las predicciones a doce meses vista tienen un error un punto porcentual superior a las predicciones a un mes vista.\nPor otro lado, para horizontes temporales de hasta 9 meses vista las predicciones realizadas sobre el logaritmo de la serie original Pasajeros son de las más precisas, seguidas de las predicciones realizadas con Pasajeros por día del mes. Para predicciones de 10 a 12 meses, en general las mejores predicciones se obtienen con Pasajeros. En contra de lo esperado, las predicciones a partir de la serie de pasajeros por día laborable son de las que mayor error porcentual presentan."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#conclusión-1",
    "href": "03-20-Ejemplo-Pasajeros.html#conclusión-1",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "4.3 Conclusión",
    "text": "4.3 Conclusión\nLos modelos de Alisado exponencial resultan excelentes para predecir la serie Pasajeros. El error de ajuste, del 2.4%, es un punto inferior al error obtenido con el método ingenuo con estacionalidad. Además, en las predicciones extramuestrales a 12 meses vista el error porcentual sigue manteniéndose bajo, no superando el 4%.\nLa transformación logarítmica de la serie pasajeros y la serie Pasajeros por día del mes han dado mejores predicciones por Alisado exponencial que el análisis directo de la serie."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#transformación-de-la-serie-pasajeros",
    "href": "03-20-Ejemplo-Pasajeros.html#transformación-de-la-serie-pasajeros",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "5.1 Transformación de la serie Pasajeros",
    "text": "5.1 Transformación de la serie Pasajeros\nPor un lado, el análisis por Alisado exponencial ha puesto de relieve el carácter lineal de Pasajeros y la efectividad que podría tener usar la transformación logarítmica para mejorar la calidad de las predicciones.\nPor otro lado, tras un análisis preliminar por modelos Arima se puede ver que la transformación logarítmica mejora la identificación del modelo y facilitaba su interpretación.\nAsí, optamos por aplicar la transformación logarítmica a Pasajeros.\nLas FAC del logaritmo de la serie y algunas de sus diferenciaciones (Figura 12) indican que es necesaria la doble diferenciación regular y estacional para alcanzar las hipótesis de estacionariedad y ergodicidad: \\(\\log(Pasajeros) \\sim I(1)I_{12}(1)\\). Los resultados ofrecidos por las funciones ndiffs y nsdiffs apoyan esta conclusión.\n\nggAcf(log(Pasajeros), lag = 48, ylim = c(-1, 1), \n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(Pasajeros)), lag = 48, ylim = c(-1, 1), \n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(Pasajeros), lag = 12), lag = 48, ylim = c(-1, 1), \n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(diff(log(Pasajeros), lag=12)), lag = 48, ylim = c(-1, 1), \n      xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Log serie\n\n\n\n\n\n\n\n\n\n\n\n(b) Dif. regular log serie\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Dif. estacional log serie\n\n\n\n\n\n\n\n\n\n\n\n(d) Dif. regular y estacional log serie\n\n\n\n\n\n\n\nFigura 12: FAC para Pasajeros\n\n\n\n\n\nndiffs(log(Pasajeros))\n\n[1] 1\n\nnsdiffs(log(Pasajeros))\n\n[1] 1\n\n\nLa Figura 13 muestra la serie original \\(y_t\\) y la serie transformada \\(\\nabla \\nabla_{12} \\log(y_t)\\). En la serie transformada destacan las compensaciones asociadas a la intervención de Semana Santa.\n\nseries &lt;- cbind(\"Original\" = Pasajeros,\n                \"Dif reg. y est. de log\" = diff(diff(log(Pasajeros), lag = 12)))\n\nautoplot(series, facets = TRUE,\n         xlab = \"\",\n         ylab = \"\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 13: Serie original de Pasajeros y su transformación"
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#identificación-de-la-serie-pasajeros",
    "href": "03-20-Ejemplo-Pasajeros.html#identificación-de-la-serie-pasajeros",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "5.2 Identificación de la serie Pasajeros",
    "text": "5.2 Identificación de la serie Pasajeros\nVamos a identificar los valores de \\(p\\), \\(q\\), \\(P\\) y \\(Q\\) del proceso Arima. Para ello, solicitaremos con auto.arima y seas una identificación automática, en el primer caso incluyendo todos los efectos calendario ya identificados.\n\n\n\nIdentificación automática con auto.arima\nPara ayudar a la función auto.arima en el proceso de identificación vamos a definir previamente todas las variables de intervención que en el desarrollo del análisis de la serie hemos ido identificando: días del mes, días laborables del mes, meses de diciembre con el día de Navidad en lunes y Semana Santa:\n\nLa variable Días laborables del mes ya ha sido definida previamente como DiasLaborables.\nLa variable Días del mes se puede definir directamente con la función monthdays de la librería forecast. En lugar de días del mes, consideraremos la variable días no laborables del mes, resultante de restar a los días del mes los días laborables.\nLos meses de diciembre en que el día de Navidad cae en lunes requiere un poco más de trabajo. La idea general es generar un rango de fechas diarias que cubra todo el periodo de análisis (variable fechas), identificar los lunes de Navidad (variable dicotómica lunesNavidad), eliminar el identificador del día del rango de fechas con la función format y, por último, con tapply sumar para cada mes-año los lunes de Navidad, que lógicamente solo tendrán lugar algunos meses de diciembre y una sola vez. En los objetos definidos con la función as.POSIXlt los meses van de 0 a 11 (enero a diciembre) y los días de la semana de 0 a 6 (domingo a sábado).\nLa creación de las variables de intervención que estiman el efecto de la Semana Santa es aún más complejo. El efecto del viernes de Semana Santa ya queda recogido en la variable DiasNoLaborables. Lo que vamos a hacer ahora es crear una variable que permita estimar el efecto de las vacaciones escolares (y de muchos padres y madres) de lunes a Jueves Santo en aquellas comunidades donde así es; y otra variable para estimar el efecto de las vacaciones escolares que tienen lugar la semana posterior al Domingo de Resurrección, de lunes a viernes tras Semana Santa. Estas nuevas variables (DiasPreSanta y DiasPascua) para marzo y abril valdrán la proporción de días vacacionales que recaen en el correspondiente mes, y valdrán cero para los demás meses del año.\n\nDías no laborables\nGeneramos la variables para DiasNoLaborables y se muestra su valor para los últimos 5 años.\n\nDiasNoLaborables &lt;- monthdays(DiasLaborables) - DiasLaborables\npDiasNoLaborables &lt;- monthdays(pDiasLaborables) - pDiasLaborables\ntail(DiasNoLaborables, n = 60)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2015  11   8   9   9  11   8   8  10   8  10   9  10\n2016  12   8   9   9   9   8  10   9   8  11   9  11\n2017  10   8   8  11   9   8  10   9   9  10   9  13\n2018   9   8  10   9   9   9   9   9  10   9   9  12\n2019   9   8  10   9   9  10   8  10   9   8  10  11\n\n\nNavidad cae en lunes\nGeneramos la variable que identifica los mes de diciembre en los que la Navidad cayó en lunes.\n\nfechas &lt;- as.POSIXlt(seq(from = as.Date(\"1996-1-1\"), \n                         to = as.Date(\"2024-12-31\"), \n                         by = \"day\"))\nLunesNavidad &lt;- 1*(fechas$wday == 1 & fechas$mon == 11 & fechas$mday == 25)\nfechas &lt;- format(fechas, format = \"%Y-%m\")\nLunesNavidad &lt;- tapply(LunesNavidad, fechas, sum)\nLunesNavidad &lt;- ts(LunesNavidad, start = 1996, frequency = 12)\npLunesNavidad &lt;- subset(LunesNavidad, start = length(LunesNavidad) - 59)\nLunesNavidad &lt;- subset(LunesNavidad, end = length(LunesNavidad) - 60)\n\nLunesNavidad[LunesNavidad == 1]\n\n2000-12 2006-12 2017-12 \n      1       1       1 \n\n\nSemana Santa\nSe generan las variables DiasPreSanta y DiasPascua y se muestra su valor para los últimos 5 años.\n\nLunSanto &lt;- Easter(1996:2024, shift = -6)\nMarSanto &lt;- Easter(1996:2024, shift = -5)\nMieSanto &lt;- Easter(1996:2024, shift = -4)\nJueSanto &lt;- Easter(1996:2024, shift = -3)\n\nPreSanta &lt;- c(LunSanto, MarSanto, MieSanto, JueSanto)\nbiz &lt;- fechaDiaria[isBizday(fechaDiaria, holidays = PreSanta, wday = 0:6)]\nbizdays &lt;- format(biz, format = \"%Y-%m\")\n\nDiasPreSanta &lt;- table(bizdays)\nDiasPreSanta &lt;- ts(DiasPreSanta, start = 1996, frequency = 12)\nDiasPreSanta &lt;- (monthdays(DiasPreSanta) - DiasPreSanta)/4\n\npDiasPreSanta &lt;- subset(DiasPreSanta, start = length(DiasPreSanta) - 59)\nDiasPreSanta &lt;- subset(DiasPreSanta, end = length(DiasPreSanta) - 60)\n\nLunPascua &lt;- Easter(1996:2024, shift = 1)\nMarPascua &lt;- Easter(1996:2024, shift = 2)\nMiePascua &lt;- Easter(1996:2024, shift = 3)\nJuePascua &lt;- Easter(1996:2024, shift = 4)\nViePascua &lt;- Easter(1996:2024, shift = 5)\n\nPascua &lt;- c(LunPascua, MarPascua, MiePascua, JuePascua, ViePascua)\nbiz &lt;- fechaDiaria[isBizday(fechaDiaria, holidays = Pascua, wday = 0:6)]\nbizdays &lt;- format(biz, format = \"%Y-%m\")\n\nDiasPascua &lt;- table(bizdays)\nDiasPascua &lt;- ts(DiasPascua, start = 1996, frequency = 12)\nDiasPascua &lt;- (monthdays(DiasPascua) - DiasPascua)/5\n\npDiasPascua &lt;- subset(DiasPascua, start = length(DiasPascua) - 59)\nDiasPascua &lt;- subset(DiasPascua, end = length(DiasPascua) - 60)\n\ntail(DiasPreSanta, n = 60)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2015 0.0 0.0 0.5 0.5 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2016 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2017 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2018 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2019 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n\ntail(DiasPascua, n = 60)\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2015 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2016 0.0 0.0 0.8 0.2 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2017 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2018 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n2019 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0\n\n\nAhora tenemos todos los elementos para pedir la identificación automática con auto.arima.\n\nauto.arima(Pasajeros, \n           lambda = 0,\n           d = 1, \n           D = 1,\n           xreg = cbind(DiasLaborables, DiasNoLaborables, \n                        LunesNavidad, DiasPreSanta, DiasPascua))\n\nSeries: Pasajeros \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasLaborables  DiasNoLaborables  LunesNavidad\n      -0.5775  -0.4194          0.0352            0.0159         0.028\ns.e.   0.0496   0.0531          0.0057            0.0057         0.008\n      DiasPreSanta  DiasPascua\n           -0.0577     -0.0248\ns.e.        0.0042      0.0070\n\nsigma^2 = 0.0003214:  log likelihood = 718.25\nAIC=-1420.51   AICc=-1419.97   BIC=-1391.58\n\n\nLa identificación automática muestra el proceso de las aerolíneas. Además, parece que todas las variables de intervención son significativas.\n\n\n\n\nIdentificación automática con seas\nLa función seas de seasonal incluye automáticamente durante la identificación las variables de intervención necesarias.\n\nsummary(seas(Pasajeros, transform.function = \"log\"))\n\n\nCall:\nseas(x = Pasajeros, transform.function = \"log\")\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \nWeekday            0.0053245  0.0002834  18.787  &lt; 2e-16 ***\nEaster[1]         -0.0863100  0.0034777 -24.818  &lt; 2e-16 ***\nAR-Nonseasonal-01 -0.9566747  0.2791436  -3.427  0.00061 ***\nAR-Nonseasonal-02 -0.5939742  0.1383640  -4.293 1.76e-05 ***\nAR-Nonseasonal-03 -0.2879049  0.0881848  -3.265  0.00110 ** \nMA-Nonseasonal-01 -0.4666487  0.2885044  -1.617  0.10578    \nMA-Seasonal-12     0.3907450  0.0555134   7.039 1.94e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSEATS adj.  ARIMA: (3 1 1)(0 1 1)  Obs.: 288  Transform: log\nAICc:  1635, BIC:  1663  QS (no seasonality in final):    0  \nBox-Ljung (no autocorr.): 52.54 *** Shapiro (normality): 0.9846 **\n\n\nEn este caso el proceso identificado en la parte regular es más complejo que el obtenido con auto.arima, ARIMA(3,1,1)(0,1,1). Además, se han incluido variables de intervención asociadas a la Semana Santa y días laborables. Conjuntamente estas variables de intervención recogen los mismos efectos considerados por nosotros.\nConcluimos que el modelo de partida para Pasajeros será \\(\\log(Pasajeros) \\sim ARIMA_{12}(0, 1, 1)(0, 1, 1) + AI\\)."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#estimación-del-modelo-e-identificación-de-otras-componentes-de-intervención",
    "href": "03-20-Ejemplo-Pasajeros.html#estimación-del-modelo-e-identificación-de-otras-componentes-de-intervención",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "5.3 Estimación del modelo e identificación de otras componentes de intervención",
    "text": "5.3 Estimación del modelo e identificación de otras componentes de intervención\nVamos a estimar el modelo identificado y a analizar la presencia de otros valores atípicos en el residuo.\n\nPasajerosAri &lt;- Arima(Pasajeros, \n                      lambda = 0,\n                      order = c(0, 1, 1),  \n                      seasonal = c(0, 1, 1),\n                      xreg = cbind(DiasLaborables, DiasNoLaborables, \n                                   LunesNavidad, DiasPreSanta, DiasPascua))\nPasajerosAri\n\nSeries: Pasajeros \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasLaborables  DiasNoLaborables  LunesNavidad\n      -0.5775  -0.4194          0.0352            0.0159         0.028\ns.e.   0.0496   0.0531          0.0057            0.0057         0.008\n      DiasPreSanta  DiasPascua\n           -0.0577     -0.0248\ns.e.        0.0042      0.0070\n\nsigma^2 = 0.0003214:  log likelihood = 718.25\nAIC=-1420.51   AICc=-1419.97   BIC=-1391.58\n\n\n\nerror &lt;- residuals(PasajerosAri)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 0, 2, 3)*sderror, \n             colour = c(\"red\", \"blue\", \"black\", \"blue\", \"red\"), \n             lty = 2) + \n  scale_x_continuous(breaks= seq(1996, 2020, 2))\n\nfechasMes[abs(error) &gt; 3 * sderror]\n\n[1] \"2005-08\"\n\n\n\n\n\n\n\n\nFigura 14: Error + Intervención. Modelo Arima\n\n\n\n\n\nEn la Figura 14 identificamos claramente agosto de 2005 como atípico, con un error que supera las cinco desviaciones típicas.\nTras incluir la correspondiente variable artificial en el modelo y estimarlo, identificamos otros valores extremos, por superar las 3 desviaciones típicas, en agosto de 2006, abril de 2002 y marzo de 2010. Procedemos a incluir las variables artificiales en el modelo y repetir el análisis. En esta ocasión ya no identificamos más valores atípicos (véase Figura 15).\n\nd0402 &lt;- 1*(trunc(time(Pasajeros)) == 2002 & cycle(Pasajeros) == 4)\nd0805 &lt;- 1*(trunc(time(Pasajeros)) == 2005 & cycle(Pasajeros) == 8)\nd0806 &lt;- 1*(trunc(time(Pasajeros)) == 2006 & cycle(Pasajeros) == 8)\nd0310 &lt;- 1*(trunc(time(Pasajeros)) == 2010 & cycle(Pasajeros) == 3)\n\nPasajerosAri &lt;- Arima(Pasajeros,\n                      lambda = 0,\n                      order = c(0, 1, 1),  \n                      seasonal =  c(0, 1, 1),\n                      xreg = cbind(DiasLaborables, DiasNoLaborables, \n                                   LunesNavidad, DiasPreSanta, DiasPascua,\n                                   d0402, d0805, d0806, d0310))\nPasajerosAri\n\nSeries: Pasajeros \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasLaborables  DiasNoLaborables  LunesNavidad\n      -0.5276  -0.3752          0.0343            0.0158        0.0259\ns.e.   0.0539   0.0591          0.0051            0.0052        0.0072\n      DiasPreSanta  DiasPascua   d0402   d0805   d0806   d0310\n           -0.0579     -0.0253  0.0333  0.0644  0.0284  0.0377\ns.e.        0.0042      0.0067  0.0130  0.0126  0.0126  0.0126\n\nsigma^2 = 0.0002842:  log likelihood = 737.61\nAIC=-1451.23   AICc=-1450.03   BIC=-1407.82\n\n\n\nerror &lt;- residuals(PasajerosAri)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 0, 2, 3)*sderror, \n             colour = c(\"red\", \"blue\", \"black\", \"blue\", \"red\"), \n             lty = 2) + \n  scale_x_continuous(breaks= seq(1996, 2020, 2))\n\nfechasMes[abs(error) &gt; 2.8 * sderror]\n\ncharacter(0)\n\n\n\n\n\n\n\n\nFigura 15: Error + Intervención. Modelo Arima\n\n\n\n\n\nAntes de finalizar el proceso de identificación vamos a confirmar la significatividad de todos los parámetros estimados.\n\ncoeftest(PasajerosAri)\n\n\nz test of coefficients:\n\n                   Estimate Std. Error  z value  Pr(&gt;|z|)    \nma1              -0.5275620  0.0538773  -9.7919 &lt; 2.2e-16 ***\nsma1             -0.3751743  0.0591070  -6.3474 2.190e-10 ***\nDiasLaborables    0.0342656  0.0051246   6.6865 2.285e-11 ***\nDiasNoLaborables  0.0157855  0.0051814   3.0466 0.0023146 ** \nLunesNavidad      0.0258983  0.0072072   3.5934 0.0003264 ***\nDiasPreSanta     -0.0579159  0.0041802 -13.8548 &lt; 2.2e-16 ***\nDiasPascua       -0.0252714  0.0066643  -3.7921 0.0001494 ***\nd0402             0.0332966  0.0130224   2.5569 0.0105619 *  \nd0805             0.0644211  0.0126345   5.0988 3.418e-07 ***\nd0806             0.0283617  0.0126198   2.2474 0.0246149 *  \nd0310             0.0377276  0.0126289   2.9874 0.0028135 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#validación-del-modelo",
    "href": "03-20-Ejemplo-Pasajeros.html#validación-del-modelo",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "5.4 Validación del modelo",
    "text": "5.4 Validación del modelo\nEn el proceso de validación analizaremos la calidad de ajuste y predicción del modelo estimado.\n\n\n\nCalidad del ajuste\nAnalizando los criterios de bondad de ajuste (sobre el error de predicción intramuestral a un periodo vista) se tiene un error medio (ME) de -0.05 millones de pasajeros, prácticamente cero por lo que no parece que haya sesgo en las predicciones; en media nos equivocamos 3.7 millones de pasajeros (RMSE) y el error porcentual medio (MAPE) es 1.3%, muy bajo. Para ambos indicadores de bondad de ajuste el error obtenido es la mitad que el visto con Alisado exponencial. Al contrario que para Alisado, el ajuste con modelos Arima generará predicciones por intervalo válidas.\n\n\n                ME RMSE  MAE  MPE MAPE MASE ACF1\nTraining set -0.05 3.72 2.92 0.01 1.26 0.35 0.02\n\n\n\n\n\n\nCalidad de las predicciones\nSe completará el proceso de validación estimado el error de predicción extramuestral según el horizonte temporal. Se considerarán 12 años para el periodo de estimación y un año para el de predicción.\n\nk &lt;- 144                  \nh &lt;- 12                   \nT &lt;- length(Pasajeros)    \ns&lt;-T - k - h            \n\nmapeArima &lt;- matrix(NA, s + 1, h)\n\nX &lt;- data.frame(cbind(DiasLaborables, DiasNoLaborables, \n                      LunesNavidad, DiasPreSanta, DiasPascua))\n\nfor (i in 0:s) {\n  train.set &lt;- subset(Pasajeros, start = i + 1, end = i + k)\n  test.set &lt;-  subset(Pasajeros, start = i + k + 1, end = i + k + h) \n  \n  X.train &lt;- as.matrix(X[(i + 1):(i + k),])\n  X.test &lt;- as.matrix(X[(i + k + 1):(i + k + h),])\n  \n  fit &lt;- try(Arima(train.set, \n                   lambda = 0,\n                   order = c(0, 1, 1),\n                   seasonal = c(0, 1, 1),\n                   xreg=X.train), \n             silent = TRUE)\n  \n  if (!is.element(\"try-error\", class(fit))) {\n    fcast &lt;- forecast(fit, h = h, xreg = X.test)\n    mapeArima[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  }\n}\n\nerrorArima &lt;- apply(mapeArima, MARGIN = 2, FUN = median, na.rm = TRUE)\nround(errorArima, 2)\n\n [1] 1.09 1.12 1.32 1.52 1.51 1.46 1.66 1.87 2.12 2.02 2.21 2.59\n\n\nEl error es creciente en el horizonte temporal de predicción. Para predicciones extramuestrales a un periodo vista vale 1.1%, algo superior al error de estimación, pero realmente bajo. Incluso para predicciones a doce meses vista, el error sigue siendo reducido, 2.6%. Recordemos que para Alisado exponencial el error a 12 meses vista era de 2.9%, muy similar."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#interpretación-del-modelo-estimado",
    "href": "03-20-Ejemplo-Pasajeros.html#interpretación-del-modelo-estimado",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "5.5 Interpretación del modelo estimado",
    "text": "5.5 Interpretación del modelo estimado\nEl modelo estimado y validado corresponde al modelo de las aerolíneas con intervención: \\(ARIMA_{12}(0,1,1)(0,1,1) + AI\\). La ecuación teórica completa del modelo es:\n\\[(1-L)(1-L^{12})\\log(Pasajeros) = (1+\\theta_1 L)(1 + \\theta_{12} L^{12})\\varepsilon_t+\\]\n\\[\\gamma_1 DiasLaborables +\\gamma_2 DiasNoLaborables +\\gamma_3 LunesNavidad+\\]\n\\[\\gamma_4 DiasPreSanta + \\gamma_5 DiasPascua +\\]\n\\[\\gamma_6 d0402 +\\gamma_7 d0805 +\\gamma_8 d0806 +\\gamma_9 d0310.\\]\nSi se desarrolla el modelo y se deja en función de la tasa de variación anual del número de pasajero, queda (la parte de intervención no cambia):\n\\[TVAPasajeros_t = TVAPasajeros_{t-1} + \\theta_1 \\varepsilon_{t-1} + \\theta_{12} \\varepsilon_{t-12}+ \\theta_1 \\theta_{12} \\varepsilon_{t-13}+\\varepsilon_t + AI.\\]\nFinalmente, el modelo estimado es:\n\\[\\widehat{TVAPasajeros}_t = TVAPasajeros_{t-1} -0.53 \\varepsilon_{t-1} -0.37 \\varepsilon_{t-12}+ 0.20 \\varepsilon_{t-13} +\\]\n\\[0.034\\cdot DiasLaborables +0.016\\cdot DiasNoLaborables+ 0.026\\cdot LunesNavidad\\]\n\\[- 0.058\\cdot DiasPreSanta - 0.025\\cdot DiasPascua +\\]\n\\[0.033\\cdot d0402 +0.064\\cdot d0805 +0.028\\cdot d0806 +0.038\\cdot d0310.\\] Interpretación:\n\nLa tasa de variación anual del número de pasajeros en transporte urbano para un mes dado es la misma que la observada en el mes previo.\nSi hace uno, doce o trece meses se observó un número atípico de pasajeros, se debe tener en cuenta para corregir la predicción.\nCada día laborable adicional en un mes supone un incremento en el número de pasajeros del 3.4% y cada día no laborable un incremento adicional del 1.6%.\nSi la Navidad cae en lunes y por tanto Nochebuena en domingo, ese mes de diciembre el número de pasajeros será un 2.6% superior al de un mes de diciembre donde la Navidad no cae en lunes.\nEl mes (marzo o abril) en que caigan los días laborables (lunes a jueves) de la Semana Santa el número de pasajeros se reducirá un 5.8% respecto de lo esperado.\nDe la misma forma, el mes (marzo o abril) en que caigan los días laborables (lunes a viernes) de la semana posterior a Domingo de Resurrección el número de pasajeros se reducirá un 2.5% respecto de lo esperado.\nAdemas, para cuatro meses se observó una tasa de variación anual atípicamente superior a la esperada."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#predicción-del-número-de-pasajeros-en-transporte-urbano",
    "href": "03-20-Ejemplo-Pasajeros.html#predicción-del-número-de-pasajeros-en-transporte-urbano",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "5.6 Predicción del número de pasajeros en transporte urbano",
    "text": "5.6 Predicción del número de pasajeros en transporte urbano\nUna vez dado por válido el modelo, podemos pasar a realizar predicciones para los próximos años. Para las variables de intervención sujetas a fecha de calendario ya hemos ido creando sus valores previstos, para las demás los fijaremos a cero.\n\npPasajerosAri &lt;- forecast(PasajerosAri, \n                          h = 60,\n                          xreg = cbind(pDiasLaborables, pDiasNoLaborables, \n                                       pLunesNavidad, pDiasPreSanta, pDiasPascua,\n                                       rep(0, 60), rep(0, 60), \n                                       rep(0 ,60), rep(0, 60)), \n                          level = 95)\nautoplot(pPasajerosAri, \n         xlab = \"\",\n         ylab = \"\",\n         main = \"\") +\n  scale_x_continuous(breaks= seq(1996, 2024, 4))\n\n\n\n\n\n\n\nFigura 16: Pasajeros (1996-2019) y predicción (2020-2024). Modelo Arima\n\n\n\n\n\nAsí, en 2020 se esperan 3180 millones de pasajeros y para 2021 un total de 3247 millones de pasajeros."
  },
  {
    "objectID": "03-20-Ejemplo-Pasajeros.html#footnotes",
    "href": "03-20-Ejemplo-Pasajeros.html#footnotes",
    "title": "Análisis de la serie Pasajeros en transporte urbano",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRecordemos que hemos recortado la serie hasta 2019 y vivimos en un mundo donde nada sabemos de la Covid-19.↩︎\nRealmente en 2020 el número de Pasajeros fue de 1682 millones, un 45% menos que en 2019.↩︎"
  },
  {
    "objectID": "05-Recursos-R.html",
    "href": "05-Recursos-R.html",
    "title": "Recursos de la asignatura",
    "section": "",
    "text": "Durante el curso usaremos diferentes ficheros de datos para los ejemplos y para el código en R. Desde esta página puedes descargarte todo el material\n\n\n\n\n\n\nFicheros de datos\n\nResiduos recogidos: Residuos recogidos por o en nombre de las autoridades municipales y eliminados a través del sistema de gestión de residuos (fuente Instituto Nacional de Estadística). Es una serie anual de 1995 a 2022.\nNacimientos: Nacimientos en España (fuente Instituto Nacional de Estadística). Serie mensual de enero de 1975 a diciembre de 2023.\nDefunciones: Número de defunciones diarias en España desde el 1 de enero de 2022 hasta el 31 de diciembre de 2023, 730 datos. Esta serie está disponible en Ministerio de Ciencia, Innovación y Universidades.\nConsumo eléctrico: Consumo eléctrico en España en GW (fuente Red Eléctrica de España). Es una serie horaria desde las 00:00 horas del 1 de febrero de 2021 hasta las 23:00 horas del 28 de febrero de 2021.\nConsumo eléctrico por hora: Consumo eléctrico en España en GWh (fuente Red Eléctrica de España). Es una serie diaria desde el 1 de enero de 2023 hasta el 31 de diciembre de 2023.\nAforo de vehículos en Oropesa: Aforo de vehículos por Oropesa (número medio de vehículos por día), carretera N-340, km. 996,48 (fuente Ministerio de Fomento). La serie es anual de 1960 a 2022.\nConsumo de alimentos per cápita: Consumo alimentario en hogar per cápita en España. Esta serie está construida a partir de la serie de consumo alimentario en hogar (fuente Ministerio de Agricultura, Alimentación y Medio Ambiente), y la serie de población (fuente Instituto Nacional de Estadística). Es una serie anual de 1990 a 2023 y la unidad es el kg per cápita.\nExportaciones de España a la UE-27: volumen de exportaciones de bienes, en millones de euros, desde España hacía la UE-27 (conjunto de 27 países de la Unión Europea), desde enero de 1999 hasta diciembre de 2023 (fuente Eurostat).\nExportaciones de España a la UE-27 de productos químicos: volumen de exportaciones de productos químicos, en millones de euros, desde España hacía la UE-27 (conjunto de 27 países de la Unión Europea), desde enero de 1999 hasta diciembre de 2020 (fuente Eurostat).\nPernoctaciones: Número de pernoctaciones que los turistas extranjeros realizan en España en alojamientos turísticos autorizados (fuente Eurostat). Es una serie mensual de enero de 2000 a diciembre de 2023.\nPasajeros en transporte urbano: Número de pasajeros en transporte urbano en España (fuente Instituto Nacional de Estadística). Serie mensual de enero 1996 a diciembre de 2023.\nTemperatura: Temperatura media diaria en España medida en el aeropuerto de Madrid (fuente Agencia Estatal de Meteorología, AEMET). Serie diaria del 1 enero de 2023 al 31 de diciembre de 2023.\nProducto básico: Unidades compradas en una cadena de supermercados para un producto básico de alimentación. Serie semanal para las 52 semanas de 2023.\n\n\n\n\nTodos los ficheros de datos en un único fichero comprimido\n\n\n\n\n\n\nCódigo R\nTienes el código para los temas de teoría aquí:\n\nCódigo para el tema 2\nCódigo para el tema 4\nCódigo para el tema 5\nCódigo para el tema 6\nCódigo para el tema 7\nCódigo para el tema 8\n\n\n\nPara el ejemplo de Pernoctaciones tienes el código aquí:\n\nCódigo para descriptiva\nCódigo para modelos sencillos\nCódigo para modelo de Alisado\nCódigo para Arima sin estacionalidad\nCódigo para Arima con estacionalidad\n\n\n\nY para el ejemplo de Pasajeros en transporte urbano aquí:\n\nCódigo para el ejemplo Pasajeros en transporte urbano\n\n\n\nY si quieres todos los ficheros de código de golpe aquí:\n\nTodos los ficheros de código en un único fichero comprimido"
  },
  {
    "objectID": "04-04-Series_acotadas.html#predicciones-positivas",
    "href": "04-04-Series_acotadas.html#predicciones-positivas",
    "title": "Series acotadas",
    "section": "Predicciones positivas",
    "text": "Predicciones positivas\nPara imponer que las predicciones sean positivas basta trabajar con la transformación logarítmica. Por ejemplo, consideremos la serie anual de nacimientos. Vamos ha realizar predicciones a muy largo plazo (30 años) usando Alisado de Holt con y sin transformación logarítmica.\nEn el panel superior de la Figura 1, donde se ha usado la transformación logarítmica, no solo la predicción, sino también el intervalo es siempre positivo. Por el contrario, en el panel inferior de la Figura 1, donde no se ha usado la transformación logarítmica, las predicciones a partir de 2042 ya son negativas y el extremo inferior del intervalo de confianza es negativo desde el año 2028.\n\nConLog &lt;- forecast(ets(nacimientos,\n                       model = \"AAN\", \n                       damped = FALSE, \n                       lambda = 0),\n                   h = 30,\n                   level = 95)\n\nSinLog &lt;- forecast(ets(nacimientos, \n                       model = \"AAN\", \n                       damped = FALSE),\n                   h = 30,\n                   level = 95)\n\nautoplot(ConLog, main = \"\", xlab = \"\", ylab = \"Nacimientos (miles)\")\n\nautoplot(SinLog, main = \"\", xlab = \"\", ylab = \"Nacimientos (miles)\") + \n  geom_hline(yintercept=0, size = .3, linetype = 2)\n\n\n\n\n\n\n\n\n\n\n\n(a) Con transformación logarítmica\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Sin transformación logarítmica\n\n\n\n\n\n\n\nFigura 1: Ajuste y predicción de Nacimientos con Holt"
  },
  {
    "objectID": "04-04-Series_acotadas.html#predicciones-dentro-de-un-intervalo",
    "href": "04-04-Series_acotadas.html#predicciones-dentro-de-un-intervalo",
    "title": "Series acotadas",
    "section": "Predicciones dentro de un intervalo",
    "text": "Predicciones dentro de un intervalo\nSupongamos que el valor de la serie es un porcentaje y que debe estar comprendido entre \\(a = 0\\) y \\(b = 100\\), como por ejemplo la serie anual consistente en el porcentaje de nacimientos de mujeres con nacionalidad española. La transformación que garantiza que las predicciones se mantendrán dentro del intervalo \\([a,\\;b]\\) es\n\\[z_t = \\log\\Big(\\frac{y_t - a}{b - y_t}\\Big),\\] donde \\(y_t\\) es la serie original y \\(z_t\\) la serie transformada. Una vez tenemos las predicciones de la serie \\(z_t\\), tenemos que deshacer la transformación con\n\\[y_t = \\frac{a +b\\, e^{z_t}}{1 + e^{z_t}}.\\]\nEn este caso no hay un argumento lambda que nos facilite el trabajo y hay que escribir más código.\n\na &lt;- 0\nb &lt;- 100\n\nz &lt;- log((serie - a) / (b - serie))\n\nmodelo &lt;- ets(z, \n              model = \"AAN\", \n              damped = FALSE)\n\npz &lt;- forecast(modelo, \n               h = 30,\n               level = 95)\n\npz[[\"mean\"]] &lt;-  (a + b * exp(pz[[\"mean\"]]) ) / (1 + exp(pz[[\"mean\"]]))\npz[[\"lower\"]] &lt;- (a + b * exp(pz[[\"lower\"]])) / (1 + exp(pz[[\"lower\"]]))\npz[[\"upper\"]] &lt;- (a + b * exp(pz[[\"upper\"]])) / (1 + exp(pz[[\"upper\"]]))\npz[[\"x\"]] &lt;- serie\n\nautoplot(pz, \n         main = \"\",\n         xlab = \"\",\n         ylab = \"Nacimientos de mujeres españolas (%)\")\n\n\n\n\n\n\n\nFigura 2: Predicción con Holt. Valores acotados entre 0% y 100%\n\n\n\n\n\nHemos solicitado una previsión a 30 años vista para poder ver mejor el efecto de acotar la serie. En la Figura 2 se observa que no solo la predicción, sino también el intervalo está siempre entre 0% y 100%."
  },
  {
    "objectID": "03-14-Ejemplo4.html#identificación",
    "href": "03-14-Ejemplo4.html#identificación",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.1 Identificación",
    "text": "3.1 Identificación\nIdentificaremos los valores de \\(p\\) y \\(q\\) a partir de auto.arima. Pero antes vamos a crear dos variables artificiales que recojan la intervención asociada a la pandemia. Asumiremos que su efecto solo afectó los años 2020 y 2021.\n\nd2020 &lt;- 1 * (time(Pernoctaciones) == 2020)\nd2021 &lt;- 1 * (time(Pernoctaciones) == 2021)\nauto.arima(Pernoctaciones, \n           d = 1,\n           xreg = cbind(d2020, d2021))\n\nSeries: Pernoctaciones \nRegression with ARIMA(0,1,0) errors \n\nCoefficients:\n          d2020      d2021\n      -228.9771  -166.3128\ns.e.    10.7224    10.7224\n\nsigma^2 = 188.9:  log likelihood = -91.86\nAIC=189.72   AICc=190.99   BIC=193.13\n\n\nSe identifica un proceso ARIMA(0, 1, 0) sin deriva, es decir un paseo aleatorio (equivalente al método Ingenuo I).\n\narima010 &lt;- Arima(Pernoctaciones, \n                  order = c(0, 1, 0),\n                  include.constant = FALSE,\n                  xreg = cbind(d2020, d2021))\n\narima010\n\nSeries: Pernoctaciones \nRegression with ARIMA(0,1,0) errors \n\nCoefficients:\n          d2020      d2021\n      -228.9771  -166.3128\ns.e.    10.7224    10.7224\n\nsigma^2 = 188.9:  log likelihood = -91.86\nAIC=189.72   AICc=190.99   BIC=193.13\n\n\nTras estimar el modelo, el análisis del error revela de nuevo que no es necesaria más intervención (Figura 2).\n\nerror &lt;- residuals(arima010)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(2000, 2024, 2))\n\n\n\n\n\n\n\nFigura 2: Error + Intervención"
  },
  {
    "objectID": "03-14-Ejemplo4.html#validación",
    "href": "03-14-Ejemplo4.html#validación",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.2 Validación",
    "text": "3.2 Validación\n\nMedidas de error\nEl error medio es 12.9 millones de pernoctaciones (RMSE) y el error porcentual medio es 4.61% (MAPE). Los intervalos de confianza de las predicciones no son válidos.\n\naccuracy(arima010)\n\n\n\n               ME  RMSE  MAE  MPE MAPE MASE ACF1\nTraining set 2.84 12.86 9.84 0.24 4.61 0.34 0.19\n\n\n\n\nCoeficientes significativos\nLos coeficientes asociados a la intervención son significativos.\n\ncoeftest(arima010)\n\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(&gt;|z|)    \nd2020 -228.977     10.722 -21.355 &lt; 2.2e-16 ***\nd2021 -166.313     10.722 -15.511 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nError de previsión extramuestral según horizonte temporal\nAsumimos que se precisan diez años para hacer una buena estimación, \\(k=10\\), y que el horizonte temporal es cuatro años vista, \\(h = 4\\).\n\nk &lt;- 10                  \nh &lt;- 4                    \nT &lt;- length(Pernoctaciones)     \ns &lt;- T - k - h    \n\nmapeArima010 &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(Pernoctaciones, start = i + 1, end = i + k)\n  test.set &lt;-  subset(Pernoctaciones, start = i + k + 1, end = i + k + h) \n  \n  fit &lt;- Arima(train.set, \n               include.constant = FALSE,\n               order = c(0, 1, 0))\n  \n  fcast &lt;- forecast(fit, h = h)\n  \n  mapeArima010[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n}\n\nmapeArima010 &lt;- apply(mapeArima010, MARGIN = 2, FUN = median)\nmapeArima010\n\n[1]  3.588371 11.787518 14.295619 17.350341\n\n\nEl error mediano de previsión varia entre el 3.6% a un año vista y el 17.4% a cuatro años vista."
  },
  {
    "objectID": "03-06-Tema6.html#métodos-sencillos-de-predicción-1",
    "href": "03-06-Tema6.html#métodos-sencillos-de-predicción-1",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "2.1 Métodos sencillos de predicción",
    "text": "2.1 Métodos sencillos de predicción\nMétodo ingenuo II: \\(\\hat{y}_{T+h}=y_T + h(y_T-y_{T-1})\\).\n\nLa predicción \\(h\\) periodos adelante es la última observación disponible más \\(h\\) veces el último incremento observado.\nNo tiene función en R, pero se podría emular mediante la función ets (véase epígrafe de 3 de este tema, Alisado de Holt).\n\nMétodo de la deriva: \\(\\hat{y}_{T+h}=y_T+h\\frac{y_T - y_1}{T-1}\\).\n\nLa predicción \\(h\\) periodos adelante es la última observación disponible más \\(h\\) veces el incremento medio observado.\nFunción de R: rwf(y, h, drift = TRUE)\n\nObserva que ambos métodos realmente solo hacen uso de dos observaciones de toda la serie y en ambos casos para obtener una pendiente con la que predecir."
  },
  {
    "objectID": "03-06-Tema6.html#ejemplo-de-aplicación-a-la-serie-residuos",
    "href": "03-06-Tema6.html#ejemplo-de-aplicación-a-la-serie-residuos",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "2.2 Ejemplo de aplicación a la serie Residuos",
    "text": "2.2 Ejemplo de aplicación a la serie Residuos\nAnalizaremos Residuos, una serie anual de 1995 a 2022 (fuente Instituto Nacional de Estadística) que muestra los residuos recogidos por o en nombre de las autoridades municipales y eliminados a través del sistema de gestión de residuos. Los datos están disponibles en el fichero Residuos.csv. La primera columna tiene el año de la serie y la segunda contiene los residuos recogidos en kg per cápita. El panel a) de la Figura 1 muestra que es una serie con tendencia que ha cambiado con el tiempo.\n\nresiduos &lt;- read.csv2(\"./series/Residuos.csv\", \n                      header = TRUE)\n\nresiduos &lt;- ts(residuos[, 2],\n               start = 1995, \n               frequency  = 1)\n\nderivaResiduos &lt;- rwf(residuos, h = 5, \n                      drift = TRUE)\n\nsummary(derivaResiduos)\n\n\nForecast method: Random walk with drift\n\nModel Information:\nCall: rwf(y = residuos, h = 5, drift = TRUE) \n\nDrift: -1.4074  (se 4.2266)\nResidual sd: 21.962 \n\nError measures:\n                        ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -1.684166e-14 21.55142 16.49657 -0.0954967 3.044183 0.9986713\n                  ACF1\nTraining set 0.4069491\n\nForecasts:\n     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n2023       465.5926 436.9307 494.2544 421.7581 509.4271\n2024       464.1852 422.9337 505.4366 401.0965 527.2738\n2025       462.7778 411.3916 514.1640 384.1894 541.3662\n2026       461.3704 401.0539 521.6869 369.1242 553.6165\n2027       459.9630 391.4480 528.4779 355.1784 564.7475\n\n\nLa salida obtenida con summary muestra el resultado de la aplicación del método de la deriva, donde se ha fijado un horizonte de previsión de cinco años (h = 5). Primero el método calcula la pendiente media de toda la serie a partir del primer y último dato \\(\\frac{y_T - y_1}{T-1}\\) que vale \\(-1.4074\\) (Drift en la salida). Después, la previsión para 2023 se obtiene sumando al último dato de la serie (467) la pendiente, que por ser negativa ofrece un volumen de residuos inferior al de 2023. Si sumamos sucesivamente la pendiente, vamos obteniendo el resto de predicciones.\nLa calidad de ajuste muestra un RMSE de 21.6 kg per cápita (16.5 kg per cápita si usamos el MAE) o del 3%. El método no ofrece sesgo (MPE inferior al 1%), pero las predicciones por intervalo no son fiables (ACF1 superior a 0.1).\nEn la Figura 2 muestra el resultado gráfico de la aplicación de este método. Observa que la predicción seria la continuación de una línea imaginaria que pasa por el primer y último dato de la serie.\n\nautoplot(derivaResiduos, \n         series = \"\",\n         xlab = \"\",\n         ylab = \"Kg per cápita\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 2: Recogida de residuos y predicción por el método de la Deriva"
  },
  {
    "objectID": "03-06-Tema6.html#definición",
    "href": "03-06-Tema6.html#definición",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "3.1 Definición",
    "text": "3.1 Definición\nDentro de las series con tendencia y sin estacionalidad, para obtener una predicción en el periodo \\(t+1\\) con datos hasta el periodo \\(t\\) necesitamos dos componentes:\n\nLa estimación del nivel de la serie en el periodo \\(t\\): \\(l_t\\)\nLa estimación de la pendiente de la serie en el periodo \\(t\\): \\(b_t\\)\n\nA partir de estas componentes obtenidas en el periodo \\(t\\) y para un esquema aditivo, se tendría que la predicción en el periodo \\(t+1\\) es:\n\\[\\widehat{y}_{t+1} = l_t+b_t.\\] Si el objetivo es estimar una previsión \\(h\\) periodos hacia delante desde el periodo \\(t\\), \\(\\widehat{y}_{t+h}\\), hay que modificar la ecuación de predicción adecuadamente. Por ejemplo, para el caso aditivo se tendría que\n\\[\\widehat{y}_{t+h} = l_t+hb_t.\\]"
  },
  {
    "objectID": "03-06-Tema6.html#casos-posibles",
    "href": "03-06-Tema6.html#casos-posibles",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "3.2 Casos posibles",
    "text": "3.2 Casos posibles\nEn las expresiones previas hemos supuesto que el nivel y la pendiente tienen esquema aditivo, pero puede ser multiplicativo (\\(\\widehat{y}_{t+h} = l_t \\cdot b_t^h\\)), donde la pendiente incremente porcentualmente el nivel de la serie. Además, la pendiente puede ser amortiguada, concepto que definiremos en breve.\nPor otro lado, recordemos que el término de error de los modelos de alisado puede ser aditivo o multiplicativo. Si el residuo es aditivo, entonces el modelo es \\(y_t = \\widehat{y}_t + \\widehat{\\varepsilon}_t\\). Ahora bien, si el residuo es multiplicativo, entonces el modelo es \\(y_t = \\widehat{y}_t \\cdot (1 + \\widehat{\\varepsilon}_t)\\).\nPor tanto, dentro de las series con tendencia y sin estacionalidad hay 8 posibles casos: dos según el tipo de error por 4 según el tipo de tendencia. Si, por completitud, añadimos a estos casos los dos ya vistos para series estacionarias en el Tema 4, tememos la Tabla 1 de posibilidades. En la tabla, la primera letra hace referencia al tipo de error y la segunda al tipo de pendiente.\n\n\n\nTabla 1: Casos de alisado según el tipo de error y tendencia\n\n\n\n\n\nTendencia\n\nError\n\n\n\n\n\nAditivo (A)\nMultiplicativo (M)\n\n\nNinguna (N)\nA, N\nM, N\n\n\nAditiva (A)\nA, A\nM, A\n\n\nAditiva Amortiguada (Ad)\nA, Ad\nM, Ad\n\n\nMultiplicativa (M)\nA, M\nM, M\n\n\nMultiplicativa Amortiguada (Md)\nA, Md\nM, Md\n\n\n\n\n\n\nCada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización:\n\\[\n\\begin{aligned}\nl_t& = f_l(y_t,y_{t-1}\\ldots, l_{t-1},l_{t-2}\\ldots,b_{t-1},b_{t-2}\\ldots) \\\\\nb_t& = f_b(y_t,y_{t-1}\\ldots, l_{t},l_{t-1}\\ldots,b_{t-1},b_{t-2}\\ldots)\n\\end{aligned}\n\\]\nRecordemos que el tipo de error (aditivo o multiplicativo) es sobre todo relevante en el cálculo del intervalo de confianza de las predicciones.\nLos modelos más usuales para series con tendencia y sin estacionalidad son (recordemos que las letras indican: error, tendencia y estacionalidad):\n\n(A, A, N): Alisado de Holt\n(A, Ad, N): Alisado con tendencia amortiguada (d de damped, amortiguamiento)\n\nAhora bien, podemos estimar cualquiera de los 10 modelos usando la función ets del paquete forecast.\nAcude al artículo de Hyndman and Khandakar (2008) para saber más de cada modelo, o al libro de Hyndman et al. (2008)."
  },
  {
    "objectID": "03-06-Tema6.html#alisado-exponencial-de-holt-a-a-n",
    "href": "03-06-Tema6.html#alisado-exponencial-de-holt-a-a-n",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "3.3 Alisado exponencial de Holt (A, A, N)",
    "text": "3.3 Alisado exponencial de Holt (A, A, N)\n\nFormulas interactivas de sus componentes\nLas ecuaciones recursivas son\n\\[\n\\begin{aligned}\nl_t & =\\alpha y_t + (1-\\alpha)(l_{t-1}+b_{t-1}) \\\\\nb_t & =\\beta (l_t - l_{t-1}) + (1-\\beta)b_{t-1}\n\\end{aligned}\n\\]\nLa ecuación de la predicción intramuestral a un periodo vista es\n\\[\\widehat{y}_{t+1} = l_t + b_t,\\] de forma que la ecuación de predicción extramuestral es \\[\\widehat{y}_{T+h}=l_T + h b_T.\\]\nDos estimaciones razonables del nivel de la serie en el periodo \\(t\\) son el valor observado para la serie en ese periodo \\(y_t\\), y una estimación del nivel del periodo \\(t\\) realizada desde el periodo \\(t-1\\): \\(l_{t-1} + b_{t-1}\\). Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo \\(t\\) son el cambio de nivel de \\(t-1\\) a \\(t\\) (el último observado) \\(l_t-l_{t-1}\\), y el valor de la pendiente en el periodo previo, \\(b_{t-1}\\). En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por \\(0 &lt; \\alpha, \\beta &lt; 1\\).\nObserva que el método ingenuo II es un caso concreto de Alisado de Holt. Si hacemos \\(\\alpha=\\beta = 1,\\) queda \\(l_t=y_t\\) y \\(b_t=y_t-y_{t-1}\\), por tanto \\[\\widehat{y}_{t+1}=l_t + b_t = y_t + (y_t - y_{t-1})\\] y \\[\\widehat{y}_{T+h}=l_T + h \\cdot b_T = y_T + h(y_T - y_{T-1}).\\]\n\n\n\n\n\n\n¿Sabrías responder a estas preguntas?\n\n\n\nHemos visto que en modelo de Alisado con tendencia, si \\(\\alpha = \\beta = 1\\), la ecuación de predicción que queda es la del método Ingenuo II.\n¿Cómo quedaría la ecuación de predicción si \\(\\alpha = \\beta = 0\\)?\n¿Y si \\(\\alpha = 1\\) y \\(\\beta = 0\\)? ¿Y si \\(\\alpha = 0\\) y \\(\\beta = 1\\)?\n\n\n\n\nEstimación de los parámetros del modelo\nPara aplicar este método es necesario estimar unos valores iniciales \\(l_0\\) y \\(b_0\\) de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros \\(\\alpha\\) y \\(\\beta\\).\nLa función ets por defecto estima los parámetros \\(\\alpha\\), \\(\\beta\\), \\(l_0\\) y \\(b_0\\) maximizando la función de verosimilitud. En este caso la búsqueda está restringida a \\(0 &lt; \\beta &lt; \\alpha &lt; 1\\). Por tanto, \\(\\alpha\\) y \\(\\beta\\) nunca pueden ser 0 o 1 y en la práctica sus valores limite son 0.0001 y 0.9999.\nLa interpretación del parámetro \\(\\alpha\\) es similar al caso del alisado exponencial simple.\nInterpretación del parámetro \\(\\beta\\):\n\nSi \\(\\beta = 1\\), \\(b_t = l_t - l_{t-1}\\), la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).\nSi \\(\\beta = 0\\), \\(b_t = b_{t-1}= \\ldots = b_0\\), la pendiente se mantiene constante en el tiempo.\n\n\n\nEjemplo de aplicación a la serie Residuos\nVamos a usar el método de alisado de Holt para predecir la serie Residuos. Usaremos para ello la función ets con el argumento model = \"AAN\" (error y tendencia aditivas sin estacionalidad). Además, es necesario añadir el argumento damped = FALSE para prevenir el uso de tendencia amortiguada, que veremos en el siguiente epígrafe.\n\netsResiduos &lt;- ets(residuos, \n                   model = \"AAN\",\n                   damped = FALSE)\nsummary(etsResiduos)\n\nETS(A,A,N) \n\nCall:\nets(y = residuos, model = \"AAN\", damped = FALSE)\n\n  Smoothing parameters:\n    alpha = 0.9917 \n    beta  = 1e-04 \n\n  Initial states:\n    l = 568.957 \n    b = -2.8916 \n\n  sigma:  26.1313\n\n     AIC     AICc      BIC \n281.7210 284.4483 288.3820 \n\nTraining set error measures:\n                     ME     RMSE      MAE        MPE     MAPE     MASE\nTraining set -0.7573797 24.19288 18.21516 -0.2531821 3.386255 1.102711\n                  ACF1\nTraining set 0.2192994\n\n\nLos valores óptimos de los cuatro parámetros estimados son \\(\\alpha=\\) 0.99, \\(\\beta=\\) 0, \\(l_0 =\\) 568.96 y \\(b_0 =\\) -2.89.\nObserva que \\(\\alpha\\) es prácticamente 1 y que \\(\\beta\\) es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extramuestral, obtenemos \\(y_{T+h}=y_T + h\\cdot b_0\\): la predicción es el último valor observado más \\(h\\) veces la primera pendiente estimada. La calidad de las predicciones es razonable, con un error porcentual medio del 3.4%.\nPor otro lado, el valor de \\(l_0\\) indica que el nivel estimado para el volumen de residuos de 1994 es de 568.96. Además, el incremento entre 1994 y 1995 se estima en \\(b_0 =\\) -2.89.\n\n\n\n\n\n\nParámetros estimados\n\n\n\n¿Cuántos parámetros se han estimado (y la respuesta no es 4)? ¿Cuál es el denominador en el cálculo de RMSE y de sigma?\n\n\nEn el objeto etsResiduos la matriz etsResiduos$states guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de \\(l_{2022}\\) y \\(b_{2022}\\) en su última fila, que valen respectivamente\n\ntail(etsResiduos$states, 1)\n\nTime Series:\nStart = 2022 \nEnd = 2022 \nFrequency = 1 \n            l         b\n2022 466.9747 -2.893718\n\n\nAsí, la predicción para \\(2023\\) es \\(\\widehat{y}_{2023}=l_{2022} + b_{2022}=\\) 466.97 \\(+\\) -2.89 \\(=\\) 464.08. Igualmente \\(\\widehat{y}_{2024}=l_{2022} + 2\\cdot b_{2022}=\\) 461.19. Es decir, el incremento entre previsiones es constante e igual a \\(b_{2022}\\) que, por ser \\(\\beta\\) prácticamente nulo, casi coincide con \\(b_0\\).\n\netsResiduosf &lt;- forecast(etsResiduos,\n                         h = 5, \n                         level = 95)\netsResiduosf\n\n     Point Forecast    Lo 95    Hi 95\n2023       464.0810 412.8646 515.2974\n2024       461.1873 389.0510 533.3236\n2025       458.2936 370.0626 546.5245\n2026       455.3998 353.5850 557.2147\n2027       452.5061 338.7153 566.2970\n\n\nLa Figura 3 muestra la serie Residuos y las previsiones extramuestrales, que muestran una ligera tendencia decreciente.\n\nautoplot(etsResiduosf,\n         xlab = \"\",\n         ylab = \"Kg. per cápita\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 3: Residuos y predicción con alisado de Holt"
  },
  {
    "objectID": "03-06-Tema6.html#alisado-exponencial-con-pendiente-amortiguada-a-ad-n",
    "href": "03-06-Tema6.html#alisado-exponencial-con-pendiente-amortiguada-a-ad-n",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "3.4 Alisado exponencial con pendiente amortiguada (A, Ad, N)",
    "text": "3.4 Alisado exponencial con pendiente amortiguada (A, Ad, N)\nLas previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por Gardner and Mckenzie (1985), es introducir un nuevo parámetro \\(0 \\leq \\phi \\leq 1\\) que amortigua la tendencia hasta hacerla plana en el largo plazo.\n\nFormulas interactivas de sus componentes\nLas ecuaciones recursivas son\n\\[\n\\begin{aligned}\nl_t & =\\alpha y_t + (1-\\alpha)(l_{t-1}+\\phi b_{t-1}) \\\\\nb_t & =\\beta (l_t - l_{t-1}) + (1-\\beta)\\phi b_{t-1}\n\\end{aligned}\n\\]\nLa ecuación de la predicción intramuestral a un periodo vista es \\[\\widehat{y}_{t+1} = l_t + \\phi b_t,\\] de forma que la ecuación de predicción extramuestral es \\[\\widehat{y}_{T+h}=l_T + (\\phi + \\phi^2 + \\ldots + \\phi^h) b_T.\\]\nSe ha añadido un nuevo parámetro \\(\\phi\\in [0, 1]\\) que acompaña siempre a la pendiente \\(b_t\\). Si \\(\\phi = 1\\), se tiene el alisado de Holt y si \\(\\phi = 0\\), se tiene el alisado simple. Se puede comprobar que en el largo plazo las predicciones se hacen constantes e iguales a \\(l_T + \\phi b_T/(1 - \\phi)\\).\nPor razones prácticas el rango de búsqueda de \\(\\phi\\) queda en el intervalo \\([0.8, 0.98]\\). Si el valor óptimo de \\(\\phi\\) fuera su valor máximo de \\(0.98\\) o muy cercano a este, cabría plantearse si no sería más adecuado un modelo sin amortiguamiento.\n\n\nEjemplo de aplicación a la serie Residuos\nVamos a usar el método de Alisado con amortiguamiento para predecir, una vez más, la serie Residuos añadiendo a la función ets el argumento damped = TRUE. En este caso, para ver el efecto del amortiguamiento vamos a pedir un horizonte temporal de previsión más largo.\n\netsDResiduos &lt;- ets(residuos, \n                    model = \"AAN\", \n                    damped = TRUE)\nsummary(etsDResiduos)\n\nETS(A,Ad,N) \n\nCall:\nets(y = residuos, model = \"AAN\", damped = TRUE)\n\n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.1808 \n    phi   = 0.8 \n\n  Initial states:\n    l = 564.3968 \n    b = 14.5779 \n\n  sigma:  26.4267\n\n     AIC     AICc      BIC \n283.1587 287.1587 291.1520 \n\nTraining set error measures:\n                    ME    RMSE      MAE        MPE     MAPE     MASE       ACF1\nTraining set -3.193352 23.9512 17.42662 -0.6361345 3.226137 1.054975 0.04099902\n\n\nEl valor óptimo del parámetro \\(\\phi\\) es \\(0.8\\) y el error porcentual 3.2%, algo inferior al obtenido con el alisado de Holt sin amortiguamiento. Además, el modelo de Alisado con amortiguamiento genera intervalos de predicción correctos, cosa que no ocurría con el modelo de Alisado de Holt.\n\n\n\n\n\n\nParámetros estimados\n\n\n\n¿Cuántos parámetros se han estimado en este caso? ¿Cuáles?\n\n\nLa Figura 4 muestra la serie Residuos, su estimación intramuestral y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se amortigua en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años.\n\netsDResiduosf &lt;- forecast(etsDResiduos, \n                          h = 15,\n                          level = 95)\netsDResiduosf\n\n     Point Forecast    Lo 95    Hi 95\n2023       467.3276 415.5323 519.1229\n2024       467.5896 388.8679 546.3113\n2025       467.7992 365.5349 570.0635\n2026       467.9669 343.9999 591.9340\n2027       468.1011 323.7753 612.4269\n2028       468.2084 304.6386 631.7782\n2029       468.2943 286.4588 650.1298\n2030       468.3630 269.1417 667.5842\n2031       468.4179 252.6118 684.2240\n2032       468.4619 236.8035 700.1202\n2033       468.4971 221.6584 715.3357\n2034       468.5252 207.1236 729.9268\n2035       468.5477 193.1509 743.9445\n2036       468.5657 179.6963 757.4351\n2037       468.5801 166.7198 770.4405\n\nautoplot(etsDResiduosf,\n         xlab = \"\",\n         ylab = \"kg per cápita\",\n         main = \"\",\n         PI = FALSE)\n\n\n\n\n\n\n\nFigura 4: Residuos y predicción con alisado exponencial con amortiguamiento"
  },
  {
    "objectID": "03-06-Tema6.html#casos-generales-de-alisado-exponencial",
    "href": "03-06-Tema6.html#casos-generales-de-alisado-exponencial",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "3.5 Casos generales de alisado exponencial",
    "text": "3.5 Casos generales de alisado exponencial\nEn los epígrafes previos hemos visto dos de los diez casos expuestos en la taxonomía de la Tabla 1, fijados a partir de los argumentos model y damped de la función ets. ¿Pero cómo sabemos nosotros cuál es realmente el modelo que mejor se ajusta a nuestros datos? Veamos ahora como estimar cualquiera de los modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md) y el error (A, M).\nRecordemos que el tipo de modelo en ets se especifica con el argumento model y que damped indica si hay amortiguamiento. Por ejemplo, model = \"AAN\", damped = FALSE indica alisado de Holt y model = \"MMN\", damped = TRUE indica un modelo con error y pendiente multiplicativas y con amortiguamiento.\nSi en una de las tres letras del código del modelo se indica “Z”, la función ets selecciona de entre los modelos posibles el que mejor se ajusta. Si ademas se indica damped = NULL (o no se indica nada) se dejaría a la función total libertad para buscar entre modelos con y sin amortiguamiento.\nPor ejemplo, model = \"ZAN\" indica un modelo con pendiente aditiva, sin estacionalidad y dejaría a ets la búsqueda de la mejor opción para el error (aditivo o multiplicativo) y para el amortiguamiento. Si se especifica model = \"ZZZ\" junto con damped = NULL (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos. Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar damped = FALSE y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento additive.only = TRUE.\nEn realidad, por defecto ets no considera modelos con tendencia multiplicativa (últimas dos líneas de la Tabla 1). Debes fijar el parámetro allow.multiplicative.trend = TRUE para incluir en la búsqueda estos modelos.\nCuando se pide a función ets elegir entre varias modelos, por defecto elige aquel con menor AICc, pero recuerda que el argumento ic permite cambiar de criterio.\nPor ejemplo, para Residuos si no restringimos la búsqueda, la función ets muestra que el modelo con mejor ajuste es “MNN” con \\(\\alpha = 1\\). Es decir, el Ingenuo I con error multiplicativo.\n\nsummary(ets(residuos))\n\nETS(M,N,N) \n\nCall:\nets(y = residuos)\n\n  Smoothing parameters:\n    alpha = 0.9999 \n\n  Initial states:\n    l = 504.2743 \n\n  sigma:  0.0395\n\n     AIC     AICc      BIC \n267.4168 268.4168 271.4134 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -1.331356 21.20947 15.95526 -0.3461958 2.946509 0.9659013\n                  ACF1\nTraining set 0.4113965\n\n\n\n\n\n\n\n\nUna reflexión sobre los métodos automáticos de selección de modelos\n\n\n\n\n\nCon el comando forecast(ets(nacimientos),h=24) obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?\nParémonos a reflexionar sobre lo que hemos hecho o, más bien, lo que el algoritmo ha hecho y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.\nSi consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intramuestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.\nPero no es esto lo que hacemos.\nNada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por mejores quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea el que minimiza nuestro criterio de calidad de las predicciones.\nAhora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.\nAlguien dirá que casi seguro entre las predicciones subóptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo subóptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.\nEsta reflexión realizada en el contexto de series temporales y para la función ets es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados.\nA pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir nuestro propio código, seguiremos trabajando con modelos subóptimos y obteniendo estimaciones subóptimas, pero diciendo que son las mejores."
  },
  {
    "objectID": "03-06-Tema6.html#diferenciación-de-una-serie",
    "href": "03-06-Tema6.html#diferenciación-de-una-serie",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "4.1 Diferenciación de una serie",
    "text": "4.1 Diferenciación de una serie\nRecuerda que para poder aplicar estos modelos, la serie tiene que ser estacionaria en media, en varianza y ergódica. Además, por el tipo de series que estamos analizando, estas son siempre estacionarias en varianza y la estacionariedad en media implica ergodicidad. Es decir, para series sin estacionalidad solo necesitamos para aplicar modelos Arima que la serie sea estacionaria en media.\nPor tanto, ¿qué pasa si una serie temporal \\(\\{y_t\\}_{t=1}^T\\) no es estacionaria en media?. A continuación veremos una transformación muy sencilla que convierten una serie no estacionaria en estacionaria, la diferenciación.\nEn el panel superior de la Figura 5 vuelves a tener la serie de aforo vista al inicio del tema, que denominaremos \\(y_t\\). En el panel inferior la diferencia de la serie, \\(y_t - y_{t-1}\\). La serie Aforo no es estacionaria en media, pero su diferencia si es estacionaria en media.\n\n\n\n\n\n\n\n\nFigura 5: Aforo y su diferencia\n\n\n\n\n\nLa diferenciación permite transformar una serie no estacionaria en media en estacionaria en media. Diferenciar de orden \\(k\\) consiste en restar a la observación de un periodo la de \\(k\\) periodos antes: \\[\\nabla_k y_t = y_t - y_{t-k}.\\]\nUn caso concreto es la diferenciación regular o diferenciación de orden uno, que consiste en restar a la observación de un periodo la del periodo precedente: \\[\\nabla y_t = y_t - y_{t-1}.\\]\nSi \\(\\nabla y_t\\) no fuera estacionaria, se diferenciaría una segunda vez para obtener una doble diferenciación de primer orden: \\[\\nabla^{2} y_t = \\nabla(\\nabla y_t) = \\nabla y_t - \\nabla y_{t-1} = (y_t - y_{t-1}) - (y_{t-1} - y_{t-2}) = y_t - 2y_{t-1} + y_{t-2}\\]\nEn la práctica una sola diferenciación suele ser suficiente para obtener la estacionariedad en media; diferenciar dos veces es excepcional; y diferenciar tres o más veces no se da.\n\nDiferenciación con R\nR dispone de la función diff para diferenciar una serie:\n\ndiff(x, lag = k) calcula la diferencia de orden \\(k\\), \\(\\nabla_k y_t\\)\ndiff(x) calcula la diferencia regular o de orden \\(1\\), \\(\\nabla y_t\\) (el valor por defecto de lag es 1)\ndiff(x, difference = d) calcula \\(d\\) diferencias regulares, \\(\\nabla^d y_t\\)\n\nAdemás, en forecast está disponible la función ndiffs que estima el número de diferencias regulares necesarias para que una serie sea estacionaria. Para ello usa un contraste de raíces unitarias (que no veremos en este curso). Para la serie Aforo la función sugiere una diferenciación. Lo mismo ocurre para la serie Residuos.\n\nndiffs(aforo)\n\n[1] 1\n\nndiffs(residuos)\n\n[1] 1\n\n\nSin embargo, para la serie Nacimientos, el número de diferenciaciones sugerida es 2.\n\nndiffs(nacimientos)\n\n[1] 2\n\n\n\n\nOperador Retardo (de nuevo)\nPodemos usar el operador retardo para escribir la diferenciación de una forma más operativa. Así,\n\\[\n\\begin{aligned}\n  \\nabla y_t & =  y_t - y_{t-1} = y_t - Ly_t = (1-L)y_t \\\\\n  \\nabla^d y_t & =  (1-L)^d y_t\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "03-06-Tema6.html#procesos-arimap-d-p",
    "href": "03-06-Tema6.html#procesos-arimap-d-p",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "4.2 Procesos ARIMA(p, d, p)",
    "text": "4.2 Procesos ARIMA(p, d, p)\nYa vimos que ARIMA surge de combinar las siglas de tres procesos diferentes: AR de AutoRegresive, I de Integrated y MA de Moving Average. De ellos vimos en el Tema 4 los procesos AR y MA.\nVeamos ahora la I.\nIntegración, I\nSi la serie \\(y_t\\) no es estacionaria, pero tras diferenciarla \\(d\\) veces se hace estacionaria, diremos que la serie es integrada de orden \\(d\\): \\(y_t \\sim I(d)\\). Por tanto,\n\nuna serie estacionaria se indicará como \\(y_t \\sim I(0)\\)\n\\(y_t \\sim I(d)\\) es equivalente a \\(\\nabla^d y_t = (1 - L)^d y_t \\sim I(0)\\)\n\nUna serie \\(y_t\\) sigue un proceso \\(ARIMA(p,d,q)\\) si:\n\nhay que diferenciar la serie \\(d\\) veces para hacerla estacionaria, \\(y_t \\sim I(d)\\); y\nla serie diferenciada sigue un proceso ARMA(p,q), \\(\\nabla^d y_t \\sim ARMA(p,q)\\).\n\nEntonces, podemos escribir \\(y_t \\sim ARIMA(p,d,q)\\):\n\\[\\begin{equation*}\n  \\begin{array}{c@{\\qquad}c@{\\quad}ccc}\n   (1 - \\phi_1 L - \\ldots - \\phi_p L^p) & (1- L)^d y_t & = & c + (1 + \\theta_1 L + ... + \\theta_q L^q) \\varepsilon_t \\\\\n                           \\uparrow                            & \\uparrow      &   & \\uparrow \\\\\n                           AR(p)                               & I(d)          &   & MA(q)\n  \\end{array}\n\\end{equation*}\\]\nAlgunos ejemplos son:\n\n\\(y_t \\sim ARIMA(0, 1, 0): \\;\\;(1- L) y_t = c + \\varepsilon_t\\) o \\(y_t = c + y_{t-1} + \\varepsilon_t\\). Si \\(c=0\\), tenemos un paseo aleatorio; si \\(c \\neq 0\\), tenemos un paseo aleatorio con deriva.\n\\(y_t \\sim ARIMA(1, 1, 1): \\;\\;(1 - \\phi_1 L)(1- L) y_t = c + (1 + \\theta_1 L) \\varepsilon_t\\) o \\(y_t = c + y_{t-1} + \\phi_1(y_{t-1} - y_{t-2}) + \\theta_1 \\varepsilon_{t-1} + \\varepsilon_t\\). Observa que a pesar de ser un proceso AR(1), la prediccion de la serie en el periodo \\(t\\) depende no solo del valor de la serie en el periodo \\(t-1\\), sino también de su valor en el periodo \\(t-2\\). Solo el uso del operador retardo permite escribir adecuadamente la ecuación de predicción."
  },
  {
    "objectID": "03-06-Tema6.html#ejemplo-de-aplicación-a-la-serie-residuos-3",
    "href": "03-06-Tema6.html#ejemplo-de-aplicación-a-la-serie-residuos-3",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "4.3 Ejemplo de aplicación a la serie Residuos",
    "text": "4.3 Ejemplo de aplicación a la serie Residuos\nVamos a aplicar la metodología de Box-Jenkins a la serie Residuos.\n\nDiferencación de la serie\nEl primer paso es transformar la serie original para que sea estacionaria. La Figura 6 muestra la gráfica de la serie y de su primera diferencia. Se aprecia que la serie original no es estacionaria en media, pero si lo es la serie diferenciada.\n\ncbind(\"Residuos\" = residuos,\n      \"Dif. Residuos\" = diff(residuos)) %&gt;%\n  autoplot(facets = TRUE,\n           xlab = \"\",\n           ylab = \"kg. per cápita\",\n           main = \"\")\n\n\n\n\n\n\n\nFigura 6: Residuos recogidos\n\n\n\n\n\nAdemás,\n\nndiffs(residuos)\n\n[1] 1\n\n\nPodemos concluir que la primera diferencia de la serie Residuos es estacionaria y, por tanto, ergódica. Es decir, \\(d=1\\) o \\(residuos_t \\sim I(1)\\).\n\n\nIdentificación\nTras diferenciar la serie, vamos a identificar los valores de \\(p\\) y \\(q\\), el paso más difícil, ayudándonos de la función auto.arima. Como ya hemos decidido el número de diferenciaciones, fijamos este parámetro con d = 1.\n\nauto.arima(residuos, \n           d = 1)\n\nSeries: residuos \nARIMA(1,1,0) \n\nCoefficients:\n         ar1\n      0.4178\ns.e.  0.1741\n\nsigma^2 = 397.8:  log likelihood = -118.71\nAIC=241.42   AICc=241.92   BIC=244.01\n\n\nObserva como la identificación automática da como mejor modelo \\(p=1\\) y \\(q=0\\), donde el parámetro estimado parece siginficativo (supera los dos errores estándar). Es decir \\(residuos_t \\sim ARIMA(1,1,0)\\) sin deriva (sin constante).\n\n\nEstimación\nProcedemos a estimar el modelo identificado con la función Arima, donde el proceso a estimar se indica en el argumento order y si hay constante en el argumento con include.constant.\n\narima110 &lt;- Arima(residuos, \n                  order = c(1, 1, 0), \n                  include.constant = FALSE)\narima110\n\nSeries: residuos \nARIMA(1,1,0) \n\nCoefficients:\n         ar1\n      0.4178\ns.e.  0.1741\n\nsigma^2 = 397.8:  log likelihood = -118.71\nAIC=241.42   AICc=241.92   BIC=244.01\n\n\n\n\nIntervención\nSe analiza si para algún año se observa un error atípico (por ejemplo 3 veces superior al error estándar). La Figura 7 muestra que en los años 1999 y 2004, el residuo sobrepasa los dos errores estándar pero queda lejos de los tres errores estándar así que asumiremos que no hay valores atípicos.\n\nerror &lt;- residuals(arima110)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1995, 2023, 2)) \n\n\n\n\n\n\n\nFigura 7: Error + Intervención\n\n\n\n\n\n\n\nValidación\nEl parámetro estimado \\(\\phi_1\\) es significativo.\n\ncoeftest(arima110)\n\n\nz test of coefficients:\n\n    Estimate Std. Error z value Pr(&gt;|z|)  \nar1  0.41776    0.17414   2.399  0.01644 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nMedidas de error\nEl error medio es 19 kg per cápita (RMSE) y el error porcentual medio (MAPE) es 2.65%.\n\naccuracy(arima110)\n\n\n\n                ME  RMSE   MAE   MPE MAPE MASE  ACF1\nTraining set -0.85 19.22 14.54 -0.19 2.65 0.88 -0.05\n\n\nAdemás, hay no hay sesgo y la fórmula usada para la previsión por intervalo es correcta.\n\n\nInterpretación del modelo\nLa serie Residuos sigue un proceso ARIMA(1, 1, 0). Es decir ls ecuación del modelo es \\[(1 - \\phi_1 L)(1 - L)y_t = \\varepsilon_t\\] y la de predicción es \\[y_t = y_{t-1} + \\phi_1(y_{t-1}- y_{t-2}) + \\varepsilon_t\\]\nSi sustituimos los parámetros estimados se tiene que la ecuación de predicción estimada \\[\\hat y_t =y_{t-1} + 0.42(y_{t-1}- y_{t-2})\\] Cada año, los residuos recogidos y tratados son iguales a los del año pasado más un 42% de la última variación observada.\n\n\nPredicción\nUna vez validado el modelo podemos pasar a realizar predicciones, en este caso a 5 años vista.\n\nparima110 &lt;- forecast(arima110, \n                      h = 5, \n                      level = 95)\nparima110\n\n     Point Forecast    Lo 95    Hi 95\n2023            467 427.9075 506.0925\n2024            467 399.1766 534.8234\n2025            467 374.9424 559.0576\n2026            467 354.2518 579.7482\n2027            467 336.2096 597.7904\n\n\n\nautoplot(parima110, \n         xlab = \"\", \n         ylab = \"Kg. per cápita\",\n         main = \"\") +\n  scale_x_continuous(breaks= seq(1995, 2028, 2)) \n\n\n\n\n\n\n\nFigura 8: Residuos (1995-2022) y predicción (2023-2027)\n\n\n\n\n\nLa Figura 8 muestra la serie, la previsión y el intervalo de confianza al 95%. La predicción es constante porque anecdoticamente el volumen de residuos de los dos últimos años ha sido el mismo (\\(y_{T-1}=y_T\\)). Es decir, la última variación es cero y la ecuación de predicción queda \\(\\hat y_{T+1} =y_T\\). En las series diferenciadas el intervalo de confianza de las predicciones crece muy rápidamente porque los errores se van acumulando sin ningún tipo de amortiguamiento."
  },
  {
    "objectID": "03-06-Tema6.html#métodos-sencillos",
    "href": "03-06-Tema6.html#métodos-sencillos",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "6.1 Métodos sencillos",
    "text": "6.1 Métodos sencillos\nVamos a empezar aplicando el método de la deriva a la serie. Podemos observar que el incremento promedio de la serie es de 114.6 vehículos diarios. Este será el incremento que se aplicará al dato de 2023 para obtener las predicciones. En concreto, para 2025 se espera un paso de 9071 vehículos diarios por la N-340 a su paso por Oropesa.\n\nderivaAforo &lt;- rwf(aforo, h = 4, drift = TRUE)\nsummary(derivaAforo)\n\n\nForecast method: Random walk with drift\n\nModel Information:\nCall: rwf(y = aforo, h = 4, drift = TRUE) \n\nDrift: 114.6349  (se 127.5966)\nResidual sd: 1012.7662 \n\nError measures:\n                       ME     RMSE      MAE       MPE     MAPE      MASE\nTraining set 5.775913e-14 1004.696 688.7579 0.6342941 7.716355 0.9515316\n                  ACF1\nTraining set 0.1926475\n\nForecasts:\n     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n2024       8956.635 7648.462 10264.81 6955.958 10957.31\n2025       9071.270 7206.837 10935.70 6219.866 11922.67\n2026       9185.905 6884.952 11486.86 5666.902 12704.91\n2027       9300.540 6623.576 11977.50 5206.478 13394.60\n\n\nEl modelo ofrece un error de ajuste medio del 7.7% (unos 1000 vehículos según RMSE), no presenta sesgo y la predicción por intervalo no es fiable.\nComo la pendiente media estimada es de 114.6 vehículos al día (drift), la predicción crece anualmente en esta cantidad."
  },
  {
    "objectID": "03-06-Tema6.html#asilado-exponencial",
    "href": "03-06-Tema6.html#asilado-exponencial",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "6.2 Asilado exponencial",
    "text": "6.2 Asilado exponencial\n\nEstimacion del modelo\nSi estimamos el mejor modelo de alisado exponencial para la serie Aforo sin ningún tipo de restricción, nos encontramos:\n\netsAforo &lt;- ets(aforo)\nsummary(etsAforo) \n\nETS(M,A,N) \n\nCall:\nets(y = aforo)\n\n  Smoothing parameters:\n    alpha = 0.9432 \n    beta  = 0.0516 \n\n  Initial states:\n    l = 754.8422 \n    b = 748.8161 \n\n  sigma:  0.1\n\n     AIC     AICc      BIC \n1150.507 1151.541 1161.301 \n\nTraining set error measures:\n                    ME     RMSE     MAE       MPE     MAPE      MASE      ACF1\nTraining set -253.4493 1020.318 675.912 -3.048656 7.427081 0.9337848 0.1775309\n\n\nEl modelo estimado es ETS(M,A,N) o “MAN”, un modelo con pendiente aditiva, sin estacionalidad y con error multiplicativo. Es decir, \\(y_{t+1} = (l_t + b_t) \\cdot (1 + \\varepsilon_{t+1})\\).\nEl valor de \\(\\alpha\\) prácticamente es 1, indicando que el nivel de la serie varía en el tiempo. Por otro lado, el valor de \\(\\beta\\) prácticamente es 0, es decir, la pendiente se mantiene contante en el tiempo.\nRespecto de la calidad ajuste del modelo, el valor de MAPE = \\(7.4\\)% es solo ligeramente inferior al obtenido con el método sencillo. Por otro lado, el modelo estimado presenta un marcado sesgo negativo (las predicciones en promedio son mayores que los valores reales) y las predicciones por intervalos no están correctamente calculadas.\n\n\nPredicción\nMediante la función forecast podemos predecir el aforo para los proximos años. Como el último valor calculado para la pendiente \\(b_T\\) es negativo, se espera una progresiva reducción en el paso de vehículos por Oropesa. Con este método la predicción para 2025 es de 8638 vehículos diarios.\n\ntail(etsAforo$states, 1)\n\nTime Series:\nStart = 2023 \nEnd = 2023 \nFrequency = 1 \n            l         b\n2023 8814.216 -88.05432\n\netsResiduosPre &lt;- forecast(etsAforo, \n                         h = 4,\n                         level = 95)\netsResiduosPre\n\n     Point Forecast    Lo 95    Hi 95\n2024       8726.162 7016.524 10435.80\n2025       8638.108 6232.767 11043.45\n2026       8550.053 5561.714 11538.39\n2027       8461.999 4944.569 11979.43\n\n\n\n\nAnálisis del residuo\nVeamos si hay años atípicos.\n\nerror &lt;- residuals(etsAforo)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"Periodo\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, \n             colour = c(\"red\", \"blue\", \"blue\", \"red\"), lty = 2) + \n  scale_x_continuous(breaks= seq(1960, 2022, 4)) \n\n# Creamos un variable con todos las años de la serie\nfechas &lt;- format(seq(as.Date(\"1960-01-01\"), as.Date(\"2022-01-01\"), \"year\"), \"%Y\")\n# Identificamos los años atípicos\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"1979\" \"2020\"\n\n\n\n\n\n\n\n\nFigura 11: Error + Intervención\n\n\n\n\n\nLa Figura 11 muestra como intervención el año de la pandemia, con una caída en el aforo que superó las tres desviaciones típicas. También destaca en 1979 la caída en el aforo debida a la inauguración de la AP-7 en este tramo de carretera.\nLa prueba de Tukey solo identifica como atípico el año 2020.\n\natipicos &lt;- tsoutliers(error)\nfechas[atipicos$index]\n\n[1] \"2020\""
  },
  {
    "objectID": "03-06-Tema6.html#modelo-arima",
    "href": "03-06-Tema6.html#modelo-arima",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "6.3 Modelo Arima",
    "text": "6.3 Modelo Arima\n\nTransformación de la serie\nLa Figura 12 muestra que la serie Aforo no es estacionaria. Así, el primer paso es transformar la serie original para que lo sea. La serie no es estacionaria, pero sí lo es su primera diferencia. Ten siempre presente que diferenciar más veces de las necesarias puede dificultar la identificación y la interpretación. Por otro lado, la función ndiffs aconseja una diferenciación. Así, optamos por fijar \\(d = 1\\).\n\nautoplot(aforo, xlab = \"\", ylab = \"\", main = \"\")\nautoplot(diff(aforo), xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Serie original\n\n\n\n\n\n\n\n\n\n\n\n(b) Dif. de la serie\n\n\n\n\n\n\n\nFigura 12: Gráfica para Aforo y su primera diferencia\n\n\n\n\n\nndiffs(aforo)\n\n[1] 1\n\n\n\n\nIdentificación y Estimación\nVeamos a identificar los valores de \\(p\\) y \\(q\\) a partir de auto.arima, indicándole que d = 1. La función sugiere un proceso ARIMA(0,1,0) sin constante.\n\nauto.arima(aforo, \n           d = 1)\n\nSeries: aforo \nARIMA(0,1,0) \n\nsigma^2 = 1022556:  log likelihood = -525.28\nAIC=1052.57   AICc=1052.63   BIC=1054.71\n\n\nVamos a ver la gráfica de los residuos del modelo ARIMA(0,1,0) para identificar los valores extremos (intervención).\n\narima010 &lt;- Arima(aforo, \n                  order = c(0, 1, 0),\n                  include.constant = FALSE)\n\nerror &lt;- residuals(arima010)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1960, 2020, 4)) \n\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"1979\" \"2011\" \"2020\"\n\n\n\n\n\n\n\n\nFigura 13: Error + Intervención\n\n\n\n\n\nSe identifican tres posibles valores extremos, tres intervenciones, en los años 1979, 2011 (relacionado con la Gran Recesión) y 2020, donde el error supera las 2.5 desviaciones típicas. Cada una de las intervenciones es del tipo pulso porque solo afecta un periodo de la serie y tienen una causa identificada.\nAhora, creamos una variable ficticia asociada a cada intervención, que denominaremos d1979, d2011 y d2020, y las incluiremos en la autoidentificación.\n\nd1979 &lt;- 1*(time(error) == 1979)\nd2011 &lt;- 1*(time(error) == 2011)\nd2020 &lt;- 1*(time(error) == 2020)\n\nauto.arima(aforo,\n           d = 1,\n           xreg = cbind(d1979, d2011, d2020))\n\nSeries: aforo \nRegression with ARIMA(2,1,0) errors \n\nCoefficients:\n         ar1     ar2       d1979       d2011       d2020\n      0.2008  0.4051  -1664.2472  -1187.5328  -2368.0686\ns.e.  0.1176  0.1209    497.3584    460.7665    461.7576\n\nsigma^2 = 608880:  log likelihood = -506.59\nAIC=1025.18   AICc=1026.68   BIC=1038.04\n\n\nObserva como la inclusión de intervención modifica la autoidentificación, que ahora es un proceso ARIMA(2,1,0).\n\narima210 &lt;- Arima(aforo, \n                  order = c(2, 1, 0),\n                  include.constant = FALSE,\n                  xreg = cbind(d1979, d2011, d2020))\narima210\n\nSeries: aforo \nRegression with ARIMA(2,1,0) errors \n\nCoefficients:\n         ar1     ar2       d1979       d2011       d2020\n      0.2008  0.4051  -1664.2472  -1187.5328  -2368.0686\ns.e.  0.1176  0.1209    497.3584    460.7665    461.7576\n\nsigma^2 = 608880:  log likelihood = -506.59\nAIC=1025.18   AICc=1026.68   BIC=1038.04\n\n\nTodos los coeficientes estimados, excepto el ar1 (\\(\\phi_1\\)), superan las dos desviaciones estándar y parece que son significativos.\nLa Figura 14 muestra que para ningún año se observa un error atípico. Es decir, no es necesaria más intervención.\n\nerror &lt;- residuals(arima210)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1960, 2020, 4)) \n\n\n\n\n\n\n\nFigura 14: Error + Intervención\n\n\n\n\n\n\n\nValidación\nVeamos qué coeficientes estimados son significativos.\n\ncoeftest(arima210)\n\n\nz test of coefficients:\n\n         Estimate  Std. Error z value  Pr(&gt;|z|)    \nar1       0.20083     0.11757  1.7082 0.0876036 .  \nar2       0.40512     0.12089  3.3510 0.0008052 ***\nd1979 -1664.24718   497.35837 -3.3462 0.0008194 ***\nd2011 -1187.53277   460.76649 -2.5773 0.0099576 ** \nd2020 -2368.06859   461.75755 -5.1284 2.922e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nLas tres variables de intervención son significativas y el coeficiente \\(\\phi_2\\) (ar2) también. No es significativo el coeficiente \\(\\phi_1\\) (ar1) al 5% pero si al 10%.\nConfirmamos que \\(aforo_t \\sim ARIMA(2,1,0)\\) con intervención.\n\n\nMedidas de error\nEl error de ajuste medio, medido con el RMSE, es 743 vehículos por día y el error porcentual medio (MAPE) es 5.99%, ambos muy inferiores a los obtenidos con el método sencillo y el Alisado exponencial. Además, hay sesgo de predicción (aunque menor que el observado con Alisado) y la fórmula empleada para el cálculo del intervalo de confianza de las predicciones es válida.\n\naccuracy(arima210)\n\n\n\n                ME   RMSE    MAE  MPE MAPE MASE ACF1\nTraining set 49.26 742.83 551.43 1.23 5.99 0.76 0.04\n\n\n\n\nInterpretación del modelo\nEl modelo teórico es \\(aforo_t \\sim ARIMA(2,1,0) + d1979 + d2011 + d2020\\):\n\\[(1 - \\phi_1 L - \\phi_2 L^2)(1 - L)aforo_t =  \\varepsilon_t + \\gamma_1 \\cdot d1979 + \\gamma_2 \\cdot d2011 + \\gamma_3 \\cdot d2020.\\]\nSi desarrollamos, queda:\n\\[aforo_t = aforo_{t-1} + \\phi_1(aforo_{t-1}-aforo_{t-2}) + \\phi_2(aforo_{t-2}-aforo_{t-3}) +\\] \\[\\gamma_1 \\cdot d1979 +  \\gamma_2 \\cdot d2011 + \\gamma_3 \\cdot d2020 + \\varepsilon_t.\\]\nFinalmente, el modelo estimado es: \\[\\widehat{aforo}_t = aforo_{t-1} + 0.20(aforo_{t-1}-aforo_{t-2}) + 0.41(aforo_{t-2}-aforo_{t-3})\\] \\[-1664 \\cdot d1979 - 1188 \\cdot d2011 - 2368 \\cdot d2020\\] Cada año el aforo es el mismo que el aforo del año pasado más un 20% del último incremento observado y un 41% del incremento anterior.\nRespecto de la intervención, en 1979 hubo cerca de 1700 de vehículos por día menos de lo esperado debido a la apertura de la autopista AP-7; en 2011 hubo unos 1200 vehículos menos debido a la Gran Recesión; y en 2020 las restricciones de movilidad debidas a la pandemia redujeron el aforo en 2400 vehículos al día.\n\n\nPredicción\nComo hemos incluido tres variables ficticias en el ajuste, de cara a predecir el aforo hemos de indicar cuales serán los valores futuros para estas variables. En este caso serán cero puesto que son intervenciones que no responden a un efecto calendario. Las causas detrás de estas intervenciones no se espera que se repitan en el futuro.\nYa sabemos que en R esto se hace incluyendo en el comando forecast el argumento xreg = cbind(rep(0, 4), rep(0, 4), rep(0, 4)) que añade cinco ceros por cada variable de intervención porque la predicción va a ser a cinco años vista.\n\nparima210 &lt;- forecast(arima210, \n                      h = 4, \n                      level = 95,\n                      xreg = cbind(d1979=rep(0, 4), d2011=rep(0, 4), \n                                   d2020=rep(0, 4)))\nparima210\n\n     Point Forecast    Lo 95    Hi 95\n2024       9131.695 7602.320 10661.07\n2025       9323.968 6934.030 11713.91\n2026       9479.943 6008.483 12951.40\n2027       9589.161 5142.358 14035.96\n\n\nPara 2025 se espera un paso de 9324 vehículos al día por la N-340 a la altura de Oropesa."
  },
  {
    "objectID": "03-06-Tema6.html#comparación-entre-modelos",
    "href": "03-06-Tema6.html#comparación-entre-modelos",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "6.4 Comparación entre modelos",
    "text": "6.4 Comparación entre modelos\nHemos visto que en calidad de ajuste, el modelo Arima supera en 1.5 p.p. al modelo de Alisado o en 280 vehículos, según atendamos al MAPE o al RMSE. Además, es el único método que ofrece predicciones por intervalo fiables.\nSin embargo seguimos sin saber cuál de los tres métodos ofrece la mejor calidad en las predicciones. La Figura 15 muestra la serie aforo y las predicciones obtenidas con cada método. Tanto Arima como el método simple preveen un incremento en el aforo, continuando con la tendencia reciente observada tras la pandemia. Por el contrario, según el método de Alisado el aforo irá disminuyendo, resultado que concuerda con el la tendencia general observada tras la Gran Recesión. ¿Que previsión resultará acertada?\n\n\n\n\n\n\n\n\nFigura 15: Aforo y predicicones con tres métodos\n\n\n\n\n\nVamos a aplicar origen de previsión móvil a los tres métodos para elegir la mejor predicción. Consideraremos que son necesarios 30 años para ajustar bien los modelos y haremos previsiones a 4 años vista.\nComo criterio de calidad de las predicciones vamos a usar el RMSE. Se ha elegido calcular el error medio con lo que el cálculo las medidas de precisión estará algo afectado por los elevados errores observados en los tres año atípicos.\n\nk &lt;- 30\nh &lt;- 4\nTT &lt;- length(aforo)\ns &lt;- TT - k - h\n\nrmseDer &lt;- rmseAli &lt;- rmseAri &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(aforo, start = i + 1, end = i + k)\n  test.set &lt;-  subset(aforo, start = i + k + 1, end = i + k + h)\n  \n  fcast &lt;- rwf(train.set, h = h, drift = TRUE)\n  rmseDer[i + 1,] &lt;- (test.set - fcast$mean)^2\n\n  fit &lt;- ets(train.set, model = \"MAN\", damped = FALSE)\n  fcast &lt;- forecast(fit, h = h)\n  rmseAli[i + 1,] &lt;- (test.set - fcast$mean)^2\n\n  fit &lt;- Arima(train.set, order = c(2, 1, 0), include.constant = FALSE)\n  fcast &lt;- forecast(fit, h = h)\n  rmseAri[i + 1,] &lt;- (test.set - fcast$mean)^2\n}\n\nrmseDerMedia &lt;- sqrt(colMeans(rmseDer))\nrmseAliMedia &lt;- sqrt(colMeans(rmseAli))\nrmseAriMedia &lt;- sqrt(colMeans(rmseAri))\n\nround(rmseDerMedia, 2)\n\n[1] 1045.48 1652.23 2207.89 2742.52\n\nround(rmseAliMedia, 2)\n\n[1] 1108.34 1767.07 2399.95 3129.44\n\nround(rmseAriMedia, 2)\n\n[1]  985.41 1487.23 1957.45 2484.06\n\n\nEl método Arima ofrece mejores predicciones para todos los horizontes temporales y el método de Alisado muestra la peor calidad en las previsiones, especialmente a largo plazo."
  },
  {
    "objectID": "03-06-Tema6.html#métodos-sencillo-de-la-deriva",
    "href": "03-06-Tema6.html#métodos-sencillo-de-la-deriva",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "7.1 Métodos sencillo de la deriva",
    "text": "7.1 Métodos sencillo de la deriva\nVamos a empezar aplicando el método de la deriva a la transformación logarítmica de la serie. Ni para este método ni para los siguientes usaremos predicciones insesgadas.\n\nderivaNacimientos &lt;- rwf(nacimientos, \n                         h = 4, \n                         lambda = 0, \n                         drift = TRUE)\n\nsummary(derivaNacimientos)\n\n\nForecast method: Random walk with drift\n\nModel Information:\nCall: rwf(y = nacimientos, h = 4, drift = TRUE, lambda = 0) \n\nDrift: -0.0091  (se 0.0075)\nResidual sd: 0.0359 \n\nError measures:\n                   ME     RMSE      MAE         MPE     MAPE      MASE\nTraining set 599.0297 15473.06 13338.83 -0.06127007 3.075667 0.9486111\n                  ACF1\nTraining set 0.5195922\n\nForecasts:\n     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n2024       319342.1 304700.7 334687.1 297223.7 343106.5\n2025       316437.9 295711.7 338616.8 285295.2 350980.2\n2026       313560.1 288121.2 341245.1 275501.0 356876.8\n2027       310708.5 281264.3 343235.0 266824.4 361810.0\n\n\nComo el número de nacimientos en 2023 es solo algo inferior al de 2000, el valor medio de la pendiente estimado por el método de la deriva es -0.0091. Por este motivo las predicciones para los próximos 4 años muestran una lenta caída de la natalidad del 0.91% anual.\nPor otro lado, el modelo ofrece un error de ajuste medio del 3.1% (unos 15500 bebés según RMSE), no presenta sesgo y la predicción por intervalo no es fiable."
  },
  {
    "objectID": "03-06-Tema6.html#asilado-exponencial-1",
    "href": "03-06-Tema6.html#asilado-exponencial-1",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "7.2 Asilado exponencial",
    "text": "7.2 Asilado exponencial\n\nEstimacion del modelo\nSi estimamos el mejor modelo de alisado exponencial para la transformación logarítmica de la serie Nacimientos sin ningún tipo de restricción, nos encontramos:\n\n# ets(nacimientos)\netsNacimientos &lt;- ets(nacimientos, \n                      lambda = 0)\nsummary(etsNacimientos) \n\nETS(A,A,N) \n\nCall:\nets(y = nacimientos, lambda = 0)\n\n  Box-Cox transformation: lambda= 0 \n\n  Smoothing parameters:\n    alpha = 0.8677 \n    beta  = 0.5162 \n\n  Initial states:\n    l = 12.8623 \n    b = 0.0288 \n\n  sigma:  0.0287\n\n      AIC      AICc       BIC \n-88.47180 -85.13847 -82.58153 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -2281.097 12257.41 8412.686 -0.4502361 1.919209 0.5982808\n                    ACF1\nTraining set -0.06026791\n\n\nEl modelo estimado es ETS(A,A,N) o “AAN”, un modelo con pendiente y error aditivos y sin estacionalidad. Es decir, \\(\\log(y_{t+1}) = l_t + b_t + \\varepsilon_{t+1}\\). Cuando se usa la transformación logarítmica, nunca aparecerán componentes multiplicativas.\nEl valor de \\(\\alpha\\) es cercano a 1, indicando que el nivel de la serie varía en el tiempo. El valor de \\(\\beta\\) es 0.5. Es decir, la pendiente ha cambiado gradualmente con en el tiempo, pasando, en este caso, de positiva a negativa (véase Figura 17).\n\nautoplot(etsNacimientos)\n\n\n\n\n\n\n\nFigura 17\n\n\n\n\n\nRespecto de la calidad ajuste del modelo, el valor de MAPE= \\(1.9\\)% es 1.2 p.p. inferior al obtenido con el método de la deriva. Otra ventaja del método de Alisado frente al de la deriva es que las predicciones por intervalos están correctamente calculadas.\n\n\nPredicción\nEl último valor calculado para la pendiente \\(b_T\\) es igual al -0.0227. Es decir, cada año se espera una caída en los nacimientos del 2.3%.\n\ntail(etsNacimientos$states, 1)\n\nTime Series:\nStart = 2023 \nEnd = 2023 \nFrequency = 1 \n            l           b\n2023 12.68321 -0.02272149\n\netsNacimientosPre &lt;- forecast(etsNacimientos, \n                         h = 4,\n                         level = 95)\netsNacimientosPre\n\n     Point Forecast    Lo 95    Hi 95\n2024       315051.3 297793.5 333309.2\n2025       307973.6 279730.8 339067.9\n2026       301054.9 260703.0 347652.4\n2027       294291.6 241405.6 358763.6"
  },
  {
    "objectID": "03-06-Tema6.html#modelo-arima-1",
    "href": "03-06-Tema6.html#modelo-arima-1",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "7.3 Modelo Arima",
    "text": "7.3 Modelo Arima\n\nTransformación de la serie\nLa Figura 18 muestra que la serie Nacimientos, transformada logarítmicamente, no es estacionaria, pero si los es su primera diferencia. Sin embargo, la función ndiffs aconseja dos diferenciaciones al interpretar el escalón que se observa en la serie diferenciada (panel izquierdo de la Figura 18) como tendencia. Así, optamos por fijar \\(d = 1\\).\n\nautoplot(log(nacimientos), xlab = \"\", ylab = \"\", main = \"\")\nautoplot(diff(log(nacimientos)), xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Serie original (log)\n\n\n\n\n\n\n\n\n\n\n\n(b) Dif. de la serie (log)\n\n\n\n\n\n\n\nFigura 18: Gráfica para Nacimientos y su primera diferencia\n\n\n\n\n\nndiffs(log(nacimientos))\n\n[1] 2\n\n\n\n\nIdentificación y Estimación\nVeamos a identificar los valores de \\(p\\) y \\(q\\) a partir de auto.arima, indicándole que d = 1. La función sugiere un proceso ARIMA(2,1,0) sin constante.\n\nauto.arima(nacimientos, \n           d = 1,\n           lambda = 0)\n\nSeries: nacimientos \nARIMA(2,1,0) \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n         ar1     ar2\n      0.3590  0.3863\ns.e.  0.1824  0.1853\n\nsigma^2 = 0.0007691:  log likelihood = 50.62\nAIC=-95.23   AICc=-93.97   BIC=-91.83\n\n\nVamos a ver la gráfica de los residuos del modelo ARIMA(2,1,0) para identificar los valores extremos (intervención).\n\narima210 &lt;- Arima(nacimientos, \n                  order = c(2, 1, 0),\n                  include.constant = FALSE)\n\nerror &lt;- residuals(arima210)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(2000, 2024, 4)) \n\n# Creamos un variable con todos las años de la serie\nfechas &lt;- format(seq(as.Date(\"2000-01-01\"), as.Date(\"2023-01-01\"), \"year\"), \"%Y\")\n# Identificamos los años atípicos\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"2009\"\n\n\n\n\n\n\n\n\nFigura 19: Error + Intervención\n\n\n\n\n\nSe identifica un valor extremo en el año 2009, cuando se prodice el cambio en la tendencia y el número de nacimientos cae bruscamente.\nCreamos una variable ficticia asociada a la intervención, que denominaremos d2009, y la incluimos en la autoidentificación.\n\nd2009 &lt;- 1*(time(error) == 2009)\n\nauto.arima(nacimientos,\n           d = 1,\n           lambda = 0,\n           xreg = cbind(d2009))\n\nSeries: nacimientos \nRegression with ARIMA(1,1,0) errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n         ar1     xreg\n      0.6770  -0.0292\ns.e.  0.1452   0.0126\n\nsigma^2 = 0.0007516:  log likelihood = 50.95\nAIC=-95.9   AICc=-94.64   BIC=-92.49\n\n\nObserva como la inclusión de intervención modifica la autoidentificación, que ahora es un proceso ARIMA(1,1,0).\n\narima110 &lt;- Arima(nacimientos, \n                  order = c(1, 1, 0),\n                  include.constant = FALSE,\n                  lambda = 0,\n                  xreg = cbind(d2009))\narima110\n\nSeries: nacimientos \nRegression with ARIMA(1,1,0) errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n         ar1     xreg\n      0.6770  -0.0292\ns.e.  0.1452   0.0126\n\nsigma^2 = 0.0007516:  log likelihood = 50.95\nAIC=-95.9   AICc=-94.64   BIC=-92.49\n\n\nTodos los coeficientes estimados superan las dos desviaciones estándar y parecen ser significativos.\nLa Figura 20 muestra que para ningún año se observa un error atípico. Es decir, no es necesaria más intervención.\n\nerror &lt;- residuals(arima110)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(2000, 2024, 4)) \n\n#fechas[abs(error) &gt; 2.5 * sderror]\n\n\n\n\n\n\n\nFigura 20: Error + Intervención\n\n\n\n\n\n\n\nValidación\nVeamos qué coeficientes estimados son significativos.\n\ncoeftest(arima110)\n\n\nz test of coefficients:\n\n      Estimate Std. Error z value  Pr(&gt;|z|)    \nar1   0.677044   0.145205  4.6627 3.121e-06 ***\nxreg -0.029205   0.012631 -2.3120   0.02078 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nConfirmamos que \\(Nacimientos_t \\sim ARIMA(1,1,0)\\) sin constante y con intervención.\n\n\nMedidas de error\nEl error de ajuste medio, medido con el RMSE, es 11887 bebés, inferior al obtenido con el método de Alisado. Sin embargo, el error porcentual medio (MAPE) es 1.97%, algo superior al del método de Alisado. Un ejemplo perfecto de que el método con mejor ajuste puede depender del criterio de calidad seleccionado. Además, no hay sesgo de predicción y la fórmula empleada para el cálculo del intervalo de confianza de las predicciones es válida.\n\naccuracy(arima110)\n\n\n\n                   ME     RMSE     MAE   MPE MAPE MASE  ACF1\nTraining set -1442.23 11886.86 8577.24 -0.34 1.97 0.61 -0.02\n\n\n\n\nInterpretación del modelo\nEl modelo teórico es \\(\\log(Nacimientos_t) \\sim ARIMA(1,1,0) + d2009\\):\n\\[(1 - \\phi_1 L)(1 - L)\\log(Nacimientos_t) =  \\varepsilon_t + \\gamma_1 \\cdot d2009.\\] Equivalentemente, \\[(1 - \\phi_1 L)TVA\\_Nacimientos_t =  \\varepsilon_t + \\gamma_1 \\cdot d2009\\]\nSi desarrollamos, queda:\n\\[TVA\\_Nacimientos_t = \\phi_1TVA\\_Nacimientos_{t-1} + \\gamma_1 \\cdot d2009+ \\varepsilon_t.\\] Finalmente, el modelo estimado es: \\[\\widehat{TVA\\_Nacimientos_t} = 0.69 \\cdot TVA\\_Nacimientos_t -0.029 \\cdot d2009\\]\nCada año la tasa de variación anual de los nacimientos es un 70% de la tasa del año previo. Respecto de la intervención, en 2009 la tasa de variación anual fue 2.9 p.p inferior a lo esperado. Alternativamente, el 2009 el número de nacimientos fue un 2.9% inferior a lo esperado.\n\n\nPredicción\nIncluimos el argumento xreg = cbind(rep(0, 4)) para recoger el efecto nulo en el futuro de la intervención.\n\nparima110 &lt;- forecast(arima110, \n                      h = 4, \n                      level = 95,\n                      xreg = cbind(d1979=rep(0, 4)))\nparima110\n\n     Point Forecast    Lo 95    Hi 95\n2024       316994.9 300411.8 334493.4\n2025       313470.5 282249.5 348145.1\n2026       311106.7 266310.2 363438.5\n2027       309516.4 252506.6 379397.6"
  },
  {
    "objectID": "03-06-Tema6.html#comparación-entre-modelos-1",
    "href": "03-06-Tema6.html#comparación-entre-modelos-1",
    "title": "Series con tendencia y sin estacionalidad",
    "section": "7.4 Comparación entre modelos",
    "text": "7.4 Comparación entre modelos\nHemos visto que en calidad de ajuste, los modelos de Alisado y Arima superan al modelo simple. También hemos visto que el mejor entre Alisado y Arima depende del criterio de calidad de ajuste empleado.\nLa Figura 21 muestra la serie Nacimientos y las predicciones obtenidas con cada método. Todas ellas muestran un descenso continuado en la natalidad, especialmente marcado para el método de Alisado.\n\n\n\n\n\n\n\n\nFigura 21: Nacimiento y predicicones con tres métodos\n\n\n\n\n\nVeamos ahora qué metodo ofrece las predicciones con menor error con origen de previsión móvil. Consideraremos que son necesarios 20 años para ajustar bien los modelos y haremos previsiones a 4 años vista. Como criterio de calidad de las predicciones vamos a usar el MAPE.\n\nk &lt;- 20\nh &lt;- 4\nTT &lt;- length(nacimientos)\ns &lt;- TT - k - h\n\nmapeDer &lt;- mapeAli &lt;- mapeAri &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(nacimientos, start = i + 1, end = i + k)\n  test.set &lt;-  subset(nacimientos, start = i + k + 1, end = i + k + h)\n  \n  fcast &lt;- rwf(train.set, h = h, drift = TRUE, lambda = 0)\n  mapeDer[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n\n  fit &lt;- ets(train.set, model = \"AAN\", damped = FALSE, lambda = 0)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAli[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n\n  fit &lt;- Arima(train.set, order = c(1, 1, 0), include.constant = FALSE, lambda = 0)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAri[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n}\n\nmapeDerMedia &lt;- colMeans(mapeDer)\nmapeAliMedia &lt;- colMeans(mapeAli)\nmapeAriMedia &lt;- colMeans(mapeAri)\n\nround(mapeDerMedia, 2)\n\n[1] 4.54 5.19 6.88 8.93\n\nround(mapeAliMedia, 2)\n\n[1] 0.74 2.18 4.08 5.67\n\nround(mapeAriMedia, 2)\n\n[1] 3.15 3.25 4.84 7.06\n\n\nEl método de Alisado ofrece mejores predicciones para todos los horizontes temporales y es especialmente bueno en sus predicciones a 1 o 2 años vista. El método Arima es el segundo en calidad de las predicciones, pero no puede competir contra el método de Alisado."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Iván Arribas",
    "section": "",
    "text": "Iván Arribas es licenciado en Ciencias Matemáticas con la especialidad de Estadística e Investigación Operativa, y doctor en Ciencias Económicas. Actualmente es Profesor Titular en el Departamento de Análisis Económico de la Universitat de València, donde lleva más de 25 años como docente e investigador."
  },
  {
    "objectID": "03-13-Ejemplo3.html#ajuste-por-alisado-exponencial",
    "href": "03-13-Ejemplo3.html#ajuste-por-alisado-exponencial",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.1 Ajuste por Alisado exponencial",
    "text": "3.1 Ajuste por Alisado exponencial\nSi se estima el modelo sin imponer ninguna restricción, ets identifica como modelo óptimo ETS(A,Ad,A).\n\n(PernoctacionesEts &lt;- ets(Pernoctaciones))\n\nETS(A,Ad,A) \n\nCall:\nets(y = Pernoctaciones)\n\n  Smoothing parameters:\n    alpha = 0.9999 \n    beta  = 0.0203 \n    gamma = 1e-04 \n    phi   = 0.8001 \n\n  Initial states:\n    l = 19.4022 \n    b = 0.0366 \n    s = -8.5839 -7.372 1.788 6.9247 13.8752 12.2769\n           4.7636 1.202 -3.8813 -5.5148 -7.4679 -8.0106\n\n  sigma:  1.5792\n\n     AIC     AICc      BIC \n1912.595 1915.138 1978.528 \n\n\nEl modelo estimado tiene pendiente amortiguada, estacionalidad y residuo aditivos: \\[y_{t+1} = l_t + \\phi b_t + s_{t+1-m} + \\varepsilon_{t+1}.\\]\nEl valor de \\(\\alpha\\) indica que el nivel de la serie varía constantemente en el tiempo. El valor de \\(\\beta\\) y \\(\\gamma\\) casi nulos indica que la pendiente y la componente estacional han evolucionado muy poco con el paso de los años (véase Figura 3). El parámetro de amortiguamiento \\(\\phi\\) está su valor permitido más bajo, por lo que las previsiones se realizarán aplicando un fuerte amortiguamiento.\n\nautoplot(PernoctacionesEts,\n         xlab = \"\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 3: Descomposición para Pernoctaciones\n\n\n\n\n\n\naccuracy(PernoctacionesEts, test = 1:240)\n\n                     ME     RMSE       MAE      MPE     MAPE     MASE      ACF1\nTraining set 0.01107867 0.961168 0.6920091 0.167214 3.737123 0.760681 0.1622215\n\n\nLa calidad del ajuste es bastante buena, con un MAPE de 3.7% y un RMSE de 961 mil pernoctaciones (o 692 mill si usamos el MAE). Además, según el MASE, el modelo de Alisado exponencial supone una mejora del 34% respecto del método Ingenuo con estacionalidad, que ya usamos para Pernoctaciones y tenía un MAPE del 4.6%. Por otro lado, el MPE indica que no hay sesgo y el ACF1 que la predicción por intervalo no está correctamente calculada.\nLos últimos valores estimados del nivel y la estacionalidad, que corresponden a diciembre de 2023, nos permiten mostrar gráficamente la componente estacional más reciente (Figura 4).\n\nTT &lt;- nrow(PernoctacionesEts$states)\nPernoctacionesEts$states[TT,]\n\n\n\n    l     b    s1    s2    s3    s4    s5    s6    s7    s8    s9   s10   s11 \n23.55 -0.04 -8.58 -7.37  1.79  6.92 13.88 12.28  4.76  1.20 -3.88 -5.51 -7.47 \n  s12 \n-8.01 \n\n\n\ncomponenteEstacional &lt;- PernoctacionesEts$states[TT, 14:3]\n\nggplot() +\n  geom_line(aes(x = 1:12, y = componenteEstacional)) + \n  geom_hline(yintercept = 0, colour = \"blue\", lty = 2) +\n  ggtitle(\"\") +\n  xlab(\"\") +\n  ylab(\"Efecto estacional\") +\n  scale_x_continuous(breaks= 1:12, \n                     labels = c(\"Ene\", \"Feb\", \"Mar\", \"Abr\", \"May\", \"Jun\", \n                                \"Jul\", \"Ago\", \"Sep\", \"Oct\", \"Nov\", \"Dic\")) \n\n\n\n\n\n\n\nFigura 4: Componente estacional\n\n\n\n\n\nEl nivel de las pernoctaciones en diciembre de 2023 (última observación) es de 25.6 millones de noches y cada mes se estima una reducción de 42 mil pernoctaciones. El mayor número de pernoctaciones dentro del año tiene lugar en verano, en los meses de julio y agosto. En concreto, destaca el mes agosto con un incremento de 13.9 millones de pernoctaciones (s5) respecto de la media anual. Las pernoctaciones en invierno bajan drásticamente respecto de la media anual, observándose en diciembre 8.6 millones menos de pernoctaciones (s1). El efecto estacional estimado por el método de Alisado es muy similar al estimado durante la descriptiva de la serie."
  },
  {
    "objectID": "03-13-Ejemplo3.html#predicción",
    "href": "03-13-Ejemplo3.html#predicción",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.2 Predicción",
    "text": "3.2 Predicción\nSi pedimos los valores de predicción y su intervalo de confianza al 95% para los próximos cuatro años, tenemos (numéricamente sólo se muestra el primer año):\n\nPernoctacionesEtsPre &lt;- forecast(PernoctacionesEts, \n                                 h = 48, \n                                 level = 95)\n\nPernoctacionesEtsPre\n\n\n\n         Point Forecast     Lo 95    Hi 95\nJan 2024       15.51062 12.415449 18.60580\nFeb 2024       16.02644 11.613676 20.43920\nMar 2024       17.95846 12.516028 23.40089\nApr 2024       19.57425 13.251739 25.89676\nMay 2024       24.64449 17.538507 31.75047\nJun 2024       28.19496 20.375101 36.01482\nJul 2024       35.69862 27.218434 44.17880\nAug 2024       37.29071 28.193255 46.38816\nSep 2024       30.33423 20.655194 40.01326\nOct 2024       25.19291 14.962578 35.42324\nNov 2024       16.02945  5.273956 26.78494\nDec 2024       14.81461  3.556837 26.07238\n\n\n\nautoplot(PernoctacionesEtsPre,\n         xlab = \"\",\n         ylab = \"Casos\",\n         main = \"\",\n         PI = FALSE)  +\n  scale_x_continuous(breaks= seq(2000, 2028, 2)) \n\n\n\n\n\n\n\nFigura 5: Pernoctaciones (2000-2023) y predicción (2024-2027)\n\n\n\n\n\nDado que el modelo estimado presenta una ligera tendencia decreciente muy amortiguada, las predicciones aparentemente se mantienen constantes en el tiempo. (Véase Figura 5.)"
  },
  {
    "objectID": "03-13-Ejemplo3.html#análisis-del-error",
    "href": "03-13-Ejemplo3.html#análisis-del-error",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.3 Análisis del error",
    "text": "3.3 Análisis del error\nLa Figura 6 muestra el residuo del modelo.\n\nerror &lt;- residuals(PernoctacionesEts)\nsderror &lt;- sd(error)\n\nautoplot(error,\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\",\n         colour = \"black\") +\n  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, \n             colour = c(\"red\", \"blue\", \"blue\", \"red\"), lty = 2) + \n  scale_x_continuous(breaks= seq(2000, 2024, 2)) \n\nfechas &lt;- format(seq(as.Date(\"2000-01-01\"), as.Date(\"2023-12-01\"), by = 'month'), \n                 \"%Y-%m\")\nfechas[abs(error) &gt; 3 * sderror]\n\n[1] \"2020-03\" \"2020-04\" \"2020-05\" \"2020-10\" \"2020-11\" \"2021-10\"\n\n\n\n\n\n\n\n\nFigura 6: Error + Intervención\n\n\n\n\n\nSe observan seis meses en los que el residuo supera las tres desviaciones típicas, 5 en 2020 y otro en 2021, claramente asociados al efecto de la pandemia.\nVamos a repetir este ejercicio considerando solo los errores hasta diciembre de 2019 para identificar meses atípicos no relacionados con la pandemia. Ahora se observan seis meses atípicos: noviembre de 2016, 2017, 2018 y 2019, abril de 2017 y mayo de 2018. La causa de estos errores se localiza en el brusco incremento en las pernoctaciones ocurrido en 2016, seguido de una caída en 2018. Estos cambios tan seguidos impiden que el método de Alisado termine de ajustar bien los datos.\n\nerror &lt;- window(error, end = c(2019, 12))\nsderror &lt;- sd(error)\nfechas &lt;- format(seq(as.Date(\"2000-01-01\"), as.Date(\"2019-12-01\"), by = 'month'), \n                 \"%Y-%m\")\nfechas[abs(error) &gt; 3 * sderror]\n\n[1] \"2016-11\" \"2017-04\" \"2017-11\" \"2018-05\" \"2018-11\" \"2019-11\"\n\n\nLa prueba de Tukey identifica como atípicos solo algunos de los meses de noviembre ya identificados.\n\natipicos &lt;- tsoutliers(error)\nfechas[atipicos$index]\n\n[1] \"2016-11\" \"2017-11\" \"2018-11\""
  },
  {
    "objectID": "03-13-Ejemplo3.html#validación",
    "href": "03-13-Ejemplo3.html#validación",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.4 Validación",
    "text": "3.4 Validación\nYa hemos visto que el modelo comete un error próximo al 3.7%. Este valor es la estimación del error en la previsión intramuestral y a un periodo vista. A fin de poder estimar mejor la capacidad predictiva del modelo vamos a estimar el error de previsión extramuestral según el horizonte temporal.\nAsumimos que se precisan diez años para hacer una buena estimación, \\(k=120\\), y que el horizonte temporal es un año, \\(h = 12\\) meses.\n\nk &lt;- 120                 \nh &lt;- 12                  \nTT &lt;- length(Pernoctaciones)\ns &lt;- TT - k - h          \n\nmapeAlisado &lt;- matrix(NA, s + 1, h)\nfor (i in 0:s) {\n  train.set &lt;- subset(Pernoctaciones, start = i + 1, end = i + k)\n  test.set &lt;-  subset(Pernoctaciones, start = i + k + 1, end = i + k + h)\n  \n  fit &lt;- ets(train.set, model = \"AAA\", damped = TRUE)\n  fcast&lt;-forecast(fit, h = h)\n  mapeAlisado[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n}\n\nerrorAlisado &lt;- apply(mapeAlisado, MARGIN = 2, FUN = median)\nerrorAlisado\n\n [1]  2.972417  5.093576  8.405491 10.459123 12.331484 13.011905 12.628651\n [8] 11.120994 10.223398  8.527012  6.612335  5.983599\n\nggplot() +\n  geom_line(aes(x = 1:12, y = errorAlisado)) +\n  ggtitle(\"\") +\n  xlab(\"Horizonte temporal de predicción\") +\n  ylab(\"MAPE\") +\n  ylim(0, 14) + \n  scale_x_continuous(breaks= 1:12)\n\n\n\n\n\n\n\nFigura 7: Error de predicción según horizonte temporal\n\n\n\n\n\nLa Figura 7 muestra el error de previsión extramuestral según el horizonte de previsión. Se observa como para horizontes de predicción de uno a seis meses el error de predicción aumenta según lo hace el horizonte de predicción, pasando del 3% para predicciones a un mes vista hasta el 13% para predicciones a seis meses vista.\nSin embargo, para previsiones a más largo plazo el error de predicción decrece, hasta situarse en el 6% en las previsiones a un año vista."
  },
  {
    "objectID": "03-11-Ejemplo2.html#identificación-del-método-sencillo-con-mejor-ajuste",
    "href": "03-11-Ejemplo2.html#identificación-del-método-sencillo-con-mejor-ajuste",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "2.1 Identificación del método sencillo con mejor ajuste",
    "text": "2.1 Identificación del método sencillo con mejor ajuste\nPara series con tendencia y sin estacionalidad el método sencillo de predicción es el de la Deriva, al que vamos a añadir el método Ingenuo I porque repetir el último dato siempre es una buena estrategia para predicciones a cortísimo plazo. Veamos en primer lugar cual de ellos ajusta mejor a los datos, es decir, cual ofrece las mejores predicciones intramuestrales a un periodo vista.\n\nnaivePernoctaciones &lt;- naive(PernoctacionesAnual, h = 4)\nderivaPernoctaciones &lt;- rwf(PernoctacionesAnual,  h = 4, drift = TRUE)\n\nautoplot(PernoctacionesAnual, series = \"Pernoctaciones\",\n                xlab = \"\",\n                ylab = \"Noches (millones)\",\n                main = \"\") +\n  autolayer(naivePernoctaciones, series=\"Ingenuo\", PI = FALSE) +\n  autolayer(derivaPernoctaciones, series=\"Deriva\", PI = FALSE) +\n  scale_colour_discrete(limits=c(\"Pernoctaciones\", \"Ingenuo\", \"Deriva\")) +\n  labs(colour=\"Métodos\") + \n  theme(legend.position=c(0.15,0.2))\n\n\n\n\n\n\n\nFigura 3: Pernoctaciones anuales y predicción por métodos sencillos\n\n\n\n\n\nLa Figura 3 no deja claro entre los métodos Ingenuo I y de la Deriva cuál es más adecuado. El primero ofrece una previsión constante –igual al último dato observado– y el segundo previsiones crecientes –acordes con la tendencia general de la serie.\nVeamos la capacidad de ajuste de cada método. Como el efecto de la pandemia genera errores muy elevados en dos años y da lugar a medidas de calidad de ajuste poco interpretables, vamos a calcular las medidas de calidad usando solo los datos de los años 2000 a 2019, es decir los primeros 20 datos. Esto se consigue añadiendo el argumento test = 1:20 de la función accuracy.\n\nround(accuracy(naivePernoctaciones, test = 1:20), 2)\n\n               ME RMSE  MAE  MPE MAPE MASE ACF1\nTraining set 3.43 12.1 9.36 1.16 3.89    1 0.26\n\nround(accuracy(derivaPernoctaciones, test = 1:20), 2)\n\n               ME  RMSE  MAE   MPE MAPE MASE ACF1\nTraining set 0.47 11.61 9.26 -0.07  3.9 0.99 0.26\n\n\nTanto el método Ingenuo I, como el método de la Deriva resultan similares respecto a su ajuste a los datos (MAPE de 3.9%). El primero, porque repetir el último dato siempre es una buena estrategia para predicciones a cortísimo plazo. El segundo, porque considerar la pendiente media pasada es también una buena estrategia, que solo fallará en los periodos de cambio de tendencia. Solo el método de la Deriva no presenta sesgo en las predicciones. Sin embargo, para ninguno de los métodos el intervalo de confianza de las predicciones será de utilidad."
  },
  {
    "objectID": "03-11-Ejemplo2.html#identificación-del-método-sencillo-con-mejor-predicción-extramuestral",
    "href": "03-11-Ejemplo2.html#identificación-del-método-sencillo-con-mejor-predicción-extramuestral",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "2.2 Identificación del método sencillo con mejor predicción extramuestral",
    "text": "2.2 Identificación del método sencillo con mejor predicción extramuestral\nYa hemos visto que para los dos métodos el error es próximo al 3.9%. Este valor es la estimación del error en la previsión intramuestral y a un periodo vista. A fin de poder estimar mejor la capacidad predictiva de los dos métodos vamos a aplicar el método de origen de predicción móvil para obtener los errores extramuestrales según el horizonte de previsión.\nAsumiremos que necesitamos 10 años para obtener un buena estimación. La siguiente rutina permite obtener el MedAPE para previsiones con un horizonte temporal desde 1 a 4 años.\n\nk &lt;- 10                  \nh &lt;- 4                 \nTT &lt;- length(PernoctacionesAnual) \ns &lt;- TT - k - h          \n\nmapeNaiveI &lt;- matrix(NA, s + 1, h)\nmapeDeriva &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(PernoctacionesAnual, start = i + 1, end = i + k)\n  test.set &lt;-  subset(PernoctacionesAnual, start = i + k + 1, end = i + k + h)\n  \n  fcast &lt;- naive(train.set, h = h)\n  mapeNaiveI[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n  fcast &lt;- rwf(train.set, h = h,  drift = TRUE)\n  mapeDeriva[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n}\n\nmapeNaiveI &lt;- apply(mapeNaiveI, MARGIN = 2, FUN = median)\nmapeDeriva &lt;- apply(mapeDeriva, MARGIN = 2, FUN = median)\n\nmapeNaiveI\n\n[1]  3.588371 11.787518 14.295619 17.350341\n\nmapeDeriva\n\n[1]  4.377508  8.368445  9.714776 13.654276\n\n\nExcepto para predicciones a un año vista, el método de la Deriva es el que ofrece las predicciones más precisas. Para el método de la Deriva, el error de previsión extramuestral a un periodo (4.4%) es algo mayor que el error de ajuste (3.9%), pero para horizontes de predicción mayores el error crece rápidamente, haciendo muy poco fiables las predicciones."
  },
  {
    "objectID": "03-11-Ejemplo2.html#predicciones",
    "href": "03-11-Ejemplo2.html#predicciones",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "2.3 Predicciones",
    "text": "2.3 Predicciones\nUna vez identificado el mejor método sencillo de ajuste para la serie anual, mostramos las predicciones numéricamente.\n\nderivaPernoctaciones\n\n     Point Forecast    Lo 80    Hi 80     Lo 95    Hi 95\n2024       304.8851 222.1918 387.5783 178.41658 431.3535\n2025       307.8429 188.4854 427.2004 125.30138 490.3844\n2026       310.8008 161.7233 459.8782  82.80647 538.7951\n2027       313.7586 138.3397 489.1776  45.47846 582.0388\n\n\nSe espera que el número de pernoctaciones crezca lentamente (a razón de unos 3 millones al año), manteniendo la tendencia media observada desde el año 2000 al año 2023."
  },
  {
    "objectID": "03-11-Ejemplo2.html#validación",
    "href": "03-11-Ejemplo2.html#validación",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.1 Validación",
    "text": "3.1 Validación\nVamos a aplicar el método de origen de predicción móvil para obtener los errores extramuestrales según el horizonte de previsión.\nAsumimos que se precisan diez años para hacer una buena estimación, \\(k=120\\), y que el horizonte temporal es un año, \\(h = 12\\) meses.\n\nk &lt;- 120                 \nh &lt;- 12                  \nTT &lt;- length(Pernoctaciones)  \ns &lt;- TT - k - h          \n\nmapeSnaive &lt;- matrix(NA, s + 1, h)\nfor (i in 0:s) {\n  train.set &lt;- subset(Pernoctaciones, start = i + 1, end = i + k)\n  test.set &lt;-  subset(Pernoctaciones, start = i + k + 1, end = i + k + h)\n  \n  fit &lt;- snaive(train.set, h = h)\n  mapeSnaive[i + 1,] &lt;- 100*abs(test.set - fit$mean)/test.set\n}\n\nmapeSnaive &lt;- apply(mapeSnaive, MARGIN = 2, FUN = median)\nmapeSnaive\n\n [1] 5.581444 5.849766 5.969798 6.039284 6.357646 6.357646 6.357646 6.039284\n [9] 6.039284 6.039284 6.039284 6.039284\n\nggplot() +\n  geom_line(aes(x = 1:12, y = mapeSnaive)) +\n  ggtitle(\"\") +\n  xlab(\"Horizonte temporal de predicción\") +\n  ylab(\"MAPE\") +\n  scale_x_continuous(breaks= 1:12)\n\n\n\n\n\n\n\nFigura 5: Error de predicción según horizonte temporal\n\n\n\n\n\nLa Figura 5 muestra el error de previsión extramuestral según el horizonte de previsión. Cuidado con la interpretación. El error prácticamente no varía con el horizonte temporal y se mueve en una estrecha franja de 0.8 puntos porcentuales, entre el 5.6% y el 6.4%. La serie Pernoctaciones es tan sencilla que la mejor predicción a corto plazo es repetir la última observación del mismo mes."
  },
  {
    "objectID": "03-10-Ejemplo1.html#tendencia",
    "href": "03-10-Ejemplo1.html#tendencia",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.1 Tendencia",
    "text": "3.1 Tendencia\nHemos obtenido la serie anual pernoctaciones, que presentamos en la Figura 3. Se confirma la tendencia decreciente de la primera década, aunque con un comportamiento muy irregular. En el año 2000 el número de pernoctaciones alcanzaba los 234 millones al año, mientras que en 2009 se redujo a 200 millones. En los años siguientes se produce una recuperación de las pernoctaciones (a pesar de la crisis económica), superando rápidamente los niveles de principios de siglo y alcanzado a finales de la segunda década los 300 millones de pernoctaciones. La Covid-19 produjo en los años 2020 y 2021 una caída en las pernoctaciones sin precedentes, aunque en 2023 ya se ha vuelto al nivel precovid.\n\nautoplot(aggregate(Pernoctaciones, FUN = sum),\n         xlab = \"\",\n         ylab = \"Noches (millones)\",\n         main = \"\") +\n  scale_x_continuous(breaks= seq(2000, 2024, 2)) \n\n\n\n\n\n\n\nFigura 3: Pernoctaciones"
  },
  {
    "objectID": "03-10-Ejemplo1.html#estacionalidad",
    "href": "03-10-Ejemplo1.html#estacionalidad",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "3.2 Estacionalidad",
    "text": "3.2 Estacionalidad\nVeamos ahora el patrón estacional, como varían las pernoctaciones de los turistas extranjeros en España según el mes del año.\n\nggmonthplot(Pernoctaciones, \n             polar=TRUE,\n             xlab = \"\",\n             ylab = \"\",\n             main = \"\") +\n  guides(colour=FALSE)\n\n\n\n\n\n\n\nFigura 4: Variación estacional de la serie Pernoctaciones\n\n\n\n\n\nLa Figura 4 muestra la evolución estacional de Pernoctaciones. Se aprecia que el principal determinante es la temperatura y los movimientos vacacionales asociados a ella, puesto que el número de pernoctaciones aumenta progresivamente desde enero a agosto para luego caer bruscamente de septiembre a diciembre. También cabría esperar un efecto días del mes y observar más pernoctaciones en los meses de 31 días que en los de 30, pero el efecto de la temperatura es tan dominante que anula cualquier otro efecto."
  },
  {
    "objectID": "03-10-Ejemplo1.html#footnotes",
    "href": "03-10-Ejemplo1.html#footnotes",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLos 12 NA que aparecen en la identificación de los meses atípicos se corresponden con los 6 valores que se pierden al inicio de la serie y los 6 valores que se pierden al final al aplicar la descomposición por medias móviles. El error para estas 12 fechas es NA.↩︎"
  },
  {
    "objectID": "03-05-Tema5.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita",
    "href": "03-05-Tema5.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita",
    "title": "Evaluación de las predicciones",
    "section": "2.1 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita",
    "text": "2.1 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita\nEn el tema pasado vimos como predecir con diferentes metodologías el consumo alimentario en hogar per cápita (kg per cápita) en España, serie estacionaria anual de 1990 a 2023. Vamos a evaluar la calidad de las predicciones centrándonos en el método Ingenuo I y el modelo Arima.\n\nMétodo Ingenuo I\nVamos a reservar, por ejemplo, las últimas 7 observaciones de la serie Alimentos (años 2017 a 2023) y ajustar el modelo con las restantes observaciones (años 1990 a 2016). Después, usaremos este modelo para calcular las predicciones a 7 años vista y compararlas con los valores reales de la serie.\n\nalimentospc &lt;- read.csv2(\"./series/Alimentacionpc.csv\",\n                         header = TRUE)\n\nalimentospc &lt;- ts(alimentospc, \n                  start = 1990, \n                  freq = 1)\n\nautoplot(alimentospc, \n         main = \"\", \n         xlab = \"Año\", \n         ylab = \"\", \n         ylim = c(0, 700))\n\n\n\n\n\n\n\n\n\n# Definimos las observaciones intra- y extramuestrales\nAlimentospcIntra &lt;- subset(alimentospc, end = length(alimentospc) - 7)\nAlimentospcExtra &lt;- subset(alimentospc, start = length(alimentospc) - 6)\n\n# Estimamos el modelo con todos los datos menos los 7 ultimos y\n# predecimos los 7 años que hemos quitado de la serie \nAlimentospcExtraPre &lt;- naive(AlimentospcIntra,  h = 7)\n\n# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales\naccuracy(AlimentospcExtraPre, AlimentospcExtra)\n\n\n\n                       ME     RMSE      MAE         MPE     MAPE     MASE\nTraining set   0.03203846 14.33568 10.52073 -0.02070288 1.655404 1.000000\nTest set     -16.35414286 40.08671 30.05100 -3.05709480 5.091292 2.856361\n                    ACF1 Theil's U\nTraining set -0.04888459        NA\nTest set      0.29319433   1.10547\n\n\nAtendiendo al MAPE se tiene que el error de previsión a un periodo vista en el periodo intramuestral de 1990 a 2016 es del 1.7%; mientras que el error de previsión a largo plazo en el periodo extramuestral de 2017 a 2023 es del 5.1%. Ademas, para el periodo extramuestral el error medio (ME) es negativo y muy elevado, un indicativo de que las previsiones están segadas (sobrestiman la realidad). En resumen, la calidad del modelo se deteriora muy rápidamente en cuanto nos salimos de las condiciones óptimas.\nLa Figura 1 puede ayudar a entender este proceso de validación:\n\nLa línea de puntos vertical separa el periodo muestral (1990-2016) usado para estimar el modelo, del periodo extramuestral (2017-2023) usado sólo para hacer las previsiones.\nLa serie Alimentación aparece como una línea sólida en negro, desde 1990 hasta 2023.\nLa previsión intramuestral (a un periodo vista) de la serie aparece como una línea azul.\nLa línea en rojo es la previsión extramuestral a largo plazo. Observa que excepto para 2020 todas las previsiones están por encima del valor real de la serie.\nAl lado de cada previsión (intra y extramuestral) se ha indicado el error estimado (MAPE).\n\nClaramente estos resultados dependen del punto de corte seleccionado. En este caso, al dejar fuera del periodo de estimación la pandemia y la posterior caída en el consumo de alimento en el hogar, las previsiones resultan muy desacertadas.\n\n\n\n\n\n\n\n\nFigura 1: Precisión en la predicción de Alimentos por el método Ingenuo I\n\n\n\n\n\n\n\n\n\n\n\nImportancia del punto de corte\n\n\n\nPrueba a reservar las últimas 6 observaciones de la serie Alimentación y repite el análisis.\n\n\n\n\nModelo Arima\nAhora vamos a repetir el ejercicio, pero usando el modelo Arima estimado para la serie Alimentos en el tema previo, que recordemos era ARIMA(1, 0, 0) con constante e intervención. Como la intervención tiene lugar durante el periodo extramuestral, las variables ficticias valen cero durante todo el rango intramuestral y deben ser excluidas del análisis.\n\n# Definimos las observaciones intra- y extramuestrales\nAlimentospcIntra &lt;- subset(alimentospc, end = length(alimentospc) - 7)\nAlimentospcExtra &lt;- subset(alimentospc, start = length(alimentospc) - 6)\n\n# Estimamos el modelo con todos los datos menos los 7 ultimos y\n# predecimos los 7 años que hemos quitado de la serie \nariAlimentospcIntra &lt;- Arima(AlimentospcIntra, \n                             order = c(1, 0, 0),\n                             include.constant = TRUE)\nariAlimentospcIntraPre &lt;- forecast(ariAlimentospcIntra,  h = 7)\n\n# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales\naccuracy(ariAlimentospcIntraPre, AlimentospcExtra)\n\n\n\n                      ME     RMSE      MAE       MPE     MAPE     MASE\nTraining set   0.3696849 12.79181  9.36163  0.016599 1.476634 0.889827\nTest set     -25.2641938 45.08782 36.16203 -4.533005 6.151504 3.437217\n                   ACF1 Theil's U\nTraining set 0.09289229        NA\nTest set     0.30152455  1.240974\n\n\nAhora el error de ajuste o previsión a un periodo vista intramuestral es del 1.5 %; mientras que el error de previsión extramuestral es del 6.2 %. De nuevo, las previsiones están segadas y sobrestiman la realidad (véase Figura 2).\n\n\n\n\n\n\n\n\nFigura 2: Precisión en la predicción de Alimentos por el método Arima\n\n\n\n\n\nEn el tema previo vimos que Arima ajustaba mejor que el método Ingenuo I gracias a poder incorporar la intervención. En este ejercicio, al quedar el periodo de intervención fuera del periodo intramuestal de ajuste, ambos modelos tienen una calidad de ajuste muy similar (1.7 para Ingenuo I y 1.5 para Arima). Sin embargo, a la hora de predecir, el método más sencillo resulta algo mejor, con un error 1 p.p inferior al del método Arima.\nEn cualquier caso, la precisión obtenida es una media de errores desde un periodo vista hasta 7 periodos vista que no permite saber como crece el error conforme se incrementa el horizonte temporal de previsión. Por ejemplo, un error medio del 5% podría ser el resultado de errores inferiores al 2% para previsiones a uno o dos periodos vista junto con errores por encima del 10% para previsiones a 6 o 7 periodos vista."
  },
  {
    "objectID": "03-05-Tema5.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita-1",
    "href": "03-05-Tema5.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita-1",
    "title": "Evaluación de las predicciones",
    "section": "3.1 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita",
    "text": "3.1 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita\nVamos a aplicar la metodología previa a la serie anual de Alimentos. Asumimos que se precisan quince años para hacer una buena estimación, \\(k=15\\), y que el horizonte temporal es de cinco años, \\(h = 5\\). Volveremos a comparar los métodos Ingenuo I y Arima (sin considerar la intervención). Como medida de error de predicción vamos a considerar el MAPE.\n\nMétodo Ingenuo I\n\nk &lt;- 15                   # Minimo numero de datos para estimar\nh &lt;- 5                    # Horizonte de las prediciciones\nTT &lt;- length(alimentospc) # Longitud serie\ns &lt;- TT - k - h           # Total de estimaciones\n\nmapeIng &lt;- matrix(NA, s + 1, h)\nfor (i in 0:s) {\n  train.set &lt;- subset(alimentospc, start = i + 1, end = i + k)\n  test.set &lt;-  subset(alimentospc, start = i + k + 1, end = i + k + h)\n  \n  fcast &lt;- naive(train.set, h = h)\n  mapeIng[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n}\n\nLa matriz mapeIng contiene los errores de previsión extramuestral, donde cada columna corresponde a un horizonte temporal de previsión diferente. Ahora vamos a calcular el error medio por columna.\n\nmapeIngMedia &lt;- colMeans(mapeIng)\nround(mapeIngMedia, 2)\n\n[1] 1.11 2.39 2.78 3.41 4.24\n\n\nPara evitar el efecto de los altos errores que se darán cuando el rango de previsión alcanza los últimos años, se puede calcular el error mediano en lugar del error medio. En este caso no hay una función directa en R y usaremos apply.\n\nmapeIngMediana &lt;- apply(mapeIng, MARGIN = 2, FUN = median)\nround(mapeIngMediana, 2)\n\n[1] 0.94 2.07 2.37 2.86 3.85\n\n\nEl error de previsión extramuestral (medio o mediano) crece gradualmente con el horizonte de previsión. Para el primer año el error de predicción se mantiene en un moderado 1%, para el segundo año de predicción el MAPE salta a más del 2% y para los restantes años sigue creciendo. Sin embargo, incluso para 5 años vista el error se mantiene razonablemente bajo. En todos los casos, el error mediano es menor que el medio al ser el primero robusto frente a años atípicos.\n\n\nModelo Arima\n\nk &lt;- 15                   # Minimo numero de datos para estimar\nh &lt;- 5                    # Horizonte de las prediciciones\nTT &lt;- length(alimentospc) # Longitud serie\ns &lt;- TT - k - h           # Total de estimaciones\n\nmapeAri &lt;- matrix(NA, s + 1, h)\nfor (i in 0:s) {\n  train.set &lt;- subset(alimentospc, start = i + 1, end = i + k)\n  test.set &lt;-  subset(alimentospc, start = i + k + 1, end = i + k + h)\n  \n  fit &lt;- Arima(train.set, order = c(1, 0, 0), include.constant = TRUE)\n  fcast&lt;- forecast(fit, h = h)\n  mapeAri[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n}\n\nmapeAriMedia &lt;- colMeans(mapeAri)\nround(mapeAriMedia, 2)\n\n[1] 1.31 2.44 2.63 3.48 4.29\n\nmapeAriMediana &lt;- apply(mapeAri, MARGIN = 2, FUN = median)\nround(mapeAriMediana, 2)\n\n[1] 1.39 2.54 2.76 3.20 3.03\n\n\nComo en el caso previo, el error de previsión extramuestral (medio o mediano) crece gradualmente con el horizonte de previsión, desde el 1.3% para previsiones a un año vista hasta el 4% de media o 3% de mediana para previsiones a 5 años vista. En este caso la diferencia entre el error medio y mediano solo es notable para para previsiones a 5 años vista.\n\n\nComparación entre modelos\nLa mejor forma de comparar la calidad en las previciones extramuestrales de diferentes métodos es gráficamente. La Figura 4 muestra el error mediano obtenido con los métodos Ingenuo I y Arima según el horizonte temporal. Se ha elegido el error mediano para evitar el efecto de la pandemia.\n\nggplot() +\n  geom_line(aes(x = 1:5, y = mapeIngMediana, colour = \"blue\")) + \n  geom_line(aes(x = 1:5, y = mapeAriMediana, colour = \"red\")) + \n  ggtitle(\"\") +\n  xlab(\"\") +\n  ylab(\"%\") +\n  scale_color_discrete(name = \"Método\", \n                       labels = c(\"Ingenuo I\", \"Arima\")) +\n  theme(legend.position=c(0.2,0.8))\n\n\n\n\n\n\n\nFigura 4: Comparación de errores medianos (MAPE)\n\n\n\n\n\nEl método Ingenuo I ofrece predicciones más precisas que el método Arima y es mucho más rápido de aplicar. Solo para predicciones a 5 años vista el método Arima supera en calidad de predicciones al método Ingenuo I"
  },
  {
    "objectID": "03-05-Tema5.html#validación-por-conjuntos-de-entrenamiento-y-prueba",
    "href": "03-05-Tema5.html#validación-por-conjuntos-de-entrenamiento-y-prueba",
    "title": "Evaluación de las predicciones",
    "section": "4.1 Validación por conjuntos de entrenamiento y prueba",
    "text": "4.1 Validación por conjuntos de entrenamiento y prueba\nVamos a reservar en este caso las dos últimas semanas de la serie (14 días). Usaremos los modelos ya identificados para calcular las predicciones a 14 días vista y después compararlas con los valores reales de la serie.\n\n# Definimos las observaciones intra- y extramuestrales\nDefuncionesIntra &lt;- subset(defunciones, end = length(defunciones) - 14)\nDefuncionesExtra &lt;- subset(defunciones, start = length(defunciones) - 13)\n\n# Estimamos el modelo de Alisado MNN y predecimos\nfit &lt;- ets(DefuncionesIntra, \n           model = \"MNN\")\n\nDefuncionesExtraPreAli &lt;- forecast(fit, h = 14)\n\n# Estimamos el modelo de Arima(2, 0 ,0) y predecimos\nfit &lt;- Arima(DefuncionesIntra, \n             order = c(2, 0 ,0), \n             include.constant = TRUE)\n\nDefuncionesExtraPreAri &lt;- forecast(fit, h = 14)\n\n# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales\naccuracy(DefuncionesExtraPreAli, DefuncionesExtra)\n\n                      ME      RMSE       MAE        MPE      MAPE      MASE\nTraining set  -0.5148402  65.32886  52.24719 -0.2849683  4.353032 0.9374338\nTest set     154.9742064 180.11936 154.97421 10.3916378 10.391638 2.7805912\n                  ACF1 Theil's U\nTraining set 0.2532441        NA\nTest set     0.7167275  3.347972\n\naccuracy(DefuncionesExtraPreAri, DefuncionesExtra)\n\n                      ME      RMSE       MAE        MPE      MAPE      MASE\nTraining set  -0.4409052  65.95095  52.97001 -0.3297377  4.412686 0.9504029\nTest set     200.0817499 223.15146 200.08175 13.5037939 13.503794 3.5899235\n                   ACF1 Theil's U\nTraining set -0.0257479        NA\nTest set      0.7260915   4.16499\n\n\nAtendiendo al MAPE se tiene que el error de previsión intramuestral a un periodo vista es idéntico para ambos modelos, 4.4%. A la hora de comparar la precisión de la previsión extramuestral a largo plazo, el modelo de Alisado, con un error del 10.4%, muestra ser superior al modelo Arima, con un error del 13.5%. Es decir, aunque por calidad de ajuste ambos modelos son equivalentes, el método de Alisado predice en promedio mejor. Otra conclusión es que al pasar de ajuste a predicción, hay una pérdida de calidad muy notable. Si en lugar del MAPE usamos el RMSE o el MAE, obtenemos los mismos resultados.\n\n\n\n\n\n\n\n\nFigura 5: Previsión extramuestral de Defunciones por los métodos de Alisado y Arima\n\n\n\n\n\nLa Figura 5 muestra que ambos métodos ofrecen previsiones muy inferiores al número real de defunciones. Esto es así, porque a partir del punto de corte las temperaturas fueron menores que las observadas previamente. La entrada del invierno en el periodo extramuestral y la caída de la temperatura ha provocado un aumento de las defunciones que ningún modelo ha capturado."
  },
  {
    "objectID": "03-05-Tema5.html#origen-de-predicción-móvil-1",
    "href": "03-05-Tema5.html#origen-de-predicción-móvil-1",
    "title": "Evaluación de las predicciones",
    "section": "4.2 Origen de predicción móvil",
    "text": "4.2 Origen de predicción móvil\nAhora aplicaremos la metodología de origen de predicción móvil a la serie de Defunciones. En este caso se asumirá que se precisan veinte semanas para hacer una buena estimación, \\(k = 140\\), y que el horizonte temporal es de 2 semanas, \\(h = 14\\). La siguiente rutina permite obtener el RMSE para previsiones con un horizonte temporal desde uno a 14 días. Como esta serie no presenta intervención, podemos calcular el error medio.\n\n\n\n\n\n\nCódigo para cálculo del error deseado\n\n\n\nPara Alimentos hemos visto el código necesario para calcular el MAPE por origen de predicción móvil. Las dos líneas clave del código son:\n\n\nmapeAri[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\nmapeAriMedia &lt;- colMeans(mapeAri)\n\n\nLa primera línea obtiene el error porcentual absoluto de cada observación y la segunda calcula la media de estos errores.\n\n\nPara calcular el RMSE es necesario adaptar estás dos líneas de código adecuadamente. Ahora la primera línea debe calcular el error cuadrático de cada observación y la segunda la raíz de la media de estos errores:\n\n\nrmseAri[i + 1,] &lt;- (test.set - fcast$mean)^2\nrmseAri &lt;- sqrt(colMeans(rmseAri))\n\n\nEn general, según el error que desees obtener, deberás modificar estas dos líneas de código como corresponda.\n\n\nAdemás, si hay valores atípicos, puede ser conveniente calcular el error mediano en lugar del error medio.\n\n\n\nk &lt;- 140                  # Minimo numero de datos para estimar\nh &lt;- 14                   # Horizonte de las prediciciones\nTT &lt;- length(defunciones) # Longitud serie\ns &lt;- TT - k - h           # Total de estimaciones\n\nrmseAli &lt;- matrix(NA, s + 1, h)\nrmseAri &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(defunciones, start = i + 1, end = i + k)\n  test.set &lt;-  subset(defunciones, start = i + k + 1, end = i + k + h)\n  \n  fit &lt;- ets(train.set, model = \"MNN\")\n  fcast &lt;- forecast(fit, h = h)\n  rmseAli[i + 1,] &lt;- (test.set - fcast$mean)^2\n  \n  fit &lt;- Arima(train.set, order = c(2, 0, 0), include.constant = TRUE)\n  fcast &lt;- forecast(fit, h = h)\n  rmseAri[i + 1,] &lt;- (test.set - fcast$mean)^2\n}\n\nrmseAli &lt;- sqrt(colMeans(rmseAli))\nround(rmseAli, 2)\n\n [1] 66.24 74.30 77.54 77.99 77.11 75.50 77.49 84.35 89.58 92.31 92.39 92.64\n[13] 92.73 96.39\n\nrmseAri &lt;- sqrt(colMeans(rmseAri))\nround(rmseAri, 2)\n\n [1]  68.74  85.92  94.38  99.48 103.24 104.41 107.21 113.62 119.23 123.97\n[11] 127.13 130.39 132.11 134.48\n\n\nEl error de previsión extramuestral crece día a día, desde algo menos de las 70 defunciones para previsiones a un día vista, hasta casi 100 defunciones a 14 días vista con el modelo de Alisado y las 134 defunciones para el método Arima. La Figura 6 muestra gráficamente la precisión en la previsiones.\n\nggplot() +\n  geom_line(aes(x = 1:14, y = rmseAli, colour = \"blue\")) + \n  geom_line(aes(x = 1:14, y = rmseAri, colour = \"red\")) + \n  ggtitle(\"\") +\n  xlab(\"\") +\n  ylab(\"Defunciones\") +\n  scale_color_discrete(name = \"Método\", \n                       labels = c(\"Alisado\", \"Arima\")) +\n  theme(legend.position=c(0.2,0.8))\n\n\n\n\n\n\n\nFigura 6: Comparación de errores medios (RMSE)\n\n\n\n\n\nEl método Alisado ofrece las predicciones más precisas con independencia del horizonte temporal. Además, cuanto mayor es el horizonte temporal más se incrementa la diferencia en la calidad de las predicciones de ambos métodos."
  },
  {
    "objectID": "02-Logistica.html",
    "href": "02-Logistica.html",
    "title": "Logística",
    "section": "",
    "text": "El grueso del material del curso lo podéis encontrar en esta página web. Sin embargo, hay muuuucho material adicional disponible en formato papel y online. A continuación os describo brevemente dónde podéis encontrar parte de este material.\n\n\n\n\n\n\nContenidos del curso\n\nPágina web del curso dónde encontrarás todo el material teórico y práctico necesario para seguir el curso y realizar las prácticas de evaluación.\nAula Virtual donde encontrarás una copia de todo el material del curso en un único fichero comprimido. Además, Aulavirtual será el medio de comunicación oficial entre nosotros y dónde subiréis las respuestas a las pruebas tipo test y las prácticas de evaluación.\n\n\n\n\n\n\n\n\nMateriales\n\nContenidos teóricos: los encontrarás en la sección Diapos. Las primeras entradas corresponden a los contenidos teóricos del curso y las restantes a un ejemplo práctico de aplicación para cada tema. Este ejemplo no necesariamente lo veremos durante el curso, pero puede serte de ayuda para terminar de comprender los conceptos teóricos vistos y su aplicación práctica con R.\nEn Píldoras encontrarás extensiones a conceptos del curso, algunos de los cuales iremos vendo en clase de teoría.\nRecursos de la asignatura: contiene los ficheros de datos de los ejemplos utilizados durante el curso (ficheros .csv) así como el código de R que usaremos en las clases (ficheros .R).\n\n\n\n\n\n\nMás recursos\nLa última sección de la página web Más es un pequeño baúl de recursos que te pueden ser útiles:\n\nR: enlaces a páginas con recursos sobre R y RStudio\nMarkdown: enlaces a páginas con recursos sobre (R)Markdown y Quatro\nOtros: enlace a R-bloggers, un blog sobre R que te puede ser de gran ayuda y a libros online sobre R, análisis de datos, inferencia…\n\n\n\n\n\n\n\n\nBibliografía\nEl material de este curso debe mucho a\n\nForecasting: Principles and Practice: un libro online (realizado con bookdown) de Rob J. Hyndman y George Athanasopoulos. Durante el curso usaremos fundamentalmente la librería forecast de Hyndman, Athanasopoulos y otros (aquí).\n\n\n\nHay un montón de bibliografía sobre Predicción con Datos Temporales, tanto en formato libro como online. Es imposible ser exhaustivos, así que aquí va una muestra.\nSentíos libres de hurgar en la web en busca de tutoriales, videos, libros… que os puedan ser útiles. Si algún material que localizáis creéis que es realmente útil, por favor, compartirlo con vuestros compañeros y conmigo.\n\n\nGrandes clásicos de Series Temporales\n\nAbraham, B. y Ledolter, J. (1983) Statistical methods for forecasting. Wiley\nBox, G.E.P. y Jenkins, G.M. (1976) Time series analysis, forecasting and control. Holden-Day\nBox, G.E.P., Jenkins, G.M. y Reinsel, G.C. (1994) Time series análisis. Prentice-Hall\nBrockwell, P.J. y Davis, R.A. (1996) Introduction to time series and forecasting. Springer-Verlag\nChatfield, C. (1989) The analysis of time series. An introduction. Chapman & Hall\nGreene, W. (1998) Análisis econométrico. Prentice Hall\nHolden, K., Peel D.A. y Thompson, J. L. (1990) Economic Forecasting: an introduction. Cambridge University Preess: Cambridge\nHolton, J. y Keating, B. (1996) Previsión en los negocios. IRWIN\nMarkridakis, S., Weelwright, S.C. y Hyndman, R.J. (1998) Forecasting: Methods and Applications. Willey\nPeña, D. (1999) Estadística: modelos y métodos 2 (Modelos lineales y Series Temporales.) Alianza Universidad Textos.\nPulido, A. y López, A.M. (1999) Predicción y simulación aplicada al a economía y gestión de empresas. Pirámide.\nUriel, E. (2005) Introducción al análisis de series temporales. Paraninfo.\n\n\n\nBibliografía de Series Temporales con R\n\nCowpertwait, P. S. P. y Metcalfe, A. V. (2009) Introductory Time Series with R. Springer (Collection Use R!)\nPfaff, B. (2008) Analysis of Integrated and Cointegrated Time Series with R. Springer (Collection Use R!)\nCryer, J. D., Chan, Kung-Sik. (2008) Time Series Analysis. With Applications in R. Springer\n\n\n\nDirecciones de internet\n\nQuick-R: Time Series and Forecasting: un vistazo muy pero que muy rápido al análisis de series temporales con R.\nTres manuales online de series temporales al estilo del comentado al inicio de la bibliografía se pueden encontrar aquí, aquí y aquí\nA First Course on Time Series Analysis with SAS: es un libro de análisis de series temporales con SAS online\nJournal of Time Series Analysis: revista científica sobre series temporales\n\nInternational Journal of Forecasting: revista científica sobre predicción\n\n\n\nSoftware gratuito\n\nR-project: creo que ya lo conocemos todos.\nJDemetra+: ajuste automático de series con modelos ARIMA aplicando dos métodos: TRAMO-SEATS+ y X-12ARIMA/X-13ARIMA-SEATS.\nGretl: programa de modelización gratuito: regresión múltiple, modelos de elección binaria, series temporales, etc."
  },
  {
    "objectID": "03-04-Tema4.html#notación-y-definiciones",
    "href": "03-04-Tema4.html#notación-y-definiciones",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "2.1 Notación y definiciones",
    "text": "2.1 Notación y definiciones\nDada una serie temporal \\(\\{y_t\\}_{t=1}^T\\), se define:\n\nPrevisión \\(h\\) periodos adelante, como la previsión de la serie para el periodo \\(t+h\\) disponiendo de información hasta el periodo \\(t\\), y se denota por \\(\\hat{y}_{t+h|t}\\). Por simplicidad lo escribiremos también como \\(\\hat{y}_{t+h}\\).\nAsí, \\(\\hat{y}_{t+1|t}\\) es la previsión un periodo adelante o a un periodo vista. Es decir, la previsión de la serie en el periodo \\(t+1\\) desde el periodo \\(t\\).\nPor simplicidad denotaremos a \\(\\hat{y}_{t+1|t}\\) como \\(\\hat{y}_{t+1}\\). Por tanto, \\(\\hat{y}_{t}\\) será la previsión en \\(t\\) con datos hasta el periodo \\(t-1\\) (\\(\\hat{y}_{t} = \\hat{y}_{t|t-1}\\)).\n\nSi para un periodo \\(t\\) se tiene la observación \\(y_t\\) y una previsión \\(\\hat{y}_t\\), se define como error a un periodo vista a \\[\\hat{e}_t=y_t-\\hat{y}_t,\\] de forma que la serie \\(\\{\\hat{e}_t\\}_{t=1}^T\\) nos permitirá definir varios criterios de calidad.\n\n¿Calidad de ajuste o de previsión?\nLos mismos criterios que se van a definir a continuación pueden ser criterios de calidad de ajuste o de calidad de las previsiones. Esta diferencia depende de cómo se ha obtenido \\(\\hat{y}_t\\).\nSi en el proceso de predicción hay parámetros cuyo ajuste o estimación se ha realizado usando toda la serie temporal, entonces hablaremos de calidad de ajuste: para obtener \\(\\hat{y}_t\\) se habrá usado el dato \\(y_t\\) y los siguientes, es decir, datos posteriores al periodo \\(t\\) y entonces \\(\\hat{e}_t\\) es un error de ajuste.\nPor el contrario, si en el proceso de predicción no hay parámetros o habiéndolos su estimación se ha realizado usando la serie temporal hasta el periodo \\(t-1\\), entonces hablaremos de calidad de predicción: para obtener \\(\\hat{y}_t\\) solo se habrán usado el datos hasta \\(y_{t-1}\\), es decir, datos anteriores al periodo \\(t\\), y entonces \\(\\hat{e}_t\\) es un error de predicción.\nA veces al error de ajuste se le denomina error de previsión intramuestral y hablaremos de criterios de calidad intramuestral. De la misma forma al error de previsión se le denomina error de previsión extramuestral y hablaremos de criterios de calidad extramuestral o precisión de las predicciones."
  },
  {
    "objectID": "03-04-Tema4.html#criterios-de-calidad-1",
    "href": "03-04-Tema4.html#criterios-de-calidad-1",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "2.2 Criterios de calidad",
    "text": "2.2 Criterios de calidad\nDada una serie \\(\\{y_t\\}_{t=1}^T\\), un método de predicción y su vector de errores asociado \\(\\{\\hat{e}_t\\}_{t=1}^T\\), podemos definir múltiples criterios de calidad de ajuste o predicción del método que hacen referencia a la presencia de sesgo en las predicciones, la magnitud del error cometido y la calidad del intervalo de confianza de las predicciones. Las más habituales son (siglas en inglés):\n\nError medio (ME): \\(\\frac{1}{T}\\sum_{t=1}^T \\hat{e}_t\\)\n\n\nRaíz del error cuadrático medio (RMSE): \\(\\sqrt{\\frac{1}{T}\\sum_{t=1}^T \\hat{e}^2_t}\\)\n\n\nError absoluto medio (MAE): \\(\\frac{1}{T}\\sum_{t=1}^T |\\hat{e}_t|\\)\n\n\nError porcentual medio (MPE): \\(\\frac{100}{T}\\sum_{t=1}^T \\frac{\\hat{e}_t}{y_t}\\)\n\n\nError porcentual absoluto medio (MAPE): \\(\\frac{100}{T}\\sum_{t=1}^T \\big|\\frac{\\hat{e}_t}{y_t}\\big|\\)\n\n\nError escalado absoluto medio (MASE): \\(\\big(\\frac{1}{T}\\sum_{t=1}^T |\\hat{e}_t|\\big)/q\\), donde \\(q\\) es el error absoluto medio para un método ingenuo de predicción: el método ingenuo I para series sin estacionalidad y el método ingenuo con estacionalidad para series con estacionalidad.\n\n\nCorrelación entre \\(\\hat{e}_t\\) y \\(\\hat{e}_{t-1}\\) (ACF1).\n\n\n\nME y MPE permiten valorar el sesgo de las predicciones (que estén sistemáticamente por encima o por debajo de los valores reales).\n\nLo esperado es un valor cercano a cero (en el caso de ME con relación al valor medio de la serie). Valores muy alejados de cero son indicadores de sesgo de predicción.\nLa más cómoda de interpretar es MPE. Asumiremos que si MPE es menor que 1% en valor absoluto, no hay sesgo.\n\nRMSE y MAE son medidas de calidad de ajuste/precisión. Indican el error medio cometido, independientemente del signo, medido en las mismas unidades que la serie temporal.\n\nEstán acotadas inferiormente por el valor óptimo de 0, pero no hay cota superior.\n\nMAPE es una medida de calidad de ajuste/precisión alternativa que indica el error porcentual medio cometido.\n\nEstá acotado inferiormente por el valor óptimo de 0%, y la cota superior natural es 100%, aunque podría sobrepasarse.\nSi \\(y_t\\) puede valer 0, entonces MAPE no se puede calcular. Además, MAPE penaliza más los errores negativos frente a los errores positivos. Se puede definir el error porcentual absoluto medio simétrico (sMAPE) \\(\\frac{200}{T}\\sum_{t=1}^T \\Big|\\frac{\\hat{e}_t}{y_t + \\hat{y}_t}\\Big|\\) a fin de corregir estos problemas.\n\nMASE es la ratio entre el error del método usado y el error de un método ingenuo de predicción. Permite saber cuánto ganamos en capacidad predictiva al pasar de un método ingenuo a otro más complicado.\n\nUn valor cercano a 1 indica que el método usado no es mejor que el método ingenuo\nCuanto más cercano a 0, mejor es el método usado respecto del método ingenuo\nSu complementario a 1 se puede interpretar como la tasa de mejora\n\nACF1 permite saber si el método empleado ha extraído toda la información disponible en los datos de la serie para hacer las predicciones. Si no es así, la fórmula usada para estimar el intervalo de confianza de las predicciones no será válida:\n\nUn valor muy cercano a 0 (menor que 0.1) indica que se ha extraído toda la información y la fórmula usada para estimar el intervalo de confianza de las predicciones es válida.\nValores minimamente alejados de 0 indican que la fórmula no es válida.\n\n\n\n\n\n\n\nCálculo del intervalo de confianza de las predicciones\n\n\n\nVe a la Píldora Bootstrapping para intervalos de predicción para saber más sobre las fórmulas usadas para estimar el intervalo de confianza de las predicciones y alternativas de cálculo cuando estas fórmulas no son válidas.\n\n\nEn todas las fórmulas de criterios de calidad las medias se pueden sustituir por medianas. Esto es especialmente útil cuando para hay observaciones atípicas que generan errores muy altos.\n\n\nLos indicadores de calidad de ajuste que se basan en predicciones intramuestrales a un periodo vista, presentan dos problemas. Primero, evalúan el error a un periodo vista, cuando en muchas situaciones reales las predicciones se realizan sobre un horizonte temporal más amplio. Segundo, son errores intramuestrales, resultantes de predecir los mismos datos que ha usado el método para calcular la predicción y, por tanto, sobrestiman la capacidad predictiva del modelo.\nVeremos en el Tema 5 métodos de evaluación de la precisión de las predicciones que superan estas limitaciones."
  },
  {
    "objectID": "03-04-Tema4.html#métodos-sencillos-de-predicción-1",
    "href": "03-04-Tema4.html#métodos-sencillos-de-predicción-1",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "3.1 Métodos sencillos de predicción",
    "text": "3.1 Métodos sencillos de predicción\nMétodo de la Media: \\(\\hat{y}_{T+h}=(y_1+\\ldots,y_T)/T\\).\n\nLa predicción para cualquier periodo futuro es la media de las observaciones disponibles previas.\nFunción de R: meanf(y, h)\n\nMétodo ingenuo I: \\(\\hat{y}_{T+h}=y_T\\).\n\nLa predicción para cualquier periodo futuro es la última observación disponible.\nFunción de R: naive(y, h) o rwf(y, h) (rw de random walk)\nPara series sin estacionalidad este es el método ingenuo de comparación del MASE.\n\nMétodo de la media móvil: \\(\\hat{y}_{T+h}=\\frac{1}{r}(y_T + y_{T-1} + \\cdots + y_{T-r+1})\\).\n\nLa predicción para cualquier periodo futuro es la media de las últimas \\(r\\) observaciones.\nEl valor de \\(r\\) lo debe determinar el investigador. Cuanto mayor es su valor, más suave es la linea de predicciones obtenida y menos efecto tiene el valor de una observación individual sobre la predicción. En el caso límite \\(r=1\\) se tiene el método Ingenuo I y para \\(r=T\\) el método de la Media.\nPara poder aplicar la media móvil de orden \\(r\\) se necesitan al menos \\(r\\) datos.\nPara los \\(r-1\\) periodos iniciales no es posible calcular la media móvil y, por tanto, para los \\(r\\) periodos iniciales no es posible obtener una predicción intramuestral.\n\nEste método no tiene una función de R, así que usaremos una creada por nosotros: mmf(x, r, h, level).1\n\nmmf &lt;- function (x, r = 3, h = 10, level = c(80, 95)) \n{\n  n &lt;- length(x)\n  startx &lt;- start(x)\n  frequencyx &lt;-frequency(x)\n  \n  mm &lt;- stats::filter(x, rep(1/r, r), side = 1)\n  fits &lt;- c(NA, mm[-n])\n  res &lt;- x - fits\n  f &lt;- rep(mm[n], h)\n  \n  if (min(level) &gt; 0 && max(level) &lt; 1) {\n    level &lt;- 100 * level\n  } else if (min(level) &lt; 0 || max(level) &gt; 99.99) \n    stop(\"Confidence limit out of range\")\n\n  nconf &lt;- length(level)\n  s &lt;- sd(res, na.rm = TRUE)\n  \n  lower &lt;- upper &lt;- matrix(NA, nrow = h, ncol = nconf)\n  for (i in 1:nconf) {\n    if (n &gt; 1) {\n      tfrac &lt;- qt(0.5 - level[i]/200, n - 1)\n    } else {\n      tfrac &lt;- -Inf\n    }\n    w &lt;- -tfrac * s * sqrt(1 + 1/n)\n    lower[, i] &lt;- f - w\n    upper[, i] &lt;- f + w\n  }\n  \n  colnames(lower) &lt;- colnames(upper) &lt;- paste(level, \"%\", sep = \"\")\n  \n  fits &lt;- ts(fits, start = startx, frequency = frequencyx)\n  res &lt;- ts(res, start = startx, frequency = frequencyx)\n  f &lt;- ts(f, start = time(x)[n] + 1/frequencyx, frequency = frequencyx)\n  lower &lt;- ts(lower, start = time(x)[n] + 1/frequencyx, frequency = frequencyx)\n  upper &lt;- ts(upper, start = time(x)[n] + 1/frequencyx, frequency = frequencyx)\n\n  out &lt;- list(method = \"Moving average\", level = level, x = x,\n              mean = f, lower = lower, upper = upper, fitted = fits, \n              residuals = res, order = r)\n\n  return(structure(out, class = \"forecast\"))\n}\n\nLa función mmf precisa de tres argumentos, una serie temporal, el orden de la media móvil \\(r\\) y el horizonte de previsión \\(h\\). Los valores por defecto de los dos últimos argumentos están fijados a 3, 10."
  },
  {
    "objectID": "03-04-Tema4.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita",
    "href": "03-04-Tema4.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "3.2 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita",
    "text": "3.2 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita\nAnalizaremos el consumo alimentario en hogar per cápita en España. Esta serie está construida a partir de la serie de consumo alimentario en hogar (disponible en el Ministerio de Agricultura, Alimentación y Medio Ambiente) y la serie de población (disponible en el Instituto Nacional de Estadística). Es una serie anual de 1990 a 2023 (34 datos) y la unidad es el kg per cápita. El panel a) de la Figura 1 muestra que es una serie estacionaria.\n\nalimentospc &lt;- read.csv2(\"./series/Alimentacionpc.csv\", \n                         header = TRUE)\n\nalimentospc &lt;- ts(alimentospc[, 1], \n                  start = 1990, \n                  freq = 1)\n\nLas siguientes salidas muestran el resultado de la aplicación de los métodos sencillos a la serie. Se ha fijado un horizonte de previsión de cinco años (h = 5). Todos estos métodos realizan una predicción constante, el método de la media da la media del consumo de alimentos per cápita en el periodo de análisis (632.14); el Ingenuo I da el último dato observado (555.47); y la media móvil de orden \\(r=4\\), valor fijado por nosotros, da la media de las cuatro últimas observaciones 604.63.\n\n(mediaAlimentospc &lt;- meanf(alimentospc, h = 5))\n\n     Point Forecast    Lo 80    Hi 80   Lo 95    Hi 95\n2024       632.1406 598.4999 665.7812 579.804 684.4771\n2025       632.1406 598.4999 665.7812 579.804 684.4771\n2026       632.1406 598.4999 665.7812 579.804 684.4771\n2027       632.1406 598.4999 665.7812 579.804 684.4771\n2028       632.1406 598.4999 665.7812 579.804 684.4771\n\n(naiveAlimentospc &lt;- naive(alimentospc, h = 5))\n\n     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n2024        555.472 527.5726 583.3714 512.8036 598.1404\n2025        555.472 516.0163 594.9277 495.1297 615.8143\n2026        555.472 507.1488 603.7952 481.5681 629.3759\n2027        555.472 499.6732 611.2708 470.1351 640.8089\n2028        555.472 493.0871 617.8569 460.0625 650.8815\n\n(mmAlimentospc    &lt;- mmf(alimentospc, r = 4, h = 5)) #Fijamos r = 4 años.\n\n     Point Forecast    Lo 80    Hi 80    Lo 95    Hi 95\n2024       604.6273 572.4228 636.8317 554.5251 654.7294\n2025       604.6273 572.4228 636.8317 554.5251 654.7294\n2026       604.6273 572.4228 636.8317 554.5251 654.7294\n2027       604.6273 572.4228 636.8317 554.5251 654.7294\n2028       604.6273 572.4228 636.8317 554.5251 654.7294\n\n\nLa Figura 2 muestra el resultado gráfico de la aplicación de estos métodos. El argumento PI = FALSE hace que no se impriman los intervalos de confianza de las predicciones.\n\nautoplot(alimentospc, \n         series = \"Alimentos\",\n         xlab = \"\",\n         ylab = \"Kg per cápita\",\n         main = \"\",\n         ylim = c(0, 700)) +\n  autolayer(mediaAlimentospc, series=\"Media\", PI = FALSE) +\n  autolayer(naiveAlimentospc, series=\"Ingenuo\", PI = FALSE) +\n  autolayer(mmAlimentospc, series=\"Media móvil (r = 4)\", PI = FALSE) +\n  scale_colour_discrete(limits=c(\"Alimentos\", \"Media\", \n                                 \"Ingenuo\", \"Media móvil (r = 4)\")) +\n  labs(colour=\"Métodos\") + \n  theme(legend.position=c(0.2,0.3))\n\n\n\n\n\n\n\nFigura 2: Consumo de alimentos en el hogar y predicción por métodos sencillos\n\n\n\n\n\nCon la función accuracy se puede obtener el error de ajuste a un periodo vista de cada método:\n\naccuracy(mediaAlimentospc)\naccuracy(naiveAlimentospc)\naccuracy(mmAlimentospc)\n\n\n\n               ME  RMSE   MAE   MPE MAPE MASE  ACF1\nMedia        0.00 24.98 18.59 -0.16 3.00 1.30  0.49\nIngenuo I   -2.09 21.77 14.32 -0.42 2.28 1.00 -0.03\nMedia móvil -5.49 24.49 18.27 -1.01 2.97 1.28  0.39\n\n\nPodemos destacar que:\n\nEl método Ingenuo I presenta la mejor calidad de ajuste con un error de 22 kg per cápita (RMSE) o del 2.3% (MAPE). El método de Media y de la Media móvil tienen una calidad de ajuste similar, con un error medio en torno a los 24.5–25 kg per cápita (RMSE) y un error porcentual del 3% (MAPE).\nSi se usa como criterio de calidad de ajuste el error absoluto medio (MAE), vuelve a ser mejor el método Ingenuo I.\nAdemás, el método de Ingenuo I genera predicciones por intervalo fiables (ACF1 = -0.03), mientras que los métodos de la Media y de la Media móvil no (ACF1 de 0.49 y 0.39, respectivamente).\nLos métodos de la Media e Ingenuo I no presentan sesgo (|MPE| &lt; 1%). Además, el error medio (ME) siempre será nulo para el método de la Media, lo que indica que nos equivocamos lo mismo por exceso como por defecto. Esta es una buena propiedad, que el método Ingenuo I y de la Media móvil no verifican.\nPara series sin estacionalidad el método sencillo de comparación usado en el cálculo del MASE es el Ingenuo I. Es por ello que este indicador vale 1 para este método. Como el método de Media tiene un MAE superior al Ingenuo I, su MASE es mayor que 1. En concreto, MASE = 1.3 = 18.59 / 14.32. Lo mismo pasa con el método de la Media móvil.\n\nConcluimos que, con independencia del criterio usado, el método que mejor ajusta los datos es el Ingenuo I.\n\nIdentificación del orden \\(r\\) del método de la Media móvil\nEn este ejemplo hemos fijado \\(r=4\\). ¿Es el mejor valor? ¿hay alguna forma de determinar el valor óptimo de \\(r\\)?\nUna forma sencilla de responder a estas preguntas consiste en aplicar el método de la media móvil para diferentes órdenes \\(r\\) y comprobar para cual de ellos se obtiene el mejor valor del criterio de calidad deseado. Realizaremos este ejercicio considerando como indicador de bondad de ajuste el MAPE:\n\nfor(r in 1:5) {\n  error &lt;- accuracy(mmf(alimentospc, r = r))[5]\n  error &lt;- formatC(error, format = \"f\", digits = 2)\n  cat(\"\\nPara un orden de\", r, \"el error es\", error, \"%\")\n}\n\n\nPara un orden de 1 el error es 2.28 %\nPara un orden de 2 el error es 2.65 %\nPara un orden de 3 el error es 2.89 %\nPara un orden de 4 el error es 2.97 %\nPara un orden de 5 el error es 3.16 %\n\n\nPodemos concluir que el orden óptimo es 1, donde se alcanza el menor MAPE, es decir el método Ingenuo I."
  },
  {
    "objectID": "03-04-Tema4.html#definición",
    "href": "03-04-Tema4.html#definición",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "4.1 Definición",
    "text": "4.1 Definición\nRecordemos que las series sin tendencia ni estacionalidad giran en torno a un nivel medio desconocido: \\(y_t = \\mu + \\varepsilon_t\\). Por tanto, para obtener una predicción en el periodo \\(t+1\\) necesitamos la estimación del nivel de la serie con la información disponible hasta el periodo \\(t\\). Denominaremos a este nivel \\(l_t\\), de esta forma se tendrá que: \\[\\widehat{y}_{t+1} = l_t.\\]\nEs decir, \\(l_t\\) es la estimación del nivel desconocido \\(\\mu\\) con información hasta el periodo \\(t\\).\n¿Pero cómo obtenemos \\(l_t\\)? Mediante una expresión recursiva donde el nivel \\(l_t\\) se calcula a partir de los valores hasta \\(t\\) de la serie y los valores pasados estimados para el nivel. En concreto, para el Alisado exponencial simple la ecuación recursiva de suavizado es \\[l_t=\\alpha y_t + (1-\\alpha)l_{t-1}.\\] Dos estimaciones razonables de \\(l_t\\), el nivel de la serie en el periodo \\(t\\), son el valor observado para la serie en ese periodo \\(y_t\\) y el nivel del periodo previo \\(l_{t-1}\\). La estimación final de \\(l_t\\) es una media ponderada de ambas según el parámetro \\(\\alpha\\), y esta estimación final es la previsión de la serie para el periodo siguiente.\nEl parámetro \\(\\alpha\\) se denomina parámetro de suavizado y verifica que \\(0 \\leq \\alpha \\leq 1\\).\nYa hemos comentado que la ecuación de predicción intramuestral es \\(\\widehat{y}_{t+1} = l_t\\). La ecuación de predicción extramuestral es \\[\\widehat{y}_{T+h} = \\widehat{y}_{T+1} = l_T.\\] El método de Alisado también ofrece predicciones constantes para series sin tendencia ni estacionalidad."
  },
  {
    "objectID": "03-04-Tema4.html#térmimo-de-error",
    "href": "03-04-Tema4.html#térmimo-de-error",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "4.2 Térmimo de error",
    "text": "4.2 Térmimo de error\nPor otro lado, el término de error de los modelos de alisado puede seguir un esquema aditivo o multiplicativo. Si el residuo es aditivo, entonces el modelo es \\(y_t = \\widehat{y}_t + \\widehat{\\varepsilon}_t\\) y el residuo se define de la forma usual \\[\\widehat{\\varepsilon}_t = y_t - \\widehat{y}_t.\\]\nAhora bien, si el residuo es multiplicativo, entonces el modelo es \\(y_t = \\widehat{y}_t \\cdot (1 + \\widehat{\\varepsilon}_t)\\), y no \\(y_t = \\widehat{y}_t \\cdot \\widehat{\\varepsilon}_t\\) como se podría esperar. Por tanto, el residuo multiplicativo se define como \\[\\widehat{\\varepsilon}_t = (y_t - \\widehat{y}_t)/\\widehat{y}_t.\\]\nObserva que el error multiplicativo no es el error porcentual tal y como se define para el calculo del MPE o del MAPE.\nEn ambos casos –error aditivo y multiplicativo– el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco.\nSegún el tipo de error tenemos dos posibles casos de Alisado exponencial simple:\n\n\\(y_t = \\widehat{y}_t + \\widehat{\\varepsilon}_t = l_{t-1} + \\widehat{\\varepsilon}_t\\)\n\\(y_t = \\widehat{y}_t (1 + \\widehat{\\varepsilon}_t) = l_{t-1} \\cdot (1 + \\widehat{\\varepsilon}_t)\\)\n\nEl tipo de error (aditivo o multiplicativo) es sobre todo relevante en el cálculo del intervalo de confianza de las predicciones."
  },
  {
    "objectID": "03-04-Tema4.html#las-funciones-ets-y-forecast",
    "href": "03-04-Tema4.html#las-funciones-ets-y-forecast",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "4.3 Las funciones ets y forecast",
    "text": "4.3 Las funciones ets y forecast\nPodemos estimar cualquiera de los dos modelos usando la función ets del paquete forecast.\n\nEl tipo de modelo en ets se especifica con el argumento model, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, model = \"ANN\" indica un modelo con error aditivo, sin tendencia ni estacionalidad y model = \"MNN\" indica un modelo con error multiplicativo sin tendencia ni estacionalidad. Es decir los dos casos de Alisado exponencial simple.\nSi deseas que sea la función ets la que decida el tipo de error más adecuado, puedes escribir model = \"ZNN\".\n\nA diferencia de las funciones vistas para métodos simples y media móvil (naive, meanf y mmf), la función ets solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función forecast sobre un modelo estimado con ets. El argumento h de esta función especifica el horizonte temporal de predicción. También puedes usar level para fijar el nivel de confianza del intervalo de predicción.\nMira la ayuda de R para ver una explicación detallada de los argumentos de estas las funciones ets y forecast."
  },
  {
    "objectID": "03-04-Tema4.html#estimación-de-los-parámetros-del-modelo",
    "href": "03-04-Tema4.html#estimación-de-los-parámetros-del-modelo",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "4.4 Estimación de los parámetros del modelo",
    "text": "4.4 Estimación de los parámetros del modelo\nDado el proceso iterativo para el cálculo de \\(l_t\\) se necesita un valor inicial de arranque \\(l_0\\). Cada programa estadístico usa su propio método para obtener \\(l_0\\).\nRespecto de \\(\\alpha\\), usualmente se estima el valor optimo según un criterio de calidad de ajuste. El parámetro \\(\\alpha\\) se puede interpretar:\n\nSi \\(\\alpha = 1\\), la ecuación recursiva queda \\(l_t = y_t\\), es decir, el método ingenuo I (\\(\\widehat{y}_{t+1}=y_t\\)). Este caso es óptimo cuando el nivel de la serie varía constantemente en el tiempo.\nSi \\(\\alpha = 0\\), la ecuación recursiva queda \\(l_t=l_{t-1}=\\ldots = l_0\\), es decir, \\(\\hat y_{t+1}= l_0\\). Esto es óptimo cuando el nivel permanece constante en el tiempo.\n\nEn concreto, ets por defecto estima los parámetros \\(\\alpha\\) y \\(l_0\\) maximizando la función de verosimilitud2, pero el argumento opt.crit permite cambiar de criterio. Esta búsqueda está restringida a \\(0 &lt; \\alpha &lt; 1\\). Es decir el parámetro \\(\\alpha\\) nunca puede ser 0 o 1 y en la práctica sus valores limite son 0.0001 y 0.9999."
  },
  {
    "objectID": "03-04-Tema4.html#criterios-de-selección-de-modelos",
    "href": "03-04-Tema4.html#criterios-de-selección-de-modelos",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "4.5 Criterios de selección de modelos",
    "text": "4.5 Criterios de selección de modelos\nQueda pendiente saber que criterio se usa para seleccionar entre el modelo con error aditivo o multiplicativo. Este aspecto es muy importante porque en temas posteriores veremos que el conjunto de selección de modelos se va ampliando, hasta un total de 30 posibles modelos.\nLa selección se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son: \\[aic = -2log(L) + 2k\\] \\[aicc = aic + \\frac{k(k+1)}{T-k-1}\\] \\[bic=aic + k(log(T) - 2)\\] donde \\(L\\) es la verosimilitud, \\(T\\) el número de datos y \\(k\\) el número de parámetros estimados (incluidos los puntos iniciales de arranque y la desviación típica del error).\nCuanto menor es el criterio de información, mejor modelo. Por defecto se usa Akaike corregido para pequeñas muestras (aicc), pero el argumento ic permite cambiar de criterio."
  },
  {
    "objectID": "03-04-Tema4.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita-1",
    "href": "03-04-Tema4.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita-1",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "4.6 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita",
    "text": "4.6 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita\nVamos a usar el método de alisado exponencial simple para predecir la serie Consumo de alimento en el hogar. Usaremos para ello la función ets con model = \"ZNN\".\n\netsAlimentospc &lt;- ets(alimentospc, \n                      model = \"ZNN\")\nsummary(etsAlimentospc)\n\nETS(A,N,N) \n\nCall:\nets(y = alimentospc, model = \"ZNN\")\n\n  Smoothing parameters:\n    alpha = 0.954 \n\n  Initial states:\n    l = 625.4154 \n\n  sigma:  22.0981\n\n     AIC     AICc      BIC \n334.3284 335.1284 338.9074 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -2.138992 21.43828 14.04374 -0.4243009 2.243991 0.9810031\n                    ACF1\nTraining set 0.004506905\n\n\nVeamos la salida en detalle:\n\nEl modelo óptimo tiene error aditivo: ETS(A,N,N).\nEl valor de \\(\\alpha\\) óptimo (minimiza la verosilimilitud) es \\(\\alpha =\\) 0.95, un valor muy cercano a 1. Es decir, el nivel de Alimentos varía constantemente en el tiempo.\nEl valor de arranque \\(l_0\\) óptimo es 625.42. Es decir, el año 1989 (año anterior al primero de la serie) se estima un nivel de consumo de 625.42 kg per cápita.\nsigma es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular sigma en lugar de dividir por \\(T\\) se divide por \\(T-k\\). En este caso \\(k=3\\): \\(l_0\\), \\(\\alpha\\) y sigma. Sí, sigma se considerará siempre otro parámetro estimado.\nSe obtiene un AICc \\(= 335.13\\). Si estimamos un modelo con error multiplicativo, obtendremos un AICc mayor.\nLa calidad del ajuste es buena, como evidencia el error porcentual medio del 2.2%. Además, no hay sesgo (MPE = -0.42%) y el cálculo de la predicciones por intervalo es correcto (ACF1 = 0.0045).\nComo el valor de \\(\\alpha\\) es próximo a 1, el modelo de Alisado se aproxima mucho al Ingenuo I. Por este motivo el MASE es casi igual a 1.\n\nEn el objeto etsAlimentospc la matriz etsAlimentospc$states guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluido el valor de arranque, así que es una matriz con \\(T+1\\) filas (35 en el ejemplo). Puedes ver en su última fila que el valor de \\(l_{2023}\\), el nivel del último año, vale 556.03.\n\ntail(etsAlimentospc$states, 1)\n\nTime Series:\nStart = 2023 \nEnd = 2023 \nFrequency = 1 \n            l\n[1,] 556.0329\n\n\nPor tratarse de un modelo sin pendiente ni estacionalidad, la predicción es constante en el tiempo. Recuerda que \\(\\widehat{y}_{T+h} = l_T\\). Así, la predicción para 2024 es \\(\\widehat{y}_{2024}=l_{2023}=\\) 556.03. Igualmente \\(\\widehat{y}_{2025}=l_{2023}=\\) 556.03. Todas las previsiones son iguales a \\(l_{2023}\\).\nMediante la función forecast podemos predecir el consumo de alimentos per cápita para los próximos cinco años.\n\netsAlimentospcf &lt;- forecast(etsAlimentospc,\n                            h = 5, \n                            level = 95)\netsAlimentospcf\n\n     Point Forecast    Lo 95    Hi 95\n2024       556.0329 512.7215 599.3443\n2025       556.0329 496.1726 615.8932\n2026       556.0329 483.2962 628.7696\n2027       556.0329 472.3789 639.6870\n2028       556.0329 462.7303 649.3355\n\n\nLa Figura 3 muestra la serie Consumo de alimentos, las previsiones extramuestrales que son constantes y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.\n\nautoplot(etsAlimentospcf,\n         xlab = \"\",\n         ylab = \"Kg per cápita\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 3: Consumo de alimentos per cápita (1990 - 2023) y predicción con Alisado exponencial simple\n\n\n\n\n\n\nIdentificación de valores atípicos (Intervención)\nEn el método de alisado, como en cualquier otro método, el error de ajuste contiene tanto la propia componente del error como la intervención. Si hay años donde hubo un consumo de alimentos muy inusual, por alto o por bajo, quedarán identificados en el error del modelo.\nA lo largo del curso prestaremos mucha atención al análisis del error y a la identificación de datos atípicos (o extremos).\nConsideraremos un error como atípico si su valor sin signo supera un número determinado de veces la desviación típica del error. El error de un modelo lo obtendremos con la función residuals y su desviación típica con la función sd. Un error que supera las tres desviaciones típicas es claramente atípico (la probabilidad de ocurrir del 0.3%). Si solo supera dos desviaciones típicas, no está tan claro porque la probabilidad de ocurrir es del 5%.\nVamos a ver la gráfica de los residuos de este modelo para identificar rápidamente si hay valores atípicos (Figura 4).\n\nerror &lt;- residuals(etsAlimentospc)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1990, 2024, 4)) \n\n# Creamos un variable con todos las años de la serie\nfechas &lt;- format(seq(as.Date(\"1990-01-01\"), as.Date(\"2023-01-01\"), \"year\"), \"%Y\")\n# Identificamos los años atípicos\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"2020\" \"2022\"\n\n\n\n\n\n\n\n\nFigura 4: Error + Intervención\n\n\n\n\n\nSe identifican dos posibles valores extremos, dos intervenciones, en los años 2020 y 2022 (el error está cerca de las 3 desviaciones típicas). Cada una de las intervenciones es del tipo pulso porque solo afecta un periodo de la serie. En el año 2020 el consumo de alimentos en el hogar fue muy superior a lo esperado (por encima de las tres desviaciones típicas) debido a que el confinamiento durante la pandemia aumentó las comidas en el hogar. Por contra, en 2022 el consumo de alimentos en el hogar fue inferior a lo esperado en casi tres desviaciones típicas debido a que tras la pandemia se incrementó el deseo de ocio y de comer o cenar fuera de casa, especialmente entre los jóvenes.\nUn método alternativo para obtener valores atípicos es la prueba de Tukey (véase la píldora Valores perdidos y valores atípicos). Si el error se distribuye como una normal, la prueba de Tukey identifica como atípicos los errores que superan 4.7 veces la desviación típica. Es decir, es un criterio muy conservador.\n\natipicos &lt;- tsoutliers(error)\nfechas[atipicos$index]\n\n[1] \"2020\" \"2022\"\n\n\nEn este caso, con el método de Tukey se identifican los mismos años atípicos."
  },
  {
    "objectID": "03-04-Tema4.html#hipótesis-necesarias",
    "href": "03-04-Tema4.html#hipótesis-necesarias",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "5.1 Hipótesis necesarias",
    "text": "5.1 Hipótesis necesarias\nLa aplicación de los modelos Arima requiere el cumplimiento de una serie de hipótesis. No siendo muy riguroso en su planteamiento, para aplicar un modelo ARIMA a un serie temporal esta debe ser estacionaria en media, estacionaria en varianza y ergódica; y, además, el error del modelo debe seguir una distribución normal. No vamos a definir estos conceptos con rigor y nos limitaremos a dar su noción intuitiva.\n\nUna serie temporal es estacionaria en media (o de primer orden) si su nivel se mantiene en el tiempo. Es decir, es el concepto de estacionariedad visto en el Tema 2.\nUna serie temporal, ya estacionaria en media, es estacionaria en varianza si no presenta en unos periodos más variabilidad que en otros.\nUna serie temporal es ergódica si cuanto más en el pasado está una observación, menos información aporta sobre los valores presentes. Es decir, que el pasado cada vez ayuda menos a entender el presente.\nAsumiremos que el error del modelo \\(\\varepsilon_t\\) se distribuye como una variable aleatoria normal incorrelada. En este curso no vamos a prestar atención a esta hipótesis hipótesis porque no jugará ningún papel en la elección del modelo óptimo —aquel con mejores predicciones— y se puede relajar si la serie tiene suficientes datos.\n\nEn este tema, donde analizamos series estacionarias y sin estacionalidad, todas estas hipótesis se van a cumplir y no deben preocuparnos. Primero, ya estamos trabajando con series estacionarias en media. Segundo, por su naturaleza también serán estacionarias en varianza (no trabajaremos con series financieras). Tercero, una serie estacionaria y sin estacionalidad, siempre es ergódica. Por último, en general trabajaremos con series suficientemente largas como para no ser relevante la hipótesis de normalidad.\nEn concreto, el Consumo de alimentos en el hogar y el número diario de Defunciones verifican estas hipótesis."
  },
  {
    "objectID": "03-04-Tema4.html#operador-retardo",
    "href": "03-04-Tema4.html#operador-retardo",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "5.2 Operador Retardo",
    "text": "5.2 Operador Retardo\nPara escribir correctamente los modelos Arima y la ecuación de predicción es necesario definir un nuevo concepto, el operador retardo. Se define el operador retardo \\(L\\) como \\[Ly_t = y_{t-1},\\] es decir, retrasa un periodo la serie. El operador retardo se puede aplicar \\(k\\) veces, \\[L^k y_t = y_{t-k}.\\]\nEn inglés se denomina lag operator (L) o backward shift (B). Aunque realmente este operador no será necesario hasta que no veamos las series con tendencia, vamos a empezar a trabajar con él ya para ir familiarizándonos con su uso.\nLa Tabla 1 muestra un sencillo ejemplo del efecto del operador retardo sobre la serie \\(y_t\\)\n\n\n\n\nTabla 1: Ejemplo de aplicación del operador retardo\n\n\n\n\n\n\ny\nlag1_y\nlag2_y\nlag3_y\n\n\n\n\n1\nNA\nNA\nNA\n\n\n2\n1\nNA\nNA\n\n\n3\n2\n1\nNA\n\n\n4\n3\n2\n1\n\n\n5\n4\n3\n2\n\n\n6\n5\n4\n3\n\n\n7\n6\n5\n4"
  },
  {
    "objectID": "03-04-Tema4.html#procesos-arima",
    "href": "03-04-Tema4.html#procesos-arima",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "5.3 Procesos ARIMA",
    "text": "5.3 Procesos ARIMA\nARIMA surge de combinar las siglas de tres procesos diferentes: AR de AutoRegresive (autorregresivo), I de Integrated (integración) y MA de Moving Average (medias móviles). En este tema nos vamos a centrar en el primero (AR) y el ultimo (MA). La I tiene que ver con que la serie no sea estacionaria y lo veremos en el Tema 6.\nPor tanto, propiamente vamos a ver modelos ARMA y no ARIMA.\n\nProcesos autorregresivos AR(p)\nEl modelo general autorregresivo de orden p, \\(y_t \\sim AR(p)\\) viene definido por \\[y_t=c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p} + \\varepsilon_t,\\] que usando el operador retardo queda \\[(1 - \\phi_1 L - \\phi_2 L^2 - \\ldots - \\phi_p L^p)y_t = c + \\varepsilon_t\\]\nEn este y en cualquier proceso ARIMA, al polinomio en \\(L\\) que acompaña a \\(y_t\\) se le denomina polinomio autorregresivo.\nAlgunos ejemplos son:\n\n\\(y_t \\sim AR(1): \\;\\;y_t = c + \\phi_1 y_{t-1} + \\varepsilon_t\\) o \\((1 - \\phi_1 L)y_t = c + \\varepsilon_t\\)\n\\(y_t \\sim AR(2): \\;\\;y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\varepsilon_t\\) o \\((1 - \\phi_1 L - \\phi_2 L^2)y_t = c + \\varepsilon_t\\)\n\n\n\n\n\nProcesos en medias móviles MA(q)\nEl modelo general en medias móviles de orden q, \\(y_t \\sim MA(q)\\) viene definido por \\[y_t=c + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\ldots + \\theta_q \\varepsilon_{t-q},\\] que usando el operador retardo queda \\[y_t = c + (1 + \\theta_1 L + \\theta_2 L^2 + \\ldots + \\theta_q L^q) \\varepsilon_t\\]\nEn este y en cualquier proceso ARIMA, al polinomio en \\(L\\) que acompaña a \\(\\varepsilon_t\\) se le denomina polinomio en medias móviles.\nAlgunos ejemplos son:\n\n\\(y_t \\sim MA(1): \\;\\;y_t = c + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1}\\) o \\(y_t = c + (1 + \\theta_1 L)\\varepsilon_t\\)\n\\(y_t \\sim MA(2): \\;\\;y_t=c + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2}\\) o \\(y_t = c + (1 + \\theta_1 L + \\theta_2 L^2)\\varepsilon_t\\)\n\n\n\n\n\nIntegración I(d)\nAl orden autorregresivo se le denomina \\(p\\) y al de medias móviles \\(q\\). De la misma forma, al orden de integración I se le denomina \\(d\\). Si la serie es estacionaria, entonces \\(d = 0\\), indicando que la serie no tiene que ser transformada para que sea estacionaria (0 transformaciones), porque ya lo es.\nDe esta forma, los procesos que veremos en este tema son \\(ARIMA(p, 0 ,q)\\).\n\n\n\n\nProcesos ARIMA(p, 0, q)\nEl modelo general \\(y_t \\sim ARMA(p, 0, q)\\) viene dado por \\[y_t = c + \\phi_1 y_{t-1} + \\phi_2 y_{t-2} + \\ldots + \\phi_p y_{t-p}  +\n        \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\ldots +\n        \\theta_q \\varepsilon_{t-q}+ \\varepsilon_t,\\] que usando el operador retardo queda\n\\[\\begin{equation*}\n  \\begin{array}{c@{\\qquad}c@{\\quad}ccc}\n   (1 - \\phi_1 L - \\ldots - \\phi_p L^p) y_t & = & c + (1 + \\theta_1 L + ... + \\theta_q L^q) \\varepsilon_t \\\\\n                           \\uparrow                            &   & \\uparrow \\\\\n                           AR(p)                               &   & MA(q)\n  \\end{array}\n\\end{equation*}\\]\nAlgunos ejemplos son:\n\n\\(y_t \\sim ARIMA(1, 0, 1): \\;\\;y_t = c + \\phi_1 y_{t-1} + \\theta_1 \\varepsilon_{t-1} + \\varepsilon_{t}\\) o \\((1 - \\phi_1 L)y_t = c + (1 + \\theta_1 L)\\varepsilon_t\\)\n\\(y_t \\sim ARIMA(0, 0, 0): \\;\\;y_t = c + \\varepsilon_{t}\\). Si \\(c = 0\\), a este proceso se le denomina ruido blanco."
  },
  {
    "objectID": "03-04-Tema4.html#aproximación-de-box-jenkins",
    "href": "03-04-Tema4.html#aproximación-de-box-jenkins",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "5.4 Aproximación de Box-Jenkins",
    "text": "5.4 Aproximación de Box-Jenkins\nLa Figura 5 muestra el flujo de procesos asociado a la modelización por modelos ARIMA, con cuatro grandes áreas:\n\nIdentificación, que requiere primero transformar la serie para que sea estacionaria y ergódica (no aplicable en este tema), para después identificar los valores de p y q.\nHaremos uso de algunas funciones de autoidentificación que nos ayudaran en este punto.\nEstimación de los parámetros del modelo, incluidas las variables de intervención. El método usual de estimación de los parámetros es por máxima verosimilitud.\nValidación de las hipótesis sobre el modelo. Analizaremos que no es necesaria más intervención y veremos la pertinencia de los parámetros del modelo (bien contrastando su significatividad o bien por alguna regla más sencilla).\nSi la validación no se pasa, puede ser necesario volver al proceso inicial y realizar una nueva identificación del modelo.\nPredicción e interpretación del modelo válido. Si las predicciones se alejan de los valores reales más de lo esperado o presentan sesgo, puede ser necesario identificar y estimar un nuevo modelo.\n\n\n\n\n\n\n\nFigura 5: Esquema de la aproximación de Box-Jenkins a la modelización de procesos ARIMA\n\n\n\n\nIdentificación automática\nEl paquete forecast dispone de la función auto.arima() que localiza el mejor modelo basándose en el AIC corregido para pequeñas muestras (AICc), el mismo criterio que usa la función ets para localizar el mejor modelo. Básicamente el algoritmo consiste:\n\nEstiman una serie de modelos Arima básicos predeterminados\nUsar el criterio AICc para seleccionar el mejor de estos modelos.\nA partir del modelo seleccionado, se hacen pequeñas variaciones modificando en una unidad p y q y añadiendo/quitando la constante y se vuelve a seleccionar el mejor de los nuevos modelos.\nSe repite el paso 3 hasta que no se puede mejorar el AICc.\n\nCuando usemos la función auto.arima, debemos tener cuenta que:\n\nSi se desea hacer una búsqueda exhaustiva entre todos los modelos posibles, se debe usar el argumento stepwise = FALSE.\nSi se desea que el cálculo de AICc sea exacto (por defecto para ganar tiempo calcula una aproximación), se debe usar el argumento approximation = FALSE.\nSi se desea ver para todos los modelos analizados y su valor de AICc, se debe incluir el argumento trace = TRUE.\n\nNo hay que fiarse ciegamente de los resultados de esta función, pero ayuda en la identificación. En concreto, la función auto.arima tiende a sobreparametrizar los modelos y es muy recomendable ayudarla indicando si la serie es estacionaria o no y la posible intervención."
  },
  {
    "objectID": "03-04-Tema4.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita-2",
    "href": "03-04-Tema4.html#ejemplo-de-aplicación-a-la-serie-consumo-alimentarios-en-el-hogar-per-cápita-2",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "5.5 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita",
    "text": "5.5 Ejemplo de aplicación a la serie consumo alimentarios en el hogar per cápita\nVamos a usar el método de alisado exponencial simple para predecir la serie Consumo de alimento en el hogar (véase panel a) de la Figura 1.\nEl pico en el año 2020 se debe al aumento del consumo de alimentos en el hogar causado por el periodo de confinamiento por la Covid-19 (marzo a junio) y el aumento del trabajo desde casa. La aparente caída en 2022 y 2023 se debe a que como efecto rebote, los españoles ahora comemos y cenamos más fuera del hogar.3\n\nEstacionariedad de la serie\nLa Figura 1 muestra que la serie original ya es estacionaria. Si hay dudas sobre la estacionariedad en media de una serie, puedes usar la función ndiffs que si vale cero confirma que la serie es estacionaria. Una vez más, no te fíes ciegamente de esta función y decide sobre la estacionariedad de una serie usando varios criterios.\n\nndiffs(alimentospc)\n\n[1] 0\n\n\n\n\nIdentificación y Estimación\nUn proceso ARIMA queda identificado por los valores de \\(p\\), \\(d\\) y \\(q\\). Como la serie es estacionaria, sabemos que \\(d = 0\\). Vamos ahora a identificar los valores de \\(p\\) y \\(q\\). Este es el proceso más difícil y para simplificar las cosas vamos a ayudarnos de la función auto.arima, fijando el parámetro d = 0.\nAdemás, con el método de Alisado se han identificado dos posibles valores extremos, dos intervenciones, en los años 2020 y 2022 (el error casi alcanza las 3 desviaciones típicas). Vamos a incorporar esta información en nuestro modelo. Para ello crearemos una variable ficticia asociada a cada intervención, que denominaremos d2020 y d2022. La forma de definir la variable ficticia asociada a un pulso consiste en crear una variable de ceros, excepto para el periodo atípico en que la variable valdrá 1.\n\nd2020 &lt;- 1* (time(alimentospc) == 2020)\nd2022 &lt;- 1* (time(alimentospc) == 2022)\n\nPor último, incluimos las dos variables ficticias en la autoidentificación.\n\nauto.arima(alimentospc,\n           d = 0,\n           xreg = cbind(d2020, d2022),\n           trace = TRUE)\n\n\n Regression with ARIMA(2,0,2) errors : Inf\n Regression with ARIMA(0,0,0) errors : 312.8244\n Regression with ARIMA(1,0,0) errors : 294.6787\n Regression with ARIMA(0,0,1) errors : 301.2503\n Regression with ARIMA(0,0,0) errors : 539.8936\n Regression with ARIMA(2,0,0) errors : 296.3297\n Regression with ARIMA(1,0,1) errors : 295.8126\n Regression with ARIMA(2,0,1) errors : 299.0078\n Regression with ARIMA(1,0,0) errors : Inf\n\n Best model: Regression with ARIMA(1,0,0) errors \n\n\nSeries: alimentospc \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1  intercept    d2020     d2022\n      0.8437   621.3033  56.3963  -25.8095\ns.e.  0.1165    15.9562  11.5793   11.6058\n\nsigma^2 = 260:  log likelihood = -141.27\nAIC=292.54   AICc=294.68   BIC=300.17\n\n\nAl poner el argumento trace = TRUE podemos ver todos los modelos que la función ha considerado. La identificación automática sugiere un proceso AR(1) con constante (intercept) por ser el que menor AICc tiene. Por tanto, ha estimado los coeficientes \\(\\phi_1\\) y \\(\\mu\\) (que denomina ar1 e intercept) y los coeficientes de la intervención (d2020 y d2022). ¿Pero son realmente relevantes (significativos) estos coeficientes?\nUna forma rápida, aunque imprecisa, de determinar si un coeficiente es relevante (significativo) es compararlo con su error estándar (standard error, s.e). Si el coeficiente es mayor que dos veces su error estándar, hay evidencia de que es significativo. En la salida de R, en la tabla Coefficients tienes en la primera fila el nombre de los coeficientes; su valor estimado aparece en la segunda fila de la tabla; y los errores estándar en la tercera fila (precedida por s.e.). Todos los coeficientes estimados superan las dos desviaciones estándar y parece que son significativos.\nAhora vamos a estimar el modelo identificado. Aunque existe la función arima de stats, vamos a usar la función Arima de la librería forecast por ser más versátil. El argumento order indica los valores de (p, d, q) como un vector y el argumento lógico include.constant indica si se desea incluir la constante \\(c\\) en el modelo.4\n\nariAlimentospc &lt;- Arima(alimentospc, \n                        order = c(1, 0, 0),\n                        include.constant = TRUE,\n                        xreg = cbind(d2020, d2022))\nariAlimentospc\n\nSeries: alimentospc \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1  intercept    d2020     d2022\n      0.8437   621.3033  56.3963  -25.8095\ns.e.  0.1165    15.9562  11.5793   11.6058\n\nsigma^2 = 260:  log likelihood = -141.27\nAIC=292.54   AICc=294.68   BIC=300.17\n\n\nVamos a ver la gráfica de los residuos de este proceso para determinar si hay más valores extremos (Figura 6).\n\nerror &lt;- residuals(ariAlimentospc)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1990, 2024, 4)) \n\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"2023\"\n\n\n\n\n\n\n\n\nFigura 6: Error + Intervención\n\n\n\n\n\nSe identifican otro posible valor extremo para el año 2023 (el error supera las 2.5 desviaciones típicas). Parece que, tras la pandemia, los españoles tenemos más ganas de disfrutar de nuestro ocio y salimos mas a comer y cenar fuera, reduciendo el consumo de alimentos del hogar. Vamos a crear una variable para 2023. Además, si aplicamos auto.arima añadiendo esta nueva intervención, la identificación se mantiene.\n\nd2023 &lt;- 1* (time(alimentospc) == 2023)\n\nariAlimentospc &lt;- Arima(alimentospc, \n                        order = c(1, 0, 0),\n                        include.constant = TRUE,\n                        xreg = cbind(d2020, d2022, d2023))\nariAlimentospc\n\nSeries: alimentospc \nRegression with ARIMA(1,0,0) errors \n\nCoefficients:\n         ar1  intercept    d2020     d2022     d2023\n      0.6779   633.7288  55.2611  -62.9218  -74.1954\ns.e.  0.1217     6.1392   9.8598   12.0579   14.7748\n\nsigma^2 = 164:  log likelihood = -132.55\nAIC=277.09   AICc=280.2   BIC=286.25\n\n\nSi se repite el análisis de intervención, aparece otro valor extremo en 1999, con un consumo inferior al esperado. Sin embargo, para este año no se identifica ninguna razón para la caída del consumo por lo que damos el modelo previo como definitivo. Toda intervención debe tener detrás una causa identificable, si no puede ser fruto de simple azar.\n\n\nValidación\nLa regla de que un coeficiente es relevante si supera dos veces su desviación típica es muy sencilla de aplicar, pero poco rigurosa. Para ver si un coeficiente es significativo (relevante) debemos realizar la prueba de significatividad correspondiente, obtener el valor de p y compararlo con el nivel de significatividad fijado (usualmente el 5%). Todo esto lo hace la función coeftest del paquete lmtest.\n\ncoeftest(ariAlimentospc)\n\n\nz test of coefficients:\n\n           Estimate Std. Error  z value  Pr(&gt;|z|)    \nar1         0.67790    0.12175   5.5680 2.577e-08 ***\nintercept 633.72878    6.13923 103.2262 &lt; 2.2e-16 ***\nd2020      55.26113    9.85985   5.6047 2.087e-08 ***\nd2022     -62.92176   12.05786  -5.2183 1.806e-07 ***\nd2023     -74.19542   14.77481  -5.0218 5.120e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTanto \\(\\phi_1\\) como el intercepto \\(\\mu\\) y las variables de intervención son significativas porque sus valores de p (columna Pr(&gt;|z|)) son menores que 0.05, incluso menores que 0.01.\nConsideraremos que \\(alimentospc_t \\sim ARIMA(1,0,0)\\) con constante e intervención.\n\n\nMedidas de error\nLa precisión del ajuste es 11.8 kg per cápita (RMSE) y el error absoluto porcentual medio (MAPE) es 1.3%. No hay sesgo y los intervalos de confianza de las predicciones los vamos a considerar correctos.\n\naccuracy(ariAlimentospc)\n\n\n\n               ME  RMSE  MAE MPE MAPE MASE ACF1\nTraining set 0.25 11.83 8.33   0 1.32 0.58  0.1\n\n\n\n\nInterpretación del modelo\nEl modelo teórico identificado es \\[(1 - \\phi_1 L) alimentospc_t = c +  \\gamma_1 d2020 + \\gamma_2 d2022 + \\gamma_3 d2023 + \\varepsilon_t,\\] que desarrollando queda \\[alimentospc_t = c + \\phi_1 alimentospc_{t-1} + \\gamma_1 d2020 + \\gamma_2 d2022 + \\gamma_3 d2023 + \\varepsilon_t.\\]\nFinalmente, el modelo estimado es \\[\\widehat{alimentospc}_t = 204.1 + 0.68 \\cdot alimentospc_{t-1} +\\] \\[55.3\\cdot d2020 - 62.9\\cdot d2022 - 74.2\\cdot d2023.\\]\n\n\n\n\n\n\nLa constante del modelo teórico y la media del modelo estimado\n\n\n\nEl término contante \\(\\mu\\) que estima R no es el valor “c” que hemos visto en la teoría. Para convertir la contante estimada por R en “c” hemos de multiplicarla por el polinomio autorregresivo. En este caso, \\[c = (1 - \\phi_1)\\cdot \\mu = (1 - 0.67790) \\cdot 633.72878= 204.124\\]\n\n\nCada año el consumo de alimentos per cápita en el hogar es 204 kilos más un 68% del consumo del año pasado.\nEn 2020, debido al efecto combinado del periodo de confinamiento entre marzo y junio y el incremento del trabajo en casa, se produjo un fuerte aumento del consumo de alimentos en el hogar, estimado en 55 kg per cápita. Por el contrario, en 2022 y 2023 se redujo en 63 y 74 kg, respectivamente, por el aumento del ocio.\nSi el incremento en las salidas a comer y cenar fuera se mantiene, la caída en el consumo de alimentos en el hogar se hará permanente y debemos pensar en un cambio de nivel más que en la presencia de dos intervenciones independientes.\n\n\nPredicciones de la serie\nComo hemos incluido tres variables ficticias en el ajuste, de cara a predecir el consumo de alimentos hemos de indicar cuales serán los valores futuros para estas variables. En el caso de asumir que el consumo de alimentos en el hogar va a volver a sus valores prepandemia, el valor futuro de las variables intervención será cero. Estamos asumiendo que las causas detrás de estas intervenciones no se espera que se repitan en el futuro.\nEn R esto se hace incluyendo en el comando forecast el argumento xreg = cbind(rep(0, 5), rep(0, 5), rep(0, 5)) que añade cinco ceros por cada variable de intervención porque la predicción va a ser a cinco años vista.\n\nariAlimentospcf &lt;- forecast(ariAlimentospc, \n                            h = 5, \n                            level = 95,\n                            xreg = cbind(rep(0, 5), rep(0, 5), rep(0, 5)))\nariAlimentospcf\n\n     Point Forecast    Lo 95    Hi 95\n2024       630.9756 605.8746 656.0765\n2025       631.8624 601.5375 662.1873\n2026       632.4635 600.0188 664.9083\n2027       632.8711 599.4973 666.2448\n2028       633.1473 599.3552 666.9395\n\n\nAhora bien, si pensamos que la caída del consumo de alimentos en el hogar por un aumento del ocio es un efecto permanente, podemos actualizar nuestras previsiones poniendo el valor de 1, en lugar de 0, como valores futuros de d2022 o de d2023, según creamos que el efecto va a ser mayor o menor.\n\nariAlimentospcfb &lt;- forecast(ariAlimentospc, \n                             h = 5, \n                             level = 95,\n                             xreg = cbind(rep(0, 5), rep(0, 5), rep(1, 5)))\nariAlimentospcfb\n\n     Point Forecast    Lo 95    Hi 95\n2024       556.7802 531.6792 581.8811\n2025       557.6670 527.3420 587.9919\n2026       558.2681 525.8234 590.7129\n2027       558.6757 525.3019 592.0494\n2028       558.9519 525.1598 592.7441\n\n\nObserva que estas últimas predicciones son menores que las obtenidas previamente. Podemos ver gráficamente el efecto sobre las predicciones de cada supuesto (véase la Figura 7).\n\nautoplot(alimentospc, \n         series = \"Alimentos\",\n         xlab = \"\",\n         ylab = \"Kg per cápita\",\n         main = \"\",\n         PI = FALSE,\n         ylim = c(300, 700)) +\n  autolayer(ariAlimentospcf,  PI = FALSE, series = \"Aumento ocio desaparece\") +\n  autolayer(ariAlimentospcfb, PI = FALSE, series = \"Aumento ocio se mantiene\") +\n  scale_x_continuous(breaks= seq(1990, 2028, 4)) +\n  scale_colour_discrete(limits=c(\"Alimentos\", \"Aumento ocio desaparece\", \n                                 \"Aumento ocio se mantiene\")) +\n  labs(colour=\"Predicciones\") + \n  theme(legend.position=c(0.2,0.2))\n\n\n\n\n\n\n\nFigura 7: Consumo de alimentos y predicción\n\n\n\n\n\n\n\n\n\nComparación entre modelos\nVamos a comparar de forma sencilla la calidad de ajuste de los cuatro métodos empleados considerando el MAPE.\n\nIngenuo I: \\(2.28\\%\\)\nMedia simple: \\(3.00\\%\\)\nMedia móvil: \\(2.97\\%\\)\nETS: \\(2.24\\%\\) - ETS(A,N,N), \\(\\alpha = 0.95\\)\nARIMA: \\(1.32\\%\\) - ARIMA(1,0,0) con constante e intervención\n\nLos modelos un poco más sofisticados (Alisado y Arima) muestran una mayor calidad de ajuste que los métodos sencillos. Arima es el más preciso al capturar la intervención. Alisado, prácticamente tiene la misma calidad de ajuste que el método Ingenuo I.\nFinalmente, vamos a comparar gráficamente las predicciones (véase la Figura 8).\n\nautoplot(alimentospc, \n         series = \"Alimentos\",\n         xlab = \"\",\n         ylab = \"Kg per cápita\",\n         main = \"\") +\n  autolayer(mediaAlimentospc, series=\"Media\", PI = FALSE) +\n  autolayer(naiveAlimentospc, series=\"Ingenuo\", PI = FALSE) +\n  autolayer(mmAlimentospc, series=\"Media móvil\", PI = FALSE) +\n  autolayer(etsAlimentospcf, series=\"Alisado\", PI = FALSE) +\n  autolayer(ariAlimentospcfb, series=\"ARIMA\", PI = FALSE) +\n  scale_colour_discrete(limits=c(\"Alimentos\", \"Media\", \"Ingenuo\",\n                                 \"Media móvil\", \"Alisado\", \"ARIMA\")) +\n  labs(colour=\"Métodos\") + \n  theme(legend.position=c(0.1,0.3))\n\n\n\n\n\n\n\nFigura 8: Consumo de alimentos y predicción por cinco métodos\n\n\n\n\n\nLas predicciones por el método Ingenuo I, Alisado y Arima son las más bajas. La dos primeras casi coinciden porque el parámetro de alisado \\(\\alpha = 0.95\\) está próximo al valor de 1, caso en que ambos métodos son equivalentes.\nArima es la única que no muestra predicicones constantes.\nLas predicciones más elevadas las ofrecen el método de la media y el método de la Media móvil da unas previsiones intermedias."
  },
  {
    "objectID": "03-04-Tema4.html#método-ingenuo-i",
    "href": "03-04-Tema4.html#método-ingenuo-i",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "6.1 Método Ingenuo I",
    "text": "6.1 Método Ingenuo I\nEmpezamos por en método más sencillo, que usa el último dato disponible como predicción. Aunque se ha pedido una predicción para los próximos 28 días (1 de enero a 28 de enero de 2024), solo se muestra la primera semana.\n\nnaiveDefunciones &lt;- naive(defunciones, \n                        h = 28,\n                        level = 95)\nsummary(naiveDefunciones)\n\n\n\n\nForecast method: Naive method\n\nModel Information:\nCall: naive(y = defunciones, h = 7, level = 95) \n\nResidual sd: 68.5753 \n\nError measures:\n                    ME     RMSE      MAE        MPE     MAPE MASE       ACF1\nTraining set 0.1893004 68.57527 55.47051 -0.1493542 4.605408    1 -0.2052727\n\nForecasts:\n    Point Forecast    Lo 95    Hi 95\n731           1528 1393.595 1662.405\n732           1528 1337.923 1718.077\n733           1528 1295.204 1760.796\n734           1528 1259.190 1796.810\n735           1528 1227.461 1828.539\n736           1528 1198.776 1857.224\n737           1528 1172.398 1883.602\n\n\nEl método Ingenuo I predice 1528 defunciones de forma constante. Los criterios de calidad de ajuste muestran un error medio medido con el RMSE de 69 defunciones (o de 55 si usamos el MAE) y un error porcentual del 4.6%. El método no presenta sesgo (MPE = -0.15%) y las previsiones por intervalos no están correctamente calculadas (ACF1 = -0.21) y no serán fiables."
  },
  {
    "objectID": "03-04-Tema4.html#método-de-la-media-móvil",
    "href": "03-04-Tema4.html#método-de-la-media-móvil",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "6.2 Método de la media móvil",
    "text": "6.2 Método de la media móvil\nSeguimos con el método de la media móvil, que aplicaremos con una orden elevado (10 semanas) para suavizar lo más posible la serie.\n\nmmDefunciones &lt;- mmf(defunciones, \n                     r = 70,\n                     h = 28)\nsummary(mmDefunciones)\n\n\n\n\nForecast method: Moving average\n\nModel Information:\nNULL\n\nError measures:\n                    ME     RMSE      MAE        MPE     MAPE    MASE      ACF1\nTraining set -3.795584 112.7603 87.60515 -0.9582865 7.249869 1.57931 0.8031665\n\nForecasts:\n    Point Forecast    Lo 80   Hi 80    Lo 95    Hi 95\n731       1230.914 1086.148 1375.68 1009.347 1452.482\n732       1230.914 1086.148 1375.68 1009.347 1452.482\n733       1230.914 1086.148 1375.68 1009.347 1452.482\n734       1230.914 1086.148 1375.68 1009.347 1452.482\n735       1230.914 1086.148 1375.68 1009.347 1452.482\n736       1230.914 1086.148 1375.68 1009.347 1452.482\n737       1230.914 1086.148 1375.68 1009.347 1452.482\n\n\nEl método de la media móvil predice 1231 defunciones de forma constante. Los criterios de calidad de ajuste muestran un error (RMSE) de 113 defunciones (o de 88 si usamos MAE) y un error porcentual del 7.2%. El método no presenta sesgo (MPE = -0.96%) y las previsiones por intervalos no están correctamente calculadas (ACF1 = 0.80) y no serán fiables."
  },
  {
    "objectID": "03-04-Tema4.html#método-de-alisado",
    "href": "03-04-Tema4.html#método-de-alisado",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "6.3 Método de Alisado",
    "text": "6.3 Método de Alisado\nVamos a localizar el mejor modelo con la función ets. Recuerda que en este método la función de ajuste ets no predice y hay que usar la función forecast.\n\netsDefunciones &lt;- ets(defunciones, \n                      model = \"ZNN\")\nsummary(etsDefunciones)\n\nETS(M,N,N) \n\nCall:\nets(y = defunciones, model = \"ZNN\")\n\n  Smoothing parameters:\n    alpha = 0.3591 \n\n  Initial states:\n    l = 1405.5281 \n\n  sigma:  0.0536\n\n     AIC     AICc      BIC \n10911.46 10911.49 10925.24 \n\nTraining set error measures:\n                    ME     RMSE     MAE        MPE     MAPE      MASE      ACF1\nTraining set 0.4817552 65.35745 52.3533 -0.2084728 4.345772 0.9438043 0.2428118\n\n\n\netsDefuncionesf &lt;- forecast(etsDefunciones, \n                            h = 28,\n                            level = 95)\netsDefuncionesf\n\n\n\n    Point Forecast    Lo 95    Hi 95\n731       1531.814 1370.881 1692.747\n732       1531.814 1360.791 1702.837\n733       1531.814 1351.261 1712.367\n734       1531.814 1342.206 1721.421\n735       1531.814 1333.562 1730.066\n736       1531.814 1325.275 1738.353\n737       1531.814 1317.306 1746.322\n\n\nEl método de Alisado exponencial simple ajusta un modelo con error multiplivativo y donde el parámetro \\(\\alpha = 0.36\\) indica que el nivel de la serie va cambiando poco a poco con el tiempo. Este cambio posiblemente esté asociado con el aumento del número de defunciones en invierno y verano, que persiste aunque trabajemos con la serie corregida por temperatura.\nLa predicción es de 1532 defunciones diarias. Los criterios de calidad de ajuste muestran un RMSE de 65 defunciones (o de 52 si usamos MAE) y un error porcentual del 4.3%. El método no presenta sesgo (MPE = -0.21%) y las previsiones por intervalos no están correctamente calculadas (ACF1 = 0.24).\nVamos a usar el error del método de Alisado para identificar los días donde el número de defunciones fue inusual por alto o por bajo. Dado el elevado número de observaciones, usaremos como criterio superar las 3 desviaciones típicas. Sin embargo, incluso para un nivel de confianza del 99.7%, con 730 datos cabe esperar que dos errores superen este umbral sin realmente corresponder a días atípicos.\n\nerror &lt;- residuals(etsDefunciones)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, 3)*sderror, \n             colour = c(\"red\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1990, 2024, 4)) \n\n# Creamos un variable con todos las días de la serie\nfechas &lt;- format(seq(as.Date(\"2022-1-1\"), as.Date(\"2023-12-31\"), \"day\"), \"%Y-%m-%d\")\n# Identificamos los días atípicos\nfechas[abs(error) &gt; 3 * sderror]\n\n[1] \"2022-08-15\" \"2023-03-26\"\n\n\n\n\n\n\n\n\nFigura 10: Error + Intervención\n\n\n\n\n\nEn la Figura 10 se identifica dos días atípicos, el 15 de agosto de 2022 y el 26 de marzo de 2023, pero pueden deberse a simple azar dado que en esos días no pasó nada excepcional. Además, la prueba de Tukey no identifica ningún valor atípico.\n\natipicos &lt;- tsoutliers(error)\nfechas[atipicos$index]\n\ncharacter(0)"
  },
  {
    "objectID": "03-04-Tema4.html#modelos-arima-1",
    "href": "03-04-Tema4.html#modelos-arima-1",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "6.4 Modelos ARIMA",
    "text": "6.4 Modelos ARIMA\n\nIdentificación y Estimación\nVamos a ayudarnos de la función auto.arima, fijando el parámetro d = 0 dado que la serie es estacionaria.\n\nauto.arima(defunciones,\n           d = 0)\n\nSeries: defunciones \nARIMA(5,0,0) with non-zero mean \n\nCoefficients:\n         ar1     ar2     ar3     ar4     ar5       mean\n      0.6619  0.0280  0.0226  0.0514  0.1890  1243.4269\ns.e.  0.0363  0.0438  0.0438  0.0440  0.0366    47.3757\n\nsigma^2 = 3976:  log likelihood = -4058.96\nAIC=8131.91   AICc=8132.07   BIC=8164.06\n\n\nLa identificación automática sugiere un complejo proceso ARIMA(5, 0, 0) con constante (denominada mean en este caso porque no hay intervención) y por tanto ha estimado los coeficientes \\(\\phi_1\\) a \\(\\phi_5\\) y \\(\\mu\\). Además, observamos que solo los coeficientes \\(\\phi_1\\) y \\(\\phi_5\\) son significativos.\nPodemos usar el modelo identificado para predecir y no darle más vueltas. ¿Pero qué sentido tiene que las defunciones de hace 5 días sean relevantes para predecir las defunciones futuras, pero no lo sean las de hace 2, 3 o 4 días? Quizás el modelo está muy sobreidentificado y posiblemente baste un proceso AR(2) para obtener buenas predicciones. Se ha probado con las especificaciones AR(4) hasta AR(2) y se ha comprobado que esta última es la más adecuada por tener todos los coeficientes significativos y una adecuada calidad de ajuste.\n\nariDefunciones &lt;- Arima(defunciones, \n                        order = c(2, 0, 0),\n                        include.constant = TRUE)\nariDefunciones\n\nSeries: defunciones \nARIMA(2,0,0) with non-zero mean \n\nCoefficients:\n         ar1     ar2       mean\n      0.7498  0.1573  1227.8049\ns.e.  0.0365  0.0367    25.8845\n\nsigma^2 = 4355:  log likelihood = -4093.47\nAIC=8194.94   AICc=8195   BIC=8213.31\n\n\nParece que todos los coeficiente son significativos.\nVamos a ver la gráfica de los residuos de este proceso para identificar rápidamente si hay valores extremos (Figura 11).\n\nerror &lt;- residuals(ariDefunciones)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  geom_point() +\n  scale_x_continuous(breaks= seq(1990, 2024, 4)) \n\nfechas[abs(error) &gt; 3 * sderror]\n\n[1] \"2023-03-26\"\n\n\n\n\n\n\n\n\nFigura 11: Error + Intervención\n\n\n\n\n\nHay solo un día atípico, el 26 de marzo de 2023, donde el error supera las 3 desviaciones típicas sin una causa conocida. Esto se puede dar por simple azar, como indicamos al analizar el error de la serie por el método de Alisado. Tucky no identifica ningún valor atípico. Por tanto, vamos a considerar que no hay intervención y ya tenemos el modelo identificado.\n\n\nValidación\nUsamos la función coeftest para contrastar la significatividad de los coeficientes del modelo. Obtenemos que para un nivel de significatividad del 5% todos los coeficientes son significativos.\n\ncoeftest(ariDefunciones)\n\n\nz test of coefficients:\n\n            Estimate Std. Error z value  Pr(&gt;|z|)    \nar1       7.4981e-01 3.6494e-02 20.5461 &lt; 2.2e-16 ***\nar2       1.5728e-01 3.6678e-02  4.2881 1.802e-05 ***\nintercept 1.2278e+03 2.5884e+01 47.4341 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\nMedidas de error\nEl error de ajuste es de 66 defunciones (RMSE) o un 4.4% (MAPE). No hay sesgo y los intervalos de confianza de las predicciones son correctos.\n\naccuracy(ariDefunciones)\n\n\n\n                ME  RMSE   MAE   MPE MAPE MASE  ACF1\nTraining set -0.43 65.85 52.95 -0.33  4.4 0.95 -0.02\n\n\n\n\nInterpretación del modelo\nEl modelo teórico identificado es \\[(1 - \\phi_1 L - \\phi_2 L^2) defunciones_t = c + \\varepsilon_t \\] que desarrollando queda \\[defunciones_t = c + \\phi_1 defunciones_{t-1} + \\phi_2 defunciones_{t-2} + \\varepsilon_t.\\] Finalmente, el modelo estimado es \\[\\widehat{defunciones}_t = 114.1 + 0.75 \\cdot defunciones_{t-1} + 0.16 \\cdot defunciones_{t-2}.\\] La constante c se ha obtenido como \\((1 - \\phi_1 - \\phi_2)\\mu = (1 - 0.7498 - 0.1573) \\cdot 1227.8049\\) \\(= 114.0631\\).\nCada día el número de defunciones es igual a 114 más un 75% de la defunciones del día previo más un 16% de las de hace dos días.\n\n\nPredicciones\nPodemos predecir el número de defunciones para las primeras 4 semanas de 2024 (aunque solo mostramos la primera).\n\narimaDefuncionesf &lt;- forecast(ariDefunciones, \n                              h = 28,\n                              level = 95)\narimaDefuncionesf\n\n\n\n    Point Forecast    Lo 95    Hi 95\n731       1504.982 1375.644 1634.320\n732       1482.847 1321.189 1644.505\n733       1462.630 1276.102 1649.159\n734       1443.990 1238.997 1648.984\n735       1426.834 1207.364 1646.305\n736       1411.039 1180.013 1642.065\n737       1396.497 1156.112 1636.883\n\n\nObserva como en este caso, aunque la serie es estacionaria el número de defunciones previsto disminuye lentamente."
  },
  {
    "objectID": "03-04-Tema4.html#comparación-entre-métodos.",
    "href": "03-04-Tema4.html#comparación-entre-métodos.",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "6.5 Comparación entre métodos.",
    "text": "6.5 Comparación entre métodos.\nVamos a finalizar este ejemplo comparando primero la calidad de ajuste de los cuatro modelos utilizados para estudiar la serie de Defunciones, y después las predicciones.\n\nComparación de los criterios de calidad de ajuste\nLa siguiente table recoge los criterios de calidad de ajuste obtenidos para cada método.\n\n\n               ME   RMSE   MAE   MPE MAPE MASE  ACF1\nIngenuo I    0.19  68.58 55.47 -0.15 4.61 1.00 -0.21\nMedia móvil -3.80 112.76 87.61 -0.96 7.25 1.58  0.80\nAlisado      0.48  65.36 52.35 -0.21 4.35 0.94  0.24\nArima       -0.43  65.85 52.95 -0.33 4.40 0.95 -0.02\n\n\nPor calidad de ajuste, los métodos de Alisado y Arima con comparables, ambos con un RMSE cercano a las 65 defunciones y un MAPE de 4.4%. El método Ingenuo I solo se muestra algo inferior en calidad y el método de la media móvil es claramente muy inferior. Sin embargo, solo el método Arima ofrece predicciones por intervalo correctamente calculadas.\nRecordemos que un mejor ajuste no indica una mejor predicción. Habrá que esperar hasta el siguiente tema para ver cual de los métodos ofrece las mejores predicciones.\n\n\nComparación de las predicciones\nLa Figura 12 muestra las predicciones para las próximas cuatro semanas de estos métodos.\n\nautoplot(defunciones, \n         series = \"Defunciones\",\n         xlab = \"\",\n         ylab = \"\",\n         main = \"\",\n         ylim = c(900, 1600)) +\n  xlim(600, 750) +\n  autolayer(naiveDefunciones, series=\"Ingenuo I\", PI = FALSE) +\n  autolayer(mmDefunciones, series=\"Media móvil (r = 70)\", PI = FALSE) +\n  autolayer(etsDefuncionesf, series=\"Alisado\", PI = FALSE) +\n  autolayer(arimaDefuncionesf, series=\"Arima\", PI = FALSE) +\n  scale_colour_discrete(limits=c(\"Defunciones\", \"Ingenuo I\", \"Media móvil (r = 70)\", \n                                 \"Alisado\", \"Arima\")) +\n  labs(colour=\"Métodos\") + \n  theme(legend.position=c(0.13, 0.75))\n\n\n\n\n\n\n\nFigura 12: Defunciones y predicción\n\n\n\n\n\nSolo las predicciones del método Arima muestan una progresiva caída en las defunciones para las cuatro próximas semanas. El método Ingenuo I y Alisado ofrecen las predicciones más elevadas, mientras que el método de la Media móvil de alto orden ofrece las predicciones más bajas."
  },
  {
    "objectID": "03-04-Tema4.html#footnotes",
    "href": "03-04-Tema4.html#footnotes",
    "title": "Series sin tendencia ni estacionalidad",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEl cálculo de la media móvil se hace mediante la función filter (librería stats), que calcula la media móvil simple. Realmente la función filter calcula una media ponderada, tiene como primer argumento la serie y el segundo argumento son los pesos de la media móvil, es decir \\(1/r\\) repetido \\(r\\) veces o rep(1/r, r). El tercer argumento indica si la media es centrada side = 2 (como la usada en el método de descomposición de la media móvil visto en el Tema 2) o hacia atrás side = 1.↩︎\nNo vamos a definir en detalle que es la función de verosimilitud. Basta saber que básicamente es la suma de los errores al cuadrado.\n↩︎\nSegún el INE, el gasto monetarios per cápita de los españoles en restauración y hoteles cayó ligeramente en 2018 y 2019, y retrocedió un 40% en 2020 a causa de la pandemia. Desde entonces, el gasto per cápita en esta partida ha crecido año tras año: un 30.7% en el 2021 y 2022 y un 13.6% en el 2023.↩︎\nLa función Arima denomina a la constante de varias formas. Si la serie es estacionaria y no hay intervención, la denomina mean. Si es estacionaria y hay intervención (nuestro caso), la denomina intercept. Si la serie no es estacionaria, la denomina drift.↩︎"
  },
  {
    "objectID": "03-02-Tema2.html#definición",
    "href": "03-02-Tema2.html#definición",
    "title": "Series Temporales. Definición y componentes",
    "section": "1.1 Definición",
    "text": "1.1 Definición\nUna serie temporal es una variable medida secuencialmente en el tiempo a intervalos equiespaciados.\nLa representaremos por,\n\\[\\{y_t\\}_{t=1}^T=\\{y_1,y_2,\\ldots,y_T\\}.\\]\nLa serie aparece indexada por su fechado \\(t\\) y el valor \\(T\\) hará siempre referencia a la fecha del último dato.\nEl fechado varía en su frecuencia, que puede ser anual (baja frecuencia), trimestral, mensual, semanal, diario (alta frecuencia) o disponer casi de un continuo de datos."
  },
  {
    "objectID": "03-02-Tema2.html#proceso-generador-de-datos",
    "href": "03-02-Tema2.html#proceso-generador-de-datos",
    "title": "Series Temporales. Definición y componentes",
    "section": "1.2 Proceso generador de datos",
    "text": "1.2 Proceso generador de datos\nEl proceso generador de los datos de una serie temporal es en general desconocido, pero se puede aproximar por un modelo estadístico. Estos modelos se pueden clasificar en tres grandes familias según su naturaleza: deterministas, estocásticos y mixtos\nEn ocasiones las series temporales pueden ser modeladas de forma determinista ajustando los datos a funciones matemáticas: \\[y_t=f(t)+\\varepsilon_t.\\]\nSi las observaciones cercanas en el tiempo tienden a estar (cor)relacionadas, se puede aprovechar esta dependencia para entender la serie y predecirla con un modelo estocástico: \\[y_t=f(y_{t-1},y_{t-2},\\ldots)+\\varepsilon_t.\\]\nA veces, ambas situaciones se dan simultáneamente (modelos mixtos): \\[y_t=f(t,y_{t-1},y_{t-2},\\ldots)+\\varepsilon_t.\\]\nLa Figura 1 muestra un ejemplo gráfico de estos tres modelos estadísticos. La complejidad de la serie es mayor en los modelos con parte estocástica.\n\n\n\n\n\n\n\n\nFigura 1: Ejemplos de procesos generadores\n\n\n\n\n\nEn este curso se asumirá en todo momento que la serie temporal tiene una componente estocástica. Para series deterministas puedes usar los modelos de regresión que has visto en Previsión con Datos Transversales."
  },
  {
    "objectID": "03-02-Tema2.html#lectura-de-datos-y-representación-gráfica",
    "href": "03-02-Tema2.html#lectura-de-datos-y-representación-gráfica",
    "title": "Series Temporales. Definición y componentes",
    "section": "1.3 Lectura de datos y representación gráfica",
    "text": "1.3 Lectura de datos y representación gráfica\nAntes de continuar vamos a importar con R tres de las series que usaremos de ejemplo en este tema: generación anual de residuos municipales per cápita (kg per cápita), los nacimientos mensuales y la demanda eléctrica diaria (GWh). Las tres series se refieren a España y servirán de ejemplo para el análisis de series con diferente fechado: anual, mensual y diario, respectivamente.\n\nGeneración de residuos municipales per cápita\nResiduos es una serie anual de 1995 a 2022 (fuente Instituto Nacional de Estadística) que muestra los residuos recogidos por o en nombre de las autoridades municipales y eliminados a través del sistema de gestión de residuos. Los datos están disponibles en el fichero Residuos.csv, que contiene dos variables o columnas de datos. La primera columna corresponde al año de la serie y la segunda contiene los residuos recogidos en kg per cápita. En la primera fila del fichero aparece el nombre de cada columna. Los valores no tienen decimales y los datos de cada fila vienen separados por un punto y coma.\n\nresiduos &lt;- read.csv2(\"./series/Residuos.csv\", \n                      header = TRUE)\n\nresiduos &lt;- ts(residuos[, 2], \n               start = 1995, \n               frequency  = 1)\n\n\n\n\n\n\n\nOjo con la lectura de datos\n\n\n\nUsamos para leer los datos read.csv2, indicando que la primera línea tiene el nombre de las variables. Esta función asume que el separador decimal es la coma “,” y que el separador entre variables es el punto y coma “;”.\nSi el separador decimal es el punto “.” y el separador de variables es la coma “,”, debes usar read.csv.\nEn cualquiera de estas funciones puedes modificar el separador decimal por medio del argumento dec; también puedes usar el argumento sep para indicar el carácter usado como separador de variables.\n\n\nLa función ts, de la librería stats, convierte un objeto (vector o matriz) en la clase serie temporal. En este caso seleccionamos solo la segunda columna, la que contiene el número de residuos generados.\n\nCon start indicamos el fechado del primer dato.\nCon frequency indicamos la frecuencia, que en este caso es un dato por año.\n\nUsa help(ts) para obtener más información y str(residuos) para ver qué contiene un objeto serie temporal.\n\n\n\n\n\n\nNombre del fichero y nombre de la serie\n\n\n\n\n\nPor comodidad (o pereza), muchas veces el nombre del fichero con los datos, el nombre del data.frame con su contenido en R y el nombre de la serie es el mismo. No tiene por que ser así, aunque en estos apuntes es lo más habitual.\nEn este caso, observa que primero creamos “residuos”, una base de datos (data.frame) con el contenido del fichero “Residuos.csv” que tiene dos variables (fechado y valores de la serie). Luego creamos la serie temporal “residuos” extrayendo de la base de datos la segunda columna (valores de la serie) y fechándola. Por tanto, estamos machacando la base de datos al poner a la serie el mismo nombre.\n\n\n\nPodemos dibujar la serie Residuos con la función plot o mejor con autoplot. Esta última está en el paquete forecast.\nEn general, las funciones gráficas que vamos a usar pertenecen a la librería forecast, pero en ocasiones las ampliaremos con funciones de la librería ggplot2. Te recomiendo cargar estas dos librerías desde el inicio. En casi todos los casos existe una versión de la función gráfica usada en la librería stats.\n\nlibrary(forecast)\nlibrary(ggplot2)\n\n\nautoplot(residuos,\n         xlab = \"\",\n         ylab = \"Kg per cápita\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 2: Residuos generados\n\n\n\n\n\n\n\nNacimientos en España\nNacimientos es una serie mensual de enero de 1975 a diciembre de 2023 (fuente: Instituto Nacional de Estadística). Los datos están disponibles en el fichero Nacimientos.csv. La primera columna del fichero tiene la fecha y la segunda la serie propiamente. En la primera fila aparece el nombre de cada columna. De nuevo seleccionamos solo la columna con los datos de nacimientos.\n\nnacimientos &lt;- read.csv2(\"./series/Nacimientos.csv\", \n                         header = TRUE)\n\nnacimientos &lt;- ts(nacimientos[, 2],\n                  start = c(1975, 1),\n                  frequency = 12)\n\n\n\n\n\n\n\n¿Sobrías responder a estas preguntas?\n\n\n\n¿Por qué se usa el argumento “header = TRUE”?\n¿Por qué la serie corresponde a la segunda columna de la base de datos “nacimientos”?\n\n\nEn este caso:\n\nCon start indicamos que el primer dato es enero de 1975. También sería correcto start = 1975. Si el primer dato fuera, por ejemplo, marzo de 1975, podríamos poner start = c(1975, 3) o start = 1975 + 2/12.\nCon frequency indicamos que se tienen 12 datos (meses) por año. Si la serie fuera trimestral pondríamos frequency = 4.\n\n\nautoplot(nacimientos,\n         xlab = \"\",\n         ylab = \"Nacimientos\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 3: Nacimientos mensuales\n\n\n\n\n\n\n\nDemanda eléctrica\nDemanda eléctrica es una serie diaria desde el 1 enero de 2023 hasta el 31 diciembre de 2023 (fuente: Red Electrica de España). Los datos están disponibles en el fichero Consumo electrico.csv. El fichero solo tiene una columna, encabezada con un nombre, con los datos de la serie y el carácter decimal es el punto.\n\nelectricidad &lt;- read.csv(\"./series/Consumo electrico.csv\", \n                         header = TRUE)\n\nelectricidad &lt;- ts(electricidad[, 1],\n                   start = c(1, 7),\n                   frequency = 7)\n\nEn este caso:\n\nCon start indicamos que el primer dato es un domingo (día 7 de la semana) de la primera semana. Como ves no hay referencia al año. También sería correcto start = 1 + 6/7.\nCon frequency indicamos que se tienen 7 datos (días) por semana. Si la serie fuera de lunes a viernes pondríamos frequency = 5.\n\n\nautoplot(electricidad,\n         xlab = \"\",\n         ylab = \"GWh\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 4: Consumo diario de electricidad"
  },
  {
    "objectID": "03-02-Tema2.html#funciones-útiles-para-objetos-de-clase-ts",
    "href": "03-02-Tema2.html#funciones-útiles-para-objetos-de-clase-ts",
    "title": "Series Temporales. Definición y componentes",
    "section": "1.4 Funciones útiles para objetos de clase ts",
    "text": "1.4 Funciones útiles para objetos de clase ts\nOtras funciones relacionadas con los objetos de clase serie temporal que pueden ser útiles son:\n\nstart da el fechado del primer dato, y end da el fechado del último dato.\n\n\nstart(nacimientos); end(nacimientos)\n\n[1] 1975    1\n\n\n[1] 2023   12\n\nstart(electricidad); end(electricidad)\n\n[1] 1 7\n\n\n[1] 53  7\n\n\n\nfrequency da la frecuencia de los datos.\n\n\nfrequency(nacimientos)\n\n[1] 12\n\nfrequency(electricidad)\n\n[1] 7\n\n\n\ntime crea un vector con el fechado de una serie. Observa como guarda internamente R el fechado de una serie temporal. Esta es una función que usaremos constantemente.\n\n\nhead(time(nacimientos), n = 48)  #Mostramos sólo los 4 primeros años\n\n          Jan      Feb      Mar      Apr      May      Jun      Jul      Aug\n1975 1975.000 1975.083 1975.167 1975.250 1975.333 1975.417 1975.500 1975.583\n1976 1976.000 1976.083 1976.167 1976.250 1976.333 1976.417 1976.500 1976.583\n1977 1977.000 1977.083 1977.167 1977.250 1977.333 1977.417 1977.500 1977.583\n1978 1978.000 1978.083 1978.167 1978.250 1978.333 1978.417 1978.500 1978.583\n          Sep      Oct      Nov      Dec\n1975 1975.667 1975.750 1975.833 1975.917\n1976 1976.667 1976.750 1976.833 1976.917\n1977 1977.667 1977.750 1977.833 1977.917\n1978 1978.667 1978.750 1978.833 1978.917\n\nhead(time(electricidad), n = 28)  #Mostramos sólo las 4 primeras semanas\n\nTime Series:\nStart = c(1, 7) \nEnd = c(5, 6) \nFrequency = 7 \n [1] 1.857143 2.000000 2.142857 2.285714 2.428571 2.571429 2.714286 2.857143\n [9] 3.000000 3.142857 3.285714 3.428571 3.571429 3.714286 3.857143 4.000000\n[17] 4.142857 4.285714 4.428571 4.571429 4.714286 4.857143 5.000000 5.142857\n[25] 5.285714 5.428571 5.571429 5.714286\n\n\n\n\n\n\n\n\nFechado de la serie\n\n\n\n¿Tienes claro cómo R guarda internamente el fechado de una serie? ¿Qué indican los valores decimales?\n\n\n\ncycle, crea un vector con la posición en el ciclo de cada observación. Para una serie mensual sus valores van de 1 a 12, para una serie diaria sus valores irían 1 a 7. También usaremos esta función de forma regular.\n\n\nhead(cycle(nacimientos), n = 48) #Mostramos sólo los 4 primeros años\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n1975   1   2   3   4   5   6   7   8   9  10  11  12\n1976   1   2   3   4   5   6   7   8   9  10  11  12\n1977   1   2   3   4   5   6   7   8   9  10  11  12\n1978   1   2   3   4   5   6   7   8   9  10  11  12\n\nhead(cycle(electricidad), n = 28) #Mostramos sólo las 4 primeras semanas\n\nTime Series:\nStart = c(1, 7) \nEnd = c(5, 6) \nFrequency = 7 \n [1] 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6 7 1 2 3 4 5 6"
  },
  {
    "objectID": "03-02-Tema2.html#tendencia-t_t",
    "href": "03-02-Tema2.html#tendencia-t_t",
    "title": "Series Temporales. Definición y componentes",
    "section": "2.1 Tendencia, \\(T_t\\)",
    "text": "2.1 Tendencia, \\(T_t\\)\nDefinición: la tendencia de una serie es su comportamiento a largo plazo (varios años). Describe los cambios sistemáticos de la serie temporal que no aparentan ser periódicos.\nRespecto a la dirección del movimiento la tendencia puede ser:\n\nCreciente: a largo plazo la serie aumenta su valor\nDecreciente: a largo plazo la serie disminuye su valor\nEstacionaria: a largo plazo la serie mantiene su valor\n\nRespecto del proceso generador de la tendencia, puede ser:\n\nDeterminista: \\(T_t = f(t)\\)\nEstocástica: \\(T_t = f(T_{t-1}, T_{t-2},\\ldots)\\)\nMixta: \\(T_t = f(t,T_{t-1}, T_{t-2},\\ldots)\\)\n\nEn la Figura 5 se muestran ejemplos de series temporales según dirección del movimiento y pendiente de la tendencia.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estacionaria\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Creciente (lineal)\n\n\n\n\n\n\n\n\n\n\n\n(c) Creciente (exponencial)\n\n\n\n\n\n\n\n\n\n\n\n(d) Creciente (logarítmica)\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Decreciente (lineal)\n\n\n\n\n\n\n\n\n\n\n\n(f) Decreciente (exponencial)\n\n\n\n\n\n\n\n\n\n\n\n(g) Decreciente (logarítmica)\n\n\n\n\n\n\n\nFigura 5: Ejemplos de tendencia\n\n\n\n\n\n\nSi la serie temporal es suficientemente larga es posible observar cambios en la dirección del movimiento de la tendencia que definen los ciclos."
  },
  {
    "objectID": "03-02-Tema2.html#ciclo-c_t",
    "href": "03-02-Tema2.html#ciclo-c_t",
    "title": "Series Temporales. Definición y componentes",
    "section": "2.2 Ciclo, \\(C_t\\)",
    "text": "2.2 Ciclo, \\(C_t\\)\nDefinición: Son patrones sin periodicidad fija que abarcan varios años.\nPor ejemplo, los ciclos económicos, los cambios climáticos asociados al fenómeno El Niño, o las manchas solares (véase Figura 6).\n\n\n\n\n\n\nFigura 6: Ciclos solares. Imagen tomada de Courtillot, Lopes, and Mouël (2021)\n\n\n\n\n\nLa serie de Nacimientos es lo suficientemente larga como para observarse un ciclo completo, que queda identificado por dos cambios de tendencia consecutivos de signo opuesto (véase Figura 7):\n\nA finales de la década de los 90 la tendencia decreciente en los nacimientos pasa a creciente por la llegada de inmigrantes con una mayor tasa de natalidad.\nA finales de la primera década del 2000 la tendencia creciente pasa a decreciente porque la Gran Recesión provoca el regreso a sus países de origen de muchos de estos inmigrantes.\n\nDe esta forma, observamos un ciclo completo desde 1975 hasta poco antes de 2010 (periodo entre dos cambios de tendencia), y el inicio del siguiente ciclo, en el que aun estamos.\n\n\n\n\n\n\n\n\nFigura 7: Ciclos en la serie Nacimientos"
  },
  {
    "objectID": "03-02-Tema2.html#estacionalidad-s_t",
    "href": "03-02-Tema2.html#estacionalidad-s_t",
    "title": "Series Temporales. Definición y componentes",
    "section": "2.3 Estacionalidad, \\(S_t\\)",
    "text": "2.3 Estacionalidad, \\(S_t\\)\nDefinición: Son patrones repetitivos de periodicidad fija e inferior al año.\nEl orden de la periodicidad lo denominaremos \\(m\\), por tanto el patrón estacional se repite cada \\(m\\) periodos. Lógicamente, \\(m\\) toma el valor 12 para datos mensuales, el valor 4 para datos trimestrales, 7 para datos diarios de lunes a domingo, etc.\nLa componente estacional surge por factores climatológicos, institucionales o sociales.\nEn ocasiones no es fácil determinar la existencia de estacionalidad o su orden. En este caso, se puede usar el análisis espectral, que no veremos en este curso, para analizar esta componente. La librería forecast dispone de la función findfrequency que devuelve la frecuencia dominante de una serie usando el análisis espectral.\nLa serie Nacimientos tiene una estacionalidad de orden 12, causada principalmente por el número de días del mes (véase la Figura 8). Cada año se repite una misma pauta: los meses de febrero, por tener 28 (o 29 días en años bisiestos), presentan el menor número de nacimientos y son los valles en la Figura 8; y, en general, en los meses de 31 días hay más nacimientos que en los demás meses del año.\n\n\n\n\n\n\n\n\nFigura 8: Nacimientos\n\n\n\n\n\n\n\nLa Figura 9 muestra la demanda eléctrica diariamente para cuatro semanas, desde el lunes 30 de enero hasta el domingo 26 de febrero (semanas 6 a 9 del año). Tiene, por tanto, una estacionalidad de orden 7. En el eje OX aparecen etiquetados los lunes de cada semana que permiten identificar el siguiente patrón semanal: de lunes a viernes un consumo similar, seguido de una caída en el consumo el sábado, y el domingo como el día de menor consumo\n\n\n\n\n\n\n\n\nFigura 9: Demanda diaria de electricidad\n\n\n\n\n\nSi el fechado de la serie es de muy alta frecuencia, puede ocurrir que se superponga más de una componente estacional. La Figura 10 muestra la serie corresponde a la demanda eléctrica (GW) recogida cada hora durante el mes de febrero de 2021. El eje OX señala el consumo de la primera hora de cada día del mes (desde media noche hasta la una de la madrugada). Se aprecia una estacionalidad diaria de orden \\(24\\), otra semanal de orden \\(168 =7 \\times 24\\) y si mostráramos varios años de consumo, también se observaría otra mensual.\n\n\n\n\n\n\n\n\nFigura 10: Estacionalidad múltiple para el consumo de electricidad por hora\n\n\n\n\n\n\n\n\n\n\n\nSeries con más de una componente estacional\n\n\n\nEn este curso no analizaremos series con más de una componente estacional. Si quieres tener una primera aproximación de como se hace, puedes ir a la píldora Múltiples componentes estacionales."
  },
  {
    "objectID": "03-02-Tema2.html#intervención-i_t",
    "href": "03-02-Tema2.html#intervención-i_t",
    "title": "Series Temporales. Definición y componentes",
    "section": "2.4 Intervención, \\(I_t\\)",
    "text": "2.4 Intervención, \\(I_t\\)\nDefinición: Es un factor sistemático no periódico, o irregular, que vendría determinado por fenómenos ocasionales que provocan observaciones anómalas y valores atípicos en la serie temporal.\nPor su relación con fechas concretas, podemos distinguir dos tipos:\n\nEfectos calendario: irregularidades específicas en la serie temporal que se producen durante determinados periodos de tiempo. Por ejemplos los días festivos en series diarias; o la Semana Santa, días laborales y febrero bisiesto en series mensuales.\nOtros efectos no sujetos a calendario: irregularidades no específicas ni sujetas a fechas concretas. Por ejemplo, pandemias, catástrofes naturales, huelgas, caída del sistema eléctrico o de los servidores de una red social, etc.\n\nEn la serie mensual Nacimientos, los meses de febrero bisiestos (puntos rojos) presentan un número de nacimientos mayor que los meses de febrero no bisiestos (efecto calendario). Para algunos años este hecho es mas claro (véase Figura 11). Además, a finales del año 2020 y principios del 2021 se observa una caída inusual en el número de nacimientos (puntos verdes) debido a que la pandemia causada por la Covid-19 retrasó la decisión de tener hijos de muchas parejas. Este es un ejemplo de intervención no sujeta a calendario.\n\n\n\n\n\n\n\n\nFigura 11: Efecto de los febreros bisiestos y de la Covid-19 en Nacimientos\n\n\n\n\n\nEn la serie diaria Electricidad cuando un día entre semana es festivo, el consumo se reduce notablemente, apareciendo un efecto calendario. Si se trata de un día aislado, el efecto es muy fácil de identificar y analizar. Un ejemplo, observable en la Figura 12, es el miércoles 1 de noviembre de 2023, día de Todos los Santos, identificado con un punto rojo en la figura. Se aprecia que el consumo fue muy inferior al observado el miércoles precedente y posterior (puntos verdes). Si los festivos abarcan varios días, el efecto sigue siendo perfectamente identificable, pero es más complejo de analizar. Un ejemplo es la última semana de diciembre donde el consumo es muy inferior al observado en las semanas previas debido, por un lado, al efecto del día festivo de Navidad (punto azul) y, por otro lado, al periodo semi-vacacional que estas festividades supone en España. También se aprecia la intervención asociada a la semana que contiene los festivos de la Constitución y la Inmaculada (martes 6 y jueves 8 de diciembre).\n\n\n\n\n\n\n\n\nFigura 12: Efectos calendario en Electricidad\n\n\n\n\n\nPor su naturaleza, podemos distinguir tres tipos básicos de intervención (aunque hay más):\n\nPulso (Additive Outlier, AO)\n\nEn un periodo aislado la serie toma un valor anómalo (véase Figura 13, panel izquierdo). Por ejemplo, un día entre semana es festivo y la demanda eléctrica es inferior a la usual; o el mes de agosto de 2024 la olimpiadas de París incrementan significativamente el turismo y la ocupación hotelera en la ciudad respecto de agostos precedentes.\n\nCambio transitorio (Transitory Change, TC)\n\nEn un periodo un shock genera un valor anómalo en la serie y el efecto del shock va desapareciendo poco a poco (véase Figura 13, panel central). Por ejemplo, las redes sociales ponen de moda un producto que temporalmente aumenta sus ventas. Pero, conforme pasa el tiempo, los consumidores se olvidan del producto y sus ventas vuelven poco a poco a su nivel previo.\n\nCambio permanente (Level Shift, LS)\n\nEn un periodo la serie cambia de nivel y permanece de forma permanente en este nuevo nivel (véase Figura 13, panel derecho). Por ejemplo, enfrente de un supermercado abre la competencia, de forma que sus ventas descienden bruscamente de forma permanente. La apertura en una ciudad de una nueva línea de tranvía incrementa de forma permanente los usuarios del transporte público en esa ciudad.\n\n\n\n\n\n\n\n\n\n\nFigura 13: Tipos de intervención"
  },
  {
    "objectID": "03-02-Tema2.html#residuo-r_t",
    "href": "03-02-Tema2.html#residuo-r_t",
    "title": "Series Temporales. Definición y componentes",
    "section": "2.5 Residuo, \\(R_t\\)",
    "text": "2.5 Residuo, \\(R_t\\)\nDefinición: No presenta un comportamiento sistemático a corto, medio o largo plazo por lo que no se puede predecir de modo alguno. Es la parte de la serie que se debe a puro azar.\nAunque inicialmente no se hará ningún supuesto sobre el residuo, se espera que sea ruido blanco: media cero, incorrelado y homocedástico. Es decir \\(R_t \\sim iid(0, \\sigma^2\\))."
  },
  {
    "objectID": "03-02-Tema2.html#esquema-aditivo-y-multiplicativo",
    "href": "03-02-Tema2.html#esquema-aditivo-y-multiplicativo",
    "title": "Series Temporales. Definición y componentes",
    "section": "2.6 Esquema aditivo y multiplicativo",
    "text": "2.6 Esquema aditivo y multiplicativo\nUna serie temporal siempre tiene tendencia y residuo. La presencia de estacionalidad, ciclo e intervención depende de la naturaleza de la serie. Por ejemplo, una serie anual no tendrá nunca estacionalidad y en una serie corta no se podrá observar el ciclo.\nLas componentes de una serie temporal se pueden combinar de múltiples formas.\nEn el esquema aditivo cada componente suma su efecto sobre las demás, \\[y_t = T_t + S_t + C_t + I_t + R_t.\\] La demanda diaria de electricidad es un ejemplo de este tipo de esquema (Figura 14). El panel superior muestra la serie en el tiempo e identificamos el esquema aditivo porque la amplitud estacional (para cada semana la diferencia entre el día de más consumo y el de menos consumo) se mantiene constante en el tiempo. En el panel inferior tenemos una gráfica media-varianza, donde cada punto corresponde a una semana, la coordenada X es el consumo de esa semana y la coordenada Y la desviación típica del consumo para los días de esa semana (variabilidad intrasemanal). Este segundo panel revela el esquema aditivo de la serie porque no se observa un patrón creciente en los puntos: más consumo no implica una mayor desviación típica.\n\n\n\n\n\n\n\n\n\n\n\n(a) Consumo electrico diario\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Gráfica media-varianza\n\n\n\n\n\n\n\nFigura 14: Ejemplo de esquema aditivo\n\n\n\nEn el esquema multiplicativo cada componente supone un incremento porcentual respecto de las demás, \\[y_t = T_t \\cdot S_t \\cdot C_t \\cdot I_t \\cdot R_t.\\] La serie Nacimientos es un ejemplo de esquema multiplicativo. En el panel superior de la Figura 15, que muestra la serie, se observa que según decrece el número de nacimientos, también decrece la amplitud estacional. Además, en el panel inferior cada punto corresponde a un año: en el eje X los nacimientos de ese año y en el eje Y la desviación típica de los nacimientos mensuales de ese año (variación intraanual). En este panel se observa un patrón creciente en los puntos, revelando el esquema multiplicativo de la serie.\n\n\n\n\n\n\n\n\n\n\n\n(a) Nacimientos mensuales\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Gráfica media-desviación anual\n\n\n\n\n\n\n\nFigura 15: Ejemplo de esquema multiplicativo\n\n\n\nSi una serie presenta un esquema multiplicativo, su logaritmo lo presentará aditivo. A lo largo del curso se verán otras razones por las que puede ser aconsejable analizar el logaritmo de una serie temporal.\nEn principio, cualquier combinación entre las componentes es posible (véase Temas 6 y 7):\n\n\\(y_t = (T_t + C_t) \\cdot S_t + I_t + R_t\\)\n\\(y_t = (T_t + S_t + C_t + I_t)R_t\\)\n\\(y_t = T_t \\cdot S_t \\cdot C_t \\cdot I_t + R_t\\)\n…"
  },
  {
    "objectID": "03-02-Tema2.html#idea-general",
    "href": "03-02-Tema2.html#idea-general",
    "title": "Series Temporales. Definición y componentes",
    "section": "3.1 Idea general",
    "text": "3.1 Idea general\nPodemos manipular una serie temporal con diferentes fines:\n\nextraer la tendencia (eliminando la estacionalidad), por ejemplo, pasando de una serie mensual a una anual, o de una serie diaria a una semanal.\nextraer la estacionalidad (eliminando la tendencia) de forma sencilla, aunque no muy precisa.\nrecortar una serie para obtener una submuestra.\nextraer una subserie correspondiente a un único periodo estacional. Por ejemplo, los nacimientos en febrero o el consumo de electricidad de los domingos.\n\nEstas operaciones nos permitirán mejorar nuestra capacidad descriptiva de la serie, identificar mejor el tipo de esquema entre las componentes, facilitar la estimación del proceso generador o ampliar las herramientas de análisis y predicción de una serie temporal."
  },
  {
    "objectID": "03-02-Tema2.html#extracción-de-la-tendencia",
    "href": "03-02-Tema2.html#extracción-de-la-tendencia",
    "title": "Series Temporales. Definición y componentes",
    "section": "3.2 Extracción de la tendencia",
    "text": "3.2 Extracción de la tendencia\nSi tenemos una serie con estacionalidad y agregamos la serie –obteniendo un dato por año, si la serie es mensual, o un dato por semana, si es diaria– obtenemos una nueva serie sin estacionalidad, solo con tendencia.\nDependiendo de la naturaleza de la serie, convendrá agregar sumando los datos (consumo eléctrico, residuos generados, viajeros transportados, nacimientos) o sacando la media (temperatura, número de parados, ocupación hotelera).\nVeamos como extraer la tendencia de la serie Nacimientos usando la función aggregate con el argumento FUN = sum.\n\nnacimientosAnual &lt;- aggregate(nacimientos, FUN = sum)\nautoplot(nacimientosAnual/1000,\n         xlab = \"\",\n         ylab = \"Nacimientos (miles)\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 16: Nacimientos por año\n\n\n\n\n\nAhora para la demanda de electricidad.\n\nelectricidadSemanal &lt;- aggregate(electricidad, FUN = sum)\nautoplot(electricidadSemanal,\n       xlab = \"\",\n       ylab = \"GWh\",\n       main = \"\")\n\n\n\n\n\n\n\nFigura 17: Consumo de electricidad por semana\n\n\n\n\n\nLa función aggregate aplicada a una serie temporal agrega los datos de cada periodo estacional completo aplicando la función especificada en FUN.\n\nUna serie trimestral o mensual la transforma en anual, una serie diaria en semanal.\nLa función a usar dependerá de la naturaleza de los datos y del objetivo perseguido (FUN=sum, FUN=mean, FUN=sd…)\nEsta función tiene un uso más amplio en R. Usa la función help para aprenderlo.\n\n\n\n\n\n\n\nAtención\n\n\n\nLa agregación no tiene por que empezar en el primera componente estacional. Por ejemplo, la serie Demanda eléctrica se inicia el domingo 1 de enero, así que el primer dato de la serie agregada irá del domingo 1 de enero al sábado 7 de enero, un periodo estacional completo; el segundo dato de la serie agregada ira del domingo 8 al sábado 14 de enero; y así sucesivamente. El último dato de la serie agregada será del domingo 24 al sábado 30 de diciembre. El 31 de diciembre no formará parte de la serie agregada."
  },
  {
    "objectID": "03-02-Tema2.html#extracción-de-la-estacionalidad",
    "href": "03-02-Tema2.html#extracción-de-la-estacionalidad",
    "title": "Series Temporales. Definición y componentes",
    "section": "3.3 Extracción de la estacionalidad",
    "text": "3.3 Extracción de la estacionalidad\nTenemos varias alternativas gráficas para visualizar la estacionalidad y numéricas para calcular la estacionalidad de una serie.\nVisualización de la estacionalidad\nPodemos hacer una gráfico de la serie contra cada periodo estacional. Este gráfico permite identificar el patrón estacional de la serie y su evolución en el tiempo. Existen varias opciones para este tipo de gráficos, veremos dos de ellas: gráfico de subseries y gráfico de líneas.\nVeamos primero un ejemplo de gráfico de subseries que muestra para cada periodo estacional la subserie de valores de ese periodo y el valor medio de la subserie (líneas horizontales).\nPara la serie Nacimientos, recortada desde el año 2000 para facilitar la interpretación, la Figura 18 muestra como el mes de febrero es el que presenta menor número de nacimientos. Por contra, los meses de 31 días presentan en media un número de nacimientos mayor que los meses de 30 días. La excepción es septiembre, un mes de 30 días pero donde el número de nacimientos supera el del mes de agosto de 31 días. Una explicación posible es que muchos nacimientos por cesárea que corresponderían a finales de agosto se programen en septiembre para esquivar este mes festivo.\n\nnacimientosb &lt;- window(nacimientos, start = 2000)\nggsubseriesplot(nacimientosb) +\n  ylab(\"Nacimientos\") +\n  xlab(\"\") +\n  ggtitle(\"\")\n\n\n\n\n\n\n\nFigura 18: Gráfico estacional de subseries para Nacimientos\n\n\n\n\n\nPara las series con tendencia o esquema multiplicativo, el valor medio de las subseries puede llevarnos a una interpretación incorrecta de la estacionalidad. La función monthplot de stats realiza un gráfico similar.\nUna alternativa es el gráfico de líneas, donde cada linea muestra la evolución de un periodo estacional. Para Nacimientos la Figura 19 muestra los nacimientos desde 2018 a 2023, donde cada año es una línea. Se observa perfectamente el efecto de la pandemia sobre el número de nacimientos desde noviembre de 2020. Si se incluye el argumento polar=TRUE, se obtiene una versión tipo tela de araña de este gráfico.\n\nggseasonplot(window(nacimientos, start = 2018),\n             year.labels = TRUE, \n             xlab = \"\",\n             ylab = \"Nacimientos\",\n             main = \"\")\n\n\n\n\n\n\n\nFigura 19: Gráfico estacional de lineas para Nacimientos\n\n\n\n\n\nCálculo de la componente estacionalidad\nLas gráficas ayudan a describir y entender un poco mejor el patrón estacional. Sin embargo, si deseamos estimar la componente estacional, debemos proceder de otra forma.\nLa siguiente sintaxis usa la función tapply para estimar numéricamente la componente estacional bajo un esquema multiplicativo. Básicamente, calcula para cada mes (argumento cycle(nacimientosb)) la media (FUN = mean) del cociente nacimientosb / mean(nacimientosb).\n\ncomponenteEstacional &lt;- tapply(nacimientosb/mean(nacimientosb), \n                               cycle(nacimientosb), \n                               FUN = mean)\nround(componenteEstacional, 2)\n\n   1    2    3    4    5    6    7    8    9   10   11   12 \n1.00 0.91 1.00 0.96 1.01 0.97 1.03 1.03 1.04 1.05 1.00 1.00 \n\n\nLos valores de la tabla previa indican que en febrero nacen un 9% menos de bebés respecto de la media anual y que, en general, los meses de 30 días están en la media o debajo de la media general. Por contra, los meses de 31 días están en o encima de la media general, destacando julio un 3% por encima y octubre un 5%. La anomalia es septiembre que, siendo un mes de 30 días, tiene un 4% más de nacimientos de la media anual.\nLos cambios necesarios para estimar la componente estacional bajo un esquema aditivo son mínimos. Veámoslo para la serie Demanda eléctrica.\n\ncomponenteEstacional &lt;- tapply(electricidad - mean(electricidad), \n                               cycle(electricidad), \n                               FUN = mean)\nround(componenteEstacional, 2)\n\n     1      2      3      4      5      6      7 \n 10.29  32.74  36.77  35.67  23.17 -47.56 -89.37 \n\n\nDe lunes a viernes la demanda eléctrica está por encima de la media semanal, especialmente de martes a jueves con un consumo más de 30 GWh por encima de la media. El sábado la demanda cae 48 GWh y el domingo se da la menor demanda, 89 GWh por debajo de la media semanal."
  },
  {
    "objectID": "03-02-Tema2.html#recorte-de-una-serie-y-extracción-de-una-subserie",
    "href": "03-02-Tema2.html#recorte-de-una-serie-y-extracción-de-una-subserie",
    "title": "Series Temporales. Definición y componentes",
    "section": "3.4 Recorte de una serie y extracción de una subserie",
    "text": "3.4 Recorte de una serie y extracción de una subserie\nR proporciona varias funciones que permiten extraer una submuestra de la serie original. Podemos:\n\nseleccionar una submuestra especificando los puntos temporales de inicio y fin.\nseleccionar una submuestra seleccionando un periodo estacional determinado.\nquitar fácilmente un conjunto de datos usando índices.\n\nVeamos algunos ejemplos de extracción con la serie Nacimientos y las funciones window y subset:\nFunción window, que recorta especificando fechados exactos.\n\nwindow(nacimientos, start = c(2000, 1), end = c(2009, 12)) selecciona de la serie original los datos desde enero de 2000 a diciembre de 2009.\nwindow(nacimientos, start = c(2010, 3)) selecciona de la serie original los datos desde marzo de 2010 hasta el último dato (diciembre de 2023).\nwindow(nacimientos, end = c(1999, 12)) selecciona de la serie original los datos desde el primero (enero de 1975) hasta diciembre de 1999.\nwindow(nacimientos, start = c(2000, 3), freq = TRUE) selecciona de la serie original solo los meses de marzo desde 2000.\n\nFunción subset, que recorta especificando posiciones de las observaciones.\n\nsubset(nacimientos, start = 10, end = 34) selecciona de la serie las observaciones que van desde la 10 a la 34, ambas inclusive.\nsubset(nacimientos, start = 121) selecciona de la serie las observaciones que van desde la 121 hasta la última.\nsubset(nacimientos, start = length(nacimientos) - 47) selecciona de la serie los últimos 4 años (2020 a 2023).\nsubset(nacimientos, end = length(nacimientos) - 48) selecciona de la serie todo menos los últimos 4 años. Es decir, el último dato es diciembre de 2019.\nsubset(nacimientos, season  = 5) selecciona de la serie todos los meses de mayo.\n\n\n\n\n\n\n\nwindow y subset\n\n\n\nDurante el curso haremos un uso contante de la funciones window y subset. Practícalas para familiarizarte con su uso.\n\n\nAdemás, puedes usar las funciones head y tail para extraer las primeras o las últimas observaciones."
  },
  {
    "objectID": "03-02-Tema2.html#concepto",
    "href": "03-02-Tema2.html#concepto",
    "title": "Series Temporales. Definición y componentes",
    "section": "4.1 Concepto",
    "text": "4.1 Concepto\nLos métodos que hemos visto para la descripción de la tendencia y la componente estacional son muy sencillos, pero no son ni rigurosos ni precisos. Veamos métodos más adecuados para extraer de una serie sus componentes.\nSi la serie es demasiado corta para poder extraer el ciclo, entonces el ciclo queda recogido dentro de la tendencia. Por otro lado, las técnicas de identificación de la intervención son complejas por lo que esta componente queda incorporada al residuo. Por tanto, asumiremos que una serie tiene sólo Tendencia, Estacionalidad y Residuo:\n\nEsquema aditivo \\(y_t = T_t + C_t + S_t + I_t + R_t = (T_t + C_t) + S_t +(I_t + R_t) = T'_t + S_t + R'_t\\)\nEsquema multiplicativo \\(y_t = T_t \\cdot C_t \\cdot S_t \\cdot I_t \\cdot R_t = (T_t \\cdot C_t) \\cdot S_t \\cdot (I_t \\cdot R_t) = T'_t \\cdot S_t \\cdot R'_t\\)\n\nVeremos a continuación como extraer estas tres componentes a partir de una serie original. Este proceso se denomina descomposición.\nHay múltiples formas de realizar una descomposición. Aquí veremos dos de ellas, la más sencilla, basada en el concepto de medias móviles (decompose), y otra más versátil y compleja a partir de regresiones locales ponderadas (stl).\nAdemás, R proporciona (a través de paquetes específicos) el método de descomposición que utiliza el US Census Bureau and Statistics Canada, denominado X11, y el método que utiliza el Banco de España, denominado SEATS (Seasonal Extraction in ARIMA Time Series), aunque estos métodos solo son válidos para series mensuales y trimestrales.\nEn origen, los métodos de descomposición no sirven para realizar predicciones, pero actualmente se usan también con este fin (véase las funciones stlm y stlf del paquete forecast)."
  },
  {
    "objectID": "03-02-Tema2.html#descomposición-por-medias-móviles",
    "href": "03-02-Tema2.html#descomposición-por-medias-móviles",
    "title": "Series Temporales. Definición y componentes",
    "section": "4.2 Descomposición por medias móviles",
    "text": "4.2 Descomposición por medias móviles\n\nIdeas generales\nLa función decompose estima las componentes de tendencia, estacionalidad y residuo usando el método de medias móviles. En concreto decompose sigue los siguientes pasos para obtener cada componente:\nPaso 1: Se estima la tendencia de una serie a partir de una media móvil centrada. Si el orden estacional es par, la media móvil es ponderada de orden \\(m + 1\\); y si el orden estacional es impar, la media móvil es de orden \\(m\\). En concreto,\n\nSi \\(m=2k\\): \\(\\hat{T}_t = \\frac{\\frac{1}{2}y_{t-k} + y_{t-k+1} + \\ldots + y_t + \\ldots + y_{t+k-1} + \\frac{1}{2} y_{t+k}}{m}\\),\nSi \\(m=2k+1\\): \\(\\hat{T}_t = \\frac{y_{t-k} + y_{t-k+1} + \\ldots + y_t + \\ldots + y_{t+k-1} + y_{t+k}}{m}\\).\n\nPaso 2: Para un modelo con esquema aditivo calculamos la serie sin tendencia como \\(y_t - \\hat{T}_t\\) y para un esquema multiplicativo como \\(y_t/ \\hat{T}_t\\).\nPaso 3: Para estimar la componente estacional para cada periodo estacional, calculamos el valor medio de la serie sin tendencia (paso 2) de forma independiente para los datos de cada estación. Así, obtenemos un vector con la estimación de las \\(m\\) componentes estacionales.\nDespués estos valores se ajustan para que sumen 0 (esquema aditivo) o para que sumen \\(m\\) (esquema multiplicativo). La componente estacional se obtiene repitiendo el vector de \\(m\\) componentes ajustadas hasta alcanzar la longitud de la serie original. Esto da \\(\\hat{S}_t\\)\nPaso 4: El residuo se obtiene como \\(\\hat{R}_t = y_t - \\hat{T}_t - \\hat{S}_t\\) (esquema aditivo) o \\(\\hat{R}_t = y_t / (\\hat{T}_t \\cdot \\hat{S}_t)\\) (esquema multiplicativo)\nLa Tabla 1 muestra un ejemplo de descomposición aditiva por medias móviles para una serie simulada de orden estacional 5.\n\nLa dos primeras columnas indican la estación de cada dato y el valor de la serie, para un total de 25 datos. La columna Ten ha sido obtenida siguiendo el paso 1 como una media móvil de orden 5: \\[Ten_t = (Serie_{t-2} + Serie_{t-1} + Serie_{t} + Serie_{t+1} + Serie_{t+2})/5.\\]\nLa serie sin tendencia, columna Est + Res, se obtiene restando a la columna Serie la columna Ten, tal y como se indica en el paso 2.\nPara el cálculo de la columna Est, que repite de forma periódica la primera estimación de las 5 componentes estacionales, se sigue el paso 3. Para cada estación se promedian los valores de la columna Est + Res correspondientes a dicha estación.\nPuedes comprobar que la suma de los cinco valores de la componente estacional obtenidos en la columna Est vale 1.1. Para ajustar la componente estacional para que sume 0, a cada valor de la componente estacional se le resta su suma actual 1.1 dividida por 5, el número de estaciones. El resultado de este ajuste aparece en la columna Est corregida que será la componente estacional final.\nSiguiendo el paso 4, la columna Res se calcula restando a la serie original (columna Serie) la tendencia y la estacionalidad (columnas Ten y Est corregida).\n\nObserva que en el proceso de descomposición se han perdido 4 datos para la tendencia y el residuo, dos al inicio de la serie y dos al final.\n\n\n\n\nTabla 1: Ejemplo de descomposición por medias móviles\n\n\n\n\n\n\nEstacion\nSerie\nTen\nEst + Res\nEst\nEst corregida\nRes\n\n\n\n\n1\n17.00\nNA\nNA\n9.14\n8.92\nNA\n\n\n2\n6.72\nNA\nNA\n-10.89\n-11.11\nNA\n\n\n3\n5.08\n20.62\n-15.54\n-10.06\n-10.28\n-5.48\n\n\n4\n8.79\n27.89\n-19.10\n-9.46\n-9.68\n-9.64\n\n\n5\n65.53\n28.00\n37.53\n22.37\n22.15\n15.16\n\n\n1\n53.31\n28.58\n24.73\n9.14\n8.92\n15.59\n\n\n2\n7.28\n29.79\n-22.51\n-10.89\n-11.11\n-11.62\n\n\n3\n8.00\n25.62\n-17.62\n-10.06\n-10.28\n-7.56\n\n\n4\n14.84\n19.13\n-4.29\n-9.46\n-9.68\n5.17\n\n\n5\n44.67\n20.08\n24.59\n22.37\n22.15\n2.22\n\n\n1\n20.85\n21.78\n-0.93\n9.14\n8.92\n-10.07\n\n\n2\n12.02\n21.64\n-9.62\n-10.89\n-11.11\n1.27\n\n\n3\n16.51\n18.97\n-2.46\n-10.06\n-10.28\n7.60\n\n\n4\n14.14\n22.07\n-7.93\n-9.46\n-9.68\n1.53\n\n\n5\n31.31\n23.08\n8.23\n22.37\n22.15\n-14.14\n\n\n1\n36.37\n24.68\n11.69\n9.14\n8.92\n2.55\n\n\n2\n17.06\n26.66\n-9.60\n-10.89\n-11.11\n1.29\n\n\n3\n24.53\n30.92\n-6.39\n-10.06\n-10.28\n3.67\n\n\n4\n24.02\n30.56\n-6.54\n-9.46\n-9.68\n2.92\n\n\n5\n52.62\n33.48\n19.14\n22.37\n22.15\n-3.23\n\n\n1\n34.59\n33.51\n1.08\n9.14\n8.92\n-8.06\n\n\n2\n31.66\n33.51\n-1.85\n-10.89\n-11.11\n9.04\n\n\n3\n24.65\n32.95\n-8.30\n-10.06\n-10.28\n1.76\n\n\n4\n24.01\nNA\nNA\n-9.46\n-9.68\nNA\n\n\n5\n49.86\nNA\nNA\n22.37\n22.15\nNA\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMedia movil centrada y no centrada\n\n\n\n\n\nCon esta técnica de descomposición hemos usamos la media móvil centrada para extraer la tendencia de la serie. En el tema 4 veremos la media móvil no centrada para predecir la serie.\n\n\n\n\n\nLos principales inconvenientes de este método de descomposición son: i) se perderán datos al inicio y final de la serie –por ejemplo, si la serie es mensual se perderán seis datos al inicio y seis al final; ii) asume que la componente estacional no ha variado en el tiempo, cuando sabemos que para muchas series sociales y de consumo la componente estacional se ha suavizando con el tiempo; y iii) el cálculo de las componentes de tendencia y estacionalidad puede verse muy afectado por la presencia de datos muy anómalos.\nPor el contrario, una de las ventajas de este método, además de su sencillez de cálculo, es que se puede usar tanto para esquemas aditivos (type=\"addi\") como multiplicativos (type=\"multi\").\nLa función decompose genera un objeto con las siguientes componentes:\n\n$x para la serie original,\n$trend para la tendencia,\n$seasonal para la estacionalidad,\n$random para el residuo, y\n$figure que contiene las estimaciones de los m efectos estacionales ajustados. Es una extracción para un único año o semana de $seasonal.\n\nSiempre que generes nuevos objetos en R a partir de funciones te recomiendo que con names y str mires qué hay en su interior.\nEn los métodos de descomposición que vamos a ver, para extraer las componentes individualmente puedes usar la función seasonal para la componente estacional, trendcycle para el componente de tendencia, y remainder para el residuo.\n\n\nEjemplo de esquema aditivo\nVamos a descomponer la serie Demanda eléctrica asumiendo un esquema aditivo (type = \"addi).\n\neleDesAdi &lt;- decompose(electricidad, \n                       type = \"addi\")\n\nautoplot(eleDesAdi,\n         xlab = \"\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 20: Descomposición aditiva de la Demanda eléctrica por medias móviles\n\n\n\n\n\nLa Figura 20 muestra la serie original (panel superior) y sus tres componentes: tendencia (segundo panel), estacionalidad (tercer panel) y el residuo (panel inferior). Por tratarse de un esquema aditivo, la estacionalidad y el residuo se mueven en torno al valor de 0.\nEs fácil verificar que si se suma para cada fecha la tendencia, la estacionalidad y el residuo se obtiene exactamente el valor de la serie:\n\ntmp &lt;- trendcycle(eleDesAdi) + seasonal(eleDesAdi) + remainder(eleDesAdi)\nsummary(electricidad - tmp)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n      0       0       0       0       0       0       6 \n\n\nA continuación, tienes un ejemplo del manejo de las componentes extraídas para hacer una gráfica (véase la Figura 21).\n\nautoplot(electricidad, \n         series=\"Demanda eléctrica\",\n         xlab = \"\",\n         ylab = \"MWh\",\n         main = \"\") +\n  autolayer(trendcycle(eleDesAdi), \n            series=\"Tendencia\") +\n  scale_colour_manual(values=c(\"Demanda eléctrica\"=\"black\",\"Tendencia\"=\"red\"),\n                      breaks=c(\"Demanda eléctrica\",\"Tendencia\"))\n\n\n\n\n\n\n\nFigura 21: Demanda eléctrica: serie y tendencia\n\n\n\n\n\nTambién podemos ver la componente estacional y verificar que suma 0. Ojo, como la serie empieza un domingo, el valor de la primera componente que se muestra es la del domingo y el valor de la última es la del sábado\n\neleDesAdi$figure\n\n[1] -88.89633  10.71022  32.18633  36.60378  35.23633  22.42286 -48.26319\n\nsum(eleDesAdi$figure)\n\n[1] -8.881784e-15\n\n\nPor último, podemos realizar una gráfica de la componente estacional (véase la Figura 22). Como la primera componente estacional es la del domingo, tenemos primero que ordenar las componentes. Esto es lo que hace la primera línea del siguiente código.\n\ncompEstacional &lt;- eleDesAdi$figure[c(2:7, 1)]\nggplot() +\n  geom_line(aes(x = 1:7, y = compEstacional)) + \n  geom_hline(yintercept = 0, colour = \"blue\", lty = 2) +\n  ggtitle(\"\") +\n  xlab(\"\") +\n  ylab(\"GWh\") +\n  scale_x_continuous(breaks= 1:7, \n                     labels = c(\"Lunes\", \"Martes\", \"Miércoles\", \"Jueves\", \n                                \"Viernes\", \"Sábado\", \"Domingo\")) \n\n\n\n\n\n\n\nFigura 22: Componente estacional de Electricidad (esquema aditivo)\n\n\n\n\n\n\n\nEjemplo de Esquema Multiplicativo\nVeamos ahora la descomposición de Nacimientos bajo un esquema multiplicativo (type = \"mult\").\n\nnacDesMul &lt;- decompose(nacimientos, \n                       type = \"mult\")\n\nautoplot(nacDesMul,\n         xlab = \"\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 23: Descomposición multiplicativa de Nacimientos por medias móviles\n\n\n\n\n\nObserva que por tratarse de un esquema multiplicativo en la Figura 23 la componente estacional se mueve alrededor del valor 1 y debe interpretarse como una variación porcentual. Igualmente, el residuo también gira en torno al valor 1.\nLos valores de la componente estacional se deben interpretar como variaciones porcentuales: en febrero nacen un 9.2% menos de niños y en octubre un 3.6% más, respecto de la media anual. Además, la suma de los valores de la componente estacional será 12.\n\nnacDesMul$figure\n\n [1] 0.9960154 0.9083329 1.0061351 0.9806906 1.0299231 0.9824611 1.0372353\n [8] 1.0197587 1.0324610 1.0361829 0.9802669 0.9905370\n\nsum(nacDesMul$figure)\n\n[1] 12"
  },
  {
    "objectID": "03-02-Tema2.html#descomposición-por-regresiones-locales-ponderadas",
    "href": "03-02-Tema2.html#descomposición-por-regresiones-locales-ponderadas",
    "title": "Series Temporales. Definición y componentes",
    "section": "4.3 Descomposición por regresiones locales ponderadas",
    "text": "4.3 Descomposición por regresiones locales ponderadas\n\nIdeas generales\nLa función stl estima las componentes de tendencia y estacionalidad a partir de regresiones locales ponderadas (técnica conocida como loess)\nSus ventajas son:\n\nNo se perderán datos al inicio o al final de la serie.\nAsume que tanto la tendencia como la estacionalidad pueden cambiar con el tiempo y posibilita controlar este cambio a partir de parámetros.\nEs bastante robusta frente a valores atípicos.\n\nSu principal desventaja es que esta técnica de descomposición solo es válida para esquemas aditivos. Es posible obtener con stl una descomposición multiplicativa descomponiendo primero el logaritmo de la serie, para después calcular la exponencial de las componentes.\nLa función stl genera un objeto con la componente $time.series que contiene en columna tres series temporales: seasonal, trend y remainder (de nuevo usa names y str para aprender más).\nLos dos parámetros principales que debes elegir cuando utilices stl son la ventana de tendencia (t.window) y la ventana estacional (s.window). Estos parámetros controlan la rapidez con la que pueden cambiar las componentes de tendencia y estacionalidad con el tiempo. Valores pequeños permiten cambios más rápidos, valores grandes implican que no hay cambios. Ambos parámetros deben ser números impares:\n\nt.window es el número de observaciones consecutivas que se deben utilizar al estimar la tendencia. Consulta la ayuda para ver el valor por defecto.\ns.window está relacionado con el número observaciones que se deben utilizar al estimar cada valor de la componente estacional. No hay ningún valor por defecto para este parámetro. Establecerlo como periodic equivale a que la componente estacional sea periódica (es decir, idéntica a lo largo de los años). Si es un valor numérico, debe ser impar y mayor o igual a 7.\n\n\n\nEjemplo\nVeamos un ejemplo de su uso para la serie Demanda eléctrica (Figura 24). Se ha usado el valor por defecto para t.window y se ha indicado que la estacionalidad es constante en el tiempo (s.window = \"periodic\"). Además, se ha especificado que se tenga en cuenta la posible existencia de valores atípicos (robust = TRUE).\n\neleStl &lt;- stl(electricidad, \n              s.window = \"periodic\",\n              robust = TRUE)\n\nhead(eleStl$time.series, n = 7)\n\nTime Series:\nStart = c(1, 7) \nEnd = c(2, 6) \nFrequency = 7 \n          seasonal    trend   remainder\n1.857143 -91.43206 597.5375   -4.275429\n2.000000  13.80810 610.2002   -6.288319\n2.142857  32.33979 622.8630   17.517258\n2.285714  35.70651 635.4299   13.673593\n2.428571  35.28141 647.9968  -16.168242\n2.571429  26.55179 658.5280 -109.769821\n2.714286 -52.25554 669.0592    3.736320\n\n\n\nautoplot(eleStl,\n         xlab = \"\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 24: Descomposición de Electricidad por regresiones locales ponderadas\n\n\n\n\n\nPodemos comprobar que los valores de la componente estacional suman cero.\n\nsum(head(seasonal(eleStl), 7))\n\n[1] -9.616439e-08\n\n\n\n\nPara Demanda eléctrica hemos obtenido tres estimaciones de la componente estacional: la primera obtenida con tapply, la segunda obtenida con decompose y la tercera con stl. Se puede observar que las tres estimaciones son muy similares, pero no coincidentes, y aunque los métodos de descomposición son preferibles a tapply, ninguna estimación es a priori mejor que otra.\n\n# tapply\nround(as.numeric(componenteEstacional), 2)\n# decompose\nround(seasonal(eleDesAdi)[c(2:7, 1)], 2)\n# stl\nround(seasonal(eleStl)[c(2:7, 1)], 2)\n\n\n\n              L     M     X     J     V      S      D\ntapply    10.29 32.74 36.77 35.67 23.17 -47.56 -89.37\ndecompose 10.71 32.19 36.60 35.24 22.42 -48.26 -88.90\nstl       13.81 32.34 35.71 35.28 26.55 -52.26 -91.43\n\n\n\n\nSi en lugar de periodic, fijamos el parámetro s.window a, por ejemplo, 11 (siempre un valor impar), estaremos permitiendo que la estacionalidad cambien en el tiempo. La Figura 25 muestra la componente estacional estimada previamente (bajo el supuesto de componente estacional constante) y la que se obtiene con el argumento s.window = 11. Para el periodo mostrado se observa que la componente estacional ha variando con el tiempo. Cuanto mayor es el valor (impar) de s.window más constante en el tiempo es la componente estacional.\n\n\n\n\n\n\n\n\nFigura 25: Componente estacional para Demanda eléctrica"
  },
  {
    "objectID": "04-07-Combinando_predicciones.html#footnotes",
    "href": "04-07-Combinando_predicciones.html#footnotes",
    "title": "Combinación de predicciones",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nPara ser rigurosos, solo en un caso un método supera a la media simple, el método Ingenuo I en previsiones a 4 años vista, pero por 1.5 décimas.↩︎"
  },
  {
    "objectID": "01-Guia-curso.html#introducción",
    "href": "01-Guia-curso.html#introducción",
    "title": "Guía del Curso",
    "section": "Introducción",
    "text": "Introducción\nLa asignatura de Predicción con Datos Temporales pertenece al Grado en Inteligencia y Analítica de Negocios y se configura como un módulo impartido en el segundo cuatrimestre de segundo curso con 6 créditos ECTS.\nEl objetivo general es aprender a manejarse con datos de corte temporal, Series Temporales. Es decir, ser capaces de aplicar los métodos para describir, analizar, modelizar y predecir series de datos que evolucionan en el tiempo. Además, hay que saber evaluar la calidad de las predicciones en el contexto de la estadística tradicional y con técnicas de Machine Learning.\nPara ello, veremos la teoría necesaria y, sobre todo, practicaremos utilizando el programa estadístico R y el lenguaje Markdown (o Quarto) a través de RStudio. A estas alturas del grado ya debes estar familiarizado con este programa."
  },
  {
    "objectID": "01-Guia-curso.html#contenidos",
    "href": "01-Guia-curso.html#contenidos",
    "title": "Guía del Curso",
    "section": "Contenidos",
    "text": "Contenidos\nEl programa de la asignatura contiene 7 temas distribuidos entre sesiones teóricas de una hora y prácticas de tres horas:\n\nTema 1. Introducción\nTema 2. Definición y componentes\nTema 3. Métodos de predicción\nTema 4. Series sin tendencia ni estacionalidad\nTema 5. Evaluación de las predicciones\nTema 6. Series con tendencia y sin estacionalidad\nTema 7. Series con estacionalidad (Alisado)\nTema 8. Series con estacionalidad (Arima)\n\nPasar de un tema al siguiente supone incrementar la complejidad en las técnicas empleadas para el análisis y predicción de una serie temporal. Además, dentro de los temas 4 y 6 a 8 se verán tres métodos de predicción de forma que podréis valorar con datos reales la relación entre complejidad–tiempo–resultados y optar por la metodología más adecuada."
  },
  {
    "objectID": "01-Guia-curso.html#metodología",
    "href": "01-Guia-curso.html#metodología",
    "title": "Guía del Curso",
    "section": "Metodología",
    "text": "Metodología\nDado el carácter eminentemente práctico del curso, la mayoría de las clases se impartirán haciendo uso constante del ordenador y alternaremos entre teoría y práctica según convenga:\n\nTiempo de teoría: durante las clases teóricas, de una hora de duración, veremos conceptos nucleares de cada tema de forma precisa y rigurosa, en lenguaje natural, gráfico y formal. El material teórico lo podéis encontrar en la sección Diapos.\nTambién aprovecharemos algunas clases de teoría para ampliar en algunos conceptos que no forman parte del núcleo del curso, pero pueden serte útiles en tu futuro profesional. Este material lo podéis encontrar en Píldoras.\nTiempo de práctica: durante las clases prácticas también veremos algo de teoría (material en Diapos), pero inmediatamente la practicaremos a partir del código y de los ficheros de datos que podéis encontrar en la sección Recursos de la asignatura. Aprenderemos el manejo de R para el análisis de series temporales.\nTiempo de evaluación: tras cada tema realizaréis una prueba tipo test para valorar si habéis adquirido los conocimientos teóricos y las habilidades practicas básicas. Sin embargo, el grueso de la evaluación consistirá en dos trabajos prácticos. Estas pruebas serán la evaluación continua del curso.\n\n\n\nVenid siempre a clase con vuestros ordenadores.\nTodo el material necesario para este curso lo tenéis disponible en esta página web así como en Aula Virtual. También podéis encontrar los detalles en la sección Logística de la web."
  },
  {
    "objectID": "01-Guia-curso.html#evaluación",
    "href": "01-Guia-curso.html#evaluación",
    "title": "Guía del Curso",
    "section": "Evaluación",
    "text": "Evaluación\nLa evaluación continua supondrá un 80% de la nota de la asignatura.\n\nTras cada una de las unidades temáticas se realizará una prueba tipo test con preguntas de respuesta múltiple, numérica, verdadero/falso, etc. (40%)\nRealizaréis trabajos prácticos que cubrirán los conceptos vistos en clase. (40%)\nDe la evaluación continua solo son recuperables los trabajos prácticos de cara a la segunda convocatoria, pero no lo serán las pruebas tipo test.\nTienes más información en Evaluación Continua\n\nEl examen final de la asignatura supondrá el restante 20% de la nota de la asignatura."
  },
  {
    "objectID": "06-Evaluacion_Continua.html",
    "href": "06-Evaluacion_Continua.html",
    "title": "Evaluación continua",
    "section": "",
    "text": "Durante todo el curso realizarás una serie de pruebas de evaluación continua que aplicarán las técnicas vistas en cada tema. Hay dos tipos de pruebas\n\n\n\nPruebas tipo test\n\nLa prueba la realizarás en clase al finalizar cada tema teórico (os avisaré con antelación) y consistirá en un documento PDF con preguntas (unas 10) tipo test o de respuestas numérica.\nLa prueba contendrá una plantilla de respuestas que deberás cumplimentar y entregar al final de la clase.\nLa nota de cada prueba se subirá a Aulavirtual.\n\n\n\n\n\nTrabajos prácticos\n\nDurante el curso realizarás trabajos que aplicarán las técnicas vistas.\nPara empezar, la primera tarea es descargarte tu serie temporal. Descárgate aquí el fichero .pdf con la descripción de las series y localiza en él el nombre de tu serie. En este fichero encontrarás también una descripción de la serie que vas a analizar: nombre, definición, unidades, fuente, fechado…\nPor otro lado, descárgate aquí el fichero comprimido con todas las series, descomprímelo y localiza el fichero ‘’csv’’ con tu serie.\nLa fecha máxima de entrega de cada trabajo se indicará con tiempo. Procura no retrasarte.\nEn Aulavirtual, en la tarea “Practica evaluación n” deberás subir un fichero .pdf con los resultados de la práctica n-ésima. Sólo se admite un único fichero en formato pdf.\nPiensa que además de los contenidos también su ordenación, estructura, sintaxis, comentarios, etc. son parte de la evaluación.\nIncluye siempre todo el código en R utilizado en el trabajo. Dado que utilizas Rmarkdown, haz que el código sea visible.\n\n\n\nLa media ponderada de las notas de estos test y trabajos será el 80% de la nota de la asignatura (40% + 40%), el restante 20% se obtendrá a partir del examen."
  },
  {
    "objectID": "04-05-Valores_perdidos_Outliers.html#footnotes",
    "href": "04-05-Valores_perdidos_Outliers.html#footnotes",
    "title": "Valores perdidos y valores atípicos",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nLos métodos sencillos de previsión y los modelos ARIMA funcionan perfectamente con valores perdidos, pero la función ets para Alisado exponencial o las funciones stlf y tbats, para trabajar con series con más de una componente estacional, no funcionan si hay valores perdidos.↩︎\nEl nombre de la función na.interp viene de unir na de not available (valor perdido) e interp de interpolación.↩︎\nPuedes leer más detalles sobre el proceso de identificación de valores atípicos usado por la función tsoutlier pinchando aquí↩︎"
  },
  {
    "objectID": "03-03-Tema3.html#footnotes",
    "href": "03-03-Tema3.html#footnotes",
    "title": "Métodos de predicción",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRealmente la metodología de media móvil si permite predecir series con tendencia, pero su uso en este contexto es realmente escaso, poco intuitivo y da resultados muy pobres.↩︎"
  },
  {
    "objectID": "04-08-Series_interumpidas.html#uso-de-modelos-muy-adaptativos",
    "href": "04-08-Series_interumpidas.html#uso-de-modelos-muy-adaptativos",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de modelos muy adaptativos",
    "text": "Uso de modelos muy adaptativos\nAlgunos modelos, por su naturaleza, reaccionan muy rápidamente ante cambios en la estructura de la serie, adaptándose a ellos. Uno de estos modelos es el Alisado exponencial.\nCuando los parámetros de un modelo de Alisado están próximos a 1, el modelo usa preferentemente la información más reciente de la serie para ajustarse y predecir. De esta forma, ante una perturbación en la serie, estos modelos pueden ajustarse a ella con sencillez y rapidez.\nLa ventaja de esta estrategia es que simplemente hay que usar un modelo conocido, que es muy sencillo y muy rápido computacionalmente. Además, el ajuste y predicción con estos modelos es automático. La desventaja principal de los modelos de Alisado es que tardan algunos periodos en adaptarse, así que si los cambios se producen de forma constante, el modelo estará constantemente inadaptado."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#uso-de-intervención",
    "href": "04-08-Series_interumpidas.html#uso-de-intervención",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de intervención",
    "text": "Uso de intervención\nSi la perturbación no es excesivamente compleja, puede incluirse en el proceso de ajuste como intervención de un modelo Arima.\nEsta estrategia implica que tenemos un buen entendimiento de la perturbación: punto de inicio y final, efecto sobre la serie temporal, etc.\nSu ventaja de nuevo es que trabajamos con modelos ya conocidos y, además, que podremos estimar la estructura de la tendencia y la estacionalidad pasadas y sus cambios con la perturbación. Ahora bien, el modelo asumirá que el comportamiento de la serie tras la perturbación es similar al observado antes de la perturbación. Si esto no es cierto, las predicciones serán del todo incorrectas. Pero incluso si el supuesto es cierto y las previsiones son acertadas, su intervalo de confianza será más estrecho de lo correcto."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos",
    "href": "04-08-Series_interumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Fijar las observaciones durante la perturbacion como valores perdidos",
    "text": "Fijar las observaciones durante la perturbacion como valores perdidos\nUna aproximación más radical consiste en fijar como valores perdidos todas las observaciones de la serie temporal durante el periodo de la perturbación y ajustar un modelo a la serie resultante. Las predicciones que se realicen con este modelo serían las correspondientes a una realidad donde la perturbación no ha tenido lugar.\nUna ventaja de esta aproximación es que no se usa información durante el periodo de la perturbación, por lo que el intervalo de confianza de las predicciones será amplio durante la perturbación y tras ella, y no se irá estrechando hasta que haya suficientes datos como para estimar la distribución de las predicciones con más precisión.\nEntre las desventajas de este método están que solo se pueden usar modelos que permitan estimar con datos perdidos, por ejemplo modelos Arima, y que es necesario identificar en que periodo se inicia y termina la perturbación."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si",
    "href": "04-08-Series_interumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Trabajar bajo el escenario qué hubiera pasado si",
    "text": "Trabajar bajo el escenario qué hubiera pasado si\nEsta estrategia en un poco más elaborada que las ya mencionadas dado que toma elementos de varias de ellas. La idea básica es obtener la serie temporal que correspondería a un escenario donde la perturbación no ha tenido lugar y usar esta serie para predecir.\nPara el primer paso, obtener una serie completa donde la perturbación no ha tenido lugar tenemos dos alternativas:\n\nTerminamos la serie justo antes de la perturbación, la ajustamos a un modelo y hacemos predicciones durante todo el periodo de la perturbación. Estas predicciones sustituirán los valores reales de la serie, las que han tenido lugar durante a la perturbación.\nAsignamos como valores perdidos los datos de la serie durante la perturbación y ajustamos un modelo. Luego sustituimos los valores reales de la serie durante el periodo de la perturbación por los valores estimados por el modelo durante este mismo periodo.\n\nEn cualquiera de los dos casos, el resultado es una nueva serie que coincide con la original fuera de los periodos de la perturbación y durante la perturbación toma valores que hubieran podido tener lugar en un escenario donde esta no ha ocurrido.\nEsta nueva serie se ajusta por un modelo que, posteriormente, se usa para obtener las predicciones.\nLógicamente, esta estrategia comparte las ventajas y desventajas de las estrategias que usa para su implementación."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#uso-de-modelos-muy-adaptativos-1",
    "href": "04-08-Series_interumpidas.html#uso-de-modelos-muy-adaptativos-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de modelos muy adaptativos",
    "text": "Uso de modelos muy adaptativos\nObserva que esta aproximación básicamente consiste en no hacer nada más allá de elegir un método muy adaptativo. Por este motivo compararemos los resultados obtenidos con Alisado, un modelo muy adaptativo, y con Arima, un modelo muy poco adaptativo.\nLa Figura 2 muestra el resultado de aplicar Alisado y Arima a los datos. Las predicciones para 2020 se han realizado antes de que el efecto de la Covid-19 tenga lugar y siguen el patrón de pernoctaciones observado en el pasado. Ambos métodos ofrecen prácticamente las mismas predicciones y ambos sobrestiman la realidad.\nLas predicciones para 2021 se realizan después de observar 9 meses de fuerte caída de las pernoctaciones como efecto de la Covid-19 y ambos modelos se ajustan a esta caída. Sin embargo, ninguno es capaz de captar la recuperación ocurrida en las pernoctaciones en 2021, de forma que las previsiones de ese año se quedan por debajo de la realidad. Para el año 2022 ambos modelos son capaces de reconocer el incremento en la pernoctaciones ocurrida en los pasados meses, pero de nuevo no captan que las pernoctaciones seguirán creciendo y vuelven a realizar previsiones por debajo de la realidad. Si en 2021 las predicciones mejores son las obtenidas con Arima, en el año siguiente son la de Alisado.\nPara 2023 Alisado se ha adaptado plenamente a la casi completa recuperación ocurrida en 2022 y sus predicciones son razonablemente buenas. Por el contrario Arima realiza unas predicciones muy bajas debido a que el modelo identificado usa datos no solo de 2022 sino de años pasados. Por este mismo motivo las predicciones con Arima de 2024 vuelven a ser muy bajas. Además, sorprende lo elevadas de las predicciones de Alisado, que por lo demás repiten razonablemente bien el patrón observado en los dos años previos.\nEn general, ninguno de los dos métodos lo hace especialmente bien, aunque con el método de Alisado se obtienen mejores predicciones una vez la perturbación ha pasado.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 2: Modelos adaptativos. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando modelos de Alisado y Arima."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#uso-de-intervención-1",
    "href": "04-08-Series_interumpidas.html#uso-de-intervención-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de intervención",
    "text": "Uso de intervención\nAplicaremos la estrategia de la intervención usando el modelo Arima. Con tal fin vamos a crear dos variables de intervención: un primer cambio de nivel asociado al año de la pandemia, que empieza en marzo de 2020 y termina en diciembre de 2020; y un segundo cambio de nivel para el año 2021, desde enero hasta diciembre.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 3: Intervención. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando el modelo Arima.\n\n\n\nLa Figura 3 muestra las predicciones y el intervalo de confianza al 90%. Las predicciones para 2020, realizadas sin conocimiento de la próxima pandemia, siguen el patrón observado en el pasado. Como hasta 2019 la serie era muy regular, el ajuste es muy bueno y el intervalo de confianza de las predicciones estrecho.\nLas predicciones para 2021 se realizan tras casi un año de caída en las pernoctaciones con un modelo que estima la magnitud de esta caída a partir de la variable de intervención cambio de nivel en 2020. La predicción para 2021 se corrige a la baja por la mitad de esta magnitud estimada, porque asumimos que habrá una recuperación en el turismo, pero aun así en general se subestima fuertemente la realidad. Además, se observa un intervalo de predicción mucho más ancho debido al aumento de la incertidumbre en el comportamiento de la serie. Para las predicciones del año 2022 de nuevo se aplica la mitad de la caída en las pernoctaciones estimada con la variable de intervención cambio de nivel de 2021 porque otra vez asumimos que la recuperación del turismo continua. En este caso las previsiones a veces se quedan por debajo y otras por encima de la realidad. Además, los dos años de perturbación y cambios en el patrón de la serie se reflejan en un intervalo de confianza para las predicciones aun más amplio.\nDurante 2022 la serie ha regresado casi a la normalidad. Además, para las predicciones de 2023 ya no se aplican ninguno de los cambios de nivel estimados. El resultado son unas predicciones mucho mejores que las obtenidas previamente aunque su amplio intervalo de confianza evidencia que todavía pesa mucho la incertidumbre observada en el pasado, con tres años consecutivos de cambios en la estructura de la serie.\nLa predicciones de 2024 reproducen de forma imperfecta el patrón observado en la pernoctaciones los dos últimos años. Se observa que la variación estacional de las predicciones es mucho más suave que la real. La amplitud del intervalo de confianza es menor que el observado para las predicciones de 2023 debido a que la regularidad en la serie de los dos últimos años ha reducido la incertidumbre."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos-1",
    "href": "04-08-Series_interumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Fijar las observaciones durante la perturbacion como valores perdidos",
    "text": "Fijar las observaciones durante la perturbacion como valores perdidos\nAsignar a valores perdidos las observaciones durante el periodo de la perturbación es una forma radical de resolver el problema, pero muy sencilla de implementar. Asumiremos que el efecto de la pandemia se inició en marzo de 2020 y terminó en febrero de 2022. Las 24 observaciones de este periodo se asignarán como NA y la serie resultante se ajustará a un modelo Arima, sin necesidad de incluir intervención.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 4: Valores perdidos. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando el modelo Arima.\n\n\n\nLa Figura 4 muestra las predicciones y el intervalo de confianza al 90%. Para los cuatro primeros años la predicción muestra lo que hubiera pasado sin la pandemia de la Covid-19, basándose en el comportamiento de las pernoctaciones hasta 2019. Para los años 2020 y 2021 las predicciones sobrestiman tremendamente la realidad. Pero para el año 2022, cuando el efecto de la pandemia casi había pasado, las predicciones se ajustan mucho más a la serie, aunque la siguen sobrestimando ligeramente. Además, cuanto más alejado es el horizonte temporal de las predicciones, mayor es la incertidumbre y, por tanto, más amplio es el intervalo de confianza.\nFinalmente, en 2023 las predicciones se ajustan muy bien a la realidad, y para el año 2024 las predicciones, similares a la obtenidas para el año previo, posiblemente sigan siendo muy precisas."
  },
  {
    "objectID": "04-08-Series_interumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si-1",
    "href": "04-08-Series_interumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Trabajar bajo el escenario qué hubiera pasado si",
    "text": "Trabajar bajo el escenario qué hubiera pasado si\nPara el escenario qué hubiera pasado si vamos a estimar un modelo Arima bajo el escenario previo (asignar a valores perdidos las observaciones durante el periodo de la perturbación), y usarlo para estimar que podría haber pasado durante la pandemia. Después, estimamos un segundo modelo Arima con toda la nueva serie y lo usamos para obtener las predicciones.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 5: Qué hubiera pasado si. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando el modelo Arima.\n\n\n\nBajo este escenario las predicciones resultan similares a las obtenidas bajo el supuesto previo con asignación de valores perdidos (véase Figura 5). Sin embargo, los intervalos de confianza son más estrechos. Al sustituir los valores perdidos por valores ajustados, el modelo estimado posteriormente trabaja con una serie muy regular sin incertidumbre y esto se refleja en la amplitud del intervalo de confianza."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Predicción con Datos Temporales (36519). Grado en Inteligencia y Analítica de Negocios (GBIA)",
    "section": "",
    "text": "Hola a tod@s y bienvenid@s a la página web del curso.\nEsta es la página web de la edición 2024-25 del curso de Predicción con Datos Temporales (GBIA) de la Universitat de València. El repositorio para crear esta web lo tenéis aquí en Github.\nResumen del curso: la idea principal es aprender a manejarse con datos con estructura temporal, en contraposición a los datos de corte transversal (que has visto en el primer semestre con Paco Goerlich) o espacial (que verás el proximo curso). Veremos como describir una serie temporal, como ajustarla a un modelo, como hacer predicciones y, lo que es más importante, a valorar la calidad de las predicciones desde un enfoque de Machine Learning.\nPara más información de este módulo, por favor visita la Guía del curso en esta misma página web o descárgate la Guía Docente desde la web de la Universitat de València.\n– Iván Arribas"
  },
  {
    "objectID": "index.html#license",
    "href": "index.html#license",
    "title": "Predicción con Datos Temporales (36519). Grado en Inteligencia y Analítica de Negocios (GBIA)",
    "section": "License",
    "text": "License\nThis online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International. Visit here for more information about the license."
  },
  {
    "objectID": "04-06-Covid_Nacimientos.html#ajuste-a-un-modelo-y-predicción",
    "href": "04-06-Covid_Nacimientos.html#ajuste-a-un-modelo-y-predicción",
    "title": "Efecto de la Covid-19 sobre la serie Nacimientos",
    "section": "Ajuste a un modelo y predicción",
    "text": "Ajuste a un modelo y predicción\nVamos a considerar la serie de nacimientos desde enero de 2000 hasta octubre de 2020, ajustarla a un modelo ARIMA y predecir hasta diciembre de 2022.\nEl siguiente código estima el mismo modelo visto en el tema de ARIMA con estacionalidad para la serie nacimientos. La única diferencia es que en esta ocasión la serie alcanza hasta septiembre de 2020. El ajuste, con un error porcentual del 1.5% es muy bueno.\n\nnacimientos2 &lt;- window(nacimientos, \n                       end = c(2020, 10))\n\nDiasMes &lt;- monthdays(nacimientos2)\nSemanaSanta &lt;- easter(nacimientos2)\n\nd1206 &lt;- 1*(cycle(nacimientos2) == 12 & trunc(time(nacimientos2)) == 2006)\nd1210 &lt;- 1*(cycle(nacimientos2) == 12 & trunc(time(nacimientos2)) == 2010)\nd0111 &lt;- 1*(cycle(nacimientos2) == 1 & trunc(time(nacimientos2)) == 2011)\nd0416 &lt;- 1*(cycle(nacimientos2) == 4 & trunc(time(nacimientos2)) == 2016)\n\nd12100111 &lt;- d1210 - d0111\n\nmodelo &lt;- Arima(nacimientos2, \n                 order = c(0, 1, 1),\n                 seasonal = c(0, 1, 1),\n                 lambda = 0,\n                 xreg = cbind(DiasMes, SemanaSanta, \n                              d1206, d12100111, d0416))\n\nsummary(modelo)\n\nSeries: nacimientos2 \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasMes  SemanaSanta    d1206  d12100111    d0416\n      -0.4952  -0.7600   0.0291      -0.0218  -0.0464     0.0587  -0.0548\ns.e.   0.0577   0.0452   0.0072       0.0050   0.0158     0.0099   0.0166\n\nsigma^2 = 0.0003897:  log likelihood = 593.76\nAIC=-1171.52   AICc=-1170.89   BIC=-1143.78\n\nTraining set error measures:\n                   ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -76.3823 703.4119 566.7356 -0.2259197 1.546594 0.4148193\n                   ACF1\nTraining set 0.01576144\n\n\nAhora vamos a predecir la serie desde noviembre de 2020 hasta diciembre de 2022 (26 meses).\n\ntmp &lt;- ts(rep(0, 26), start = c(2020, 11), freq = 12)\npdm &lt;- monthdays(tmp)\npss &lt;- easter(tmp)\nprediccion &lt;- forecast(modelo, \n                       h = 26,\n                       xreg = cbind(pdm, pss, \n                                    rep(0, 26), rep(0, 26), rep(0, 26)))\n\nLa Figura 2 muestra la serie original de nacimientos desde 2018 y la predicción. Por la metodología seguida, desde noviembre de 2020 disponemos para cada mes de dos datos: los nacimientos en el mundo real con Covid (observaciones) y los nacimientos en un mundo sin Covid (previsiones).\n\nautoplot(nacimientos,\n         xlab = \"\",\n         ylab = \"Nacimientos\",\n         main = \"\", \n         series = \"Con Covid\") + \n  xlim(2018, 2023) +\n  ylim(20000, 35000) + \n  autolayer(prediccion, series = \"Sin Covid\", PI = FALSE) + \n  labs(colour = \"Nacimientos\") + \n  theme(legend.position=c(0.9,0.85)) \n\n\n\n\n\n\n\nFigura 2: Nacimientos mensuales (enero 2018 - diciembre 2022) y previsiones (noviembre 2020 - diciembre 2022)\n\n\n\n\n\nUna lectura rápida de la Figura 2 muestra que efectivamente, el número observado de nacimientos entre noviembre de 2020 y febrero de 2021 (en rojo) fue muy inferior a los valores esperados (en azul). Sin embargo, el resto del año 2021 el número de nacimientos fue superior al esperado, apuntando a un ligero efecto rebote. En 2022 el efecto de la pandemia no parece haber desaparecido totalmente, observándose que el número de nacimientos real superaba la mayoría de los meses el valor predicho. Veamos estas observaciones en detalle.\nEfecto del confinamiento sobre los nacimientos {-}\nEn primer lugar veamos cuál ha sido la caída en el número de nacimientos entre noviembre de 2020 y febrero de 2021.\n\nCon_covid &lt;- as.numeric(window(nacimientos, \n                               start = c(2020, 11), \n                               end = c(2021, 2)))\nSin_covid &lt;- as.numeric(window(prediccion$mean, \n                               start = c(2020, 11), \n                               end = c(2021, 2)))\n\n# Caida porcentual\nround(100 * (Con_covid - Sin_covid)/Con_covid, 1)\n\n[1]  -6.9 -20.8 -19.6  -3.6\n\n#Caida en el total de nacidos\nsum(Con_covid - Sin_covid)\n\n[1] -12294.93\n\n\nLa mayor caída porcentual en el número de nacimientos tuvo lugar en los meses de diciembre de 2020 y enero de 2021 (20.8% y 19.6%, respectivamente) y nuestras estimaciones coinciden con las aportadas en González (2021) y Blanes, Domingo, and Esteve (2021). Respecto del número de nacimientos, nosotros estimamos una reducción de 12300 nacidos, un valor algo inferior a la estimación en González (2021) y muy superior a la estimación en Blanes, Domingo, and Esteve (2021)."
  },
  {
    "objectID": "04-06-Covid_Nacimientos.html#efecto-rebote",
    "href": "04-06-Covid_Nacimientos.html#efecto-rebote",
    "title": "Efecto de la Covid-19 sobre la serie Nacimientos",
    "section": "Efecto rebote",
    "text": "Efecto rebote\nUna posibilidad es que el confinamiento no hizo que las parejas decidieran no tener hijos de forma permanente, sino que simplemente retrasó la decisión de tenerlos. Si esto es así, cabria esperar a mediados o finales de 2021 un número de nacimientos superior al esperado: por una lado tendríamos los nacimientos de las parejas que tenían pensado tener hijos en ese momento y por otro los de las parejas que habían retrasado el momento de la maternidad. Si es así, la Covid no habría reducido de forma permanente el número de nacimientos y el acumulado en el medio/largo plazo seria el mismo que si no hubiera habido Covid.\nPara poder responder mejor a esta pregunta, vamos a calcular la diferencia acumulada entre el número de nacimientos esperado y el real desde noviembre de 2020 hasta diciembre de 2022. La diferencia acumulada crece hasta los 12300 bebés en febrero de 2021. Esta diferencia máxima se va reduciendo lentamente hasta los 3900 bebés en diciembre de 2021. Es decir, efectivamente parece que hay un efecto rebote que ha compensado a lo largo del año 2021 en un total de 8400 bebés la caída hasta febrero de ese año.\nDurante el año 2022 la diferencia acumulada ha seguido reduciéndose hasta desaparecer hacia agosto de 2022. Sin embargo, en los siguientes meses esta diferencia se hace negativa, alcanzado los -2800 bebes en diciembre de 2022. Este último resultado apunta a que durante 2022 el número de nacimientos ha sido inferior al esperado. Es aun difícil identificar la causa, que puede ir desde el error propio de nuestras previsiones para 2022, al efecto que la inestabilidad política y económica pueda tener sobre la decisión de las parejas de tener hijos (guerra ruso-ucraniana, incremento de los precios energéticos, inflación…).\n\nCon_covid &lt;- window(nacimientos, start = c(2020, 11))\nSin_covid &lt;- window(prediccion$mean, start = c(2020, 11))\n\nDiferencia &lt;- cumsum(Sin_covid - Con_covid)\nDiferencia &lt;- ts(Diferencia, \n                 start = c(2020, 11),\n                 frequency = 12)\n\n\nautoplot(Diferencia,\n         xlab = \"\",\n         ylab = \"Nacimientos\",\n         main = \"\") + \n  geom_hline(yintercept = 0, col = \"red\") + \n  xlim(2020.7, 2023) +\n   scale_x_continuous(breaks= seq(2020 + 11/12, 2022 + 11/12, 3/12),\n                     label = c(\"Dic-20\", \n                               \"Mar-21\", \"Jun-21\", \"Sep-21\", \"Dic-21\", \n                               \"Mar-22\", \"Jun-22\", \"Sep-22\", \"Dic-22\"))\n\n\n\n\n\n\n\nFigura 3: Déficit acumulado de nacimientos desde noviembre de 2020"
  },
  {
    "objectID": "03-15-Ejemplo5.html#series-interrumpida",
    "href": "03-15-Ejemplo5.html#series-interrumpida",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "2.1 Series interrumpida",
    "text": "2.1 Series interrumpida\nLa Figura 1 evidencia el fuerte impacto de la pandemia sobre el turismo en general y sobre las pernoctaciones de turistas internacionales en particular. Tanto la tendencia de la serie como su patrón estacional volaron por los aires a partir de marzo de 2020 con las medidas de confinamiento establecidas en España y en la mayoría de países del mundo. Este tipo de series recibe el nombre de series interrumpidas, haciendo referencia a que su estructura (tendencia y componente estacional) se han visto abrúptamente interrumpida durante un periodo prolongado de tiempo.\nExisten múltiples estrategias para analizar las series interrumpidas.1 Una posible estrategia es ajustar la serie por un proceso Arima donde se modeliza el periodo que abarca la perturbación mediante intervención. Sin embargo, el efecto de la pandemia sobre la serie de pernoctaciones es tan complejo que su modelización a través de variables artificiales resulta muy compicado. Como evidencia de esta complejidad, si ajustamos la serie con la función seas, que también identifica intervención, nos encontramos con 14 intervenciones durante el periodo de la pandemia (años 2020 y 2021), en concreto 6 pulsos y 8 cambios de nivel.\nUna estrategia alternativa consiste en fijar como valores perdidos todas las observaciones del periodo de la perturbación. Después se ajusta la nueva serie, que incluye los valores perdidos, por un modelo Arima. Finalmente, el modelo ajustado se utiliza para realizar las predicciones. En este ejemplo vamos a seguir esta estrategia.\nAsumiremos que el efecto de la pandemia afectó el turismo internacional durante dos años, desde marzo de 2020 a febrero de 2021. Por tanto, vamos a crear una nueva serie idéntica a la original, excepto que para este periodo las observaciones se fijaran como valores perdidos o NA en R. Véase Figura 2.\n\n# Identificamos el periodo de dos años de la perturbación\nfechas &lt;- format(seq(as.Date(\"2000-01-01\"), as.Date(\"2023-12-31\"), by = \"month\"), \n                 \"%Y-%m\")\n\ncovid &lt;- format(seq(as.Date(\"2020-03-01\"), as.Date(\"2022-02-28\"), by = \"month\"), \n                \"%Y-%m\")\n\ncovid_filtro &lt;- fechas %in% covid\n\n# Creamos una nueva serie...\nPernoctacionesp &lt;- Pernoctaciones\n\n#...y durante la perturbacion asignamos NA\nPernoctacionesp[covid_filtro] &lt;- NA\n\n\nautoplot(Pernoctacionesp,\n         xlab = \"\",\n         ylab = \"Noches (millones)\",\n         main = \"\") +\n  scale_x_continuous(breaks= seq(2000, 2024, 2))  \n\n\n\n\n\n\n\nFigura 2: Pernoctaciones asignando NA durante la Covid-19\n\n\n\n\n\nEl análisis siguiente se va a realizar sobre la serie Pernoctaciones con valores perdidos (Pernoctacionesp)."
  },
  {
    "objectID": "03-15-Ejemplo5.html#diferenciación-y-logaritmo",
    "href": "03-15-Ejemplo5.html#diferenciación-y-logaritmo",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "2.2 Diferenciación y logaritmo",
    "text": "2.2 Diferenciación y logaritmo\nEl esquema multiplicativo de la serie aconseja el uso de la transformación logarítmica. Además, vamos a ver que para que la serie sea estacionaria es necesario diferenciarla tanto regular como estacionalmente, así que el uso de logaritmo vuelve a ser aconsejable si queremos ganar en interpretabilidad.\nLa Figura 3 muestra la FAC para la serie Pernoctaciones (log). En los paneles (a) y (b) las autocorrelaciones estacionales decrecen muy lentamente, indicando que la serie analizada no es ergódica. El panel (c) muestra que las autocorrelaciones en la parte regular decrecen lentamente, indicando que la serie analizada no es estacionaria. Solo la doble diferenciación regular y estacional de la serie muestra un rápido descenso en los coeficiente de autocorrelación (panel d), indicando que la serie así transformada es estacionaria en media y ergódica.\n\nggAcf(log(Pernoctacionesp), lag = 48, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(Pernoctacionesp)), lag = 48,  ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(Pernoctacionesp), lag = 12), lag = 48,  ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(diff(log(Pernoctacionesp), lag=12)), lag = 48,  ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n(a) Log serie\n\n\n\n\n\n\n\n\n\n\n\n(b) Dif. regular log serie\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Dif. estacional log serie\n\n\n\n\n\n\n\n\n\n\n\n(d) Dif. regular y estacional log serie\n\n\n\n\n\n\n\nFigura 3: FAC para Pernoctaciones\n\n\n\n\nPor otro lado, la identificación automática de la diferenciación también concluye que es necesaria la doble diferenciación.\n\nndiffs(log(Pernoctacionesp))\n\n[1] 1\n\nnsdiffs(log(Pernoctacionesp))\n\n[1] 1\n\n\nVamos a asumir que el proceso debe ser doblemente diferenciado \\(\\log(Pernoctaciones) \\sim I(1)I_{12}(1)\\)."
  },
  {
    "objectID": "03-15-Ejemplo5.html#identificación-del-orden-regular-y-estacional",
    "href": "03-15-Ejemplo5.html#identificación-del-orden-regular-y-estacional",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "2.3 Identificación del orden regular y estacional",
    "text": "2.3 Identificación del orden regular y estacional\nVamos a identificar los valores de \\(p\\), \\(q\\), \\(P\\) y \\(Q\\). Para ello solicitaremos con auto.arima y seas una identificación automática.\nCon auto.arima incluiremos dos efectos calendarios, uno para el número de días del mes y otro para el efecto Semana Santa.\n\nDiasMes &lt;- monthdays(Pernoctacionesp)\nSemanaSanta &lt;- easter(Pernoctacionesp)\n\nauto.arima(Pernoctacionesp, \n           d = 1, \n           D = 1,\n           lambda = 0,\n           xreg = cbind(DiasMes, SemanaSanta))\n\nSeries: Pernoctacionesp \nRegression with ARIMA(1,1,0)(2,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ar1     sar1     sar2     sma1  DiasMes  SemanaSanta\n      -0.2230  -0.0274  -0.1578  -0.4009   0.0257       0.0422\ns.e.   0.0631   0.2308   0.1106   0.2296   0.0090       0.0055\n\nsigma^2 = 0.000898:  log likelihood = 521.2\nAIC=-1028.41   AICc=-1027.99   BIC=-1003.09\n\n\nLa función auto.arima identifica un proceso \\(ARIMA_{12}(1,1,0)(2,1,1)\\), donde claramente los dos coeficientes del proceso autoregresivo estacional no son significativos. Las variables de intervención consideradas si que parecen ser significativas.\nLa identificación alcanzada por seas es un proceso \\(ARIMA_{12}(0,1,1)(0,1,1)\\) (modelo de las aerolíneas) forzando la transformación logarítmica, con intervención en Semana Santa y efecto días laborables. Además, identifica un pulso en mayo de 2011, asociado a la erupción de un volcán en Islandia que obligó a cerrar temporalmente el espacio aéreo en varios países de Europa, y un cambio de nivel en marzo de 2005 sin justificación aparente.\nLas 24 variables de intervención encabezadas por MV (de missing values) son variables ficticias creadas para ajustar el periodo de la pandemia y se obtienen gracias al argumento na.action = na.x13 incluido en la función seas. El valor de estas variables puede interpretarse como las pernoctaciones (en millones) si no hubiera habido pandemia.\n\nmodeloSeas &lt;- seas(Pernoctacionesp, \n                   transform.function = \"log\", \n                   na.action = na.x13)\n\nsummary(modeloSeas)\n\n\nCall:\nseas(x = Pernoctacionesp, transform.function = \"log\", na.action = na.x13)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \nMV2020.Mar        17.8863152  0.0231353 773.119  &lt; 2e-16 ***\nMV2020.Apr        17.6602383  0.0286619 616.157  &lt; 2e-16 ***\nMV2020.May        17.4000410  0.0327312 531.604  &lt; 2e-16 ***\nMV2020.Jun        17.2799543  0.0358888 481.486  &lt; 2e-16 ***\nMV2020.Jul        17.0990580  0.0383742 445.587  &lt; 2e-16 ***\nMV2020.Aug        17.0520030  0.0402931 423.199  &lt; 2e-16 ***\nMV2020.Sep        17.2672454  0.0417032 414.051  &lt; 2e-16 ***\nMV2020.Oct        17.4621608  0.0426819 409.123  &lt; 2e-16 ***\nMV2020.Nov        18.0592630  0.0432768 417.297  &lt; 2e-16 ***\nMV2020.Dec        18.1694257  0.0434951 417.735  &lt; 2e-16 ***\nMV2021.Jan        18.1285402  0.0432008 419.634  &lt; 2e-16 ***\nMV2021.Feb        18.1300293  0.0423988 427.607  &lt; 2e-16 ***\nMV2021.Mar        17.9505843  0.0423421 423.942  &lt; 2e-16 ***\nMV2021.Apr        17.7598635  0.0430507 412.534  &lt; 2e-16 ***\nMV2021.May        17.4747368  0.0433431 403.172  &lt; 2e-16 ***\nMV2021.Jun        17.3596616  0.0432327 401.540  &lt; 2e-16 ***\nMV2021.Jul        17.1699652  0.0427657 401.489  &lt; 2e-16 ***\nMV2021.Aug        17.1246390  0.0419100 408.605  &lt; 2e-16 ***\nMV2021.Sep        17.3404670  0.0405943 427.165  &lt; 2e-16 ***\nMV2021.Oct        17.5263248  0.0388435 451.203  &lt; 2e-16 ***\nMV2021.Nov        18.1234554  0.0364898 496.671  &lt; 2e-16 ***\nMV2021.Dec        18.2302970  0.0335239 543.800  &lt; 2e-16 ***\nMV2022.Jan        18.1901944  0.0295497 615.580  &lt; 2e-16 ***\nMV2022.Feb        18.1842982  0.0238885 761.215  &lt; 2e-16 ***\nWeekday           -0.0009833  0.0003453  -2.848 0.004403 ** \nEaster[8]          0.0432220  0.0046439   9.307  &lt; 2e-16 ***\nLS2005.Mar        -0.0834733  0.0221809  -3.763 0.000168 ***\nAO2011.May        -0.0654725  0.0173227  -3.780 0.000157 ***\nMA-Nonseasonal-01  0.1919044  0.0588886   3.259 0.001119 ** \nMA-Seasonal-12     0.4337516  0.0545799   7.947 1.91e-15 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 288  Transform: log\nAICc:  1329, BIC:  1433  QS (no seasonality in final):    0  \nBox-Ljung (no autocorr.): 37.31 * Shapiro (normality): 0.9969  \n\n\nVemos que ambas identificaciones difieren en su parte regular. Así, vamos a partir de la identificación obtenida por seas, el clásico modelo de las aerolíneas: \\[log(Pernoctaciones) \\sim ARIMA_{12}(0,1,1)(0,1,1).\\]\nRespecto de la intervención, incluiremos días del mes y Semana Santa y las dos intervenciones localizadas por seas antes de la pandemia. Sin embargo, consideraremos ambas intervenciones como pulsos. Por un lado, nada justifica el cambio de nivel sugerido por seas a partir de marzo de 2005. Por otro lado, la estimación de un modelo solo con los dos efectos calendario genera dos errores muy pronunciados (mayores de 3 desviaciones típicas) en marzo de 2005 y mayo de 2011."
  },
  {
    "objectID": "03-15-Ejemplo5.html#calidad-de-ajuste",
    "href": "03-15-Ejemplo5.html#calidad-de-ajuste",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "7.1 Calidad de ajuste",
    "text": "7.1 Calidad de ajuste\nLa serie Pernoctaciones la hemos ajustado por el método ingenuo con estacionalidad, el método de Alisado Exponencial y procesos ARIMA. La Tabla 1 recoge el error medio (RMSE) y porcentual (MAPE) al usar estas tres aproximaciones con la serie original y su transformación logarítmica.\n\n\n\nTabla 1: Criterios de calidad para previsiones intramuestrales a un periodo vista. Varios modelos\n\n\n\n\n\n\n\n\n\n\n\nSerie\nMétodo\nRMSE (miles)\nMAPE (%)\n\n\n\n\nPernoctaciones\nIngenuo\n1347\n4.90\n\n\nPernoctaciones\nAlisado\n785\n3.42\n\n\nlog(Pernoctaciones)\nAlisado\n733\n2.63\n\n\nPernoctaciones\nARIMA\n633\n2.51\n\n\nlog(Pernoctaciones)\nARIMA\n640\n2.19\n\n\n\n\n\n\nPodemos extraer varias conclusiones: i) la transformación logarítmica no mejora necesariamente el ajuste de los datos; ii) el proceso Arima con transformación logarítmica es el modelo con mejor ajuste; y iii) el método de Alisado con transformación logarítmica muestra una calidad de ajuste comparable a la de los modelos Arima. La mejora en el ajuste de los modelos Arima respecto del método de Alisado se debe a la incorporación de variables ficticias para recoger la intervención y los efectos calendario."
  },
  {
    "objectID": "03-15-Ejemplo5.html#predicciones-extramuestrales",
    "href": "03-15-Ejemplo5.html#predicciones-extramuestrales",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "7.2 Predicciones extramuestrales",
    "text": "7.2 Predicciones extramuestrales\nVamos a determinar si también la aplicación de modelos Arima mejora la calidad de las predicciones extra-muestrales lo suficiente como para justificar su uso –frente a los métodos de alisado, mucho más sencillos. Para ello, aplicaremos la metodología de origen de predicción móvil para estimar la capacidad predictiva del modelo Arima y compararla con el modelo de Alisado y el ingenuo con estacionalidad.\n\nk &lt;- 120                   \nh &lt;- 12                    \nT &lt;- length(Pernoctacionesp)     \ns &lt;- T - k - h               \n\nmapeIngenuo &lt;- matrix(NA, s + 1, h)\nmapeAlisado &lt;- matrix(NA, s + 1, h)\nmapeAlisadoLog &lt;- matrix(NA, s + 1, h)\nmapeArima &lt;- matrix(NA, s + 1, h)\nmapeArimaLog &lt;- matrix(NA, s + 1, h)\n\n\nX &lt;- data.frame(cbind(DiasMes, SemanaSanta))\n\nfor (i in 0:s) {\n  train.set &lt;- subset(Pernoctaciones, start = i + 1, end = i + k)\n  test.set &lt;-  subset(Pernoctaciones, start = i + k + 1, end = i + k + h) \n  \n  train.setp &lt;- subset(Pernoctacionesp, start = i + 1, end = i + k)\n  test.setp &lt;-  subset(Pernoctacionesp, start = i + k + 1, end = i + k + h) \n  \n  X.train &lt;- as.matrix(X[(i + 1):(i + k),])\n  X.test &lt;- as.matrix(X[(i + k + 1):(i + k + h),])\n  \n  #Ingenuo\n  fit &lt;- snaive(train.set, h = h)\n  mapeIngenuo[i + 1,] &lt;- 100*abs(test.set - fit$mean)/test.set\n  \n  #Alisado sin log\n  fit &lt;- ets(train.set, model = \"AAA\", damped = TRUE)\n  fcast &lt;- forecast(fit, h = h) \n  mapeAlisado[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n  #Alisado con log\n  fit &lt;- ets(train.set, model = \"AAA\", damped = TRUE, lambda = 0)\n  fcast &lt;- forecast(fit, h = h) \n  mapeAlisadoLog[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n  #ARIMA sin log\n  fit &lt;- try(Arima(train.setp, \n                   order = c(0, 1, 1),\n                   seasonal = c(0, 1, 1),\n                   xreg = X.train), \n             silent = TRUE)\n  \n  if (!is.element(\"try-error\", class(fit))) {\n    fcast &lt;- forecast(fit, h = h, xreg = X.test)\n    mapeArima[i + 1,] &lt;- 100*abs(test.setp - fcast$mean)/test.setp\n  }\n  \n  #ARIMA con log\n  fit &lt;- try(Arima(train.setp, \n                   order = c(0, 1, 1),\n                   seasonal = c(0, 1, 1),\n                   lambda = 0,\n                   xreg = X.train),\n             silent = TRUE)\n  \n  if (!is.element(\"try-error\", class(fit))) {\n    fcast &lt;- forecast(fit, h = h, xreg = X.test) \n    mapeArimaLog[i + 1,] &lt;- 100*abs(test.setp - fcast$mean)/test.setp\n  }\n  \n}\n\nmapeIngenuo &lt;- apply(mapeIngenuo, MARGIN = 2, FUN = median)\nmapeAlisado &lt;- apply(mapeAlisado, MARGIN = 2, FUN = median)\nmapeAlisadoLog &lt;- apply(mapeAlisadoLog, MARGIN = 2, FUN = median)\nmapeArima &lt;- apply(mapeArima, MARGIN = 2, FUN = median, na.rm = TRUE, )\nmapeArimaLog &lt;- apply(mapeArimaLog, MARGIN = 2, FUN = median, na.rm = TRUE)\n\n\nggplot() +\n  geom_line(aes(x = 1:12, y = mapeIngenuo, colour = \"Ingenuo\")) +\n  geom_line(aes(x = 1:12, y = mapeAlisado, colour = \"Alisado\")) + \n  geom_line(aes(x = 1:12, y = mapeAlisadoLog, colour = \"Alisado (log)\")) +\n  geom_line(aes(x = 1:12, y = mapeArima, colour = \"Arima\")) +\n  geom_line(aes(x = 1:12, y = mapeArimaLog, colour = \"Arima (log)\")) +\n  ggtitle(\"\") +\n  xlab(\"\") +\n  ylab(\"MAPE\") +\n  scale_x_continuous(breaks= 1:12) +\n  scale_color_discrete(name = \"Modelos\")\n\n\n\n\n\n\n\nFigura 6: Errores de previsión extra-muestral. Varios modelos\n\n\n\n\n\nLa Figura 6 revela que Arima, con o sin transformación logarítmica, es superior a Alisado en calidad de predicciones.\nTambién se observa que la transformación logarítmica mejora notablemenre la calidad de las predicciones en los modelos de Alisado y Arima\nEl error con el método Ingenuo parece independiente del horizonte temporal."
  },
  {
    "objectID": "03-15-Ejemplo5.html#footnotes",
    "href": "03-15-Ejemplo5.html#footnotes",
    "title": "Pernoctaciones en alojamientos turísticos de turistas extranjeros",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nVéase la píldora Series interrumpidas para profundizar más en las estrategias que se pueden seguir para analizar y predecir series que han sufrido una larga perturbación en su estructura.↩︎"
  },
  {
    "objectID": "04-02-Multiples_CS.html#descomposición",
    "href": "04-02-Multiples_CS.html#descomposición",
    "title": "Múltiples componentes estacionales",
    "section": "Descomposición",
    "text": "Descomposición\nPodemos descomponer la serie de forma análoga a como se hacia para series con una componente estacional usando la función mstl.\n\ndescomposicion &lt;- mstl(electricidad)\nautoplot(descomposicion) \n\n\n\n\n\n\n\nFigura 2: Descomposición de Consumo eléctrico por hora\n\n\n\n\n\nEn la Figura 2 aparecen los mismos paneles que has visto en el Tema 2 –datos originales, tendencia y residuo–, más los dos paneles correspondientes a las dos componentes estacionales, de orden 24 y 168 (Seasonal24 y Seasonal168).\nPara poder interpretar adecuadamente cada serie hay que fijarse en la escala de los ejes verticales. La tendencia apenas cambia en el periodo de análisis. Las dos componentes estacionales oscilan sobre un rango de valores mayor. Dentro de cada día el consumo de electricidad oscila aproximadamente 20 GW entre las horas pico y las valle (Seasonal24): en los picos se consumen unos 7.5 GW más que la media diaria, y en los valles unos 12.5 GW menos que la media diaria. Por otro lado, el rango de variación semanal en el consumo también es de aproximadamente 20 GW (Seasonal168): de lunes a viernes se consumen como máximo unos 5 GW más que la media semanal y los domingo unos 15 GW menos.\nVamos a mostrar un detalle de la componente estacional diaria, semanal y su composición para la primera semana de la serie (véase Figura 3).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Componente estacional diaria\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Componente estacional semanal\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Componente estacional diaria + semanal\n\n\n\n\n\n\n\nFigura 3: Componentes estacionales para Consumo eléctrico"
  },
  {
    "objectID": "04-02-Multiples_CS.html#predicción-a-partir-de-la-descomposición-y-alisado-exponencial",
    "href": "04-02-Multiples_CS.html#predicción-a-partir-de-la-descomposición-y-alisado-exponencial",
    "title": "Múltiples componentes estacionales",
    "section": "Predicción a partir de la descomposición y Alisado exponencial",
    "text": "Predicción a partir de la descomposición y Alisado exponencial\nExisten varios métodos para poder estimar series con estacionalidad múltiple. Uno de los más sencillos consiste en descomponer de la serie. Después, predecir las componentes estacionales por simple repetición y predecir la componente de la tendencia usando Alisado exponencial. En último lugar, se combinan la predicción de la tendencia con las predicciones de las estacionalidades para obtener una predicción de la serie.\nLa función stlf hace todas estas operaciones de forma automática. Por defecto la tendencia se predice usando Alisado exponencial (“ets”), pero con el argumento method se pueden especificar otros modelos alternativos, “arima”, “naive” o “rwdrift”.\nEn la Figura 4 se muestra el resultado de aplicar stlf a la serie de consumo eléctrica. La línea negra representa la serie y la línea azul su predicción para las dos semanas siguientes (dos primeras semanas de marzo de 2021). El título por defecto de la figura indica que la tendencia de la serie se ha ajustado usando la función ets y presenta una pendiente aditiva amortiguada y error multiplicativo.\n\npdatos_stfl &lt;- stlf(electricidad)\n\nautoplot(pdatos_stfl, PI = FALSE) + \n  ylab(\"GW\") + \n  xlab(\"Semanas\") + \n  scale_x_continuous(breaks = seq(1, 7, by = 1))\n\n\n\n\n\n\n\nFigura 4: Consumo eléctrico y predicción. Descomposición + Alisado"
  },
  {
    "objectID": "04-02-Multiples_CS.html#predicción-a-partir-de-asilado-exponencial-y-series-de-furier",
    "href": "04-02-Multiples_CS.html#predicción-a-partir-de-asilado-exponencial-y-series-de-furier",
    "title": "Múltiples componentes estacionales",
    "section": "Predicción a partir de Asilado Exponencial y series de Furier",
    "text": "Predicción a partir de Asilado Exponencial y series de Furier\nUno de los inconvenientes del método visto es que estima todos los elementos de cada componente estacional (\\(24 + 168\\) elementos en nuestro ejemplo) como si fueran independientes, sin tener en cuenta que, por lo general, evolucionan siguiendo una suave curva. Véase en el panel (a) de la Figura 3 la curva que sigue la estacionalidad diaria, donde la componente de una hora determinada está muy relacionada con la componente de la hora precedente y posterior.\nAlgunos métodos alternativos de predicción usan la dependencia observada entre los elementos de una componente estacional para ajustarlos a una curva paramétrica, por ejemplo funciones trigonométricas o series de Fourier.\nEntre los métodos que usan funciones trigonométricas está el implementado en Livera, Hyndman, and Snyder (2011). El método de estimación que emplean estos autores es complejo, requiere tiempo de computación y no siempre el ajuste obtenido es el más adecuado, así que los resultados pueden ser en ocasiones elevados.\nVeamos un ejemplo de la implementación de este método con la función tbats. La Figura 5 muestra la predicción para dos semanas.\n\ntmp &lt;- Sys.time()\n\ndatos_tbats &lt;- tbats(electricidad)\n\npdatos_tbats &lt;- forecast(datos_tbats, \n                         h = 14 * 24,\n                         level = 95)\n\nautoplot(pdatos_tbats, PI = FALSE) + \n  ylab(\"GW\") + \n  xlab(\"Semanas\") + \n  scale_x_continuous(breaks = seq(1, 7, by = 1))\n\n(tiempo &lt;- Sys.time() - tmp)\n\nTime difference of 35.48402 secs\n\n\n\n\n\n\n\n\nFigura 5: Consumo eléctrico y predicción. Ajuste de las componentes estacionales por funciones trigonométricas\n\n\n\n\n\n\n\nEl título de la figura indica el modelo TBATS estimado. Su interpretación precisa la podéis encontrar en Livera, Hyndman, and Snyder (2011). Observa que la estimación del modelo ha requerido de 35 segundos.\nEntre los métodos que involucran series de Fourier una propuesta reciente es el modelo Prophet, disponible a través del paquete fable.prophet. Este modelo fue introducido por Facebook (Taylor and Letham (2018)) originalmente para pronosticar datos diarios con estacionalidad semanal y anual, además de efectos calendario. Posteriormente se amplió para cubrir más tipos de datos estacionales."
  },
  {
    "objectID": "03-08-Tema8.html#diferenciación-estacional",
    "href": "03-08-Tema8.html#diferenciación-estacional",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "2.1 Diferenciación estacional",
    "text": "2.1 Diferenciación estacional\nLa diferencia estacional consiste en restar a la observación de un periodo la observación precedente de la misma estación. Si el orden estacional es \\(m\\), entonces la diferencia estacional de \\(y_t\\) es \\[\\nabla_m y_t = y_t - y_{t-m}.\\] Una serie no estacionaria en media puede pasar a serlo tras diferenciarla estacionalmente. En general, cualquiera de las dos diferenciaciones vistas (regular o estacional) o ambas a la vez son alternativas para obtener la estacionariedad.\nLa Figura 1 muestra un ejemplo de diferenciación regular y/o estacional. En el primer panel aparece la serie original Nacimientos \\(y_t\\); el segundo panel muestra la serie diferenciada regularmente \\(\\nabla y_t\\); en el tercer panel la serie diferenciada estacionalmente \\(\\nabla_{12} y_t\\); y en el cuarto panel muestra la serie diferenciada regular y estacionalmente \\(\\nabla\\nabla_{12} y_t\\).\n\n\n\n\n\n\n\n\nFigura 1: Nacimientos mensuales y diferenciaciones\n\n\n\n\n\n¿Qué transformación para nacimientos consideras que genera una serie estacionaria, tanto en media como en varianza? Siempre hay un cierto grado de subjetividad en la elección de las diferencias que hay que aplicar a una serie. En la Figura 1 podemos considerar que la diferenciación regular (panel 2) es suficiente para lograr la estacionariedad en media, pero no parece que la serie generada sea estacionaria en varianza. La diferenciación estacional (panel 3) ni siquiera es suficiente para que la serie sea estacionaria en media. Finalmente, si optamos por la doble diferenciación, regular y estacional (panel 4), tenemos el proceso que más claramente verifica las hipótesis de estacionariedad en media y en varianza.\nPor último, indicar que la diferenciación (regular, estacional o ambas) también permite alcanzar la ergodicidad.\n\nDiferenciación con R\nEn el Tema 6 vimos la función diff(x, lag = k) que calculaba la diferencia de orden k y la usamos para obtener la diferencia regular \\(\\nabla y_t = y_t - y_{t-1}\\) como diff(\\(y_t\\)).\nPor tanto, si \\(m\\) es el orden estacional, diff(x, lag = m) calcula la diferencia estacional. Si necesitas calcular una diferencia regular y otra estacional, \\(\\nabla\\nabla_m y_t\\), debes usar diff(diff(x, lag = m)). El orden de las diferenciaciones no cambia el resultado.\nAdemás, en forecast está disponible la función nsdiffs que estima el número de diferencias estacionales necesarias usando un criterio ad-hoc. Esta función complementa a ndiffs, usada ya para determinar el número de diferencias regulares. Veamos que indican para la serie Nacimientos\n\nndiffs(nacimientos)\n\n[1] 1\n\nnsdiffs(nacimientos)\n\n[1] 1"
  },
  {
    "objectID": "03-08-Tema8.html#diferencia-logaritmo-y-tasa-de-variación",
    "href": "03-08-Tema8.html#diferencia-logaritmo-y-tasa-de-variación",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "2.2 Diferencia, Logaritmo y Tasa de variación",
    "text": "2.2 Diferencia, Logaritmo y Tasa de variación\nYa vimos que la diferencia regular del logaritmo es una tasa de variación, \\(\\nabla \\log(y_t) =TV y_t\\). Por ejemplo, para una serie mensual, la diferencia regular del logaritmo es la Tasa de Variación Mensual de la serie: \\(\\nabla \\log(y_t)=TVM y_t\\). Para una serie diaria, la diferencia regular del logaritmo sería la tasa de variación diaria.\nSi se opta por la diferencia estacional, entonces \\(\\nabla_m \\log(y_t) \\approx \\frac{y_t - y_{t-m}}{y_{t-m}}\\). Es decir, para una serie mensual la diferencia estacional del logaritmo es la Tasa de Variación Anual de la serie: \\(\\nabla_{12} \\log(y_t)=TVA y_t\\). Igualmente, para una serie diaria, la diferencia estacional de su logaritmo sería la tasa de variación semanal.\nCuando una serie tiene que ser diferenciada tanto regular como estacionalmente para conseguir su estacionariedad, podemos escribir\n\\[\\nabla_m \\nabla \\log(y_t) = \\nabla_m TV y_t = TV y_t - TV y_{t-m},\\] que para una serie mensual se puede interpretar como una diferencia estacional de tasas mensuales \\(TVM y_t - TVM y_{t-12}\\). Es decir, como cambia de año en año la tasa de variación mensual.\nTambién podemos escribir\n\\[\\nabla \\nabla_m \\log(y_t) = \\nabla TV_m y_t = TV_m y_t - TV_m y_{t-1},\\]\nque para una serie mensual se puede interpretar como una diferencia regular de tasas anuales \\(TVA y_t - TVA y_{t-1}\\). Es decir, Es decir, como cambia de mes en mes la tasa de variación anual.\n\n\n\n\n\n\n\n\nLa diferenciacion y el logaritmo en series con estacionalidad\n\n\n\n\nSi se tiene una serie con estacionalidad y no estacionaria, lo usual es tener que diferenciarla una vez (regular o estacionalmente) o aplicar ambas diferenciaciones para que sea estacionaria en media, en varianza y ergódica.\nSi hay una doble diferenciación, la transformación logarítmica se puede usar para ganar en interpretabilidad o para intentar mejorar las predicciones.\nLa transformación logarítmica no es necesaria para alcanzar la estacionariedad de la serie."
  },
  {
    "objectID": "03-08-Tema8.html#procesos-autorregresivos-ar_mp",
    "href": "03-08-Tema8.html#procesos-autorregresivos-ar_mp",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "4.1 Procesos autorregresivos \\(AR_m(P)\\)",
    "text": "4.1 Procesos autorregresivos \\(AR_m(P)\\)\n\nDefinición\nEl modelo general autorregresivo estacional de orden P, \\(y_t \\sim AR_m(P)\\) viene definido por \\[y_t=c + \\phi_m y_{t-m} + \\phi_{2m} y_{t-2m} + \\ldots + \\phi_{Pm} y_{t-Pm} + \\varepsilon_t,\\] que usando el operador retardo queda \\[(1 - \\phi_m L^m - \\phi_{2m} L^{2m} - \\ldots - \\phi_{Pm} L^{Pm})y_t = c + \\varepsilon_t.\\]\n\n\nEjemplos\n\n\\(y_t \\sim AR_{12}(1):\\;\\;y_t = c + \\phi_{12} y_{t-12} + \\varepsilon_t\\) o \\((1 - \\phi_{12} L^{12})y_t = c + \\varepsilon_t\\)\n\\(y_t \\sim AR_7(2):\\;\\;y_t = c + \\phi_7 y_{t-7} + \\phi_{14} y_{t-14} + \\varepsilon_t\\) o \\((1 - \\phi_7 L^7 - \\phi_{14} L^{14})y_t = c + \\varepsilon_t\\)"
  },
  {
    "objectID": "03-08-Tema8.html#procesos-en-medias-móviles-ma_mq",
    "href": "03-08-Tema8.html#procesos-en-medias-móviles-ma_mq",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "4.2 Procesos en medias móviles \\(MA_m(Q)\\)",
    "text": "4.2 Procesos en medias móviles \\(MA_m(Q)\\)\n\nDefinición\nEl modelo general en medias móviles estacional de orden Q, \\(y_t \\sim MA_m(Q)\\) viene definido por \\[y_t=c + \\varepsilon_t + \\theta_m \\varepsilon_{t-m} + \\theta_{2m} \\varepsilon_{t-2m} + \\ldots +\n  \\theta_{Qm} \\varepsilon_{t-Qm},\\] que usando el operador retardo queda \\[y_t = c + (1 + \\theta_m L^m + \\theta_{2m} L^{2m} + \\ldots + \\theta_{Qm} L^{Qm}) \\varepsilon_t.\\]\n\n\nEjemplos\n\n\\(y_t \\sim MA_7(1):\\;\\;y_t = c + \\varepsilon_t + \\theta_7 \\varepsilon_{t-7}\\) o \\(y_t = c + (1 + \\theta_7 L^7)\\varepsilon_t\\)\n\\(y_t \\sim MA_{12}(2):\\;\\;y_t=c + \\varepsilon_t + \\theta_{12} \\varepsilon_{t-12} + \\theta_{24} \\varepsilon_{t-24}\\) o \\(y_t = c + (1 + \\theta_{12} L^{12} + \\theta_{24} L^{24})\\varepsilon_t\\)"
  },
  {
    "objectID": "03-08-Tema8.html#procesos-arma_mpq",
    "href": "03-08-Tema8.html#procesos-arma_mpq",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "4.3 Procesos \\(ARMA_m(P,Q)\\)",
    "text": "4.3 Procesos \\(ARMA_m(P,Q)\\)\n\nDefinición\nEl modelo general \\(y_t \\sim ARMA_m(P,Q)\\) viene definido por\n\\[ y_t = c + \\phi_m y_{t-m} + \\phi_{2m} y_{t-2m} + \\ldots + \\phi_{Pm} y_{t-Pm}  +\n  \\varepsilon_t + \\theta_m \\varepsilon_{t-m} + \\theta_{2m} \\varepsilon_{t-2m} + \\ldots +\n  \\theta_{Qm} \\varepsilon_{t-Qm},\n\\] que usando el operador retardo queda\n\\[(1 - \\phi_m L^m - \\ldots - \\phi_{Pm} L^{Pm})y_t = c + (1 + \\theta_m L^m + \\ldots + \\theta_{Qm} L^{Qm}) \\varepsilon_t.\\]\n\n\nEjemplos\n\n\\(y_t \\sim ARMA_7(1, 1):\\;\\;y_t = c + \\phi_7 y_{t-7} + \\theta_7 \\varepsilon_{t-7} + \\varepsilon_{t}\\) o \\((1 - \\phi_7 L^7)y_t = c + (1 + \\theta_7 L^7)\\varepsilon_t\\).\n\\(y_t \\sim ARMA_{12}(1, 1):\\;\\;y_t = c + \\phi_{12} y_{t-12} + \\theta_{12} \\varepsilon_{t-12} + \\varepsilon_{t}\\) o \\((1 - \\phi_{12} L^{12})y_t = c + (1 + \\theta_{12} L^{12})\\varepsilon_t\\)."
  },
  {
    "objectID": "03-08-Tema8.html#procesos-arima_mpdq",
    "href": "03-08-Tema8.html#procesos-arima_mpdq",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "4.4 Procesos \\(ARIMA_m(P,D,Q)\\)",
    "text": "4.4 Procesos \\(ARIMA_m(P,D,Q)\\)\nSi la serie \\(y_t\\) no es estacionaria en su parte estacional, pero tras diferenciarla \\(D\\) veces se hace estacionaria, diremos que la serie es integrada estacionalmente de orden \\(D\\): \\(y_t \\sim I_m(D)\\). Por tanto,\n\nuna serie estacionaria estacionalmente se indicará como \\(y_t \\sim I_m(0)\\).\n\\(y_t \\sim I_m(1)\\) es equivalente a \\(\\nabla_m y_t = (1 - L^m)y_t \\sim I_m(0)\\)\n\nUna serie \\(y_t\\) sigue un proceso \\(ARIMA_m(P,D,Q)\\) si:\n\nhay que diferenciarla estacionalmente \\(D\\) veces para hacerla estacionaria, \\(y_t \\sim I_m(D)\\); y\nla serie diferenciada sigue un proceso ARMA(P, Q), \\(\\nabla_m^D y_t \\sim ARMA_m(P,Q)\\).\n\nEntonces, podemos escribir \\(y_t \\sim ARIMA_m(P,D,Q)\\) como \\[\\begin{equation*}\n\\begin{array}{c@{\\quad}ccc}\n  (1 - \\phi_m L^m - \\ldots - \\phi_{Pm} L^{Pm}) & (1- L^m)^D y_t & = & c + (1 + \\theta_m L^m + \\ldots + \\theta_{Qm} L^{Qm}) \\varepsilon_t \\\\\n  \\uparrow                                     & \\uparrow       &   & \\uparrow \\\\\n   AR_m(P)                                     & I_m(D)         &   & MA_m(Q)\n\\end{array}\n\\end{equation*}\\]\n\nEjemplo\n\n\\(y_t \\sim ARIMA_{12}(1, 1, 1):\\;\\;(1 - \\phi_{12} L^{12})(1- L^{12}) y_t = c + (1 + \\theta_{12} L^{12}) \\varepsilon_t\\) o \\(y_t = c + y_{t-12} + \\phi_{12}(y_{t-12} - y_{t-24}) + \\theta_{12} \\varepsilon_{t-12} + \\varepsilon_t\\).\n\\(log(y_t) \\sim ARIMA_{12}(1, 1, 1):\\;\\;(1 - \\phi_{12} L^{12})(1- L^{12}) log(y_t) = (1 - \\phi_{12} L^{12})TVAy_t  = c + (1 + \\theta_{12} L^{12}) \\varepsilon_t\\) o \\(TVAy_t = c + \\phi_{12}TVAy_{t-12} + \\theta_{12} \\varepsilon_{t-12} + \\varepsilon_t\\)."
  },
  {
    "objectID": "03-08-Tema8.html#proceso-arima_mpdqpdq",
    "href": "03-08-Tema8.html#proceso-arima_mpdqpdq",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "4.5 Proceso \\(ARIMA_m(p,d,q)(P,D,Q)\\)",
    "text": "4.5 Proceso \\(ARIMA_m(p,d,q)(P,D,Q)\\)\nLa realidad nos muestra que la mayoría de las series con estacionalidad se ajustan a una combinación de procesos regulares y estacionales.\nEl proceso \\(ARIMA_m(p, d, q)(P, D, Q)\\) puede ser expresado como \\[\\begin{equation*}\n\\begin{array}{ccccc}\n  AR(p) & AR_m(P) & I(d) & I_m(D) &  \\\\\n  \\downarrow & \\downarrow & \\downarrow & \\downarrow  &  \\\\\n  (1 - \\phi_1 L - \\ldots - \\phi_p L^p) & (1 - \\phi_m L^m - \\ldots - \\phi_{Pm} L^{Pm}) & (1 - L)^d & (1- L^m)^Dy_t & = \\\\\n  c + (1 + \\theta_1 L + \\ldots + \\theta_q L^q) & (1 + \\theta_m L^m + \\ldots + \\theta_{Qm} L^{Qm}) \\varepsilon_t & & & \\\\\n  \\uparrow & \\uparrow & & & \\\\\n  MA(q) & MA_m(Q)  & & &\n\\end{array}\n\\end{equation*}\\]\nPor ejemplo, entre las series mensuales uno de los procesos más comunes es \\(ARIMA_{12}(0, 1, 1)(0, 1, 1)\\), denominado modelo de las aerolíneas por ser el proceso generador de datos de muchas series mensuales de transporte de pasajeros, en concreto la serie mensual de pasajeros de avión. La ecuación de este modelo es\n\\[(1-L)(1-L^{12})y_t = (1+ \\theta_1L)(1 + \\theta_{12}L^{12})\\varepsilon_t\\] que si desarrollamos queda \\[y_t = y_{t-1} + (y_{t-12} - y_{t-13}) + \\theta_1 \\varepsilon_{t-1} + \\theta_{12} \\varepsilon_{t-12} + \\theta_{1}\\theta_{12} \\varepsilon_{t-13} + \\varepsilon_t \\]\n\nEl número de pasajeros del mes \\(t\\) es el mismo que el del mes previo \\(t-1\\), más la diferencia entre estos meses observada el año pasado.\nSi en los meses usados para la predicción (\\(t-1\\), \\(t-12\\) y \\(t-13\\)) ha ocurrido algo extraordinario, hay que tenerlo en cuenta a la hora de afinar la predicción.\n\nSi usamos la transformación logarítmica, tendríamos \\[(1-L)(1-L^{12})\\log(y_t) = (1+ \\theta_1L)(1 + \\theta_{12}L^{12})\\varepsilon_t\\] o \\[(1-L)TVAy_t = (1+ \\theta_1L)(1 + \\theta_{12}L^{12})\\varepsilon_t\\] que desarrollando queda \\[TVAy_t = TVAy_{t-1} + \\theta_1 \\varepsilon_{t-1} + \\theta_{12} \\varepsilon_{t-12} + \\theta_{1}\\theta_{12} \\varepsilon_{t-13} + \\varepsilon_t \\]\n\nLa tasa de variación anual en el número de pasajeros del mes \\(t\\) es la misma que la del mes previo \\(t-1\\).\nSi en los meses usados para la predicción (\\(t-1\\), \\(t-12\\) y \\(t-13\\)) ha ocurrido algo extraordinario, hay que tenerlo en cuenta a la hora de afinar la predicción."
  },
  {
    "objectID": "03-08-Tema8.html#nacimientos",
    "href": "03-08-Tema8.html#nacimientos",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "5.1 Nacimientos",
    "text": "5.1 Nacimientos\nVamos a aplicar la metodología de Box-Jenkins a la serie de nacimientos en España desde el año 2000 (véase Figura 3).\n\nnacimientos &lt;- read.csv2(\"./series/Nacimientos.csv\", \n                         header = TRUE)\n\nnacimientos &lt;- ts(nacimientos[, 2],\n                  start = c(1975, 1),\n                  freq = 12)\n\nnacimientos &lt;- window(nacimientos, start = 2000)\n\nautoplot(nacimientos,\n         xlab = \"\",\n         ylab = \"Nacimientos\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 3: Nacimientos mensuales\n\n\n\n\n\n\nTransformación de la serie\nPara nacimientos las funciones ndiffs y nsdiffs sugieren la doble diferenciación regular y estacional para alcanzar la estacionariedad.\n\nndiffs(nacimientos)\n\n[1] 1\n\nnsdiffs(nacimientos)\n\n[1] 1\n\n\nVeamos ahora que transformación es necesaria para que sea ergódica. Además, trabajaremos con el logaritmo de la serie para ganar en interpretabilidad.\nExcepcionalmente se ha fijado la escala del eje OY desde -1 a 1 (argumento ylim) en las cuatro FAC para mejorar su comparación e interpretación. A la hora de comparar gráficas, fíjate si la escala es la misma.\n\nggAcf(log(nacimientos), lag = 48, ylim = c(-1,1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(nacimientos)), lag = 48, ylim = c(-1,1), \n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(nacimientos), lag = 12), lag = 48, ylim = c(-1,1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(diff(log(nacimientos), lag = 12)), lag = 48, ylim = c(-1,1),\n      xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Serie\n\n\n\n\n\n\n\n\n\n\n\n(b) Diferencia regular\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Diferencia estacional\n\n\n\n\n\n\n\n\n\n\n\n(d) Diferencia regular y estacional\n\n\n\n\n\n\n\nFigura 4: FAC para Nacimientos (log)\n\n\n\n\nPara que la serie sea estacionaria y ergódica es necesaria la doble diferenciación regular y estacional. Es decir, trabajaremos con la siguiente serie transformada \\[\\nabla\\nabla_{12}\\log(nacimientos_t) \\sim I(0)I_{12}(0).\\]\n\n\nIdentificación\n¿Qué nos indica auto.arima? Primero vamos a generar e incluir en el proceso de autoidentificación las variables asociadas a los efectos de intervención que hemos detectado en los temas previos. En concreto, hemos visto que el número de días del mes explica el número de nacimientos. Este efecto era muy claro para los meses de febrero bisiestos. Para el calculo de la variable que recoge el número de días del mes usaremos la función monthdays de la librería forecast que devuelve el número de días de cada mes o trimestre de una serie.\n\nmonthdays(nacimientos)\n\n\n\n     Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec\n2000  31  29  31  30  31  30  31  31  30  31  30  31\n2001  31  28  31  30  31  30  31  31  30  31  30  31\n2002  31  28  31  30  31  30  31  31  30  31  30  31\n2003  31  28  31  30  31  30  31  31  30  31  30  31\n2004  31  29  31  30  31  30  31  31  30  31  30  31\n\n\nPor otro lado, los periodos vacacionales pueden afectar la programación de las cesáreas e influir en el número de nacimientos. Como la Semana Santa es un periodo festivo que puede caer en marzo o abril, dependiendo del año, los nacimientos en estos dos meses pueden variar según como cae la Semana Santa. Para capturar este efecto, usaremos la función easter de la librería forecast que devuelve para cada mes la proporción de días de la Semana Santa que contiene (considerando solo del Viernes Santo al Domingo de Resurrección, tres días).\n\neaster(nacimientos)\n\n\n\n      Jan  Feb  Mar  Apr  May  Jun  Jul  Aug  Sep  Oct  Nov  Dec\n2015 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2016 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2017 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2018 0.00 0.00 0.67 0.33 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n2019 0.00 0.00 0.00 1.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00\n\n\nAdemás, vimos en el tema de Alisado que en enero de 2011, diciembre de 2020 y febrero y marzo de 2021 el número de nacimientos era atípico.\n\nDiasMes &lt;- monthdays(nacimientos)\nSemanaSanta &lt;- easter(nacimientos)\nd0111 &lt;- 1*(cycle(nacimientos) == 1  & trunc(time(nacimientos)) == 2011)\nd1220 &lt;- 1*(cycle(nacimientos) == 12 & trunc(time(nacimientos)) == 2020)\nd0221 &lt;- 1*(cycle(nacimientos) == 2  & trunc(time(nacimientos)) == 2021)\nd0321 &lt;- 1*(cycle(nacimientos) == 3  & trunc(time(nacimientos)) == 2021)\n\nauto.arima(nacimientos, \n           d = 1, \n           D = 1, \n           lambda = 0,\n           xreg = cbind(DiasMes, SemanaSanta, \n                        d0111, d1220, d0221, d0321))\n\nSeries: nacimientos \nRegression with ARIMA(0,1,2)(0,1,2)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1      ma2     sma1     sma2  DiasMes  SemanaSanta    d0111\n      -0.3127  -0.1613  -0.7015  -0.1249   0.0266      -0.0173  -0.0772\ns.e.   0.0864   0.1012   0.0635   0.0627   0.0083       0.0050   0.0187\n        d1220   d0221   d0321\n      -0.0936  0.0468  0.0570\ns.e.   0.0221  0.0223  0.0226\n\nsigma^2 = 0.0005765:  log likelihood = 635.04\nAIC=-1248.07   AICc=-1247.07   BIC=-1208.29\n\n\nIndica el modelo, \\(ARIMA_{12}(0,1,2)(0,1,2)\\), donde los coeficiente ma2 y sma2 no parecen ser significativos. Si esto es así, estaríamos ante el modelo de la aerolíneas. Por otro lado, parece que los coeficientes del modelo asociados a las variables de intervención son significativas.\n\n\nUna alternativa a auto.arima es la función seas de la librería seasonal. La función seas tiene como ventajas que también analiza automáticamente la conveniencia de usar la transformación logarítmica, que identifica posibles efectos calendario y valores extremos, y que suele ser más parsimoniosa que auto.arima. Su desventaja es que sólo se puede aplicar para series mensuales o trimestrales.\nLa aplicación de seas sobre la serie indica que no es necesaria la transformación logarítmica así que solicitamos la identificación automática forzando la transformación. Veamos que identificación ofrece seas:\n\n#summary(seas(nacimientos))\nsummary(seas(nacimientos, transform.function = \"log\"))\n\n\nCall:\nseas(x = nacimientos, transform.function = \"log\")\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \nWeekday            0.0028341  0.0002676  10.589  &lt; 2e-16 ***\nEaster[1]         -0.0132747  0.0039909  -3.326  0.00088 ***\nAO2010.Dec         0.0655881  0.0141737   4.627 3.70e-06 ***\nAO2020.Nov        -0.0656768  0.0153456  -4.280 1.87e-05 ***\nAO2020.Dec        -0.2016273  0.0159295 -12.657  &lt; 2e-16 ***\nAO2021.Jan        -0.1568422  0.0154818 -10.131  &lt; 2e-16 ***\nMA-Nonseasonal-01  0.4250414  0.0541258   7.853 4.07e-15 ***\nMA-Seasonal-12     0.7584950  0.0413099  18.361  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 288  Transform: log\nAICc:  4348, BIC:  4380  QS (no seasonality in final):    0  \nBox-Ljung (no autocorr.): 25.18   Shapiro (normality): 0.9913 .\n\n\nEn primer lugar, la función identifica el modelo de las aerolíneas con la transformación logarítmica de Nacimientos. Además, un efecto calendario Semana Santa, un efecto calendario días laborables del mes (que podemos entender similar a nuestro efecto días del mes) y cuatro meses atípicos en diciembre de 2010, noviembre y diciembre de 2020 y enero de 2021.\nTras las dos autoidentificaciones complementarias, decidimos que la identificación de partida es \\(ARIMA_{12}(0,1,1)(0,1,1) + AI\\), \\[(1 - L)(1 - L^{12})\\log(nacimientos_t) = (1 + \\theta_1 L)(1 + \\theta_{12} L^{12})\\varepsilon_t + AI.\\] donde AI recoge las variables de intervención incluidas en auto.arima y seas.\n\n\nEstimación (y valores extremos)\nVamos a estimar el modelo identificado, incluidas las nuevas variables de intervención identificadas con la función seas.\n\nd1210 &lt;- 1*(cycle(nacimientos) == 12 & trunc(time(nacimientos)) == 2010)\nd1120 &lt;- 1*(cycle(nacimientos) == 11 & trunc(time(nacimientos)) == 2020)\nd0121 &lt;- 1*(cycle(nacimientos) ==  1 & trunc(time(nacimientos)) == 2021)\n\nnac.ar1 &lt;- Arima(nacimientos, \n                 order = c(0, 1, 1),\n                 seasonal = c(0, 1, 1),\n                 lambda = 0,\n                 xreg = cbind(DiasMes, SemanaSanta, \n                              d1210,  d0111, d1120, d1220, d0121, d0221, d0321)) \nnac.ar1\n\nSeries: nacimientos \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasMes  SemanaSanta   d1210    d0111    d1120    d1220\n      -0.5569  -0.7506   0.0293      -0.0167  0.0664  -0.0533  -0.0831  -0.2060\ns.e.   0.0513   0.0408   0.0075       0.0050  0.0171   0.0171   0.0178   0.0185\n        d0121    d0221   d0321\n      -0.1880  -0.0542  0.0229\ns.e.   0.0188   0.0187  0.0180\n\nsigma^2 = 0.0004212:  log likelihood = 680.41\nAIC=-1336.83   AICc=-1335.63   BIC=-1293.42\n\n\nYa tenemos un modelo de partida, aunque parece que el coeficiente de la intervención en marzo de 2021 no es significativo. Veamos si es necesaria más intervención.\n\nerror &lt;- residuals(nac.ar1)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2,2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  scale_x_continuous(breaks= seq(2000, 2024, 2)) \n\nfechas &lt;- format(seq(as.Date(\"2000-1-1\"), as.Date(\"2023-12-1\"), \"month\"), \"%Y-%m\")\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"2006-12\" \"2016-04\" \"2016-06\" \"2022-11\"\n\n\n\n\n\n\n\n\nFigura 5: Error + Intervención\n\n\n\n\n\nSe observa que hay cuatro candidatos a valores atípicos en diciembre de 2006, abril y junio de 2016 y noviembre de 2022, dado que los errores asociados se acercan o superan las 3 desviaciones típicas. En junio de 2016 no hay evidencia de que ocurriera nada atípico en los nacimientos y el coeficiente de esta variable resulta no ser significativo si lo incluimos en el modelo. Por tanto, no crearemos una variable asociada a este mes. Para los otros tres meses:\n\nSe crea una variable de intervención para cada caso\nSe estima de nuevo el modelo incluyendo estas variables (auto.arima identifica el mismo modelo).\nSe vuelve a analizar si quedan valores atípicos\n\nAdemás, aprovechamos para excluir la variable de intervención de marzo de 2021 que no era significativa\n\nd1206 &lt;- 1*(cycle(nacimientos) == 12 & trunc(time(nacimientos)) == 2006)\nd0416 &lt;- 1*(cycle(nacimientos) ==  4 & trunc(time(nacimientos)) == 2016)\nd1122 &lt;- 1*(cycle(nacimientos) == 11 & trunc(time(nacimientos)) == 2022)\n\nnac.ar2 &lt;- Arima(nacimientos, \n                 order = c(0, 1, 1),\n                 seasonal = c(0, 1, 1),\n                 lambda = 0,\n                 xreg = cbind(DiasMes, SemanaSanta, \n                              d1206, d1210, d0111, d0416,\n                              d1120, d1220, d0121, d0221, d1122))\nnac.ar2\n\nSeries: nacimientos \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasMes  SemanaSanta    d1206   d1210    d0111    d0416\n      -0.5125  -0.7599   0.0279      -0.0222  -0.0460  0.0621  -0.0547  -0.0542\ns.e.   0.0550   0.0398   0.0071       0.0050   0.0158  0.0164   0.0163   0.0165\n        d1120    d1220    d0121    d0221   d1122\n      -0.0799  -0.2101  -0.1939  -0.0620  0.0404\ns.e.   0.0171   0.0176   0.0177   0.0172  0.0165\n\nsigma^2 = 0.0003917:  log likelihood = 691.41\nAIC=-1354.83   AICc=-1353.21   BIC=-1304.19\n\nerror &lt;- residuals(nac.ar2)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  scale_x_continuous(breaks= seq(2000, 2022, 2)) \n\n# fechas[abs(error) &gt; 2.5 * sderror]\n\n\n\n\n\n\n\nFigura 6: Error + Intervención\n\n\n\n\n\nNo se observan errores elevados, así que vamos a asumir que ya no hay valores extremos.\n\n\nCompensación\nPodemos observar que en todos los modelos estimados los coeficientes de las variables de intervención de los meses consecutivos diciembre de 2010 y enero de 2011 son similares pero de signo opuesto. A este tipo de intervención se le denomina compensación: el efecto extraordinario en un periodo se compensa con un efecto de similar magnitud pero signo opuesto en el periodo siguiente. La causa detrás de esta compensación puede ser tan prosaica como que por error muchos nacimientos ocurridos en enero de 2011 se asignaron informaticamente a diciembre de 2010. O quizás algo pasó en esos meses que adelantó un número considerable de nacimientos.\nVamos a crear una variable de intervención asociada a esta compensación. Es tan sencillo como definir una variable ficticia que valga cero siempre excepto para los meses de diciembre de 2010 y enero de 2011 que valdrá 1 y - 1 respectivamente.\n\n# Creacion del la compensacion\nd12100111 &lt;- d1210 - d0111\n\nRespecto del efecto de la pandemia en la serie, las dos intervenciones asociadas al inicio y final del efecto (noviembre de 2020 y febrero de 2021) tienen un valor similar, y las dos intervenciones asociadas al corazón del efecto (diciembre de 2020 y enero de 2021) también tienen un valor parecido. En este caso las dos variables ficticias que vamos a crear deben valer cero siempre excepto para dos meses que valdrán 1. La primera variable valdrá 1 en noviembre de 2020 y febrero de 2021, y la segunda variable valdrá 1 en diciembre de 2020 y enero de 2021.\n\n# Variables de intervencion asociadas a la Covid-19\nd11200221 &lt;- d1120 + d0221\nd12200121 &lt;- d1220 + d0121\n\nAhora vamos a sustituir las seis variables ficticias d1210, d0111, d1120, d1220, d0121 y d0221 del modelo por las nuevas variables d12100111, d11200221 y d12200121.\n\nnac.ar3 &lt;- Arima(nacimientos, \n                 order = c(0, 1, 1),\n                 seasonal = c(0, 1, 1),\n                 lambda = 0,\n                 xreg = cbind(DiasMes, SemanaSanta, \n                              d1206, d12100111, d0416,\n                              d11200221, d12200121, d1122))\n\nnac.ar3\n\nSeries: nacimientos \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasMes  SemanaSanta    d1206  d12100111    d0416\n      -0.5063  -0.7607   0.0276      -0.0221  -0.0462     0.0584  -0.0541\ns.e.   0.0546   0.0399   0.0071       0.0050   0.0158     0.0099   0.0165\n      d11200221  d12200121   d1122\n        -0.0710    -0.2022  0.0418\ns.e.     0.0131     0.0145  0.0164\n\nsigma^2 = 0.000389:  log likelihood = 690.79\nAIC=-1359.59   AICc=-1358.58   BIC=-1319.8\n\n\nLos coeficientes estimados en este modelo son prácticamente iguales a los obtenidos en el modelo previo.\n\n\nValidación\nVamos si todos los coeficientes del modelo son significativos.\n\ncoeftest(nac.ar3)\n\n\nz test of coefficients:\n\n              Estimate Std. Error  z value  Pr(&gt;|z|)    \nma1         -0.5062827  0.0545897  -9.2743 &lt; 2.2e-16 ***\nsma1        -0.7606907  0.0398969 -19.0664 &lt; 2.2e-16 ***\nDiasMes      0.0275858  0.0071012   3.8847 0.0001025 ***\nSemanaSanta -0.0221422  0.0049579  -4.4661 7.967e-06 ***\nd1206       -0.0462432  0.0157747  -2.9315 0.0033735 ** \nd12100111    0.0584458  0.0099443   5.8773 4.170e-09 ***\nd0416       -0.0541083  0.0165482  -3.2697 0.0010765 ** \nd11200221   -0.0710234  0.0130601  -5.4382 5.383e-08 ***\nd12200121   -0.2021734  0.0144820 -13.9604 &lt; 2.2e-16 ***\nd1122        0.0418207  0.0163895   2.5517 0.0107204 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTodos los coeficientes son significativos al 5%.\n\n\nError de estimación\nEl error medio de -61, muy bajo en comparación con el valor medio de la serie, y el MPE de -0.17 indican que no hay sesgo. Además, el valor tan reducido de ACF1 indica que las previsiones por intervalo estarán correctamente calculadas.\nEn media nos equivocamos en 683 bebés (RMSE) y el error porcentual medio es del 1.5%.\n\naccuracy(nac.ar3)\n\n\n\n                 ME   RMSE    MAE   MPE MAPE MASE ACF1\nTraining set -60.62 682.74 547.63 -0.17 1.54  0.4 0.03\n\n\n\n\nError de predicción estramuestral según horizonte temporal\nAsumimos que se precisan quince años para hacer una buena estimación, \\(k = 180\\), y fijaremos el horizonte temporal en un año, \\(h = 12\\) meses.\nEl código es aun más complejo que el visto en el tema previo. Por un lado, hemos de tener en cuenta que hay variables de intervención y por otro lado que la función Arima podría fallar en el proceso de estimación.\n\nk &lt;- 180                   \nh &lt;- 12                    \nT &lt;- length(nacimientos)   \ns&lt;-T - k - h               \n\nmapeArima &lt;- matrix(NA, s + 1, h)\n\nX &lt;- data.frame(cbind(DiasMes, SemanaSanta))\n\nfor (i in 0:s) {\n  train.set &lt;- subset(nacimientos, start = i + 1, end = i + k)\n  test.set &lt;-  subset(nacimientos, start = i + k + 1, end = i + k + h) \n  \n  X.train &lt;- as.matrix(X[(i + 1):(i + k),])\n  X.test &lt;- as.matrix(X[(i + k + 1):(i + k + h),])\n  \n  fit &lt;- try(Arima(train.set, \n                   order = c(0, 1, 1),\n                   seasonal = c(0, 1, 1),\n                   lambda = 0,\n                   xreg = X.train))\n  \n  if(!is.element(\"try-error\", class(fit))) {\n    fcast &lt;- forecast(fit, h = h, xreg = X.test) \n    mapeArima[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  }\n}\n\nComo para el cálculo de los errores de predicción no se ha tenido en cuenta la intervención no sujeta a afectos calendario (la compensación a finales de 2010, la Covid-19…), vamos a obtener el error mediano como medida de precisión.\n\nerrorArima &lt;- apply(mapeArima, MARGIN = 2, FUN = median, na.rm = TRUE)\nerrorArima\n\n [1] 1.407992 1.400730 1.686976 1.778348 1.750788 1.571241 1.977455 1.962138\n [9] 2.122341 2.116743 1.740723 2.068629\n\n\n\nggplot() +\n  geom_line(aes(x = 1:12, y = errorArima), colour = \"Blue\") +\n  ggtitle(\"\") +\n  xlab(\"Horizonte temporal de predicción\") +\n  ylab(\"%\") +\n  scale_x_continuous(breaks= 1:12)\n\n\n\n\n\n\n\nFigura 7: Error de predicción (MedAPE) según horizonte temporal\n\n\n\n\n\nLa Figura 7 revela que el error de predicción aumenta según aumenta el horizonte de predicción, pero incluso a un año vista, se mantiene cercano al 2%.\n\n\nInterpretación\nEl modelo teórico es \\(log(nacimientos) \\sim ARIMA_{12}(0, 1, 1)(0, 1, 1) + AI\\),\n\\[(1 - L^{12})(1 - L)\\log(nacimientos_t) = (1 + \\theta_1 L)(1 + \\theta_{12} L^{12})\\varepsilon_t + AI.\\]\nSi sustituimos \\((1 - L^{12})\\log(nacimientos_t)\\) por \\(TVA_{nacimientos_t}\\), la tasa de variación anual de los nacimientos, y desarrollamos queda \\[\n\\begin{aligned}\nTVA\\_nac_t  = & TVA\\_nac_{t - 1} + \\theta_1 \\varepsilon_{t-1} + \\theta_{12} \\varepsilon_{t-12} + \\theta_1\\theta_{12} \\varepsilon_{t-13} +  \\varepsilon_{t}+ \\\\\n& \\gamma_1 \\cdot DiasMes_t + \\gamma_2 \\cdot SemanaSanta +\\gamma_3 \\cdot d1206_t + \\gamma_4 \\cdot d12100111_t + \\\\\n& \\gamma_5 \\cdot d0416_t + \\gamma_6 \\cdot d11200221_t + \\gamma_7 \\cdot d12200121_t + \\gamma_8 \\cdot d1122_t.\n\\end{aligned}\n\\]\nFinalmente, el modelo estimado es, \\[\n\\begin{aligned}\n\\widehat{TVA}\\_nac_t = & TVA\\_nac_{t-1}  - 0.51\\varepsilon_{t-1} - 0.76\\varepsilon_{t-12} + 0.39\\varepsilon_{t-13} + \\\\\n& 0.028 \\cdot DiasMes_t - 0.022 \\cdot SemanaSanta - 0.046 \\cdot d1206_t + 0.058 \\cdot d12100111_t \\\\\n& - 0.054 \\cdot d0416_t - 0.071 \\cdot d11200221_t - 0.20  \\cdot d12200121_t + 0.042 \\cdot d1122.\n\\end{aligned}\n\\]\n\nEn cada mes, la tasa de variación anual de los nacimientos es la misma que la del mes pasado (\\(\\widehat{TVA}_{nacimientos_t} = TVA_{nacimientos_{t-1}}\\)).\nAdemás, si algunos de los meses necesarios para predecir fue anómalo, el error hay que tenerlo en cuenta para afinar la previsión.\nRespecto de los efectos calendario, cada día adicional de un mes nacen un 2.8% más de bebés. El mes en que cae la Semana Santa los nacimientos caen un 2.2%.\nPor alguna razón, en diciembre de 2006 hubo un 4.6% menos de nacimientos de lo esperado; en diciembre de 2010 hubo un 5.8% más de nacimientos de lo esperado que fue compensado en enero de 2011; en abril de 2016 hubo un 5.4% menos de nacimientos de lo esperado; y en noviembre de 2022 hubo un 4.1% más de nacimientos.\nRespecto de la pandemia, nueve meses después del confinamiento hubo una reducción transitoria en el número de nacimientos. En concreto, en noviembre de 2020 se redujeron un 7.1% y en los dos meses siguientes la caída fue de un 20%. En febrero de 2021 los nacimientos se recuperaron parcialmente y la caída fue del 7.1%. A partir de marzo de 2021 los nacimientos recuperaron los valores prepandemia.\n\n\n\nPredicción de la serie\nUna vez dado por válido el modelo podemos pasar a realizar predicciones. Hay que tener en cuenta que hay siete variables de intervención, dos de ellas son efectos calendario (DiasMes y SemanaSanta), para las que debemos indicar qué valores tomarán en el periodo de predicción. Vamos a fijar el horizonte de predicción en cuatro años y mostrar los resultados numéricamente (solo para el primer año) y gráficamente (Figura 8).\n\ntmp &lt;- ts(rep(0, 48), start = 2024, freq = 12)\npdm &lt;- monthdays(tmp)\npss &lt;- easter(tmp)\npnac.ar3 &lt;- forecast(nac.ar3, \n                     h = 48,\n                     xreg = cbind(pdm, pss, \n                                  rep(0,48), rep(0,48), rep(0,48),\n                                  rep(0,48), rep(0,48), rep(0,48)), \n                     level = 95)\npnac.ar3\n\n\n\n         Point Forecast    Lo 95    Hi 95\nJan 2024       27053.45 26027.68 28119.66\nFeb 2024       24871.69 23822.29 25967.32\nMar 2024       25954.92 24759.70 27207.85\nApr 2024       25592.81 24323.70 26928.14\nMay 2024       26130.96 24749.32 27589.73\nJun 2024       25986.39 24532.41 27526.53\nJul 2024       27707.00 26076.31 29439.67\nAug 2024       27722.56 26014.58 29542.67\nSep 2024       27547.83 25778.28 29438.85\nOct 2024       28022.05 26151.64 30026.24\nNov 2024       26577.70 24739.60 28552.38\nDec 2024       26502.57 24608.13 28542.85\n\n\n\nautoplot(pnac.ar3, \n     ylab = \"Nacimientos\",\n     main = \"\") +\n  scale_x_continuous(breaks= seq(2000, 2028, 2)) \n\n\n\n\n\n\n\nFigura 8: Nacimientos (2000-2023) y predicción (2024-2027)"
  },
  {
    "objectID": "03-08-Tema8.html#exportaciones",
    "href": "03-08-Tema8.html#exportaciones",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "5.2 Exportaciones",
    "text": "5.2 Exportaciones\nConsideremos la serie de exportaciones de bienes desde España hacía la UE27 (conjunto de 27 países de la Unión Europea, con Reino Unido ya ha excluido). La serie va de enero de 1999 hasta diciembre de 2023 y está en millones de euros.\n\nexportaciones &lt;- read.csv2(\"./series/Exportaciones.csv\", \n                           header = TRUE)\n\nexportaciones &lt;- ts(exportaciones,\n                    start = c(1999, 1),\n                    freq = 12)\n\nautoplot(exportaciones,\n         xlab = \"\",\n         ylab = \"Millones de €\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 9: Exportaciones de España a la EU27\n\n\n\n\n\n\nTransformación de la serie\nLa Figura 9 deja claro que la serie debe ser diferenciada para ser estacionaria. También muestra dos periodos con una marcada intervención: al inicio de la Gran Recesión (2008-2014) y durante el periodo más duro de la Covid-19 en el año 2020. Además, por la naturaleza de la serie es previsible que exista un efecto días del mes o días laborables y un efecto Semana Santa.\nPor otro lado, la Figura 9 muestra que la serie tiene un esquema multiplicativa, así que trabajaremos con la transformación logarítmica.\n\nggAcf(log(exportaciones), lag = 48, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(exportaciones)), lag = 48, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(log(exportaciones), lag = 12), lag = 48, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(diff(log(exportaciones), lag = 12)), lag = 48, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Serie\n\n\n\n\n\n\n\n\n\n\n\n(b) Diferencia regular\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Diferencia estacional\n\n\n\n\n\n\n\n\n\n\n\n(d) Diferencia regular y estacional\n\n\n\n\n\n\n\nFigura 10: FAC para Exportaciones (log)\n\n\n\n\n\nndiffs(log(exportaciones))\n\n[1] 1\n\nnsdiffs(log(exportaciones))       \n\n[1] 1\n\n\nEl análisis de la Figura 10 revela la necesidad de la doble diferenciación, que es confirmada por las funciones ndiffs y nsdiffs. Concluimos que para que la serie sea estacionaria y ergódica es necesaria la doble diferenciación regular y estacional. Es decir, trabajaremos con la siguiente serie transformada \\[\\nabla\\nabla_{12}\\log(exportaciones_t) \\sim I(0)I_{12}(0).\\]\n\n\nIdentificación\nSi probamos con la función auto.arima, indicando la doble diferenciación y añadiendo el efecto de los días del mes y la Semana Santa, nos sugiere \\(ARIMA_{12}(2,1,2)(2,1,2)\\). Demasiado complejo.\nVeamos qué nos indica seas.\n\nsummary(seas(exportaciones))\n\n\nCall:\nseas(x = exportaciones)\n\nCoefficients:\n                    Estimate Std. Error z value Pr(&gt;|z|)    \nMon               -0.0002753  0.0036983  -0.074 0.940664    \nTue                0.0140569  0.0036324   3.870 0.000109 ***\nWed                0.0091676  0.0036440   2.516 0.011876 *  \nThu                0.0094801  0.0036551   2.594 0.009495 ** \nFri                0.0131957  0.0036349   3.630 0.000283 ***\nSat               -0.0187370  0.0036035  -5.200 2.00e-07 ***\nEaster[1]         -0.0678310  0.0075546  -8.979  &lt; 2e-16 ***\nLS2008.Dec        -0.1891898  0.0292510  -6.468 9.94e-11 ***\nAO2020.Mar        -0.1694793  0.0292773  -5.789 7.09e-09 ***\nAO2020.Apr        -0.5021644  0.0304350 -16.500  &lt; 2e-16 ***\nAO2020.May        -0.2740737  0.0292955  -9.356  &lt; 2e-16 ***\nLS2023.Apr        -0.1323508  0.0325300  -4.069 4.73e-05 ***\nMA-Nonseasonal-01  0.4091021  0.0531795   7.693 1.44e-14 ***\nMA-Seasonal-12     0.6302998  0.0456916  13.795  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nSEATS adj.  ARIMA: (0 1 1)(0 1 1)  Obs.: 300  Transform: log\nAICc:  4270, BIC:  4324  QS (no seasonality in final):    0  \nBox-Ljung (no autocorr.): 40.16 * Shapiro (normality): 0.996  \nMessages generated by X-13:\nWarnings:\n- At least one visually significant trading day peak has been\n  found in one or more of the estimated spectra.\n\n\nEl modelo identificado es el de las aerolíneas para la transformación logarítmica de Exportaciones. Respecto de la intervención, identifica dos efectos calendario: uno por cada día laboral y Semana Santa. También se identifican cinco intervenciones no asociadas a efectos calendario: tres pulsos –intervenciones que afectan un solo mes (AO)– y dos cambios permanentes –intervenciones que afectan un rango elevado de meses (LS):\n\nUn cambio permanente (level shift o LS) empieza en diciembre de 2008 y el coeficiente estimado es negativo. Es decir, la Gran Recesión generó una caída permanente de las exportaciones españolas a la UE27.\nEl otro cambio permanente, también de signo negativo, empieza en abril de 2023 y corrige a la baja el elevado nivel de las exportaciones observado tras la pandemia.\nTambién asociado a la Covid-19 están los pulsos de marzo, abril y mayo de 2020.\n\n\n\nEstimación (y valores extremos)\nVamos a estimar el modelo identificado con seas, incluidas las variables de intervención. A este respecto unas palabras sobre como obtener los días laborables de un mes.\nEntenderemos por días laborables los lunes a viernes de cada mes, menos los días festivos. Un inconveniente de este efecto es que los festivos que afectan a una serie dependen de su naturaleza y ámbito geográfico. Por ejemplo, en Estados Unidos el día del trabajador se celebra el primer lunes de septiembre, en Reino Unido el primer lunes de mayo y en España el 1 de mayo. Además, para la serie de transporte de pasajeros urbanos de Valencia los festivos relevantes serán diferentes que para la misma serie para Madrid.\nPara el ámbito geográfico nacional, los días laborables se puede obtener con la función bizdays. Esta función devuelve el número de días laborables de cada mes para determinados centros financieros (equivalentes a países). Por proximidad geográfica, usaremos el calendario de Londres para España.1\n\nDiasLaborables &lt;- bizdays(exportaciones, FinCenter = \"London\")\nSemanaSanta &lt;- easter(exportaciones)\n\nPara los pulsos, que solo afectan un mes, se crea una variable que vale cero excepto para el mes a intervenir que vale 1.\n\nd0320 &lt;- 1*(cycle(exportaciones) ==  3 & trunc(time(exportaciones)) == 2020)\nd0420 &lt;- 1*(cycle(exportaciones) ==  4 & trunc(time(exportaciones)) == 2020)\nd0520 &lt;- 1*(cycle(exportaciones) ==  5 & trunc(time(exportaciones)) == 2020)\n\nPara los cambios permanentes que afectan desde un mes en adelante, se crea una variable que vale cero antes del mes de inicio de la intervención y 1 desde ese mes en adelante.\n\nl1208 &lt;- 1*(trunc(time(exportaciones)) &gt; 2008) + \n  1*(cycle(exportaciones) &gt;= 12 & trunc(time(exportaciones)) == 2008)\n\nl0423 &lt;- 1*(trunc(time(exportaciones)) &gt; 2023) + \n  1*(cycle(exportaciones) &gt;= 4 & trunc(time(exportaciones)) == 2023)\n\nEstimamos el modelo de partida, en el que parece que todos los coeficientes son significativos.\n\nexp.ar1 &lt;- Arima(exportaciones, \n                 order = c(0, 1, 1),\n                 seasonal = c(0, 1, 1),\n                 lambda = 0,\n                 xreg = cbind(DiasLaborables, SemanaSanta, \n                              l1208, d0320, d0420, d0520, l0423))\nexp.ar1\n\nSeries: exportaciones \nRegression with ARIMA(0,1,1)(0,1,1)[12] errors \nBox Cox transformation: lambda= 0 \n\nCoefficients:\n          ma1     sma1  DiasLaborables  SemanaSanta    l1208    d0320    d0420\n      -0.4580  -0.6519          0.0315      -0.0206  -0.1956  -0.1822  -0.5051\ns.e.   0.0491   0.0516          0.0018       0.0093   0.0307   0.0314   0.0325\n        d0520    l0423\n      -0.2672  -0.1277\ns.e.   0.0318   0.0341\n\nsigma^2 = 0.001465:  log likelihood = 530.59\nAIC=-1041.19   AICc=-1040.39   BIC=-1004.59\n\n\nVeamos si es necesaria más intervención.\n\nerror &lt;- residuals(exp.ar1)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2,2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  scale_x_continuous(breaks= seq(1998, 2022, 2)) \n\nfechas &lt;- format(seq(as.Date(\"1999-1-1\"), as.Date(\"2023-12-1\"), \"month\"), \"%Y-%m\")\nfechas[abs(error) &gt; 2.5 * sderror]\n\n[1] \"2008-10\" \"2010-06\" \"2012-06\" \"2013-08\" \"2020-06\"\n\n\n\n\n\n\n\n\nFigura 11: Error + Intervención\n\n\n\n\n\nSe observan algunos candidatos a valores atípicos por superar el error las 2.5 desviaciones típicas, pero ninguna alcanza las 3 desviaciones típicas. A fin de aligerar este ejemplo no se van a incluir más variables de intervención.\n\n\nValidación\nVeamos si los coeficientes del modelo son significativos. Para ello, aplicamos la prueba z.\n\ncoeftest(exp.ar1)\n\n\nz test of coefficients:\n\n                 Estimate Std. Error  z value  Pr(&gt;|z|)    \nma1            -0.4580059  0.0490920  -9.3295 &lt; 2.2e-16 ***\nsma1           -0.6518852  0.0515779 -12.6389 &lt; 2.2e-16 ***\nDiasLaborables  0.0314654  0.0018045  17.4371 &lt; 2.2e-16 ***\nSemanaSanta    -0.0206082  0.0092680  -2.2236 0.0261758 *  \nl1208          -0.1956032  0.0306802  -6.3755 1.823e-10 ***\nd0320          -0.1822087  0.0313723  -5.8080 6.324e-09 ***\nd0420          -0.5050739  0.0324815 -15.5496 &lt; 2.2e-16 ***\nd0520          -0.2672099  0.0317877  -8.4061 &lt; 2.2e-16 ***\nl0423          -0.1276646  0.0341494  -3.7384 0.0001852 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTodos los coeficientes son significativos.\n\n\nError de estimación\nEn media nos equivocamos en 456 millones de euros (RMSE) y el error porcentual medio es del 2.8%, muy reducido.\nLa serie no presenta sesgo y el intervalo de confianza para las predicciones es válido.\n\naccuracy(exp.ar1)\n\n\n\n                 ME   RMSE    MAE   MPE MAPE MASE  ACF1\nTraining set -10.34 456.31 327.43 -0.25 2.82  0.3 -0.04\n\n\n\n\nError de predicción estramuestral según horizonte temporal\nAsumimos que se precisan diez años para hacer una buena estimación, \\(k = 120\\), y fijaremos el horizonte temporal en un año, \\(h = 12\\) meses. Usaremos como criterio de calidad el MedAPE\n\nk &lt;- 120                   \nh &lt;- 12                    \nT &lt;- length(exportaciones)   \ns &lt;- T - k - h               \n\nmapeArima &lt;- matrix(NA, s + 1, h)\n\nX &lt;- data.frame(cbind(DiasLaborables, SemanaSanta))\n\nfor (i in 0:s) {\n  train.set &lt;- subset(exportaciones, start = i + 1, end = i + k)\n  test.set &lt;-  subset(exportaciones, start = i + k + 1, end = i + k + h) \n  \n  X.train &lt;- as.matrix(X[(i + 1):(i + k),])\n  X.test &lt;- as.matrix(X[(i + k + 1):(i + k + h),])\n  \n  fit &lt;- try(Arima(train.set, \n                   order = c(0, 1, 1),\n                   seasonal = c(0, 1, 1),\n                   lambda = 0,\n                   xreg = X.train))\n  \n  if(!is.element(\"try-error\", class(fit))) {\n    fcast &lt;- forecast(fit, h = h, xreg = X.test) \n    mapeArima[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  }\n}\n\nerrorArima &lt;- apply(mapeArima, MARGIN = 2, FUN = median, na.rm = TRUE)\nerrorArima\n\n [1] 2.528064 2.604219 2.972136 3.220444 3.666207 4.098874 4.505794 4.770593\n [9] 4.935492 4.797301 4.768106 5.412510\n\n\nPara evitar el efecto sobre los errores de predicción de la no inclusión de las variables ficticias se ha calculado el error mediano. La Figura 12 revela que el error de predicción aumenta lentamente según aumenta el horizonte de predicción, pasando del 2.5% a un mes vista hasta el 5.4% a 12 meses vista.\n\nggplot() +\n  geom_line(aes(x = 1:12, y = errorArima), colour = \"Blue\") +\n  ggtitle(\"\") +\n  xlab(\"Horizonte temporal de predicción\") +\n  ylab(\"%\") +\n  scale_x_continuous(breaks= 1:12)\n\n\n\n\n\n\n\nFigura 12: Error de predicción (MedAPE) según horizonte temporal\n\n\n\n\n\n\n\nInterpretación\nLa parte regular del modelo estimado es la misma que la obtenida para la serie Nacimientos y su interpretación es, por tanto, idéntica: en cada mes, la tasa de variación anual de las exportaciones es la misma que la del mes pasado. Además, si algunos de los meses necesarios para predecir fue anómalo, el error hay que tenerlo en cuenta para afinar la previsión.\nVamos por tanto a centrarnos en la interpretación de la intervención:\n\nCada día laborable adicional en un mes aumenta las exportaciones en un 3.1% (coeficiente \\(0.0315\\) de DiasLAborables)\nEl mes en que cae la Semana Santa las exportaciones caen un 2.1%. (coeficiente \\(-0.0206\\) de SemanaSanta)\nA raíz de la Gran Recesión, las exportaciones se redujeron de forma permanente un 19.6% desde diciembre de 2008. Es decir, sin la Gran Recesión, las exportaciones ahora serían un 19.6% superiores (coeficiente \\(-0.1956\\) de l1208)\nA raíz de la Covid-19, las exportaciones se redujeron de forma temporal en los meses de marzo, abril y mayo de 2020 un 18%, 51% y 27%, respectivamente.\nAdemás, el nivel de las exportaciones se ha corregido a la baja desde abril de 2023 un 12.8% (coeficiente \\(-0.1277\\) de l0423).\n\n\n\nPredicción de la serie\nUna vez dado por válido el modelo, podemos pasar a realizar predicciones teniendo en cuenta las siete variables de intervención:\n\nDos de ellas son efectos calendario (DiasLaborables y SemanaSanta), para las que debemos indicar qué valores tomarán en el periodo de predicción\nOtras dos son cambios permanentes y su valor debe ser 1 en el futuro.\nSolo para los pulsos, se fijará un valor futuro de 0.\n\nVamos a fijar el horizonte de predicción en cuatro años y mostrar los resultados numérica (solo para el primer año) y gráficamente (Figura 13).\nRecuerda siempre incluir las variables ficticias en la función forecast en el mismo orden que aparecen en la estimación con Arima.\n\ntmp &lt;- ts(rep(0, 48), start = 2024, freq = 12)\npdl &lt;- bizdays(tmp, FinCenter = \"London\")\npss &lt;- easter(tmp)\npexp.ar1 &lt;- forecast(exp.ar1, \n                     h = 48,\n                     xreg = cbind(pdl, pss, \n                                  rep(1,48), \n                                  rep(0,48), rep(0,48), rep(0,48),\n                                  rep(1,48)), \n                     level = 95)\npexp.ar1\n\n\n\n         Point Forecast    Lo 95    Hi 95\nJan 2024       20398.15 18923.71 21987.48\nFeb 2024       20935.60 19223.06 22800.71\nMar 2024       21820.13 19851.88 23983.51\nApr 2024       22452.95 20257.25 24886.64\nMay 2024       23319.37 20876.66 26047.89\nJun 2024       22484.03 19983.70 25297.19\nJul 2024       21850.14 19288.37 24752.14\nAug 2024       16463.85 14439.96 18771.40\nSep 2024       22737.88 19820.28 26084.96\nOct 2024       23111.43 20027.50 26670.24\nNov 2024       23491.95 20242.32 27263.27\nDec 2024       21372.59 18315.97 24939.31\n\n\n\nautoplot(pexp.ar1, \n         xlab = \"\",\n         ylab = \"Millones de euros\",\n         main = \"\",\n         PI = FALSE) +\n  scale_x_continuous(breaks= seq(1998, 2028, 2)) \n\n\n\n\n\n\n\nFigura 13: Exportaciones (1999-2023) y predicción (2024-2027)"
  },
  {
    "objectID": "03-08-Tema8.html#demanda-eléctrica",
    "href": "03-08-Tema8.html#demanda-eléctrica",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "5.3 Demanda eléctrica",
    "text": "5.3 Demanda eléctrica\nConsideremos las serie diaria de demanda eléctrica (GWh) en España durante 2023.\n\nelectricidad &lt;- read.csv(\"./series/Consumo electrico.csv\", \n                         header = TRUE)\n\nelectricidad &lt;- ts(electricidad[, 1],\n                   start = c(1, 7),\n                   frequency = 7)\n\nautoplot(electricidad,\n         xlab = \"\",\n         ylab = \"GWh\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 14: Demanda eléctrica en España en 2023\n\n\n\n\n\n\nTransformación de la serie\nEstrictamente hablando la serie no muestra tendencia, porque solo podemos observar un año. Sin embargo, se observan cambios de nivel en la demanda eléctrica que se pueden confundir con la presencia de tendencia, pero que realmente están asociados a los cambios de temperatura y el uso de los sistemas de climatización. Estos cambios de nivel se repiten cada año y se deberían incorporar en la estructura de la serie como una segunda componente estacional. Ahora bien, dado que solo se está analizando un año de la serie, vamos a asimilar los cambios de nivel a la presencia de tendencia y a considerar, por tanto, la serie como no estacionaria.\n\nggAcf(electricidad, lag = 42, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(electricidad), lag = 42, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(electricidad, lag = 7), lag = 42, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\nggAcf(diff(diff(electricidad, lag = 7)), lag = 42, ylim = c(-1, 1),\n      xlab = \"\", ylab = \"\", main = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Serie\n\n\n\n\n\n\n\n\n\n\n\n(b) Diferencia regular\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Diferencia estacional\n\n\n\n\n\n\n\n\n\n\n\n(d) Diferencia regular y estacional\n\n\n\n\n\n\n\nFigura 15: FAC para Electricidad\n\n\n\n\n\nndiffs(electricidad)\n\n[1] 0\n\nnsdiffs(electricidad)       \n\n[1] 1\n\n\nLa FAC muestra que para que la serie sea estacionaria y ergódica es necesaria la doble diferenciación regular y estacional, aunque la función ndiffs no indica que la diferenciación regular sea necesaria. Trabajaremos con la siguiente serie transformada \\[\\nabla\\nabla_{12}electricidad_t \\sim I(0)I_{12}(0).\\]\n\n\nIdentificación\nAntes de proceder con la primera autoidentifación, vamos a analizar que intervención puede ser necesaria para estimar y predecir adecuadamente la serie.\nEfectos calendario\nLa Figura 14 muestra días con una marcada intervención asociada a la caída de la demanda de electricidad los días festivo (véase el análisis de esta serie realizada en el Tema 7). Por ejemplo, destaca el bajo consumo el 1 de enero (primer dato de la serie), en Navidades o en Semana Santa (semana 14 del año).\nLa caída en el consumo dependerá del día de la semana. Es decir, cabe esperar que en un martes festivo la caída del consumo sea mayor que la de un domingo festivo porque en el segundo caso el consumo ya es de por si muy bajo.\nPor tanto, para realizar un análisis detallado de la serie vamos crear variables ficticias que identifiquen los días festivos del calendario. Además, vamos a distinguir si el festivo ha sido entre semana (de lunes a viernes), en sábado o en domingo.\nUn repaso por el calendario para el año 2023 nos indica que ningún festivo nacional2 ha caído en sábado así que solo podremos estimar el efecto de los festivos entre semana y en domingo sobre el consumo de electricidad.\nEl siguiente código hace todo el trabajo.\n\nLa primera línea crea una serie que identifica cada fecha del año 2023. La función seq devuelve un objeto date donde cada fecha no se guarda como un texto (aunque se muestre así) sino de una forma mas compleja.\nEn la segunda línea en el objeto fiestas identificamos los 13 días festivos del año: 12 fiestas nacionales y el lunes 10 de abril, festivo un muchas comunidades.\nEn estas dos primeras líneas, la función as.Date se usa para que R identifique una secuencia de caracteres como una fecha tipo “aaaa-mm-dd”.\nLa línea 3 genera una serie ficticia para identificar los festivos entre semana. Primero se identifican que fechas del año aparecen incluidas entre las fiestas (fechas %in% fiestas), generándose un vector booleano (TRUE/FALSE) de longitud 365. Luego se identifican que días del año han caído entre semana (cycle(electricidad) &lt; 6), generandose otro vector booleano de longitud 365. El producto de estos dos vectores solo valdrá 1 (TRUE) si simultáneamente una fecha es festiva y ha caído entre semana.\nLa linea 4 usa las mismas ideas para generar una serie ficticia que identifica los festivos en domingo.\n\n\nfechas &lt;- seq(as.Date(\"2023-1-1\"), as.Date(\"2023-12-31\"), \"day\")\n\nfiestas &lt;- as.Date(c(\"2023-01-01\", \"2023-01-02\", \"2023-01-06\", \n                     \"2023-04-06\", \"2023-04-07\", \"2023-04-10\", \n                     \"2023-05-01\", \"2023-08-15\", \"2023-10-12\", \"2023-11-01\", \n                     \"2023-12-06\", \"2023-12-08\", \"2023-12-25\"))\n\nfestivosEntreSemana &lt;- (fechas %in% fiestas) * (cycle(electricidad) &lt; 6)\nfestivosDomingo &lt;- (fechas %in% fiestas) * (cycle(electricidad) == 7)\n\nAl final el código nos devuelve dos variables ficticias: festivosEntreSemana valdrá 1 en la posición del año correspondiente a un día festivo entre semana y 0 en otro caso; festivosDomingo valdrá 1 en la posición del año correspondiente a un domingo festivo y 0 en otro caso.\nComo ningún festivo en 2023 cayó en sábado, no es posible estimar su efecto sobre el consumo eléctrico y no se ha creado la variable ficticia correspondiente.\nEfecto temperatura\nEl consumo de electricidad está fuertemente relacionado con la temperatura. En concreto, cuanto más se aleja la temperatura de un día de la media anual (por exceso de frío o de calor) mayor es el consumo eléctrico (véase la Figura 16).\n\ntemperatura &lt;- read.csv(\"./series/Temperatura.csv\")\ntemperatura &lt;- temperatura[, 1]\n\nexcesotemperatura &lt;- abs(temperatura - mean(temperatura))\n\nggplot() +\n  geom_point(aes(x = excesotemperatura, y = electricidad), size = 2) +\n  xlab(\"Exceso de temperatura (ºC)\") + \n  ylab(\"Demanda eléctrica (GWh)\")\n\n\n\n\n\n\n\nFigura 16: Relación entre exceso de temperatura y consumo eléctrico\n\n\n\n\n\nUsaremos la variable excesotemperatura como otra variable de intervencion.\nIdentificación\nSi probamos con la función auto.arima, indicando la doble diferenciación, los días festivos entre semana, los festivos en domingo y el exceso de temperatura.\n\nauto.arima(electricidad,\n           d = 1,\n           D = 1,\n           xreg = cbind(festivosEntreSemana, festivosDomingo, \n                        excesotemperatura))\n\nSeries: electricidad \nRegression with ARIMA(1,1,0)(1,1,0)[7] errors \n\nCoefficients:\n         ar1     sar1  festivosEntreSemana  festivosDomingo  excesotemperatura\n      0.0815  -0.5435             -72.7484         -80.0718             2.6936\ns.e.  0.0568   0.0492               3.1198          17.3091             0.4057\n\nsigma^2 = 283.7:  log likelihood = -1513.43\nAIC=3038.86   AICc=3039.1   BIC=3062.13\n\n\nEl modelo identificado es ARIMA(1, 1, 0)(1, 1, 0), pero el coeficiente del proceso AR(1) claramente no es significativo.\nRespecto de la intervención, las tres variables de intervención parece ser significativas. Además, el efecto estimado para los días festivos por las dos variables ficticias es muy similar. Parece que la caída del consumo eléctrico en un festivo no depende del día de la semana. Ojo, no estamos diciendo que un lunes festivo, por ejemplo, se consume lo mismo que un domingo festivo. Dado que un lunes no festivo se consume más que un domingo no festivo, si la caída asociada a festividad es la misma, el lunes festivo se seguirá consumiendo más que un domingo festivo. Por tanto, vamos a crear una única variable ficticia que identifique los festivos independientemente del día de la semana en que caen.\n\nfestivos &lt;- festivosEntreSemana + festivosDomingo\n\n\n\nEstimación (y valores extremos)\nEstimamos el modelo de partida, excluyendo el proceso AR(1).\n\nele.ar1 &lt;- Arima(electricidad, \n                 order = c(0, 1, 0),\n                 seasonal = c(1, 1, 0),\n                 xreg = cbind(festivos, excesotemperatura))\nele.ar1\n\nSeries: electricidad \nRegression with ARIMA(0,1,0)(1,1,0)[7] errors \n\nCoefficients:\n         sar1  festivos  excesotemperatura\n      -0.5473  -74.2090             2.8101\ns.e.   0.0484    3.1115             0.3990\n\nsigma^2 = 283.7:  log likelihood = -1514.48\nAIC=3036.96   AICc=3037.07   BIC=3052.47\n\n\nVeamos si es necesaria más intervención.\n\nerror &lt;- residuals(ele.ar1)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2,2, 3)*sderror, \n             colour = c(\"red\", \"green\", \"green\", \"red\"), \n             lty = 2) + \n  scale_x_continuous(breaks= seq(1998, 2022, 2)) \n\nfechas[abs(error) &gt; 3 * sderror]\n\n[1] \"2023-07-25\" \"2023-08-27\" \"2023-12-25\"\n\n\n\n\n\n\n\n\nFigura 17: Error + Intervención\n\n\n\n\n\nSe observan tres candidatos a valores atípicos por superar el error las 3 desviaciones típicas.\n\n27 de julio: día de Santiago (patrón de España) y festivo en Galicia, Castilla y León, Navarra y País Vasco.\n27 de agosto: no se ha identificado nada especial este día\n25 de diciembre, Navidad: este día ya está incluido como festivo en la variable festivos, pero es tan festivo que el consumo cayó mucho más que en otro día festivo cualquiera.\n\nDeberíamos incluir el 27 de julio en nuestra lista de festivos y crear una variable ficticia especial para Navidad, pero a fin de aligerar este ejemplo no vamos a modificar el modelo actual.\n\n\nValidación\nVeamos si los coeficientes del modelo son significativos. Para ello, aplicamos la prueba z.\n\ncoeftest(ele.ar1)\n\n\nz test of coefficients:\n\n                    Estimate Std. Error  z value  Pr(&gt;|z|)    \nsar1               -0.547285   0.048413 -11.3045 &lt; 2.2e-16 ***\nfestivos          -74.208962   3.111550 -23.8495 &lt; 2.2e-16 ***\nexcesotemperatura   2.810094   0.399026   7.0424  1.89e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nTodos los coeficientes son significativos.\n\n\nError de estimación\nEn media nos equivocamos en 17 GWh (RMSE) y el error porcentual medio es del 1.8%, muy reducido.\nLa serie no presenta sesgo y el intervalo de confianza para las predicciones es válido.\n\naccuracy(ele.ar1)\n\n\n\n                ME  RMSE   MAE   MPE MAPE MASE ACF1\nTraining set -0.15 16.59 11.96 -0.05 1.81 0.38 0.07\n\n\n\n\nError de predicción estramuestral según horizonte temporal\nAsumimos que se precisan veinte semanas para hacer una buena estimación, \\(k = 140\\), y fijaremos el horizonte temporal en una semana, \\(h = 7\\) días. Como el modelo apenas presenta valores atípicos, podemos calcular como medida de precisión el valor medio en lugar del mediano.\n\nk &lt;- 140               \nh &lt;- 7                   \nT &lt;- length(electricidad)   \ns &lt;- T - k - h               \n\nmapeArima &lt;- matrix(NA, s + 1, h)\n\nX &lt;- data.frame(cbind(festivos, excesotemperatura))\n\nfor (i in 0:s) {\n  train.set &lt;- subset(electricidad, start = i + 1, end = i + k)\n  test.set &lt;-  subset(electricidad, start = i + k + 1, end = i + k + h) \n  \n  X.train &lt;- as.matrix(X[(i + 1):(i + k),])\n  X.test &lt;- as.matrix(X[(i + k + 1):(i + k + h),])\n  \n  fit &lt;- try(Arima(train.set, \n                   order = c(0, 1, 0),\n                   seasonal = c(1, 1, 0),\n                   xreg = X.train))\n  \n  if(!is.element(\"try-error\", class(fit))) {\n    fcast &lt;- forecast(fit, h = h, xreg = X.test) \n    mapeArima[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  }\n}\n\nerrorArima &lt;- apply(mapeArima, MARGIN = 2, FUN = median, na.rm = TRUE)\nerrorArima\n\n[1] 1.349262 2.111647 2.435318 2.716222 3.116016 3.311760 3.234447\n\n\nEl error de predicción parte del 1.3% para previsiones a un día vista (algo inferior al error de ajuste) y aumenta progresivamente según aumenta el horizonte de predicción, pasando al 3.2% a 7 días vista.\n\n\nInterpretación\nEl modelo teórico es \\(electricidad_t \\sim ARIMA_{7}(0, 1, 0)(1, 1, 0) + AI\\),\n\\[(1 - L^{7})(1 - L)electricidad_t = (1 + \\theta_{7} L^{7})\\varepsilon_t + AI.\\]\nSi desarrollamos queda \\[\n\\begin{aligned}\nelectricidad_t & = electricidad_{t-1} + (electricidad_{t-7} - electricidad_{t-8})  + \\theta_{7} \\varepsilon_{t-7} + \\varepsilon_{t}+ \\\\\n& \\gamma_1 \\cdot festivos +\\gamma_2 \\cdot excesotemperatura_t\n\\end{aligned}\n\\] Finalmente, el modelo estimado es, \\[\n\\begin{aligned}\n\\widehat{electricidad_t} & = electricidad_{t-1} + (electricidad_{t-7} - electricidad_{t-8}) - 0.55 \\varepsilon_{t-7}  \\\\\n& -74.2 \\cdot festivos_t + 2.8 \\cdot excesotemperatura_t\n\\end{aligned}\n\\]\n\nEl consumo de electricidad de un día es el mismo que el del día anterior más la variación observada entre estos dos días la semana pasada. Por ejemplo, el consumo un miércoles es el del martes pasado más la variación observada entre el martes y el miércoles de la semana previa.\nLos días festivos el consumo cae en 74.2 GWh respecto de la demanda en un día no festivo.\nPor cada grado centígrado de desviación de la temperatura sobre la media anual, el consumo aumenta en 2.8 GWh.\n\n\n\nPredicción de la serie\nUna vez dado por válido el modelo, podemos pasar a realizar predicciones para los próximos siete días y mostrar los resultados numérica y gráficamente (Figura 18).\nTeniendo en cuenta las dos variables de intervención:\n\nPara el efecto calendario debemos indicar qué valores tomará en el periodo de predicción, es decir, que días son festivos. Como el rango de predicción abarca del 1 al 7 de enero de 2024, se marcarán como festivos el lunes día 1 (Año nuevo) y el sábado 6 (Reyes).\nPara el efecto de la temperatura deberíamos, primero obtener la temperatura prevista para el periodo de predicción y después calcular el exceso de temperatura. La previsión de la temperatura se puede obtener de AEMET o de cualquier otro servicio de metereología.\n\nRecuerda siempre incluir las variables ficticias en la función forecast en el mismo orden que aparecen en la estimación con Arima.\n\npfestivos &lt;- c(1, 0, 0, 0, 0, 1, 0)\nptemperatura &lt;- c(6.6, 4.0, 10.0, 9.2, 7.6, 5.4, 4.8)\npexcesotemperatura &lt;- ptemperatura - mean(temperatura)\n\npele.ar1 &lt;- forecast(ele.ar1, \n                     h = 7,\n                     xreg = cbind(pfestivos, pexcesotemperatura), \n                     level = 95)\npele.ar1\n\n         Point Forecast    Lo 95    Hi 95\n54.00000       553.6264 520.6113 586.6415\n54.14286       639.1189 592.4285 685.8093\n54.28571       682.8552 625.6713 740.0390\n54.42857       672.0053 605.9751 738.0355\n54.57143       643.9064 570.0824 717.7304\n54.71429       488.0978 407.2276 568.9680\n54.85714       526.9900 439.6402 614.3397\n\n\n\nautoplot(pele.ar1, \n         xlab = \"\",\n         ylab = \"GWh\",\n         main = \"\") +\n  scale_x_continuous(breaks= seq(46, 56, 1)) \n\n\n\n\n\n\n\nFigura 18: Demanda eléctrica y predicción\n\n\n\n\n\nLa Figura 18 muestra la serie Electricidad y su predicción para la primera semana de 2024, junto con el intervalo de confianza. La calidad de ajuste es tan buena que el intervalo de confianza de las predicciones es muy estrecho."
  },
  {
    "objectID": "03-08-Tema8.html#footnotes",
    "href": "03-08-Tema8.html#footnotes",
    "title": "Series con estacionalidad. Procesos ARIMA con estacionalidad",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nR permite crear tu propio calendario de festivos y existen otras librerías que extienden las opciones de bizdays. En el ejemplo de Pasajeros puedes ver como construir la serie de días laborables del mes para España paso a paso.↩︎\nPara este análisis solo se van a considerar los festivos nacionales en 2023 al que añadiremos el lunes de Semana Santa. Es posible que algunos festivos autonómicos en comunidades muy pobladas tengan un efecto sobre el consumo eléctrico, pero esto es un ejercicio y hay que limitar el alcance del análisis.↩︎"
  },
  {
    "objectID": "04-01-Bootstrapping.html#idea-general",
    "href": "04-01-Bootstrapping.html#idea-general",
    "title": "Bootstrapping para obtener intervalos de predicción",
    "section": "Idea general",
    "text": "Idea general\nVeamos primero la idea general y luego los detalles:\n\nPartimos de una serie temporal \\(\\{y_t\\}_{t=1}^T\\) y un horizonte de predicción \\(h\\).\nA partir de la serie original vamos a generar una nueva serie que es similar a la original. Luego veremos como.\nAjustamos nuestro modelo a la nueva serie y obtenemos una predicción \\(h\\) periodos hacia adelante, que llamaremos \\(\\hat y_{T+h|T}^1\\).\nRepetimos los pasos 2 y 3 un numero \\(n\\) de veces (típicamente \\(n=5000\\)), de forma que al final del proceso tenemos \\(n\\) predicciones \\(h\\) periodos hacia adelante, \\(\\hat y_{T+h|T}^1,\\; \\hat y_{T+h|T}^2,\\; \\ldots,\\; \\hat y_{T+h|T}^n\\), obtenidas a partir de \\(n\\) series similares a la original.\nPor último, obtenemos el intervalo de predicción calculando los percentiles correspondientes a partir de estas \\(n\\) predicciones.\n\nEste proceso hay que repetirlo para cada horizonte de predicción en que estemos interesados."
  },
  {
    "objectID": "04-01-Bootstrapping.html#detalles",
    "href": "04-01-Bootstrapping.html#detalles",
    "title": "Bootstrapping para obtener intervalos de predicción",
    "section": "Detalles",
    "text": "Detalles\nLa clave del proceso es el paso 2, donde se obtiene una nueva serie similar a la original. También vale la pena aclarar un poco más el paso 5.\nPaso 2: nueva serie\nEn lo que viene a continuación no voy a ser riguroso para no perdernos en cuestiones matemáticas, pero sí suficientemente preciso para entender bien el proceso.\n\nDada la serie original, la descomponemos en sus tres componentes: tendencia, estacionalidad y error.\nA continuación, obtenemos una versión barajada de la componente del error. (Aquí es donde no estoy siendo preciso porque el proceso de barajado se tiene que hacer por bloques y es con reemplazamiento.)\nAhora se combinan –sumando o multiplicando, según el esquema– la tendencia, la estacionalidad y el error barajado para obtener una nueva serie que se parecerá a la original porque tiene la misma tendencia y estacionalidad, pero diferente error.\n\nVeamos un ejemplo muy sencillo para una serie simulada de orden estacional 5.\n\nLa dos primeras columnas indican la estación de cada dato y el valor de la serie, para un total de 15 observaciones.\nLas columnas Tendencia, Estacionalidad y Error han sido obtenidas aplicando el método de descomposición por regresiones locales ponderadas. Observa que cada dato de la serie es la suma de estas tres componentes.\nLa columna ErrorBootstrapping se ha obtenido como un muestreo con reemplazamiento de los datos de la columna Error. Como es una muestra con reemplazamiento, hay algunos errores repetidos.\nPor último, la nueva serie (columna NuevaSerie) se ha obtenido sumando las columnas Tendencia, Estacionalidad y ErrorBootstrapping. Esta serie tiene la misma tendencia y estacionalidad que la serie original y solo se diferencia en el error, así que la nueva serie debería parecerse a la serie original.\n\n\n\n   Estacion Serie Tendencia Estacionalidad  Error ErrorBootstrapping NuevaSerie\n1         1 27.00     19.96           9.60  -2.56              -2.96      26.59\n2         2 16.72     25.12         -13.33   4.93               9.43      21.22\n3         3 15.08     30.14         -12.09  -2.96              -2.56      15.49\n4         4 18.79     34.77          -9.11  -6.87               3.10      28.76\n5         5 75.53     38.58          24.94  12.01              12.01      75.53\n6         1 63.31     39.24           9.60  14.47               3.10      51.94\n7         2 17.28     38.48         -13.33  -7.87               9.43      34.58\n8         3 18.00     34.84         -12.09  -4.75              -6.87      15.88\n9         4 24.84     30.85          -9.11   3.10              -0.40      21.34\n10        5 54.67     30.13          24.94  -0.40              -6.87      48.21\n11        1 30.85     31.11           9.60  -9.86              12.01      52.72\n12        2 22.02     30.52         -13.33   4.84              -9.86       7.32\n13        3 26.51     29.17         -12.09   9.43               3.10      20.18\n14        4 24.14     27.94          -9.11   5.31              -7.87      10.96\n15        5 41.31     26.54          24.94 -10.17              12.01      63.49\n\n\nPaso 5: Predicción por intervalos\nPartimos de \\(n\\) predicciones a \\(h\\) periodos vista (\\(\\hat y_{T+h|T}^1,\\; \\hat y_{T+h|T}^2,\\; \\ldots,\\; \\hat y_{T+h|T}^n\\)) y queremos obtener a partir de ellas el intervalo de confianza.\nSupongamos que el nivel de confianza deseado es del 95%. Entonces, debemos calcular para las predicciones el percentil 2.5% y 97.5%. Recuerda que el percentil 2.5% es el valor numérico que deja un 2.5% de las predicciones por debajo de él; y que el percentil 97.5% es el valor numérico que deja un 97.5% de las predicciones por debajo de él. La función de R quantile() permite obtener estos valores.\nSi denominamos \\(l_h\\) al percentil 2.5% y \\(u_h\\) al percentil 97.5%, el intervalo de confianza de la predicción a \\(h\\) periodos vista es \\([l_h,\\; u_h]\\).\n¿Y la prediccion puntual?\nPara la predicción puntual tenemos dos opciones: obtener la predicción a partir de la serie original (como hemos visto en clase); u obtenerla como media de las \\(n\\) predicciones obtenidas\n\\[\\frac{1}{n}\\sum_{j=1}^n \\hat y_{T+h|T}^j\\]\nEste segundo método es el usual y se denomina bagging de bootstrap aggregating."
  },
  {
    "objectID": "03-07-Tema7.html#método-ingenuo-con-estacionalidad",
    "href": "03-07-Tema7.html#método-ingenuo-con-estacionalidad",
    "title": "Series con estacionalidad",
    "section": "2.1 Método ingenuo con estacionalidad",
    "text": "2.1 Método ingenuo con estacionalidad\nEn el método ingenuo con estacionalidad la predicción para un periodo es la última observación disponible de la misma estación que la fecha que se desea predecir. Es decir, \\(\\hat{y}_{T+h}=y_{T-m(k+1)}\\), donde\n\n\\(k\\) es la parte entera de \\((h-1)/m\\), el número de estaciones completas en el periodo de predicción previo al periodo \\(T+h\\).\nEste método asume que la serie no tiene tendencia.\nFunción de R: snaive(y, h)\nPara series con estacionalidad este es el método ingenuo de comparación del MASE\n\nNo hay métodos sencillos cuando la serie tiene tendencia y estacionalidad, así que se suele usar el método ingenuo con estacionalidad."
  },
  {
    "objectID": "03-07-Tema7.html#ejemplo-de-aplicación-a-la-serie-nacimientos",
    "href": "03-07-Tema7.html#ejemplo-de-aplicación-a-la-serie-nacimientos",
    "title": "Series con estacionalidad",
    "section": "2.2 Ejemplo de aplicación a la serie Nacimientos",
    "text": "2.2 Ejemplo de aplicación a la serie Nacimientos\nPodemos usar el método ingenuo con estacionalidad con la serie Nacimientos para obtener una previsión a dos años vista. Consideraremos la serie sólo desde enero de 2020.\n\nnacimientos &lt;- read.csv2(\"./series/Nacimientos.csv\", \n                         header = TRUE)\n\nnacimientos &lt;- ts(nacimientos[, 2],\n                  start = c(1975, 1),\n                  frequency = 12)\n\nnacimientos &lt;- window(nacimientos, start = 2000)\n\nsnaive.nacimientos &lt;- snaive(nacimientos, \n                              h = 24, \n                              level = 95)\naccuracy(snaive.nacimientos)\n\n                    ME     RMSE     MAE      MPE     MAPE MASE      ACF1\nTraining set -273.0399 1703.946 1367.75 -1.04244 3.941892    1 0.7367184\n\n\nEl error absoluto porcentual medio es del 3.9% (que corresponde a unos 1700 bebés según RMSE). Es decir, aplicando algo tan simple como predecir el número de nacimientos para un mes como los nacimientos del mismo mes del año previo, tenemos ya un error de ajuste muy bajo. Sin embargo, este método en general sobreestima algo el número de nacimientos (MPE inferior a -1%) y sus predicciones por intervalo no son fiables.\nLa Figura 2 muestra la serie y la predicción que, debido al método usado, no incorpora la tendencia decreciente de los últimos años.\n\nautoplot(snaive.nacimientos,\n         xlab = \"\",\n         ylab = \"Nacimientos\",\n         main = \"\",\n         PI = FALSE)\n\n\n\n\n\n\n\nFigura 2: Nacimientos y predicción por el método Ingenuo con estacionalidad"
  },
  {
    "objectID": "03-07-Tema7.html#definición",
    "href": "03-07-Tema7.html#definición",
    "title": "Series con estacionalidad",
    "section": "3.1 Definición",
    "text": "3.1 Definición\nEn las series con tendencia y estacionalidad, para obtener una predicción en el periodo \\(t+1\\) con datos hasta el periodo \\(t\\) necesitamos tres componentes:\n\nLa estimación del nivel de la serie en el periodo \\(t\\): \\(l_t\\)\nLa estimación de la pendiente de la serie en el periodo \\(t\\): \\(b_t\\)\nLa estimación de la estacionalidad en el mes correspondiente al periodo \\(t+1\\) con datos hasta \\(t\\): \\(s_{t + 1 - m}\\) (recuerda, \\(m\\) es el orden estacional)\n\nA partir de estas componentes obtenidas en el periodo \\(t\\) y para un esquema aditivo, se tendría que la predicción en el periodo \\(t+1\\) es:\n\\[\\widehat{y}_{t+1} = l_t + b_t + s_{t+1-m}.\\]\nEn general, las componentes pueden existir o no y se pueden combinar entre ellas aditiva o multiplicativamente. Veamos algunos casos:\n\nExisten todas y son multiplicativas: \\(\\widehat{y}_{t+1}=l_t \\cdot b_t \\cdot s_{t + 1 - m}\\)\nExisten todas, nivel y pendiente aditivas, y estacionalidad multiplicativa: \\(\\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}\\)\nNo hay pendiente y la estacionalidad es aditiva: \\(\\widehat{y}_{t+1}=l_t+s_{t + 1 - m}\\)\n\nEn las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista (\\(\\widehat{y}_{t+1}\\)). Si el objetivo es estimar una previsión \\(h\\) periodos hacia delante desde el periodo \\(t\\), \\(\\widehat{y}_{t+h}\\), hay que modificar la ecuación de predicción adecuadamente. Por ejemplo, para el caso aditivo se tendría que\n\\[\\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}\\] donde \\(k = \\lfloor (h-1)/m\\rfloor\\)."
  },
  {
    "objectID": "03-07-Tema7.html#casos-posibles",
    "href": "03-07-Tema7.html#casos-posibles",
    "title": "Series con estacionalidad",
    "section": "3.2 Casos posibles",
    "text": "3.2 Casos posibles\nRecordemos que en función del tipo de tendencia de la serie teníamos cinco posibilidades (N, A, Ad, M y Md). Por otro lado, si la serie tiene estacionalidad, este puede ser aditiva (A) o multiplicativa (M). Por tanto, dentro de las series con estacionalidad hay 10 posibles casos, mostrados en la Tabla 1. En la tabla, la primera letra hace referencia al tipo de tendencia y la segunda al tipo de estacionalidad.\n\n\n\nTabla 1: Casos de alisado según el tipo de tendencia y estacionalidad\n\n\n\n\n\nTendencia\n\nEstacionalidad\n\n\n\n\n\nAditiva (A)\nMultiplicativa (M)\n\n\nNinguna (N)\nN, A\nN, M\n\n\nAditiva (A)\nA, A\nA, M\n\n\nAditiva Amortiguada (Ad)\nAd, A\nAd, M\n\n\nMultiplicativa (M)\nM, A\nM, M\n\n\nMultiplicativa Amortiguada (Md)\nMd, A\nMd, M\n\n\n\n\n\n\nCada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.\nSi a los 10 casos de la Tabla 1 se añade que el error puede ser aditivo (A) o multiplicativo (M), obtenemos 20 posibilidades. Si, además, incluimos los 10 casos vistos en el Tema 6 para series sin estacionalidad, tenemos que una serie cualquiera se puede clasificar dentro de 30 posibilidades. Podemos estimar cualquiera de los treinta modelos usando la función ets del paquete forecast.\nAcude al artículo de Hyndman and Khandakar (2008) para saber más de cada modelo, o al libro de Hyndman et al. (2008)."
  },
  {
    "objectID": "03-07-Tema7.html#alisado-de-holt-winters-aditivo-a-a-a",
    "href": "03-07-Tema7.html#alisado-de-holt-winters-aditivo-a-a-a",
    "title": "Series con estacionalidad",
    "section": "4.1 Alisado de Holt-Winters aditivo (A, A, A)",
    "text": "4.1 Alisado de Holt-Winters aditivo (A, A, A)\nLas ecuaciones recursivas de actualización son:\n\\[\n\\begin{aligned}\nl_t & =\\alpha (y_t - s_{t-m} ) + (1-\\alpha)(l_{t-1}+b_{t-1}) \\\\\nb_t & =\\beta (l_t - l_{t-1}) + (1-\\beta)b_{t-1} \\\\\ns_t & =\\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \\gamma)s_{t-m}\n\\end{aligned}\n\\] con \\(0 \\leq \\alpha, \\beta, \\gamma \\leq 1\\).\nLa ecuación de la predicción intramuestral a un periodo vista es \\[\\widehat{y}_{t+1}  = l_t + b_t + s_{t+1-m},\\] de forma que la ecuación de predicción extramuestral es: \\[\\widehat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},\\] con \\(k = \\lfloor(h-1)/m\\rfloor\\).\nObserva que las ecuaciones para el nivel y la pendiente son similares a las ya vistas en el Tema 6 para el método de Holt. Respecto de la ecuación de actualización de la estacionalidad, dos estimaciones razonables de esta componente en el periodo \\(t\\) son su valor estimado a partir de la serie menos su tendencia \\(y_t-l_{t-1} - b_{t-1}\\), y la estimación que ya teníamos de la estacionalidad previamente, \\(s_{t-m}\\). La estimación final es una media ponderada, parametrizada por \\(0 \\leq \\gamma &lt; 1 - \\alpha\\).\nInterpretación del parámetro \\(\\gamma\\):\n\nSi \\(\\gamma = 1\\), \\(s_t = y_t - l_{t-1} - b_{t-1}\\), la estacionalidad se actualiza constantemente porque varía periodo a periodo\nSi \\(\\gamma = 0\\), \\(s_t = s_{t-m}= \\ldots = s_0\\), la estacionalidad se mantiene constante en el tiempo."
  },
  {
    "objectID": "03-07-Tema7.html#alisado-de-holt-winters-multiplicativo-m-a-m1",
    "href": "03-07-Tema7.html#alisado-de-holt-winters-multiplicativo-m-a-m1",
    "title": "Series con estacionalidad",
    "section": "4.2 Alisado de Holt-Winters multiplicativo (M, A, M)1",
    "text": "4.2 Alisado de Holt-Winters multiplicativo (M, A, M)1\nLas ecuaciones recursivas de actualización son:\n\\[\n\\begin{aligned}\nl_t & =\\alpha \\frac{y_t}{s_{t-m}} + (1-\\alpha)(l_{t-1}+b_{t-1}) \\\\\nb_t & =\\beta (l_t - l_{t-1}) + (1-\\beta)b_{t-1} \\\\\ns_t & =\\gamma \\frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \\gamma)s_{t-m}\n\\end{aligned}\n\\]\nLa ecuación de la predicción intramuestral a un periodo vista es \\[\\widehat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},\\] de forma que la ecuación de predicción extramuestral es: \\[\\widehat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.\\]"
  },
  {
    "objectID": "03-07-Tema7.html#ejemplo-con-nacimientos",
    "href": "03-07-Tema7.html#ejemplo-con-nacimientos",
    "title": "Series con estacionalidad",
    "section": "4.3 Ejemplo con Nacimientos",
    "text": "4.3 Ejemplo con Nacimientos\nVamos a usar el método de Alisado para predecir la serie Nacimientos.\n\nIdentificación y estimación del mejor modelo\nUsaremos la función ets sin ningún tipo de restricción para que localice el modelo (de entre los 30 posibles) que mejor se ajusta a los datos.\n\nnacimientosEts &lt;- ets(nacimientos)\nsummary(nacimientosEts)\n\nETS(A,A,A) \n\nCall:\nets(y = nacimientos)\n\n  Smoothing parameters:\n    alpha = 0.4892 \n    beta  = 0.0107 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 33052.834 \n    b = 143.8979 \n    s = -11.4659 3.8886 1957.737 1463.932 1013.289 1255.209\n           -953.4959 217.809 -1369.601 -172.4478 -3318.506 -86.3485\n\n  sigma:  906.7055\n\n     AIC     AICc      BIC \n5570.926 5573.193 5633.196 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE    MAPE      MASE\nTraining set -64.51908 881.1593 672.4836 -0.2064835 1.96789 0.4916715\n                   ACF1\nTraining set 0.05973202\n\n\nEl mejor modelos (A, A, A) tiene error, tendencia y estacionalidad aditivas: \\(y_t = l_{t-1} + b_{t-1} + s_{t + 1 - m}\\).\nEl bajo valor de \\(\\beta\\) y \\(\\gamma\\) indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la Figura 3).\n\nautoplot(nacimientosEts,\n         xlab = \"Periodo\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 3: Componentes del modelo óptimo para Nacimientos\n\n\n\n\n\nRespecto de la calidad del modelo, el MAPE de 2% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a 0.49 indica que este modelo reduce en un 51% el error del método ingenuo con estacionalidad, el más sencillo posible. El modelo no tiene sesgo y el valor de ACF1 de 0.06, inferior a 0.1, indica que el intervalo de confianza de las predicciones está bien calculado.\nPodemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos. Como el último dato de la serie es diciembre de 2023, los valores del nivel \\(l\\) y la pendiente \\(b\\) mostrados corresponden a ese mes. Sin embargo, los valores de la componente estacional están ordenados al revés: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, hasta s12 que sería enero.\n\nTT &lt;- nrow(nacimientosEts$states)\nnacimientosEts$states[TT,]\n\n           l            b           s1           s2           s3           s4 \n27041.914738   -55.737267   -11.607442     3.801462  1957.628722  1463.714031 \n          s5           s6           s7           s8           s9          s10 \n 1013.175595  1255.001436  -953.711757   217.589514 -1369.784143  -172.610401 \n         s11          s12 \n-3318.617718   -86.437475 \n\n\nFebrero es el mes con menor número de nacimientos: nacen 3318 bebés menos, respecto de la media anual. En octubre es cuando más bebés nacen: 1957 más que la media anual.\nPodemos usar estos valores para predecir los próximos 12 meses de 2024 (ojo, el etiquetado de la salida no tiene sentido):\n\nnacimientosEts$states[TT, 1] + (1:12) * nacimientosEts$states[TT, 2] + \n  nacimientosEts$states[TT, 14:3]\n\n     s12      s11      s10       s9       s8       s7       s6       s5 \n26899.74 23611.82 26702.09 25449.18 26980.82 25753.78 27906.76 27609.19 \n      s4       s3       s2       s1 \n28003.99 28442.17 26432.61 26361.46 \n\n\nNuestra predicción para enero de 2024 es de 26899.74 bebés y para diciembre de 2024 de 26361.46 bebés.\n\n\nPredicción\nSi pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):\n\nnacimientosEtsPre &lt;- forecast(nacimientosEts, \n                              h = 24, \n                              level = 95)\nnacimientosEtsPre\n\n\n\n         Point Forecast    Lo 95    Hi 95\nJan 2024       26899.74 25122.63 28676.85\nFeb 2024       23611.82 21625.03 25598.61\nMar 2024       26702.09 24517.87 28886.32\nApr 2024       25449.18 23076.55 27821.81\nMay 2024       26980.82 24426.68 29534.96\n\n\nLa Figura 4 muestra la serie Nacimientos, su predicción a dos años vista y el intervalo de confianza.\n\nautoplot(nacimientosEtsPre,\n         xlab = \"\",\n         ylab = \"Nacimientos\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 4: Nacimientos y predicción\n\n\n\n\n\n\n\nAnálisis del error\nSe identifica varios valores claramente atípicos –superan las 3 desviaciones típicas– que corresponden a enero de 2011 y, aproximadamente, nueves después del confinamiento por la pandemia (diciembre de 2020, y febrero y marzo de 2021). Abril de 2008 y diciembre de 2010 son otros candidatos a intervención por superar las 2.5 desviaciones típicas.2\n\nerror &lt;- residuals(nacimientosEts)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"Periodo\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, \n             colour = c(\"red\", \"blue\", \"blue\", \"red\"), lty = 2) + \n  scale_x_continuous(breaks= seq(2000, 2024, 2)) \n\nfechas &lt;- format(seq(as.Date(\"2000-1-1\"), as.Date(\"2023-12-1\"), \"month\"), \"%Y-%m\")\nfechas[abs(error) &gt; 3 * sderror]\n\n[1] \"2011-01\" \"2020-12\" \"2021-02\" \"2021-03\"\n\n\n\n\n\n\n\n\nFigura 5: Error + Intervención\n\n\n\n\n\nUn método alternativo para obtener valores atípicos es la prueba de Tukey (véase la píldora Valores perdidos y valores atípicos).\n\natipicos &lt;- tsoutliers(error)\nfechas[atipicos$index]\n\n[1] \"2020-12\"\n\n\nEn este caso solo se identifica como atípico el valor de diciembre de 2020."
  },
  {
    "objectID": "03-07-Tema7.html#ejemplo-con-nacimiento-y-con-transformación-logarítmica",
    "href": "03-07-Tema7.html#ejemplo-con-nacimiento-y-con-transformación-logarítmica",
    "title": "Series con estacionalidad",
    "section": "4.4 Ejemplo con Nacimiento y con transformación logarítmica",
    "text": "4.4 Ejemplo con Nacimiento y con transformación logarítmica\nUna alternativa para predecir la serie Nacimientos es predecir la transformación logarítmica de la serie. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original. Recuerda que el argumento lambda = 0 posibilita realizar todo el proceso de forma directa y sencilla.\nSi pedimos a la función ets que identifique el mejor modelo para la transformación logarítmica de la serie Nacimientos, aparece un modelo con tendencia amortiguada y un valor de \\(\\phi = 0.978\\), cercano al máximo valor permitido. Por este motivo, vamos a solicitar la identificación y estimación del mejor modelo excluyendo aquellos con tendencia amortiguada.\n\n# nacimientosEtsl &lt;- ets(nacimientos, lambda = 0)\nnacimientosEtsl &lt;- ets(nacimientos, \n                       lambda = 0,\n                       damped = FALSE)\n\nsummary(nacimientosEtsl)\n\nETS(A,N,A) \n\nCall:\nets(y = nacimientos, damped = FALSE, lambda = 0)\n\n  Box-Cox transformation: lambda= 0 \n\n  Smoothing parameters:\n    alpha = 0.481 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 10.5517 \n    s = -0.0015 -0.0031 0.0572 0.0468 0.0318 0.0416\n           -0.0231 0.0064 -0.0408 -0.0017 -0.1018 -0.0117\n\n  sigma:  0.029\n\n      AIC      AICc       BIC \n-393.7052 -391.9405 -338.7608 \n\nTraining set error measures:\n                    ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -72.14764 944.7309 706.6812 -0.2861817 2.063566 0.5166743\n                  ACF1\nTraining set 0.1615821\n\n\nEl modelo identificado es “ANA” que tiene error y estacionalidad aditiva y no tiene tendencia: \\(\\log(y_{t+1}) = l_{t} + s_{t + 1 - m} + \\varepsilon_{t+1}\\). En general, la transformación logarítmica de una serie sigue un esquema aditivo.\nEn este caso la calidad de las predicciones (MAPE = 2.1%) es algo inferior a la obtenida con la serie sin transformar. Además, con este modelo, las previsiones por intervalo no son fiables (solo se muestran los primeros meses).\n\nnacimientosfl &lt;- forecast(nacimientosEtsl,\n                           h = 24,\n                           level = 95)\nnacimientosfl\n\n\n\n         Point Forecast    Lo 95    Hi 95\nJan 2024       26884.93 25401.90 28454.55\nFeb 2024       24568.01 23068.81 26164.65\nMar 2024       27153.76 25352.86 29082.59\nApr 2024       26113.13 24254.13 28114.62\nMay 2024       27374.59 25301.98 29616.98\n\n\nLa Figura 6 muestra la serie Nacimientos y las previsiones extramuestrales obtenidas con y sin la transformación logarítmica. En este caso, las previsiones con la serie sin transformar son algo mayores que las obtenidas con la serie transformada.\n\n\n\n\n\n\n\n\nFigura 6: Nacimientos y dos predicciones con alisado de Holt-Winters\n\n\n\n\n\nRecuerda, ni la transformación logarítmica ni el uso de predicciones insesgadas (biasadj = TRUE) aseguran mejores predicciones respecto de otras opciones."
  },
  {
    "objectID": "03-07-Tema7.html#calidad-de-las-predicciones-para-los-modelos-con-y-sin-transformación-logarítmica",
    "href": "03-07-Tema7.html#calidad-de-las-predicciones-para-los-modelos-con-y-sin-transformación-logarítmica",
    "title": "Series con estacionalidad",
    "section": "4.5 Calidad de las predicciones para los modelos con y sin transformación logarítmica",
    "text": "4.5 Calidad de las predicciones para los modelos con y sin transformación logarítmica\nHemos visto que en calidad de ajuste, el modelo de Alisado sobre la serie sin transformar es superior a la del modelo sobre el logaritmo de la serie: mejores indicadores de calidad de ajuste e intervalo de confianza de las predicciones correctos.\nVeamos ahora qué método ofrece las predicciones con menor error con origen de previsión móvil. Consideraremos que son necesarios 15 años para ajustar bien los modelos y haremos previsiones a 12 meses vista. Como criterio de calidad de las predicciones vamos a usar el MAPE.\n\nk &lt;- 180\nh &lt;- 12\nTT &lt;- length(nacimientos)\ns &lt;- TT - k - h\n\nmapeAli &lt;- mapeAliL &lt;- matrix(NA, s + 1, h)\n\nfor (i in 0:s) {\n  train.set &lt;- subset(nacimientos, start = i + 1, end = i + k)\n  test.set &lt;-  subset(nacimientos, start = i + k + 1, end = i + k + h)\n  \n  fit &lt;- ets(train.set, model = \"AAA\", damped = FALSE)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAli[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n  fit &lt;- ets(train.set, model = \"ANA\", damped = FALSE, lambda = 0)\n  fcast &lt;- forecast(fit, h = h)\n  mapeAliL[i + 1,] &lt;- 100*abs(test.set - fcast$mean)/test.set\n  \n}\n\nmapeAliMedia &lt;- colMeans(mapeAli)\nmapeAliLMedia &lt;- colMeans(mapeAliL)\n\nround(mapeAliMedia, 2)\n\n [1] 2.40 2.73 2.89 2.97 2.90 2.89 3.12 3.17 3.28 3.30 3.10 3.07\n\nround(mapeAliLMedia, 2)\n\n [1] 2.44 2.91 3.24 3.44 3.46 3.51 3.93 4.11 4.21 4.35 4.38 4.54\n\n\nEl método de Alisado sobre la serie original ofrece mejores predicciones para todos los horizontes temporales. A doce meses vista la diferencia es de 1.5 p.p."
  },
  {
    "objectID": "03-07-Tema7.html#método-sencillo",
    "href": "03-07-Tema7.html#método-sencillo",
    "title": "Series con estacionalidad",
    "section": "5.1 Método sencillo",
    "text": "5.1 Método sencillo\nPodemos usar el método ingenuo con estacionalidad con la serie Demanda eléctrica, que tiene una estacionalidad de orden 7, pero no parece presentar tendencia.\n\nsnaive.electricidad &lt;- snaive(electricidad, \n                              h = 28,\n                              level = 95)\naccuracy(snaive.electricidad)\n\n                    ME    RMSE      MAE        MPE     MAPE MASE      ACF1\nTraining set 0.4959497 45.1574 31.82282 -0.1492087 4.743026    1 0.7470267\n\n\nEl error absoluto porcentual medio es del 4.7% o 45 GWh (RMSE), un error razonablemente reducido y el método no presenta sesgo. Sin embargo, la fórmula usada para el cálculo del intervalo de confianza de las predicciones no es válida.\nLa Figura 7 muestra la serie y la predicción a cuatro semanas vista. Debido a que la semana de referencia para predecir es la semana de Navidad, donde el consumo eléctrico es inferior al usual, las predicciones resultan ser claramente incorrectas. Este es un buen ejemplo de la diferencia entre calidad de ajuste y precisión de las predicciones.\n\nautoplot(snaive.electricidad,\n         xlab = \"\",\n         ylab = \"GWh\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 7: Demanda eléctrica y predicción por el método Ingenuo con estacionalidad"
  },
  {
    "objectID": "03-07-Tema7.html#alisado-exponencial-1",
    "href": "03-07-Tema7.html#alisado-exponencial-1",
    "title": "Series con estacionalidad",
    "section": "5.2 Alisado Exponencial",
    "text": "5.2 Alisado Exponencial\n\nIdentificación y estimación del mejor modelo\nEl modelo óptimo sin restricciones es (MAdM) con un valor de \\(\\phi\\) cercano al máximo de 0.98, por lo que se solicita el modelo óptimo excluyendo modelos con tendencia amortiguada.\n\n#electricidadEts &lt;- ets(electricidad)\nelectricidadEts &lt;- ets(electricidad,\n                       damped = FALSE)\n\nsummary(electricidadEts) \n\nETS(A,N,A) \n\nCall:\nets(y = electricidad, damped = FALSE)\n\n  Smoothing parameters:\n    alpha = 0.8585 \n    gamma = 1e-04 \n\n  Initial states:\n    l = 696.9707 \n    s = -49.2724 22.6105 35.9717 38.7919 33.4117 9.8245\n           -91.3378\n\n  sigma:  24.5881\n\n     AIC     AICc      BIC \n4502.001 4502.623 4541.000 \n\nTraining set error measures:\n                     ME     RMSE      MAE         MPE     MAPE      MASE\nTraining set -0.0244328 24.28306 14.89251 -0.08339514 2.300161 0.4679821\n                 ACF1\nTraining set 0.024706\n\n\nAhora el mejor modelo no presenta tendencia y tiene error y estacionalidad aditiva, es decir, \\(y_{t+1} = l_t + s_{t+1-m} + \\varepsilon_{t+1}\\).\nEl valor \\(\\gamma = 0\\) indica que las estacionalidad se mantiene contante en el tiempo, mientras que el elevado valor de \\(\\alpha\\) indica que el nivel de la serie cambia de forma constante. Este cambio de nivel está relacionado con las variaciones en el consumo eléctrico debido a los cambios en la temperatura y el uso de aparatos de climatización.\nRespecto de la calidad del modelo, el MAPE de 2.3% indica que estamos ante un modelo que se ajusta muy bien a los datos; no hay sesgo (MPE es casi cero); y el valor de ACF1, muy bajo, indica que la fórmula usada para el cálculo del intervalo de confianza de las predicciones es válida.\nPodemos ver los últimos valores estimados del nivel y la estacionalidad para interpretarlos. Recuerda que los valores de la componente estacional están ordenados alrevés (s1 es domingo y s7 es lunes).\n\nTT &lt;- nrow(electricidadEts$states)\nelectricidadEts$states[TT,]\n\n        l        s1        s2        s3        s4        s5        s6        s7 \n689.31491 -91.33788 -49.26566  22.61608  35.97953  38.78392  33.40487   9.81824 \n\n\nEl domingo la demanda eléctrica cae 91 GWh respecto de la media semanal. Por el contrario, el miércoles es el día de mayor incremento de demanda respecto de la media semanal, 39 GWh.\nTambién podemos usar los últimos valores estimados del nivel y la estacionalidad para predecir una semana,\n\nelectricidadEts$states[TT, 1] + electricidadEts$states[TT, 8:2]\n\n      s7       s6       s5       s4       s3       s2       s1 \n699.1331 722.7198 728.0988 725.2944 711.9310 640.0493 597.9770 \n\n\n\n\nPredicción\nSi pedimos los valores de predicción para las cuatro semanas siguientes, tenemos (sólo se muestran la primera):\n\nelectricidadEtsPre &lt;- forecast(electricidadEts, \n                               h = 28, \n                               level = 95)\nelectricidadEtsPre\n\n\n\n         Point Forecast    Lo 95    Hi 95\n54.00000       699.1331 650.9414 747.3249\n54.14286       722.7198 659.2057 786.2338\n54.28571       728.0988 652.2990 803.8987\n54.42857       725.2944 638.9394 811.6495\n54.57143       711.9310 616.1772 807.6848\n54.71429       640.0493 535.7402 744.3583\n54.85714       597.9770 485.7614 710.1927\n\n\nLa Figura 8 muestra la serie Demanda eléctrica, su predicción a cuatro semanas vista y el intervalo de confianza.\n\nautoplot(electricidadEtsPre,\n         xlab = \"\",\n         ylab = \"GWh\",\n         main = \"\")\n\n\n\n\n\n\n\nFigura 8: Demanda eléctrica y predicción\n\n\n\n\n\n\n\nAnálisis del error\n\nerror &lt;- residuals(electricidadEts)\nsderror &lt;- sd(error)\n\nautoplot(error, series=\"Error\",\n         colour = \"black\",\n         xlab = \"Semana\",\n         ylab = \"Error\",\n         main = \"\") +\n  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, \n             colour = c(\"red\", \"blue\", \"blue\", \"red\"), lty = 2) + \n  scale_x_continuous(breaks= seq(6, 26, 2)) \n\nfechas &lt;- format(seq(as.Date(\"2023-1-1\"), as.Date(\"2023-12-31\"), \"day\"), \"%Y-%m-%d\")\nfechas[abs(error) &gt; 3 * sderror]\n\n [1] \"2023-01-01\" \"2023-01-06\" \"2023-01-07\" \"2023-04-06\" \"2023-04-08\"\n [6] \"2023-05-01\" \"2023-08-15\" \"2023-08-27\" \"2023-10-12\" \"2023-11-01\"\n[11] \"2023-11-02\" \"2023-12-06\" \"2023-12-25\"\n\n\n\n\n\n\n\n\nFigura 9: Error + Intervención\n\n\n\n\n\nEl la Figura 9 se identifican múltiples días atípicos asociados con un consumo inferior al esperado debido a festividades: Año nuevo, Reyes, Semana Santa (el Viernes Santo fue el 7 de abril), Día del trabajador, Virgen de agosto, Día de la hispanidad, Todos los Santos, Día de la Constitución y Navidad. El Día de la Inmaculada (8 de diciembre) no aparece por caer en domingo.\nTambién se observan tres días con un consumo mayor de lo esperado justo después de un festivo, el 7 de enero (tras Reyes), el 8 de abril (Sábado Santo) y el 2 de noviembre (tras Todos los Santos). Aquí la causa no es tanto un incremento inesperado del consumo, como la dinámica del propio método de estimación. Al llegar un día festivo, el método de Alisado falla ofreciendo una predicción más alta de la real y dando lugar a un error negativo. Al día siguiente, el método de Alisado ajusta su predicción a la baja, pero por no ser festivo vuelve a fallar, esta vez ofreciendo una predicción más baja de la real y dando lugar a un error positivo.\nVeamos como en este caso la prueba de Tukey identifica las mismas fechas.\n\natipicos &lt;- tsoutliers(error)\nfechas[atipicos$index]\n\n [1] \"2023-01-01\" \"2023-01-06\" \"2023-01-07\" \"2023-04-06\" \"2023-04-08\"\n [6] \"2023-05-01\" \"2023-08-15\" \"2023-08-27\" \"2023-10-12\" \"2023-11-01\"\n[11] \"2023-11-02\" \"2023-12-06\" \"2023-12-25\""
  },
  {
    "objectID": "03-07-Tema7.html#footnotes",
    "href": "03-07-Tema7.html#footnotes",
    "title": "Series con estacionalidad",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFormalmente en el modelo de Holt-Winters multiplicativo el error es aditivo. Es decir, debería ser (A, A, M). Sin embargo, debido a que desde un punto de vista teórico este modelo, junto con otros, puede tener varianza infinita, la función ets no permite por defecto su estimación. Para poder estimar con la función ets el modelo (A, A, M) es necesario añadir el argumento restrict = FALSE. Los modelos que para poder ser estimados requieren este argumento son: ANM, AAM, AAdM, MMA, MMdA, AMN, AMdN, AMA, AMdA, AMM y AMdM.↩︎\nRecuerda que el valor de 3 es uno de los posibles y debe ajustarse a las características de la serie y el análisis.↩︎"
  },
  {
    "objectID": "03-01-Tema1.html#métodos-subjetivos",
    "href": "03-01-Tema1.html#métodos-subjetivos",
    "title": "Introducción",
    "section": "3.1 Métodos subjetivos",
    "text": "3.1 Métodos subjetivos\nRealizar predicciones a partir de opiniones y juicios subjetivos es práctica común. En muchas ocasiones las previsiones subjetivas son la única opción, tales como cuando no hay datos históricos, cuando un nuevo producto se va a sacar al mercado, cuando entra en el mercado un nuevo competidor, o cuando el entorno de mercado cambia notablemente. Por ejemplo, predecir el efecto que iba a tener la Covid-19, una situación sin precedentes, en el grado de ocupación hotelera de agosto de 2020 o las ventas de refrescos de un supermercado requiere necesariamente de juicios subjetivos.\nCon los años las predicciones por métodos subjetivos han ido ganando aceptación y reconocimiento como una ciencia. En parte porque la calidad de sus predicciones ha mejorado como resultado directo del uso de metodologías mejor estructuradas y más sistemáticas.\nLa predicciones a partir de opiniones y juicios son subjetivas y por tanto sujetas a un montón de sesgos y limitaciones. Por citar algunas:\n\nPueden ser perfectamente inconsistentes por muchos motivos: se presta más atención a acontecimientos presentes que a los pasados; podemos directamente pasar por alto información relevante; se pueden confundir algunas relaciones causales.\nPueden estar afectadas por la agenda política o personal.\nPueden sufrir del efecto ancla: las predicciones tienden a agruparse en torno a un valor inicial de referencia familiar.\no del efecto de confirmación, donde se da mas peso a la información que confirma nuestras hipótesis previas.\n… (la lista es larga)\n\n\nPrincipios básico en la implementación\nA fin de reducir el efecto adverso de estas limitaciones y sesgos, es fundamental usar una aproximación sistemática y bien estructurada, con independencia de la metodología que finalmente se vaya a seguir. Los principios a seguir son:\n\nDefinir la variable a predecir de forma clara y concisa.\nImplementar un método de previsión sistemático.\nDocumentar todo el proceso con el objetivo de promover la consistencia y la replicabilidad.\nJustificar las predicciones para reducir los sesgos.\nMonitorizar las predicciones para adelantarse a irregularidades o desviaciones importantes respecto de los valores reales.\nSeparar los agentes que hacen las predicciones de los agentes que las van a usar.\n\n\n\nAlgunos métodos subjetivos\n\nJurado de opinión: la predicción la realizan un conjunto de expertos por consenso.\nPredicción por analogía: se realiza la predicción buscando situaciones o entornos análogos donde se conoce la información solicitada.\nMétodo Delphi: similar al jurado de opinión, pero se preserva el anonimato de los expertos y el consenso se obtiene a partir de un proceso iterativo en varias rondas.\nMétodo de escenarios: se definen una serie de posibles escenarios considerando todos los factores relevantes y se les asigna una probabilidad. Para cada escenario se obtiene, siguiendo un determinado método, la predicción deseada.\nAjustes por juicios subjetivos: propiamente este no es un método subjetivo. Consiste en realizar una predicción con información histórica disponible usando herramientas estadísticas para después ser ajustada a partir del juicio de expertos."
  },
  {
    "objectID": "03-01-Tema1.html#métodos-objetivos",
    "href": "03-01-Tema1.html#métodos-objetivos",
    "title": "Introducción",
    "section": "3.2 Métodos objetivos",
    "text": "3.2 Métodos objetivos\nLa predicción se obtiene principalmente a partir de los valores pasados de la propia variable a predecir aunque también se puede utilizar el valor pasado de otras variables\n\\[\\hat y_{t+h} = f(y_t, y_{t-1},\\ldots)\\] donde \\(\\hat y_{t+h}\\) es la previsión que hacemos para el periodo \\(t+h\\) con información solo hasta el periodo \\(t\\). En este contexto, lo difícil es conocer la función f() que relaciona el comportamiento pasado de una serie temporal con su futuro.\nDentro de los métodos objetivos distinguiremos entre:\n\nNo paramétricos, donde no se asume ninguna hipótesis estadística y las predicciones se obtienen a partir de los datos pasados con cálculos sencillos que no comportan estimar ningún parámetro. Por ejemplo \\(\\hat y_{t+1} = y_t\\) (método ingenuo I).\nDentro de este grupo, en los próximos temas veremos los métodos ingenuos, medias móviles y métodos de alisado exponencial.\nParamétricos, se asume una estructura estocástica en la generación de los datos, es necesario que se verifiquen ciertos supuestos estadísticos y hay que estimar parámetros. Por ejemplo \\(\\hat y_{t+1} = \\mu + \\phi_1 y_t\\) (modelo autorregresivo de orden 1), donde los parámetros \\(\\mu\\) y \\(\\phi_1\\) deben ser estimados.\nA este categoría pertenecen los modelos ARIMA.\n\nEn el tema 3 haremos una breve introducción tanto de las técnicas no paramétricas (métodos ingenuos, medias móviles y métodos de alisado exponencial) como paramétricas (ARIMA) que veremos en el curso. En los temas 4 a 8 aprenderemos a utilizarlas."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#uso-de-modelos-muy-adaptativos",
    "href": "04-08-Series_interrumpidas.html#uso-de-modelos-muy-adaptativos",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de modelos muy adaptativos",
    "text": "Uso de modelos muy adaptativos\nAlgunos modelos, por su naturaleza, reaccionan muy rápidamente ante cambios en la estructura de la serie, adaptándose a ellos. Uno de estos modelos es el Alisado exponencial.\nCuando los parámetros de un modelo de Alisado están próximos a 1, el modelo usa preferentemente la información más reciente de la serie para ajustarse y predecir. De esta forma, ante una perturbación en la serie, estos modelos pueden ajustarse a ella con sencillez y rapidez.\nLa ventaja de esta estrategia es que simplemente hay que usar un modelo conocido, que es muy sencillo y muy rápido computacionalmente. Además, el ajuste y predicción con estos modelos es automático. La desventaja principal de los modelos de Alisado es que tardan algunos periodos en adaptarse, así que si los cambios se producen de forma constante, el modelo estará constantemente inadaptado."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#uso-de-intervención",
    "href": "04-08-Series_interrumpidas.html#uso-de-intervención",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de intervención",
    "text": "Uso de intervención\nSi la perturbación no es excesivamente compleja, puede incluirse en el proceso de ajuste como intervención de un modelo Arima.\nEsta estrategia implica que tenemos un buen entendimiento de la perturbación: punto de inicio y final, efecto sobre la serie temporal, etc.\nSu ventaja de nuevo es que trabajamos con modelos ya conocidos y, además, que podremos estimar la estructura de la tendencia y la estacionalidad pasadas y sus cambios con la perturbación. Ahora bien, el modelo asumirá que el comportamiento de la serie tras la perturbación es similar al observado antes de la perturbación. Si esto no es cierto, las predicciones serán del todo incorrectas. Pero incluso si el supuesto es cierto y las previsiones son acertadas, su intervalo de confianza será más estrecho de lo correcto."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos",
    "href": "04-08-Series_interrumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Fijar las observaciones durante la perturbacion como valores perdidos",
    "text": "Fijar las observaciones durante la perturbacion como valores perdidos\nUna aproximación más radical consiste en fijar como valores perdidos todas las observaciones de la serie temporal durante el periodo de la perturbación y ajustar un modelo a la serie resultante. Las predicciones que se realicen con este modelo serían las correspondientes a una realidad donde la perturbación no ha tenido lugar.\nUna ventaja de esta aproximación es que no se usa información durante el periodo de la perturbación, por lo que el intervalo de confianza de las predicciones será amplio durante la perturbación y tras ella, y no se irá estrechando hasta que haya suficientes datos como para estimar la distribución de las predicciones con más precisión.\nEntre las desventajas de este método están que solo se pueden usar modelos que permitan estimar con datos perdidos, por ejemplo modelos Arima, y que es necesario identificar en que periodo se inicia y termina la perturbación."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si",
    "href": "04-08-Series_interrumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Trabajar bajo el escenario qué hubiera pasado si",
    "text": "Trabajar bajo el escenario qué hubiera pasado si\nEsta estrategia en un poco más elaborada que las ya mencionadas dado que toma elementos de varias de ellas. La idea básica es obtener la serie temporal que correspondería a un escenario donde la perturbación no ha tenido lugar y usar esta serie para predecir.\nPara el primer paso, obtener una serie completa donde la perturbación no ha tenido lugar tenemos dos alternativas:\n\nTerminamos la serie justo antes de la perturbación, la ajustamos a un modelo y hacemos predicciones durante todo el periodo de la perturbación. Estas predicciones sustituirán los valores reales de la serie, las que han tenido lugar durante a la perturbación.\nAsignamos como valores perdidos los datos de la serie durante la perturbación y ajustamos un modelo. Luego sustituimos los valores reales de la serie durante el periodo de la perturbación por los valores estimados por el modelo durante este mismo periodo.\n\nEn cualquiera de los dos casos, el resultado es una nueva serie que coincide con la original fuera de los periodos de la perturbación y durante la perturbación toma valores que hubieran podido tener lugar en un escenario donde esta no ha ocurrido.\nEsta nueva serie se ajusta por un modelo que, posteriormente, se usa para obtener las predicciones.\nLógicamente, esta estrategia comparte las ventajas y desventajas de las estrategias que usa para su implementación."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#uso-de-modelos-muy-adaptativos-1",
    "href": "04-08-Series_interrumpidas.html#uso-de-modelos-muy-adaptativos-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de modelos muy adaptativos",
    "text": "Uso de modelos muy adaptativos\nObserva que esta aproximación básicamente consiste en no hacer nada más allá de elegir un método muy adaptativo. Por este motivo compararemos los resultados obtenidos con Alisado, un modelo muy adaptativo, y con Arima, un modelo muy poco adaptativo.\nLa Figura 2 muestra el resultado de aplicar Alisado y Arima a los datos. Las predicciones para 2020 se han realizado antes de que el efecto de la Covid-19 tenga lugar y siguen el patrón de pernoctaciones observado en el pasado. Ambos métodos ofrecen prácticamente las mismas predicciones y ambos sobrestiman la realidad.\nLas predicciones para 2021 se realizan después de observar 9 meses de fuerte caída de las pernoctaciones como efecto de la Covid-19 y ambos modelos se ajustan a esta caída. Sin embargo, ninguno es capaz de captar la recuperación ocurrida en las pernoctaciones en 2021, de forma que las previsiones de ese año se quedan por debajo de la realidad. Para el año 2022 ambos modelos son capaces de reconocer el incremento en la pernoctaciones ocurrida en los pasados meses, pero de nuevo no captan que las pernoctaciones seguirán creciendo y vuelven a realizar previsiones por debajo de la realidad. Si en 2021 las predicciones mejores son las obtenidas con Arima, en el año siguiente son la de Alisado.\nPara 2023 Alisado se ha adaptado plenamente a la casi completa recuperación ocurrida en 2022 y sus predicciones son razonablemente buenas. Por el contrario Arima realiza unas predicciones muy bajas debido a que el modelo identificado usa datos no solo de 2022 sino de años pasados. Por este mismo motivo las predicciones con Arima de 2024 vuelven a ser muy bajas. Además, sorprende lo elevadas de las predicciones de Alisado, que por lo demás repiten razonablemente bien el patrón observado en los dos años previos.\nEn general, ninguno de los dos métodos lo hace especialmente bien, aunque con el método de Alisado se obtienen mejores predicciones una vez la perturbación ha pasado.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 2: Modelos adaptativos. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando modelos de Alisado y Arima."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#uso-de-intervención-1",
    "href": "04-08-Series_interrumpidas.html#uso-de-intervención-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Uso de intervención",
    "text": "Uso de intervención\nAplicaremos la estrategia de la intervención usando el modelo Arima. Con tal fin vamos a crear dos variables de intervención: un primer cambio de nivel asociado al año de la pandemia, que empieza en marzo de 2020 y termina en diciembre de 2020; y un segundo cambio de nivel para el año 2021, desde enero hasta diciembre.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 3: Intervención. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando el modelo Arima.\n\n\n\nLa Figura 3 muestra las predicciones y el intervalo de confianza al 90%. Las predicciones para 2020, realizadas sin conocimiento de la próxima pandemia, siguen el patrón observado en el pasado. Como hasta 2019 la serie era muy regular, el ajuste es muy bueno y el intervalo de confianza de las predicciones estrecho.\nLas predicciones para 2021 se realizan tras casi un año de caída en las pernoctaciones con un modelo que estima la magnitud de esta caída a partir de la variable de intervención cambio de nivel en 2020. La predicción para 2021 se corrige a la baja por la mitad de esta magnitud estimada, porque asumimos que habrá una recuperación en el turismo, pero aun así en general se subestima fuertemente la realidad. Además, se observa un intervalo de predicción mucho más ancho debido al aumento de la incertidumbre en el comportamiento de la serie. Para las predicciones del año 2022 de nuevo se aplica la mitad de la caída en las pernoctaciones estimada con la variable de intervención cambio de nivel de 2021 porque otra vez asumimos que la recuperación del turismo continua. En este caso las previsiones a veces se quedan por debajo y otras por encima de la realidad. Además, los dos años de perturbación y cambios en el patrón de la serie se reflejan en un intervalo de confianza para las predicciones aun más amplio.\nDurante 2022 la serie ha regresado casi a la normalidad. Además, para las predicciones de 2023 ya no se aplican ninguno de los cambios de nivel estimados. El resultado son unas predicciones mucho mejores que las obtenidas previamente aunque su amplio intervalo de confianza evidencia que todavía pesa mucho la incertidumbre observada en el pasado, con tres años consecutivos de cambios en la estructura de la serie.\nLa predicciones de 2024 reproducen de forma imperfecta el patrón observado en la pernoctaciones los dos últimos años. Se observa que la variación estacional de las predicciones es mucho más suave que la real. La amplitud del intervalo de confianza es menor que el observado para las predicciones de 2023 debido a que la regularidad en la serie de los dos últimos años ha reducido la incertidumbre."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos-1",
    "href": "04-08-Series_interrumpidas.html#fijar-las-observaciones-durante-la-perturbacion-como-valores-perdidos-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Fijar las observaciones durante la perturbacion como valores perdidos",
    "text": "Fijar las observaciones durante la perturbacion como valores perdidos\nAsignar a valores perdidos las observaciones durante el periodo de la perturbación es una forma radical de resolver el problema, pero muy sencilla de implementar. Asumiremos que el efecto de la pandemia se inició en marzo de 2020 y terminó en febrero de 2022. Las 24 observaciones de este periodo se asignarán como NA y la serie resultante se ajustará a un modelo Arima, sin necesidad de incluir intervención.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 4: Valores perdidos. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando el modelo Arima.\n\n\n\nLa Figura 4 muestra las predicciones y el intervalo de confianza al 90%. Para los cuatro primeros años la predicción muestra lo que hubiera pasado sin la pandemia de la Covid-19, basándose en el comportamiento de las pernoctaciones hasta 2019. Para los años 2020 y 2021 las predicciones sobrestiman tremendamente la realidad. Pero para el año 2022, cuando el efecto de la pandemia casi había pasado, las predicciones se ajustan mucho más a la serie, aunque la siguen sobrestimando ligeramente. Además, cuanto más alejado es el horizonte temporal de las predicciones, mayor es la incertidumbre y, por tanto, más amplio es el intervalo de confianza.\nFinalmente, en 2023 las predicciones se ajustan muy bien a la realidad, y para el año 2024 las predicciones, similares a la obtenidas para el año previo, posiblemente sigan siendo muy precisas."
  },
  {
    "objectID": "04-08-Series_interrumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si-1",
    "href": "04-08-Series_interrumpidas.html#trabajar-bajo-el-escenario-qué-hubiera-pasado-si-1",
    "title": "Prediciendo series temporales interrumpidas",
    "section": "Trabajar bajo el escenario qué hubiera pasado si",
    "text": "Trabajar bajo el escenario qué hubiera pasado si\nPara el escenario qué hubiera pasado si vamos a estimar un modelo Arima bajo el escenario previo (asignar a valores perdidos las observaciones durante el periodo de la perturbación), y usarlo para estimar que podría haber pasado durante la pandemia. Después, estimamos un segundo modelo Arima con toda la nueva serie y lo usamos para obtener las predicciones.\n\n\n\n\n\n\n\n\n\n\n\n(a) Predicciones para 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Predicciones para 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Predicciones para 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n(d) Predicciones para 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n(e) Predicciones para 2024\n\n\n\n\n\n\n\nFigura 5: Qué hubiera pasado si. Cada panel muestra las predicciones de los doce meses de un año para la serie Pernoctaciones usando el modelo Arima.\n\n\n\nBajo este escenario las predicciones resultan similares a las obtenidas bajo el supuesto previo con asignación de valores perdidos (véase Figura 5). Sin embargo, los intervalos de confianza son más estrechos. Al sustituir los valores perdidos por valores ajustados, el modelo estimado posteriormente trabaja con una serie muy regular sin incertidumbre y esto se refleja en la amplitud del intervalo de confianza."
  }
]