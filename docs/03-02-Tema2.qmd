---
title: "Series Temporales: Alisado Exponencial"
subtitle: "Máster de Bioestadística (Modelización Estadística)"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
toc: true
toc-title: Índice
number-sections: true
bibliography: references.bib
crossref:
  fig-title: Figura
  tbl-title: Tabla
  fig-prefix: Figura
  tbl-prefix: Tabla
---

```{r}
#| label: chunk_setup
#| echo: false
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```

```{r}
#| label: librerias
#| echo: false
library(forecast)
library(ggplot2); theme_set(theme_bw())
```

\
\

# Introducción

En muchos casos es preciso aplicar un método de predicción rápido y sencillo:

-   A causa del elevado número de series que tienen que ser analizadas.
-   Debido a la rapidez con que las predicciones se han de dar.

Actualmente existen muchos métodos sencillos de predicción, entre los que cabe destacar dos:

-   **Métodos de media móvil** 
-   **Métodos de alisado exponencial**

Estas técnicas, a pesar de su sencillez, son bastante adecuadas cuando la previsión es a corto plazo:

> "Statistically sophisticated or complex methods do not necessarily produce more accurate forecasts than simpler ones." @Makridakis00

Pero hay métodos aún más sencillos que quedan englobados bajo el paraguas de **métodos sencillos** que también veremos en este tema.

\
\

# Criterios de calidad

Dado que en este tema, y en los siguientes, vamos a ver diferentes métodos para predecir una serie temporal, es preciso definir criterios que permitan estimar tanto su calidad del ajuste (bondad de ajuste) como su precisión con las predicciones, para poder elegir el *mejor* modelo.

> "The rankings of the performance of the various methods vary according to the accuracy measure being used." @Makridakis00

\

## Notación y definiciones

Dada una serie temporal $\{y_t\}_{t=1}^T$, se define:

-   **Previsión** $h$ periodos adelante, como la previsión de la serie para el periodo $t+h$ disponiendo de información hasta el periodo $t$, y se denota por $\hat{y}_{t+h|t}$. Por simplicidad lo escribiremos también como $\hat{y}_{t+h}$.

-   Así, $\hat{y}_{t+1|t}$ es la **previsión un periodo adelante** o a un periodo vista. Es decir, la previsión de la serie en el periodo $t+1$ desde el periodo $t$.

    Por simplicidad denotaremos a $\hat{y}_{t+1|t}$ como $\hat{y}_{t+1}$. Por tanto, $\hat{y}_{t}$ será la previsión en $t$ con datos hasta el periodo $t-1$ ($\hat{y}_{t} = \hat{y}_{t|t-1}$).

Si para un periodo $t$ se tiene la observación $y_t$ y una previsión $\hat{y}_t$, se define como **error** a un periodo vista a 
$$\hat{e}_t=y_t-\hat{y}_t,$$ 
de forma que la serie $\{\hat{e}_t\}_{t=1}^T$ nos permitirá definir varios criterios de calidad.

### ¿Calidad de ajuste o de previsión? {.unnumbered}

Los mismos criterios que se van a definir a continuación pueden ser criterios de calidad de ajuste o de calidad de las previsiones. Esta diferencia depende de cómo se ha obtenido $\hat{y}_t$. 

Si en el proceso de predicción hay parámetros cuyo ajuste o estimación se ha realizado usando toda la serie temporal, entonces hablaremos de calidad de ajuste: para obtener $\hat{y}_t$ se habrá usado el dato $y_t$ y los siguientes, es decir, datos posteriores al periodo $t$ y entonces $\hat{e}_t$ es un error de ajuste.

Por el contrario, si en el proceso de predicción no hay parámetros o habiéndolos su estimación se ha realizado usando la serie temporal hasta el periodo $t-1$, entonces hablaremos de calidad de predicción: para obtener $\hat{y}_t$ solo se habrán usado el datos hasta $y_{t-1}$, es decir, datos anteriores al periodo $t$, y entonces $\hat{e}_t$ es un error de predicción.

A veces al *error de ajuste* se le denomina *error de previsión intramuestral* y hablaremos de criterios de *calidad intramuestral*. De la misma forma al *error de previsión* se le denomina *error de previsión extramuestral* y hablaremos de criterios de *calidad extramuestral* o *precisión* de las predicciones.


\

## Criterios de calidad

Dada una serie $\{y_t\}_{t=1}^T$, un método de predicción y su vector de errores asociado $\{\hat{e}_t\}_{t=1}^T$, podemos definir múltiples criterios de calidad de ajuste o predicción del método que hacen referencia a la presencia de sesgo en las predicciones, la magnitud del error cometido y la calidad del intervalo de confianza de las predicciones. Las más habituales son (siglas en inglés):

-   Error medio (ME): $\frac{1}{T}\sum_{t=1}^T \hat{e}_t$

\vspace{0.3cm}

-   Raíz del error cuadrático medio (RMSE): $\sqrt{\frac{1}{T}\sum_{t=1}^T \hat{e}^2_t}$

\vspace{0.3cm}

-   Error absoluto medio (MAE): $\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|$

\vspace{0.3cm}

-   Error porcentual medio (MPE): $\frac{100}{T}\sum_{t=1}^T \frac{\hat{e}_t}{y_t}$

\vspace{0.3cm}

-   Error porcentual absoluto medio (MAPE): $\frac{100}{T}\sum_{t=1}^T \big|\frac{\hat{e}_t}{y_t}\big|$

\vspace{0.3cm}

-   Error escalado absoluto medio (MASE): $\big(\frac{1}{T}\sum_{t=1}^T |\hat{e}_t|\big)/q$, donde $q$ es el error absoluto medio para un método ingenuo de predicción: el método ingenuo I para series sin estacionalidad y el método ingenuo con estacionalidad para series con estacionalidad.

\vspace{0.3cm}

-   Correlación entre $\hat{e}_t$ y $\hat{e}_{t-1}$ (ACF1).

\

ME y MPE permiten valorar el sesgo de las predicciones (que estén sistemáticamente por encima o por debajo de los valores reales).

-   Lo esperado es un valor cercano a cero (en el caso de ME con relación al valor medio de la serie). Valores muy alejados de cero son indicadores de sesgo de predicción.
-   La más cómoda de interpretar es MPE. Asumiremos que si MPE es menor que 1% en valor absoluto, no hay sesgo.

RMSE y MAE son medidas de calidad de ajuste/precisión. Indican el error medio cometido, independientemente del signo, medido en las mismas unidades que la serie temporal.

-   Están acotadas inferiormente por el valor óptimo de 0, pero no hay cota superior.

MAPE es una medida de calidad de ajuste/precisión alternativa que indica el error porcentual medio cometido.

-   Está acotado inferiormente por el valor óptimo de 0%, y la cota superior natural es 100%, aunque podría sobrepasarse.
-   Si $y_t$ puede valer 0, entonces MAPE no se puede calcular. Además, MAPE penaliza más los errores negativos frente a los errores positivos. Se puede definir el error porcentual absoluto medio simétrico (sMAPE) $\frac{200}{T}\sum_{t=1}^T \Big|\frac{\hat{e}_t}{y_t + \hat{y}_t}\Big|$ a fin de corregir estos problemas.

MASE es la ratio entre el error del método usado y el error de un método ingenuo de predicción. Permite saber cuánto ganamos en capacidad predictiva al pasar de un método ingenuo a otro más complicado.

-   Un valor cercano a 1 indica que el método usado no es mejor que el método ingenuo
-   Cuanto más cercano a 0, mejor es el método usado respecto del método ingenuo
-   Su complementario a 1 se puede interpretar como la tasa de mejora

ACF1 permite saber si el método empleado ha extraído toda la información disponible en los datos de la serie para hacer las predicciones. Si no es así, la fórmula usada para estimar el intervalo de confianza de las predicciones no será válida:

-   Un valor muy cercano a 0 (menor que 0.1) indica que se ha extraído toda la información y la fórmula usada para estimar el intervalo de confianza de las predicciones es válida.
-   Valores minimamente alejados de 0 indican que la fórmula no es válida.

::: callout-note
## Cálculo del intervalo de confianza de las predicciones

Ve a la Píldora *Bootstrapping para intervalos de predicción* para saber más sobre las fórmulas usadas para estimar el intervalo de confianza de las predicciones y alternativas de cálculo cuando estas fórmulas no son válidas.
:::

**En todas las fórmulas de criterios de calidad las *medias* se pueden sustituir por *medianas*.** Esto es especialmente útil cuando para hay observaciones atípicas que generan errores muy altos.

\


Los indicadores de calidad de ajuste que se basan en predicciones intramuestrales a un periodo vista, presentan dos problemas. Primero, evalúan el error a un periodo vista, cuando en muchas situaciones reales las predicciones se realizan sobre un horizonte temporal más amplio. Segundo, son errores intramuestrales, resultantes de predecir los mismos datos que ha usado el método para calcular la predicción y, por tanto, sobrestiman la capacidad predictiva del modelo.

Veremos en el epígrafe 4 de este tema métodos de evaluación de la precisión de las predicciones que superan estas limitaciones.

\
\

# Métodos sencillos de predicción

Algunos métodos de predicción son extremadamente sencillos y sorprendentemente eficaces. A veces son denominados métodos ingenuos. Estos métodos:

-   posibilitan realizar predicciones prácticamente sin realizar ningún cálculo.
-   como son muy sencillos, dan las previsiones con mayor error (menos precisas). El error de un método sencillo sirve de punto de referencia (*benchmark*) para valorar la necesidad de aplicar otros métodos más complicados con el objetivo de mejorar la calidad de las predicciones.

Veamos algunos métodos sencillos y sus funciones en el paquete `forecast`.

\

## Métodos sencillos de predicción

### Series *sin* tendencia y *sin* estacionalidad {.unnumbered}

**Método de la Media**: $\hat{y}_{T+h}=(y_1+\ldots,y_T)/T$.

-   La predicción para cualquier periodo futuro es la **media** de las observaciones disponibles previas.
-   Función de `R`: `meanf(y, h)`

**Método ingenuo I**: $\hat{y}_{T+h}=y_T$.

-   La predicción para cualquier periodo futuro es la **última** observación disponible.
-   Función de `R`: `naive(y, h)` o `rwf(y, h)` (*rw* de random walk)
-   Para series sin estacionalidad este es el método ingenuo de comparación del MASE.

### Series *con* tendencia y *sin* estacionalidad {.unnumbered}

**Método ingenuo II**: $\hat{y}_{T+h}=y_T + h(y_T-y_{T-1})$.

-   La predicción $h$ periodos adelante es la **última observación** disponible más $h$ veces el **último incremento** observado.
-   No tiene función en `R`, pero se podría emular mediante la función `ets` (véase epígrafe de 5.5, Alisado exponencial de Holt).

**Método de la deriva**: $\hat{y}_{T+h}=y_T+h\frac{y_T - y_1}{T-1}$.

-   La predicción $h$ periodos adelante es la **última observación** disponible más $h$ veces el **incremento medio** observado.
-   Función de `R`: `rwf(y, h, drift = TRUE)`

### Series *sin* tendencia y *con* estacionalidad {.unnumbered}

**Método ingenuo con estacionalidad**: $\hat{y}_{T+h}=y_{T-m(k+1)}$.

-   La predicción para un periodo es la **última observación disponible de la misma estación que la fecha que se desea predecir**.

-   $k$ es la parte entera de $(h-1)/m$, es decir, el número de estaciones completas en el periodo de predicción previo al periodo $T+h$.
-   Función de `R`: `snaive(y, h)`
-   Para series con estacionalidad este es el método ingenuo de comparación del MASE

**No hay métodos sencillos cuando la serie tiene tendencia y estacionalidad**, así que se suele usar el método ingenuo con estacionalidad.

\

## Ejemplo de aplicación

### Serie Residuos {.unnumbered}

Analizaremos Residuos, una serie anual de 1995 a 2022 (fuente [Instituto Nacional de Estadística](https://www.ine.es)) que muestra los residuos recogidos por o en nombre de las autoridades municipales y eliminados a través del sistema de gestión de residuos. La @fig-Residuos muestra que es una serie con tendencia que ha cambiado con el tiempo.

```{r}
#| label: fig-Residuos
#| fig-cap: "Residuos per cápita recogidos"
residuos <- read.csv2("./series/Residuos.csv", 
                      header = TRUE)

residuos <- ts(residuos[, 2],
               start = 1995, 
               frequency  = 1)

autoplot(residuos,
         main = "",
         xlab = "",
         ylab = "Kg per cápita")
```

Las siguientes salidas muestran el resultado de la aplicación de los métodos sencillos a la serie. Se ha fijado un horizonte de previsión de cinco años (`h = 5`). Los dos primeros métodos realizan una predicción constante, el método de la media da la media de la recogida de residuos per cápita en el periodo de análisis (`r round(mean(residuos), 2)`) y el Ingenuo I da el último dato observado (`r round(tail(residuos, n=1), 2)`). El método de la deriva da una previsión que decrece de año en año un valor igual a $(y_T - y_1)/(T-1)$, que en este caso vale $-1.4074$.

```{r}
(mediaResiduos <- meanf(residuos, h = 5))
(naiveResiduos <- naive(residuos, h = 5))
(derivaResiduos <- rwf(residuos, drift = TRUE , h = 5))
derivaResiduos$model$par$drift # Permite ver la pendiente del modelo.
#summary(derivaResiduos) Con summary se puede obtener una salida más completa
```

La @fig-residuossencillos muestra el resultado gráfico de la aplicación de estos métodos. El argumento `PI = FALSE` hace que no se impriman los intervalos de confianza de las predicciones.

```{r}
#| label: fig-residuossencillos
#| fig-cap: "Recogida de residuos y predicción por métodos sencillos"
autoplot(residuos, 
         series = "Residuos",
         xlab = "",
         ylab = "Kg per cápita",
         main = "") +
  autolayer(mediaResiduos, series="Media", PI = FALSE) +
  autolayer(naiveResiduos, series="Ingenuo", PI = FALSE) +
  autolayer(derivaResiduos, series="Deriva", PI = FALSE) +
  scale_colour_discrete(limits=c("Residuos", "Media", 
                                 "Ingenuo", "Deriva")) +
  labs(colour="Métodos") + 
  theme(legend.position=c(0.2,0.3))
```

Con la función `accuracy` se puede obtener el error de ajuste a un periodo vista de cada método:

```{r}
#| eval: false
accuracy(mediaResiduos)
accuracy(naiveResiduos)
accuracy(derivaResiduos)
```

```{r}
#| echo: false
tmp <- rbind(
  accuracy(mediaResiduos),
  accuracy(naiveResiduos),
  accuracy(derivaResiduos)
)
tmp <- round(tmp,2)
rownames(tmp) <- c("Media","Ingenuo I", "Deriva")
tmp
```

Podemos destacar que:

- El método de la *deriva* presenta la mejor calidad de ajuste con un error de 21.5 kg per cápita (RMSE) o del 3.04% (MAPE). El método *Ingenuo I* tienen una calidad de ajuste similar, con un error medio de 21.6 kg per cápita (RMSE) y un error porcentual del 3.05% (MAPE).
- Si se usa como criterio de calidad de ajuste el error absoluto medio (MAE), vuelve a ser mejor el método *Ingenuo I*.
- Ningún método genera predicciones por intervalo fiables (ACF1 > 0.1). 
- Los métodos *Ingenuo I* y de la *Deriva* no presentan sesgo (|MPE| < 1%), pero si lo hace el de la *Media*. Además, el error medio (ME) siempre será nulo para el método de la *Media* y de la *Deriva*, lo que indica que en términos absolutos nos equivocamos lo mismo por exceso como por defecto. Esta es una buena propiedad, que el método *Ingenuo I* no verifica.
- Para series sin estacionalidad el método sencillo de comparación usado en el cálculo del MASE es el *Ingenuo I*. Es por ello que este indicador vale 1 para este método. Como el método de *Media* tiene un MAE superior al *Ingenuo I*, su MASE es mayor que 1. En concreto, MASE = 3.66 = 60.52 / 16.52.

Concluimos que, con independencia del criterio usado, el método que mejor ajusta los datos es el de la  *Deriva*.

### Serie Nacimientos {.unnumbered}

Podemos usar el método ingenuo con estacionalidad con la serie Nacimientos para obtener una previsión a dos años vista. 

```{r}
nacimientos <- read.csv2("./series/Nacimientos.csv", 
                         header = TRUE)

nacimientos <- ts(nacimientos[, 2],
                  start = c(1975, 1),
                  frequency = 12)

(snaive.nacimientos <- snaive(nacimientos, 
                              h = 24, 
                              level = 95))
accuracy(snaive.nacimientos)
```


El error absoluto porcentual medio es del 3.7% (que corresponde a unos 1700 bebés según RMSE). Es decir, aplicando algo tan simple como predecir el número de nacimientos para un mes como los nacimientos del mismo mes del año previo, tenemos ya un error de ajuste muy bajo. Sin embargo, este método en general sobreestima algo el número de nacimientos (MPE inferior a -1%) y sus predicciones por intervalo no son fiables.

La @fig-nacimientossencillo muestra la serie y la predicción que, debido al método usado, no incorpora la tendencia decreciente de los últimos años.

```{r}
#| label: fig-nacimientossencillo
#| fig-cap: "Nacimientos y predicción por el método Ingenuo con estacionalidad"
autoplot(snaive.nacimientos,
         xlab = "",
         ylab = "Nacimientos",
         main = "",
         PI = FALSE,
         xlim = c(2000, 2025))
```

### Serie Demanda eléctrica {.unnumbered}

Podemos usar el método ingenuo con estacionalidad con la serie Demanda eléctrica, que tiene una estacionalidad de orden 7, pero no parece presentar tendencia. El error absoluto porcentual medio es del 4.7% o 45 GWh (RMSE), un error razonablemente reducido. Sin embargo, el ACF1 indica que la fórmula usada para el cálculo del intervalo de confianza de las predicciones no es válida.

```{r}
electricidad <- read.csv("./series/Consumo electrico.csv", 
                         header = TRUE)

electricidad <- ts(electricidad[, 1],
                   start = c(1, 7),
                   frequency = 7)

snaive.electricidad <- snaive(electricidad, 
                              h = 28, 
                              level = 95)

accuracy(snaive.electricidad)
```

La @fig-electricidadsencillo muestra la serie y la predicción a cuatro semanas vista. Debido a que la semana de referencia para predecir es la semana de Navidad, donde el consumo eléctrico es inferior al usual, las predicciones resultan ser claramente incorrectas. Este es un buen ejemplo de la diferencia entre calidad de ajuste y precisión de las predicciones.

```{r}
#| label: fig-electricidadsencillo
#| fig-cap: "Demanda eléctrica y predicción por el método Ingenuo con estacionalidad"
autoplot(snaive.electricidad,
         xlab = "",
         ylab = "GWh",
         main = "")
```

\
\

# Evaluación de las predicciones

Las medidas que hemos usado hasta ahora para valorar la calidad de los modelos son medidas de bondad de ajuste, es decir, medidas de la calidad de **previsiones intramuestrales a un periodo vista**: valoran en que medida los datos se ajustan a un modelo, pero no evalúan la precisión de la previsiones más allá del periodo muestral.

En este tema vamos a ver dos metodologías que podemos usar para valorar la precisión o calidad de las **previsiones extramuestrales**, que es realmente lo que nos interesa. Estas dos metodologías están relacionadas con los métodos de *Conjunto de datos de entrenamiento y prueba* (*Training set/Test set*) y *Validación cruzada* (*Cross-validation*), pero adaptadas a datos temporales.

\
\

## Validación por conjunto de datos de entrenamiento y prueba

Vamos a estimar la calidad de las predicciones obteniendo medidas de error para **previsiones extramuestrales a varios periodos vista** usando la filosofía del *conjunto de datos de entrenamiento y prueba*.

Dividimos la serie temporal $\{y_t\}_{t=1}^T$ en dos subseries. Los primeros datos $\{y_t\}_{t=1}^{T_0}$, $T_0 < T$, se usarán para estimar el modelo (conjunto de entrenamiento); y los últimos datos $\{y_t\}_{t={T_0+1}}^{T}$ para calcular la precisión de las predicciones (conjunto de prueba).

Esta metodología, muy efectiva para datos de corte transversal, genera dos problemas cuando se aplica a series temporales: *i*) el error obtenido es una mezcla de errores de predicción a diferentes horizontes temporales, difícil de interpretar; *ii*) los resultados dependen tremendamente del punto de corte temporal seleccionado $T_0$.

### Serie Residuos {.unnumbered}

Vamos a reservar, por ejemplo, las últimas 7 observaciones de la serie Residuos (años 2016 a 2022) y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 7 periodos vista y compararlas con los valores reales de la serie.

```{r}
#| eval: false
# Definimos las observaciones intra- y extramuestrales
residuosIntra <- subset(residuos, end = length(residuos) - 7)
residuosExtra <- subset(residuos, start = length(residuos) - 6)

# Estimamos el modelo con todos los datos menos los 7 ultimos y
# predecimos los 7 años que hemos quitado de la serie 
residuosExtraPre <- rwf(residuosIntra,  h = 7, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
accuracy(residuosExtraPre, residuosExtra)
```

```{r}
#| echo: false
# Definimos las observaciones intra- y extramuestrales
residuosIntra <- subset(residuos, end = length(residuos) - 7)
residuosExtra <- subset(residuos, start = length(residuos) - 6)

# Estimamos el modelo con todos los datos menos los 6 ultimos y
# predecimos los 7 años que hemos quitado de la serie 
residuosExtraPre <- rwf(residuosIntra,  h = 7, drift = TRUE)

# Vemos la calidad del ajuste. Primero la predicción y luego los datos reales
round(accuracy(residuosExtraPre, residuosExtra), 2)

error.muestral.1 <- round(accuracy(residuosExtraPre, residuosExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(residuosExtraPre, residuosExtra)[2,5],1)
```

Atendiendo al MAPE se tiene que el error de **previsión a un periodo vista** en el **periodo intramuestral** de **1995 a 2015** es del `r error.muestral.1`%; mientras que el error de **previsión a largo plazo** en el **periodo extramuestral** de **2016 a 2022** es del `r error.extramuestral.n`%. Ademas, para el periodo extramuestral el error medio (ME) es positivo y muy elevado, un indicativo de que las previsiones están segadas (subestiman la realidad). En resumen, la calidad del modelo se deteriora cuanto nos salimos de las condiciones óptimas.

La @fig-residuostraintest puede ayudar a entender este proceso de validación:

- La línea de puntos vertical separa el periodo muestral (1995-2015) usado para estimar el modelo, del periodo extramuestral (2016-2022) usado sólo para hacer las previsiones.
- La serie Residuos aparece como una línea sólida en negro, desde 1995 hasta 2022.
- La previsión *intra*muestral (a un periodo vista) de la serie Residuos aparece como una línea azul.
- La línea en rojo es la previsión *extra*muestral a largo plazo. Observa que todas las previsiones están por debajo del valor real de la serie.
- Al lado de cada previsión (intra y extramuestral) se ha indicado el error estimado (MAPE).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r}
#| echo: false
#| label: fig-residuostraintest
#| fig-cap: "Residuos, predicción intra- y extramuestral"
autoplot(residuos, series = "Residuos",
         main="",
         xlab="", 
         ylab="Títulos"
         ) +
  autolayer(fitted(residuosExtraPre), series = "Residuos (ajustada)") + 
  autolayer(residuosExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2015.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Residuos"="black",
                               "Residuos (ajustada)"="blue", 
                               "Predicción" = "red")) +
  labs(colour="Series") + 
  annotate("text", x=2005, y=575, label="3.3%", colour = "blue") +
  annotate("text", x=2018, y=485, label="4.3%", colour = "red") +
  theme(legend.position=c(0.85,0.8)) 
```

::: callout-caution
## Importamcia del punto de corte

Prueba a reservar las últimas 6 observaciones de la serie Residuos y repite el análisis.
:::

### Serie Nacimientos {.unnumbered}

Calculamos de nuevo los diferentes criterios de bondad de ajuste para valorar la calidad de las previsiones extramuestrales a largo plazo. En este caso vamos a reservar los últimos 36 meses como periodo extramuestral.

```{r}
#| eval: false
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

accuracy(nacimientosExtraPre, nacimientosExtra)
```

```{r}
#| echo: false
nacimientosIntra <- subset(nacimientos, end = length(nacimientos) - 36)
nacimientosExtra <- subset(nacimientos, start = length(nacimientos) - 35)

nacimientosExtraPre <- snaive(nacimientosIntra, h = 36)

round(accuracy(nacimientosExtraPre, nacimientosExtra), 2)
```

```{r}
#| echo: false
#| label: fig-nacimientostraintest
#| fig-cap: "Nacimientos, predicción intra- y extramuestral"
autoplot(nacimientos, series = "Nacimientos",
         main="",
         xlab="", 
         ylab="Nacimientos"
         ) +
  autolayer(fitted(nacimientosExtraPre), series = "Nacimientos (ajustada)") + 
  autolayer(nacimientosExtraPre$mean, series = "Predicción") + 
  scale_colour_manual(values=c("Nacimientos"="black",
                               "Nacimientos (ajustada)"="blue", 
                               "Predicción" = "red")) +
  labs(colour="Series") + 
  annotate("text", x=2013, y=45000, label="3.7%", colour = "blue") +
  annotate("text", x=2022, y=34000, label="7.1%", colour = "red") + 
  theme(legend.position=c(0.8,0.8)) 
```

Las previsiones extramuestrales muestran una menor pendiente que los casos reales de nacimientos. Por un lado, el periodo de previsión contiene el atípico año de la pandemia; y, por otro lado, conforme se avanza en el horizonte temporal las previsiones se van alejando de la realidad y el error extramuestral es del 7.1%, duplicando el error de estimación intramuestral de 3.7%.

### Serie Demanda eléctrica {.unnumbered}

Para la serie de consumo eléctrico vamos a reservar las 8 últimas semanas (56 días) como periodo extramuestral.

```{r}
#| eval: false
electricidadIntra <- subset(electricidad, end = length(electricidad) - 56)
electricidadExtra <- subset(electricidad, start = length(electricidad) - 55)

electricidadExtraPre <- snaive(electricidadIntra, h = 56)

accuracy(electricidadExtraPre, electricidadExtra)
```

```{r}
#| echo: false
electricidadIntra <- subset(electricidad, end = length(electricidad) - 56)
electricidadExtra <- subset(electricidad, start = length(electricidad) - 55)

electricidadExtraPre <- snaive(electricidadIntra, h = 56)

round(accuracy(electricidadExtraPre, electricidadExtra), 2)
```

El error intramuestral obtenido es del 4.7%, que aumenta 2 p.p. al obtener el error de previsión extramuestral (6.9%). El elevado valor positivo del error medio indica que las previsiones extramuestrales subestiman el consumo real de electricidad.

```{r}
#| echo: false
#| label: fig-electricidadtraintest
#| fig-cap: "Consumo eléctrico, predicción intra- y extramuestral"
autoplot(electricidad, series = "Consumo",
         main="",
         xlab="", 
         ylab="GWh"
         ) +
  autolayer(fitted(electricidadExtraPre), series = "Consumo (ajustada)") + 
  autolayer(electricidadExtraPre$mean, series = "Predicción") + 
  scale_colour_manual(values=c("Consumo"="black",
                               "Consumo (ajustada)"="blue", 
                               "Predicción" = "red")) +
  labs(colour="Series") + 
  annotate("text", x=20, y=690, label="4.7%", colour = "blue") +
  annotate("text", x=51, y=530, label="6.9%", colour = "red") + 
  theme(legend.position=c(0.15,0.8)) 
```

\

## Origen de predicción móvil

Veamos ahora una técnica, basada en el concepto de validación cruzada que permite obtener de forma individualizada los errores de previsión extramuestral a un periodo vista, a dos periodos vista, etc.

Supongamos que para estimar el modelo se necesita un mínimo de $k$ observaciones y que se desea predecir hasta un horizonte temporal $h$.

- Seleccionamos las observaciones $1,2,...,k$ para estimar el modelo y predecimos las observaciones desde $k+1$ hasta $k+h$. Tenemos, por tanto, $h$ predicciones.

- Calculamos el error de predicción para las predicciones desde $k+1$ hasta $k+h$. Tenemos $h$ errores, el primero a un periodo vista, el segundo a dos periodos vista y el último a $h$ perriodos vista.

- Repetimos este proceso desplazando el número de observaciones seleccionadas para la estimación un periodo adelante. Es decir, ahora usamos las observaciones $2,3,...,k+1$ para estimar el modelo, predecimos las observaciones desde $k+2$ hasta $k+1+h$ y calculamos el error de predicción.

- Iteramos el proceso, desplazando cada vez las observaciones de la estimación un periodo adelante.

- En general para $i=0,1,...,T-k-h$, donde $T$ es el número total de observaciones:

    1.  Seleccionamos las observaciones $i+1,i+2,...,i+k$ para estimar el modelo.
    2.  Predecimos las observaciones desde $i+k+1$ hasta $i+k+h$.
    3.  Calculamos el error de predicción para las observaciones desde $i+k+1$ hasta $i+k+h$.
    4.  Para cada horizonte temporal de predicción se calcula la medida de error deseada.

\

::: {#fig-rollingwindows}
![](./imagenes/RollingWindows.png)

Descripción del proceso de origen de predicción móvil
:::

Este procedimiento se denomina **origen de predicción móvil**, en inglés *rolling forecast origin* o *rolling windows*.

Cuando se aplica esta metodología hay que tener en cuenta que los resultados pueden depender del número $k$ de datos usados para la estimación del modelo.

### Ejemplo de aplicación con Nacimientos {.unnumbered}

Vamos a aplicar la metodología previa a la serie anual de Nacimientos. Asumimos que se precisan veinte años para hacer una buena estimación, $k=20$, y que el horizonte temporal es de cinco años, $h = 5$. Como la serie es anual, usaremos el método de la deriva para predecir. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde uno a cinco años.

```{r}
nacAnual <- aggregate(nacimientos, FUN = sum)

k <- 20                   #Minimo numero de datos para estimar
h <- 5                    #Horizonte de las prediciciones
TT <- length(nacAnual)    #Longitud serie
s <- TT - k - h           #Total de estimaciones

mapeRwf <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacAnual, start = i + 1, end = i + k)
  test.set <-  subset(nacAnual, start = i + k + 1, end = i + k + h)
  
  fcast <- rwf(train.set, h = h, drift = TRUE)
  mapeRwf[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}
```

La matriz `mapeRwf` contiene los errores de previsión extramuestral, donde cada columna corresponde a un horizonte temporal de previsión diferente. Ahora vamos a calcular el error medio por columna.

```{r}
mapeRwfMedia <- colMeans(mapeRwf)
round(mapeRwfMedia, 2)
```

Para evitar el posible efecto datos atípicos, se puede calcular el *error mediano* en lugar del error medio. En este caso no hay una función directa en `R` y usaremos `apply`.

```{r}
mapeRwfMediana <- apply(mapeRwf, MARGIN = 2, FUN = median)
round(mapeRwfMediana, 2)
```

El error de previsión extramuestral (medio o mediano) crece gradualmente con el horizonte de previsión. Para el primer año el error de predicción se mantiene en un moderado 4%, para el segundo año de predicción el MAPE salta al 8-9% y para los restantes años sigue creciendo. Como la serie de Nacimientos no presenta años especialmente atípicos, para todos los horizontes de previsión el error medio y mediano es muy similar.

### Ejemplo de aplicación con Demanda eléctrica {.unnumbered}

Ahora aplicaremos la metodología origen de predicción móvil la serie de Demanda eléctrica. En este caso se asumirá que se precisan veinte semanas para hacer una buena estimación, $k = 140$, y que el horizonte temporal es de 4 semanas, $h = 28$. Como la serie tiene estacionalidad, usaremos el método ingenuo con estacionalidad para predecir. La siguiente rutina permite obtener el RMSE para previsiones con un horizonte temporal desde uno a 28 días.

```{r}
k <- 140                  #Minimo numero de datos para estimar
h <- 28                   #Horizonte de las prediciciones
TT <- length(electricidad)#Longitud serie
s <- TT - k - h           #Total de estimaciones

rmseRwf <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(electricidad, start = i + 1, end = i + k)
  test.set <-  subset(electricidad, start = i + k + 1, end = i + k + h)
  
  fcast <- snaive(train.set, h = h)
  rmseRwf[i + 1,] <- (test.set - fcast$mean)^2
}

rmseRwfMedia <- sqrt(colMeans(rmseRwf))
round(rmseRwfMedia, 2)

rmseRwfMediana <- sqrt(apply(rmseRwf, MARGIN = 2, FUN = median))
round(rmseRwfMediana, 2)
```

En este caso, la presencia de muchos días atípicos (todos los festivos entre semana el consumo de electricidad es notablemente más bajo de lo esperado) y de una segunda componente estacional dentro del año hacen que el error medio sea más elevado que el mediano --proximadamente, el primero es el doble que el segundo.

Respecto del error de previsión mediano, este crece semana tras semana con el horizonte de previsión. Para predicciones de uno a siete periodos vista el error de predicción está alrededor de los 20 GWh; desde 8 a 14 días vista sube hasta los 30 GWh; y a 28 días vista alcanza los 40 GWh.

\

::: callout-caution
## Código para cálculo del error deseado

Para Nacimientos hemos visto el código necesario para calcular el MAPE por origen de predicción móvil. Las dos líneas clave del código son:

\

`mapeRwf[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set`

`mapeRwfMedia <- colMeans(mapeRwf)`

\

La primera línea obtiene el error porcentual absoluto de cada observación y la segunda calcula la media de estos errores.

\

Para calcular el RMSE en el ejemplo de Demanda eléctrica ha sido necesario adaptar estás dos líneas de código adecuadamente. Ahora la primera línea calcula el error cuadrático de cada observación y la segunda la raíz de la media de estos errores:

\

`rmseRwf[i + 1,] <- (test.set - fcast$mean)^2`

`rmseRwfMedia <- sqrt(colMeans(rmseRwf))`

\

En general, según el error que desees obtener, deberás modificar estas dos líneas de código como corresponda.

\

Además, si hay valores atípicos, puede ser conveniente calcular el error mediano en lugar del error medio.
:::

\
\


# Métodos de Alisado Exponencial

## Introducción

Los métodos de alisado exponencial aparecen en los años 50 del siglo pasado de la mano de Brown, Holt y Winters [véase @Brown59; @Holt; @Winters60] y han sido la raíz de uno de los métodos de predicción más sencillos y eficaces. La idea básica es predecir usando una media ponderada de los datos pasados, donde los más recientes tienen un peso mayor y este decae exponencialmente conforme usamos observaciones más antiguas.

El alisado exponencial es una familia de métodos de ajuste y previsión que ofrece muy buenos resultados para predicciones a corto plazo o para predecir series con pocos datos o *sencillas* (sin mucho *ruido*).

Suponen un grado de modelización mayor que los métodos sencillos vistos previamente, pero sin alcanzar la complejidad de otras metodologías (modelos ARIMA).

En origen, son métodos descriptivos con el único objetivo de producir **predicciones puntuales**. Sin embargo, su enfoque como modelos de *espacio de estados* posibilita un marco teórico para obtener **intervalos de confianza de las predicciones**.

\

## Componentes de una serie en el contexto del alisado exponencial

Para obtener una predicción en el periodo $t+1$ con datos hasta el periodo $t$ necesitamos tres componentes:

- La estimación del nivel de la serie en el periodo $t$: $l_t$
- La estimación de la pendiente de la serie en el periodo $t$: $b_t$
- La estimación de la estacionalidad en el mes correspondiente al periodo $t+1$ con datos hasta $t$: $s_{t + 1 - m}$ (recuerda, $m$ es el orden estacional

A partir de estas componentes obtenidas en el periodo $t$ y para un esquema aditivo, se tendría que la predicción en el periodo $t+1$ es: 

$$\widehat{y}_{t+1} = l_t+b_t+s_{t+1-m}.$$ 

En general, las componentes pueden **existir o no** y se pueden combinar entre ellas **aditiva o multiplicativamente**. Veamos algunos casos:

- Existen todas y son multiplicativas: $\widehat{y}_{t+1}=l_t \cdot b_t \cdot s_{t + 1 - m}$

- Existen todas, nivel y pendiente aditivas, y estacionalidad multiplicativa: $\widehat{y}_{t+1}=(l_t+b_t)s_{t + 1 - m}$

- No hay pendiente y la estacionalidad es aditiva: $\widehat{y}_{t+1}=l_t+s_{t + 1 - m}$

\

¿Como obtenemos los valores de $l_t$, $b_t$ y $s_{t + 1 - m}$? Mediante **expresiones recursivas**, donde cada componente se calcula a partir de los valores hasta $t$ de la serie y de las componentes: 

$$
\begin{aligned}
l_t& = f_l(y_t,y_{t-1}\ldots, l_{t-1},l_{t-2}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
b_t& = f_b(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t-1},b_{t-2}\ldots,s_{t-1},s_{t-2}\ldots) \\
s_t& = f_s(y_t,y_{t-1}\ldots, l_{t},l_{t-1}\ldots,b_{t},b_{t-1}\ldots,s_{t-1},s_{t-2}\ldots)
\end{aligned}
$$

Por ejemplo, el *método ingenuo I* se puede interpretar dentro de este contexto como un método de alisado donde $l_t = y_t$ y no hay ni pendiente ni estacionalidad. Por tanto, $\widehat{y}_{t+1} = l_{t} = y_{t}$.

De la misma forma, el *método ingenuo II* se puede interpretar como un método de alisado donde $l_t = y_t$, $b_t = y_t - y_{t-1}$ y no hay estacionalidad. Entonces, $\widehat{y}_{t+1}=l_t + b_t = y_t + (y_t - y_{t-1})$.

En las expresiones previas hemos supuesto que se quería obtener una predicción a un periodo vista ($\widehat{y}_{t+1}$). Si el objetivo es estimar una previsión $h$ periodos hacia delante desde el periodo $t$, $\widehat{y}_{t+h}$, hay que modificar la ecuación de predicción adecuadamente. Por ejemplo, para el caso aditivo se tendría que 

$$\widehat{y}_{t+h} = l_t+hb_t+s_{t+h-m(k+1)}$$ 
donde $k = \lfloor (h-1)/m\rfloor$.

El concepto de componentes aquí visto no coincide con el definido en el Tema 1. Sin embargo, podemos asimilar la tendencia de una serie como la suma (o multiplicación) del nivel y la pendiente $T_{t+1} = l_t + b_t$ (o $T_{t+1} = l_t \cdot b_t$) y de esta forma ambas definiciones de componentes de una serie se hacen compatibles.

\

## Casos posibles

Todas las series tiene nivel, pero dependiendo del tipo de pendiente y estacionalidad hay 15 casos posibles, mostrados en la @tbl-taxonomia.

| Tendencia                       |             | Estacionalidad |                    |
|:------------------|:----------------:|:----------------:|:----------------:|
|                                 | Ninguna (N) |  Aditiva (A)   | Multiplicativa (M) |
| Ninguna (N)                     |  **N, N**   |      N, A      |        N, M        |
| Aditiva (A)                     |  **A, N**   |    **A, A**    |      **A, M**      |
| Aditiva Amortiguada (Ad)        |  **Ad, N**  |     Ad, A      |       Ad, M        |
| Multiplicativa (M)              |    M, N     |      M, A      |        M, M        |
| Multiplicativa Amortiguada (Md) |    Md, N    |     Md, A      |       Md, M        |

: Casos de alisado según el tipo de tendencia y estacionalidad {#tbl-taxonomia}

Cada caso difiere en las componentes que se observan y su esquema, dando lugar a un conjunto diferente de ecuaciones recursivas de actualización.

\

**Residuo aditivo versus residuo multiplicativo**

Todo modelo estimado tiene asociado un residuo. En los modelos usuales este error se define como, $\widehat{\varepsilon}_t = y_t - \widehat{y}_t$, pero no tiene por que ser así,. En los modelos de Alisado el residuo estimado puede ser aditivo o multiplicativo.

Si el **residuo es aditivo**, entonces el modelo es $y_t = \widehat{y}_t + \widehat{\varepsilon}_t$ y el residuo se define de la forma usual $$\widehat{\varepsilon}_t = y_t - \widehat{y}_t.$$

Ahora bien, si el **residuo es multiplicativo**, entonces el modelo es $y_t = \widehat{y}_t \cdot (1 + \widehat{\varepsilon}_t)$, y no $y_t = \widehat{y}_t \cdot \widehat{\varepsilon}_t$ como se podría esperar. Por tanto, el residuo multiplicativo se define como $$\widehat{\varepsilon}_t = (y_t - \widehat{y}_t)/\widehat{y}_t.$$

De esta forma en ambos casos --aditivo y multiplicativo-- el residuo evoluciona alrededor del valor 0 y se le pueden imponer las hipótesis usuales de ruido blanco. Observa que el error multiplicativo tampoco es el error porcentual tal y como se define para el calculo del MPE o del MAPE.

En cualquiera de los casos y para cualquier modelo estimado con `R`, podemos obtener el residuo con la función `residuals`.

\

**Casos más comunes**

Si a la @tbl-taxonomia se añade que el error puede ser aditivo (A) o multiplicativo (M), tenemos 30 posibilidades. El tipo de error (aditivo o multiplicativo) es, sobre todo, relevante en el cálculo del intervalo de confianza de las predicciones.

Los modelos más usuales son (error, tendencia, estacionalidad):

-   (A, N, N): Alisado exponencial simple
-   (A, A, N): Alisado de Holt
-   (A, Ad, N): Alisado con tendencia amortiguada (d de *damped*)
-   (A, A, A): Alisado de Holt-Winters aditivo
-   (M, A, M): Alisado de Holt-Winters multiplicativo[^1]

[^1]: Formalmente en el modelo de Holt-Winters multiplicativo el error es aditivo. Es decir, debería ser (A, A, M). Sin embargo, debido a que desde un punto de vista teórico este modelo, junto con otros, puede tener varianza infinita, la función `ets` no permite por defecto su estimación. Para poder estimar con la función `ets` el modelo (A, A, M) es necesario añadir el argumento `restrict = FALSE`. Los modelos que para poder ser estimados requieren este argumento son: ANM, AAM, AAdM, MMA, MMdA, AMN, AMdN, AMA, AMdA, AMM y AMdM.


Acude al artículo de @Hyndman08 para saber más de cada modelo, o al libro de @Hyndman08b.


### Las funciones `ets` y `forecast` {.unnumbered}

Podemos estimar cualquiera de los treinta modelos usando la función `ets` del paquete `forecast`.

-   El tipo de modelo en `ets` se especifica con el argumento `model`, un código de tres letras indicando el tipo de Error, Tendencia y eStacionalidad (ETS). Por ejemplo, `model = "ANN"` indica un modelo con error aditivo, sin tendencia ni estacionalidad, es decir, el alisado exponencial simple; `model = "AAN"` indica un modelo con error aditivo, pendiente aditiva, pero sin estacionalidad, el alisado exponencial de Holt. El alisado exponencial de Holt-Winters multiplicativo sería `model = "MAM"`.
-   Si se desea incluir amortiguamiento, hay que añadir el argumento `damped = TRUE`.
-   Por defecto `ets` no considera modelos con tendencia multiplicativa (últimas dos líneas de la @tbl-taxonomia). Debes fijar el parámetro `allow.multiplicative.trend=TRUE` para contemplar esta opción.

A diferencia de las funciones vistas en el epígrafe 3.1 (`naive`, `meanf`, `rwf` y `snaive`), la función `ets` solo estima los modelos, pero no produce predicciones. Para ello habrá que usar la función `forecast` sobre un modelo estimado con `ets`. El argumento `h` de esta función especifica el horizonte temporal de predicción. También puedes usar `level` para fijar el nivel de confianza del intervalo de predicción.

Mira la ayuda de `R` para ver una explicación detallada de los argumentos de estas las funciones `ets` y `forecast`.

\

## Alisado exponencial simple (A, N, N)

\

### Definición {.unnumbered}

El alisado exponencial simple es adecuado para una serie estacionaria y sin estacionalidad. Es decir, una serie que se mueve alrededor de un nivel medio desconocido: $y_t = \mu + \varepsilon_t$. Por tanto, para obtener una predicción en el periodo $t+1$ necesitamos la estimación del nivel de la serie con la información disponible hasta el periodo $t$. Denominaremos a este nivel $l_t$, de esta forma se tendrá que:
$$\widehat{y}_{t+1} = l_t.$$ 

Es decir, $l_t$ es la estimación del nivel desconocido $\mu$ con información hasta el periodo $t$.

¿Pero cómo obtenemos $l_t$? Mediante una expresión recursiva donde el nivel $l_t$ se calcula a partir de los valores hasta $t$ de la serie y los valores pasados estimados para el nivel. En concreto, para el Alisado exponencial simple la **ecuación recursiva** de suavizado es 
$$l_t=\alpha y_t + (1-\alpha)l_{t-1}.$$
Dos estimaciones razonables de $l_t$, el nivel de la serie en el periodo $t$, son el valor observado para la serie en ese periodo $y_t$ y el nivel del periodo previo $l_{t-1}$. La estimación final de $l_t$ es una media ponderada de ambas según el parámetro $\alpha$, y esta estimación final es la previsión de la serie para el periodo siguiente.

El parámetro $\alpha$ se denomina parámetro de suavizado y verifica que $0 \leq \alpha \leq 1$.

Ya hemos comentado que la ecuación de **predicción intramuestral** es $\widehat{y}_{t+1} = l_t$. La ecuación de **predicción extramuestral** es 
$$\widehat{y}_{T+h} = \widehat{y}_{T+1} = l_T.$$
El método de Alisado también ofrece predicciones constantes para series sin tendencia ni estacionalidad.


### Estimación de los parámetros del modelo {.unnumbered}

Dado el proceso iterativo para el cálculo de $l_t$ se necesita un **valor inicial** de arranque $l_0$. Cada programa estadístico usa su propio método para obtener $l_0$.

Respecto de $\alpha$, usualmente se estima el valor **optimo** según un criterio de calidad de ajuste. El parámetro $\alpha$ **se puede interpretar**:

-   Si $\alpha = 1$, la ecuación recursiva queda $l_t = y_t$, es decir, el *método ingenuo I* ($\widehat{y}_{t+1}=y_t$). Este caso es óptimo cuando el nivel de la serie varía constantemente en el tiempo.
-   Si $\alpha = 0$, la ecuación recursiva queda $l_t=l_{t-1}=\ldots = l_0$, es decir, $\hat y_{t+1}= l_0$. Esto es óptimo cuando el nivel permanece constante en el tiempo.

En concreto, `ets` por defecto estima los parámetros $\alpha$ y $l_0$ maximizando la función de verosimilitud, pero el argumento `opt.crit` permite cambiar de criterio. Esta búsqueda está restringida a $0 < \alpha < 1$. Es decir el parámetro $\alpha$ nunca puede ser 0 o 1 y en la práctica sus valores limite son 0.0001 y 0.9999.


### Ejemplo de aplicacion a la serie consumo de alimentos en hogar {.unnumbered} 

Analizaremos el **consumo alimentario en hogar per cápita** en España. Esta serie está construida a partir de la serie de consumo alimentario en hogar (disponible en el Ministerio de Agricultura, Alimentación y Medio Ambiente), y la serie de población (disponible en el Instituto Nacional de Estadística). Es una serie anual de 1990 a 2023 (34 datos) y la unidad es el Kg per cápita. La @fig-Alimentos muestra que es una serie estacionaria.

```{r}
#| label: fig-Alimentos
#| fig-cap: "Consumo alimentario en hogar"
alimentospc <- read.csv2("./series/Alimentacionpc.csv",
                         header = TRUE)

alimentospc <- ts(alimentospc,
                  start = 1990, 
                  freq = 1)
    
autoplot(alimentospc, 
         xlab = "", 
         ylab = "Kg per cápita",
         main = "",
         ylim = c(0, 700))
```

El pico en el año 2020 se debe al aumento del consumo de alimentos en el hogar causado por el periodo de confinamiento por la Covid-19 (marzo a junio) y el aumento del trabajo en casa.

Vamos a usar el método de alisado exponencial simple para predecir la serie Consumo de alimento en el hogar. Usaremos para ello la función `ets` con `model = "ANN"`.

```{r}
etsAlimentospc <- ets(alimentospc, 
                      model = "ANN")

summary(etsAlimentospc)
```

Veamos la salida en detalle:

- El valor de $\alpha$ óptimo (minimiza la verosilimilitud) es $\alpha =$ `r round(etsAlimentospc$par[1],2)`, un valor muy cercano a 1. Es decir, el nivel de Alimentos varía constantemente en el tiempo.
- El valor de arranque $l_0$ óptimo es `r round(etsAlimentospc$par[2],2)`. Es decir, el año 1989 (año anterior al primero de la serie) se estima un nivel de consumo de `r round(etsAlimentospc$par[2],2)` kg per cápita.
- *sigma* es la desviación típica del error (aditivo) de predicción. Se diferencia de RMSE en el denominador. Para calcular *sigma* en lugar de dividir por $T$ se divide por $T-k$, donde $k$ es el número de parámetros estimados por el modelo. En este caso, $k=3$: $l_0$, $\alpha$ y *sigma*. Sí, *sigma* se considerará siempre otro parámetro estimado.
- Se obtiene un AICc $= 335.13$. Si estimamos un modelo con error multiplicativo, obtendremos un AICc mayor.
- La calidad del ajuste es buena, como evidencia el error porcentual medio del 2.2%. Además, no hay sesgo (MPE = -0.42%) y el cálculo de la predicciones por intervalo es correcto (ACF1 = 0.0045).
- Como el valor de $\alpha$ es próximo a 1, el modelo de Alisado se aproxima mucho al Ingenuo I. Por este motivo el MASE es casi igual a 1.

En el objeto `etsAlimentospc` la matriz `etsAlimentospc$states` guarda todos los valores del nivel obtenidos con la ecuación recursiva, incluido el valor de arranque, así que es una matriz con $T+1$ filas (35 en el ejemplo). Puedes ver en su última fila que el valor de $l_{2023}$, el nivel del último año, vale `r formatC(etsAlimentospc$states[35,], format = "f", digits = 2)`.

```{r}
tail(etsAlimentospc$states, 1)
```

Por tratarse de un modelo sin pendiente ni estacionalidad, la predicción es constante en el tiempo. Recuerda que $\widehat{y}_{T+h} = l_T$. Así, la predicción para 2024 es $\widehat{y}_{2024}=l_{2023}=$ `r formatC(etsAlimentospc$states[35,], format = "f", digits = 2)`. Igualmente $\widehat{y}_{2025}=l_{2023}=$ `r formatC(etsAlimentospc$states[35,], format = "f", digits = 2)`. Todas las previsiones son iguales a $l_{2023}$.

Mediante la función `forecast` podemos predecir el consumo de alimentos per cápita para los próximos cinco años. 

```{r}
etsAlimentospcf <- forecast(etsAlimentospc,
                            h = 5, 
                            level = 95)
etsAlimentospcf
```

La @fig-alimentosANN muestra la serie Consumo de alimentos, las previsiones extramuestrales que son constantes y el intervalo de confianza. Conforme aumentamos el horizonte de predicción, el intervalo de confianza es más amplio como reflejo de la mayor incertidumbre en la predicción.

```{r}
#| label: fig-alimentosANN
#| fig-cap: "Consumo de alimentos per cápita (1990 - 2023) y predicción con Alisado exponencial simple"
autoplot(etsAlimentospcf,
         xlab = "",
         ylab = "Kg per cápita",
         main = "")
```


\

## Alisado exponencial de Holt (A, A, N)

El alisado exponencial de Holt es adecuado para una serie no estacionaria y sin estacionalidad.

\

### Formulas interactivas de sus componentes {.unnumbered}

Las **ecuaciones recursivas** son

$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} 
\end{aligned}
$$

La ecuación de la **predicción intramuestral** a un periodo vista es 

$$\widehat{y}_{t+1} = l_t + b_t,$$ 
de forma que la ecuación de **predicción extramuestral** es $$\widehat{y}_{T+h}=l_T + h b_T.$$

Dos estimaciones razonables del nivel de la serie en el periodo $t$ son el valor observado para la serie en ese periodo $y_t$, y una estimación del nivel del periodo $t$ realizada desde el periodo $t-1$: $l_{t-1} + b_{t-1}$. Por otro lado, dos estimaciones razonables de la pendiente de la serie en el periodo $t$ son el cambio de nivel de $t-1$ a $t$ (el último observado) $l_t-l_{t-1}$, y el valor de la pendiente en el periodo previo, $b_{t-1}$. En ambos casos, nivel y pendiente, la estimación final es una media ponderada, parametrizada por $0 < \alpha, \beta < 1$.

Observa que el *método ingenuo II* es un caso concreto de Alisado de Holt. Si hacemos $\alpha=\beta = 1,$ queda $l_t=y_t$ y $b_t=y_t-y_{t-1}$, por tanto
$$\widehat{y}_{t+1}=l_t + b_t = y_t + (y_t - y_{t-1})$$ 
y 
$$\widehat{y}_{T+h}=l_T + h \cdot b_T = y_T + h(y_T - y_{T-1}).$$

::: callout-note
## ¿Sabrías responder a estas preguntas?

Hemos visto que en modelo de Alisado con tendencia, si $\alpha = \beta = 1$, la ecuación de predicción que queda es la del método Ingenuo II.

¿Cómo quedaría la ecuación de predicción si $\alpha = \beta = 0$?

¿Y si $\alpha = 1$ y $\beta = 0$? ¿Y si $\alpha = 0$ y $\beta = 1$?
:::

### Estimación de los parámetros del modelo {.unnumbered}

Para aplicar este método es necesario estimar unos valores iniciales $l_0$ y $b_0$ de las ecuaciones recursivas e identificar los valores más adecuados de los parámetros $\alpha$ y $\beta$.

La función `ets` por defecto estima los parámetros $\alpha$, $\beta$, $l_0$ y $b_0$ maximizando la función de verosimilitud. En este caso la búsqueda está restringida a $0 < \beta < \alpha < 1$. Por tanto, $\alpha$ y $\beta$ nunca pueden ser 0 o 1 y en la práctica sus valores limite son 0.0001 y 0.9999.

La interpretación del parámetro $\alpha$ es similar al caso del alisado exponencial simple.

**Interpretación del parámetro** $\beta$:

-   Si $\beta = 1$, $b_t = l_t - l_{t-1}$, la pendiente se actualiza constantemente porque varía periodo a periodo Puede ser un indicador de mal ajuste (tendencia no lineal o pendiente no aditiva).
-   Si $\beta = 0$, $b_t = b_{t-1}= \ldots = b_0$, la pendiente se mantiene constante en el tiempo.

### Ejemplo de aplicación a la serie Residuos {.unnumbered}

Vamos a usar el método de alisado de Holt para predecir la serie Residuos. Usaremos para ello la función `ets` con el argumento `model = "AAN"` (error y tendencia aditivas sin estacionalidad). Además, es necesario añadir el argumento `damped = FALSE` para prevenir el uso de tendencia amortiguada, que veremos en el siguiente epígrafe.

```{r}
etsResiduos <- ets(residuos, 
                   model = "AAN",
                   damped = FALSE)
summary(etsResiduos)
```

Los valores óptimos de los cuatro parámetros estimados son $\alpha=$ `r round(etsResiduos$par[1],2)`, $\beta=$ `r round(etsResiduos$par[2],2)`, $l_0 =$ `r round(etsResiduos$par[3],2)` y $b_0 =$ `r round(etsResiduos$par[4],2)`.

Observa que $\alpha$ es prácticamente 1 y que $\beta$ es cero. Si aplicamos estos valores de los parámetros a las ecuaciones recursivas y la predicción extramuestral, obtenemos $y_{T+h}=y_T + h\cdot b_0$: la predicción es el último valor observado más $h$ veces la primera pendiente estimada. La calidad de las predicciones es razonable, con un error porcentual medio del 3.4%.

Por otro lado, el valor de $l_0$ indica que el nivel estimado para el volumen de residuos de 1994 es de `r round(etsResiduos$par[3],2)`. Además, el incremento entre 1994 y 1995 se estima en $b_0 =$ `r round(etsResiduos$par[4],2)`.


::: callout-note
# Parámetros estimados

¿Cuántos parámetros se han estimado (y la respuesta no es 4)? ¿Cuál es el denominador en el cálculo de RMSE y de *sigma*?
:::

En el objeto `etsResiduos` la matriz `etsResiduos$states` guarda todos los valores obtenidos con las ecuaciones recursivas, en este caso el nivel y la pendiente, incluidos los valores de arranque. Puedes ver los valores de $l_{2022}$ y $b_{2022}$ en su última fila, que valen respectivamente

```{r}
tail(etsResiduos$states, 1)
```

Así, la predicción para $2023$ es $\widehat{y}_{2023}=l_{2022} + b_{2022}=$ `r formatC(etsResiduos$states[29, 1], format = "f", digits = 2)` $+$ `r formatC(etsResiduos$states[29, 2], format = "f", digits = 2)` $=$ `r formatC(sum(etsResiduos$states[29,]), format = "f", digits = 2)`. Igualmente $\widehat{y}_{2024}=l_{2022} + 2\cdot b_{2022}=$ `r formatC(etsResiduos$states[29,1] + 2* etsResiduos$states[29,2], format = "f", digits = 2)`. Es decir, la diferencia entre previsiones consecutivas es constante e igual a $b_{2022}$ que, por ser $\beta$ prácticamente nulo, casi coincide con $b_0$.

```{r}
etsResiduosf <- forecast(etsResiduos,
                         h = 5, 
                         level = 95)
etsResiduosf
```

La @fig-residuosAAN muestra la serie Residuos y las previsiones extramuestrales, que muestran una ligera tendencia decreciente.

```{r}
#| label: fig-residuosAAN
#| fig-cap: "Residuos y predicción con alisado de Holt"
autoplot(etsResiduosf,
         xlab = "",
         ylab = "Kg per cápita",
         main = "")
```

\

## Alisado exponencial con pendiente amortiguada (A, Ad, N)

Las previsiones con el método de Holt presentan siempre una pendiente constante. En previsiones a corto plazo esto no es un problema, pero para previsiones a largo plazo la experiencia indica que suele aparecer un sesgo de previsión. El alisado exponencial con pendiente amortiguada trata de corregir esta limitación. El mecanismo, propuesto por @Gardner85, es introducir un nuevo parámetro $0 \leq \phi \leq 1$ que *amortigua* la tendencia hasta hacerla plana en el largo plazo.

### Formulas interactivas de sus componentes {.unnumbered}

Las **ecuaciones recursivas** son 

$$
\begin{aligned}
l_t & =\alpha y_t + (1-\alpha)(l_{t-1}+\phi b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)\phi b_{t-1} 
\end{aligned}
$$

La ecuación de la **predicción intramuestral** a un periodo vista es 
$$\widehat{y}_{t+1} = l_t + \phi b_t,$$
\noindent de forma que la ecuación de **predicción extramuestral** es 
$$\widehat{y}_{T+h}=l_T + (\phi + \phi^2 + \ldots + \phi^h) b_T.$$

Se ha añadido un nuevo parámetro $\phi\in [0, 1]$ que acompaña siempre a la pendiente $b_t$. Si $\phi = 1$, se tiene el alisado de Holt y si $\phi = 0$, se tiene el alisado simple. Se puede comprobar que en el largo plazo las predicciones se hacen constantes e iguales a $l_T + \phi b_T/(1 - \phi)$.

Por razones prácticas el rango de búsqueda de $\phi$ queda en el intervalo $[0.8, 0.98]$. Si el valor óptimo de $\phi$ fuera su valor máximo de $0.98$ o muy cercano a este, cabría plantearse si no sería más adecuado un modelo sin amortiguamiento.

### Ejemplo de aplicación a la serie Residuos {.unnumbered}

Vamos a usar el método de Alisado con amortiguamiento para predecir, una vez más, la serie Residuos añadiendo a la función `ets` el argumento `damped = TRUE`. En este caso, para ver el efecto del *amortiguamiento* vamos a pedir un horizonte temporal de previsión más largo.

```{r}
etsDResiduos <- ets(residuos, 
                    model = "AAN", 
                    damped = TRUE)
summary(etsDResiduos)
```

El valor óptimo del parámetro $\phi$ es $0.8$ y el error porcentual 3.2%, algo inferior al obtenido con el alisado de Holt sin amortiguamiento. Además, el modelo de Alisado con amortiguamiento genera intervalos de predicción correctos, cosa que no ocurría con el modelo de Alisado de Holt.

::: callout-note
## Parámetros estimados

¿Cuántos parámetros se han estimado en este caso? ¿Cuáles?
:::

La @fig-residuosAAdN muestra la serie Residuos, su estimación intramuestral y las predicciones a 15 años vista. Observa que la pendiente de las previsiones se *amortigua* en el tiempo, de forma que al principio las previsiones crecen más rápidamente que en los últimos años. 

```{r}
#| label: fig-residuosAAdN
#| fig-cap: "Residuos y predicción con alisado exponencial con amortiguamiento"
etsDResiduosf <- forecast(etsDResiduos, 
                          h = 15,
                          level = 95)
etsDResiduosf

autoplot(etsDResiduosf,
         xlab = "",
         ylab = "Kg per cápita",
         main = "",
         PI = FALSE)
```

\

## Alisado de Holt-Winters aditivo (A, A, A) y multiplicativo (M, A, M)

El método de alisado exponencial de Holt-Winters es adecuado para una serie con tendencia y estacionalidad. Existen dos versiones según que el esquema sea aditivo o multiplicativo.


### Alisado de Holt-Winters aditivo (A, A, A)

Las **ecuaciones recursivas** de actualización son: 

$$
\begin{aligned}
l_t & =\alpha (y_t - s_{t-m} ) + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma (y_t - l_{t-1} - b_{t-1}) + (1 - \gamma)s_{t-m}
\end{aligned}
$$
\noindent con $0 \leq \alpha, \beta, \gamma \leq 1$.

La ecuación de la **predicción intramuestral** a un periodo vista es 
$$\widehat{y}_{t+1}  = l_t + b_t + s_{t+1-m},$$ 
\noindent de forma que la ecuación de **predicción extramuestral es**: 
$$\widehat{y}_{T+h}=l_T + h b_T + s_{T+h - m(k+1)},$$ \noindent con $k = \lfloor(h-1)/m\rfloor$.

Observa que las ecuaciones para el nivel y la pendiente son similares a las ya vistas para el método de Holt. Respecto de la ecuación de actualización de la estacionalidad, dos estimaciones razonables de esta componente en el periodo $t$ son su valor estimado a partir de la serie menos su tendencia $y_t-l_{t-1} - b_{t-1}$, y la estimación que ya teníamos de la estacionalidad previamente, $s_{t-m}$. La estimación final es una media ponderada, parametrizada por $0 \leq \gamma < 1 - \alpha$. 

**Interpretación del parámetro** $\gamma$:

-   Si $\gamma = 1$, $s_t = y_t - l_{t-1} - b_{t-1}$, la estacionalidad se actualiza constantemente porque varía periodo a periodo 
-   Si $\gamma = 0$, $s_t = s_{t-m}= \ldots = s_0$, la estacionalidad se mantiene constante en el tiempo.

\

### Alisado de Holt-Winters multiplicativo (M, A, M)

Las **ecuaciones recursivas** de actualización son: 

$$
\begin{aligned}
l_t & =\alpha \frac{y_t}{s_{t-m}} + (1-\alpha)(l_{t-1}+b_{t-1}) \\
b_t & =\beta (l_t - l_{t-1}) + (1-\beta)b_{t-1} \\
s_t & =\gamma \frac{y_t}{l_{t-1} + b_{t-1}} + (1 - \gamma)s_{t-m}
\end{aligned}
$$

La ecuación de la **predicción intramuestral** a un periodo vista es 
$$\widehat{y}_{t+1}  = (l_t + b_t)s_{t+1-m},$$ 
de forma que la ecuación de **predicción extramuestral es**: 
$$\widehat{y}_{T+h}=(l_T + h b_T)s_{T+h - m(k+1)}.$$


### Ejemplo con Demanda electrica {.unnumbered}

Vamos a usar el método de **Holt-Winters Aditivo** para predecir la serie Demanda eléctrica, que presentaba un esquema aditivo. Para ello usaremos la función `ets` con el argumento `model = "AAA"` (y `damped = FALSE`). Vamos a considerar la serie desde el 31 de enero (lunes) hasta el 29 de mayo (domingo), 17 semanas, y pedir una previsión a dos semanas vista.

En el proceso de estimación, el parámetro $\gamma$ que gobierna la componente estacional está restringido a $0 < \gamma < 1 - \alpha$.

```{r}
#Nos quedamos con los meses de febrero a mayo.
electricidadr <- window(electricidad, 
                       start = c(6, 1), 
                       end = c(22, 7)) 

electricidadEts <- ets(electricidadr, 
                       model = "AAA", 
                       damped = FALSE)

summary(electricidadEts)
```

Los valores óptimos de los parámetros son $\alpha=$ `r round(electricidadEts$par[1],2)`, $\beta=$ `r round(electricidadEts$par[2],2)` y $\gamma=$ `r round(electricidadEts$par[3],2)`. Los valores nulos para $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, permanecen constantes en el tiempo (véase @fig-electricidadAAAComponentes). 

```{r}
#| label: fig-electricidadAAAComponentes
#| fig-cap: "Componentes del modelo de Holt-Winters aditivo para Demanda eléctrica"
#| fig-height: 7
autoplot(electricidadEts)
```

La calidad de las predicciones es notable, con un error porcentual medio del 2%.

Los últimos valores de las componentes son,

```{r}
#| eval: false
TT <- nrow(electricidadEts$states)
electricidadEts$states[TT,]
```

```{r}
#| echo: false
TT <- nrow(electricidadEts$states)
round(electricidadEts$states[TT,], 3)
```

Como el último dato de la serie es domingo 28 de mayo, los valores del nivel $l$ y la pendiente $b$ mostrados corresponden a ese día. Sin embargo, **la componente estacional tiene un orden muy peculiar**: s1 es el valor estacional para domingo (día del último dato), s2 el de sábado, s3 de viernes, hasta s7 que sería lunes. Podemos reproducir las predicciones para los próximos 7 días, 29 de mayo a 4 de junio (ojo, el etiquetado de la salida no tiene sentido):

```{r}
electricidadEts$states[TT, 1] + (1:7)*electricidadEts$states[TT, 2] + 
  electricidadEts$states[TT, 9:3]
```

O mejor usar la función `forecast` para obtener las predicciones y sus intervalos a dos semanas vista.

```{r}
electricidadf <- forecast(electricidadEts,
                          h = 14, 
                          level = 95)
electricidadf
```

La @fig-electricidadAAA muestra la serie Demanda eléctrica y las previsiones extramuestrales.

```{r}
#| label: fig-electricidadAAA
#| fig-cap: "Demanda eléctrica y predicción con alisado de Holt-Winters aditivo"
autoplot(electricidadf,
         xlab = "",
         ylab = "GWh",
         main = "",
         PI = FALSE)
```


### Ejemplo con Nacimientos {.unnumbered}

Vamos a usar el método de **Holt-Winters multiplicativo** para predecir la serie Nacimientos, que presentaba un esquema multiplicativo. En este caso usaremos el argumento `model = "MAM"`. Vamos a considerar la serie Nacimientos desde enero de 2000 y pedir una previsión a dos años vista.

```{r}
nacimientosb <- window(nacimientos, start = 2000)

nacimientosbEts <- ets(nacimientosb, 
                       model = "MAM", 
                       damped = FALSE)

summary(nacimientosbEts)
```

Los valores óptimos de los parámetros son $\alpha=$ `r round(nacimientosbEts$par[1],2)`, $\beta=$ `r round(nacimientosbEts$par[2],2)` y $\gamma=$ `r round(nacimientosbEts$par[3],2)`. Los valores tan bajos para $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, modifican su valor muy lentamente (véase @fig-nacimientosMAMComponentes). 

```{r}
#| label: fig-nacimientosMAMComponentes
#| fig-cap: "Componentes del modelo de Holt-Winters multiplicativo para Nacimientos"
#| fig-height: 7
autoplot(nacimientosbEts)
```

La calidad de las predicciones es notable, con un error porcentual medio inferior al 2%.

Los últimos valores de las componentes son,

```{r}
#| eval: false
TT <- nrow(nacimientosbEts$states)
nacimientosbEts$states[TT,]
```

```{r}
#| echo: false
TT <- nrow(nacimientosbEts$states)
round(nacimientosbEts$states[TT,], 3)
```

Como el último dato de la serie es diciembre de 2023, los valores del nivel $l$ y la pendiente $b$ mostrados corresponden a ese mes. Sin embargo, recuerda que la componente estacional sigue un orden inverso: s1 es el valor estacional para diciembre (mes del último dato), s2 el de noviembre, s3 de octubre, hasta s11 que sería febrero y s12 que es enero.

Podemos reproducir las predicciones para los primeros 12 meses de enero a diciembre (recuerda, el etiquetado de la salida no es correcto) para ver que coinciden con las obtenidas con la función `forecast` (solo se muestran los primeros meses).

```{r}
(nacimientosbEts$states[TT, 1] + (1:12)*nacimientosbEts$states[TT, 2]) * 
  nacimientosbEts$states[TT, 14:3]
```

```{r}
#| eval: false
nacimientosbf <- forecast(nacimientosbEts, 
                              h = 24, 
                              level = 95)
nacimientosbf
```

```{r}
#| echo: false
nacimientosbf <- forecast(nacimientosbEts, h = 24, level = 95)
forecast(nacimientosbEts, h = 5, level = 95)
```

La @fig-nacimientosMAM muestra la serie Nacimientos y las previsiones extramuestrales.

```{r}
#| label: fig-nacimientosMAM
#| fig-cap: "Nacimientos y predicción con alisado de Holt-Winters multiplicativo"
autoplot(nacimientosbf,
         xlab = "",
         ylab = "Nacimientos",
         main = "",
         PI = FALSE)
```

\

## Ejemplo con transformación logarítmica

Una alternativa para predecir cualquier serie es predecir su transformación logarítmica. Después, se aplica la transformación inversa y se obtienen las predicciones de la serie original. No siempre, pero este procedimiento puede mejorar la calidad de las predicciones. Además, este proceso asegura que las predicciones y sus intervalos sean siempre positivas (ve a la píldora *Series acotadas* para aprender más sobre cómo garantizar que las predicciones sean positivas o que permanezcan dentro de cierto intervalo).

El uso de la transformación logarítmica en la estimación de modelos y predicción se puede realizar de forma sencilla y transparente con cualquiera de las funciones de que hemos visto a partir de los argumentos `lambda` y `biasadj`.

- `lambda = 0` indica que se ha de realizar la transformación logarítmica de la serie previamente a su modelización. Es un parámetro de la transformación Box-Cox que no veremos en detalle en el tema 3.
- `biasadj = TRUE` es necesario si tras una transformación de la serie original queremos que las predicciones sean insesgadas. Es decir, queremos obtener la predicción *media*. 

  Sea $y_t$ la serie original y $z_t=log(y_t)$ su transformación logarítmica. Si obtenemos una predicción $\widehat{y}_t$ de la serie original, esta será insesgada $E[\widehat{y}_t]=y_t$. Ahora bien, si obtenemos una predicción $\widehat{z}_t$ de la serie transformada, podemos pensar que $e^{\widehat{z}_t}$ es una predicción insesgada de la serie original, pero resulta que $E[e^{\widehat{z}_t}] \neq y_t$. Es decir, la exponencial de la predicción de la serie con transformada logarítmica no es insesgada.
  
  Si el argumento `biasadj` es fijado a FALSE, las predicciones se calcularán de forma directa deshaciendo la transformación y serán sesgadas. En concreto, lo que se obtiene es una predicción *mediana*. Si, por el contrario, es fijado a TRUE, las predicciones se calcularán por medio de una fórmula alternativa y serán insesgadas.
  
  En ambos casos, para series largas no debería observarse mucha diferencia entre las dos alternativas.

Vamos a practicar el uso de estos argumentos con la serie Nacimientos. Como se va a predecir el logaritmo de la serie, se debe indicar a la función `ets` `model = "AAA"` que estima el modelo Holt-Winters aditivo. Además, vamos a pedir que las predicciones sean insesgadas con `biasadj = TRUE`.

```{r}
nacimientosbEtsl <- ets(nacimientosb, 
                     model = "AAA",
                     damped = FALSE,
                     lambda = 0, 
                     biasadj = TRUE)

summary(nacimientosbEtsl)

nacimientosbfl <- forecast(nacimientosbEtsl,
                           h = 24,
                           level = 95,
                           biasadj = TRUE)
nacimientosbfl
```

En este caso la calidad de las predicciones (MAPE = 2.3%) es algo superior a la obtenida con la serie sin transformar.

La @fig-nacimientoslog muestra la serie Nacimientos y las previsiones extramuestrales obtenidas con y sin la transformación logarítmica. En este caso, las previsiones con la serie sin transformar son algo mayores que las obtenidas con la serie transformada.

```{r}
#| echo: false
#| label: fig-nacimientoslog
#| fig-cap: "Nacimientos y dos predicciones con alisado de Holt-Winters"
autoplot(nacimientosb,
         xlab = "",
         ylab = "Nacimientos",
         main = "") + 
  autolayer(nacimientosbf, series = "Nacimientos", PI = FALSE) + 
  autolayer(nacimientosbfl, series = "Nacimientos (log)", PI = FALSE) + 
  guides(colour = guide_legend(title = "Predicción")) + 
  theme(legend.position=c(0.98,0.98), legend.justification=c(1,1)) 
```

La @tbl-nacimientoslog muestra las predicciones de Nacimientos obtenidas sin transformar la serie, con transformación logarítmica y predicciones insesgadas (`biasadj = TRUE`), y con transformación logarítmica y predicciones sesgadas (`biasadj = FALSE`).

```{r}
#| echo: false
#| label: tbl-nacimientoslog
#| tbl-cap: "Diferencias en la predicción según transformación logarítmica y corrección por sesgo"
nacimientosbfl2 <- forecast(nacimientosbEtsl,
                            h = 24,
                            level = 95,
                            biasadj = FALSE)
datos <- cbind(
  `Sin transformar` = nacimientosbf$mean,
  `log(Nac) insesgadas` = nacimientosbfl$mean,
  `log(Nac) sesgadas` = nacimientosbfl2$mean
  )
knitr::kable(head(datos, 12))
```

Las predicciones sesgadas son menores que las insesgadas. Esto siempre es así. La diferencia depende fundamentalmente de la desviación típica del error, *sigma* en la salida de los métodos de alisado exponencial. Cuanto mayor es *sigma*, mayores son las diferencias.

Por otro lado, las predicciones obtenidas sin y con la transformación logarítmica no guardan ninguna relación.

**Ni la transformación logarítmica ni el uso de predicciones insesgadas aseguran mejores predicciones respecto de otras opciones**, como puede ser trabajar con predicciones sesgadas o no realizar la transformación logarítmica. Hay que usar Origen de predicción móvil para determinar que transformación es la mejor.

\

## Casos generales de alisado exponencial: la función `ets` (de nuevo)

En los epígrafes previos hemos visto cinco de los casos expuestos en la taxonomía de la @tbl-taxonomia, fijados a partir de los argumentos `model` y `damped` de la función `ets`. Veamos ahora como estimar cualquiera de los treinta modelos que surgen según las diferentes posibilidades de la tendencia (N, A, Ad, M y Md), la estacionalidad (N, A y M) y el error (A, M).

Recordemos que el tipo de error no influye en el cálculo de las previsiones, solo influye en el cálculo del intervalo de confianza de estas.

**Podemos estimar cualquiera de los treinta modelos usando la función `ets` del paquete `forecast`.**

Lo más habitual es no saber cual es el mejor modelo, entendiendo como tal, el que mejor se ajusta a la serie temporal. De hecho, si lo que buscamos es predecir bien, el mejor modelo será el que mejor prediga.

Si en una de las tres letras del código del modelo se indica "Z", la función `ets` selecciona de entre los modelos posibles el que mejor se ajusta. Por ejemplo, `model = "AAZ"` indica un modelo con error y pendiente aditivos y dejaría a `ets` la búsqueda de la mejor opción para la estacionalidad (aditiva o multiplicativa). Si se especifica `model = "ZZZ` junto con `damped = NULL` (opciones por defecto) se dejaría a la función total libertad para buscar entre todos los modelos (excepto aquellos con pendiente multiplicativa). Si se desea restringir la búsqueda a modelos sin amortiguamiento basta indicar `damped = FALSE` y si se desea restringir la búsqueda solo a modelos aditivos se puede usar el argumento `additive.only = TRUE`.

### Criterios de optimización {.unnumbered}

Fijado un modelo, `ets` estima por defecto sus parámetros maximizando la función de verosimilitud. Esta búsqueda esta restringida a $0 < \beta < \alpha < 1$, $0 < \gamma < 1 - \alpha$ y $0.8 < \phi < 0.98$. Es decir, los tres primeros parámetros nunca pueden ser 0 o 1, y en la práctica sus valores límite son 0.0001 y 0.9999.

Puedes cambiar el criterio de optimización con el argumento `opt.crit`. Por defecto vale "lik" (de *likelihood* o verosimilitud), pero si lo fijas a `opt.crit = "mse"` se estiman los parámetros que minimizan el error cuadrático medio. Otra opción interesante es `opt.crit = "amse"` que minimiza la media de los errores cuadráticos medios obtenido sobre las previsiones hasta `nmse` periodos vista. En este caso usa el argumento `nmse` para fijar el valor numérico del horizonte temporal.

### Criterios de selección de modelos {.unnumbered}

Queda pendiente saber que criterio se usa para seleccionar el modelo cuando se ofrece esta opción. Esto se hace a partir de un criterio de información entre Akaike (aic), Akaike corregido para pequeñas muestras (aicc) y el Bayesiano (bic). Sus fórmulas son: $$aic = -2log(L) + 2k$$ $$aicc = aic + \frac{k(k+1)}{T-k-1}$$ $$bic=aic + k(log(T) - 2)$$ \noindent donde $L$ es la verosimilitud, $T$ el número de datos y $k$ el de parámetros estimados (incluidos los puntos iniciales de arranque y la desviación típica del error).

**Cuanto menor es el criterio de información, mejor modelo**. Por defecto se usa Akaike corregido para pequeñas muestras (aicc), pero el argumento `ic` permite cambiar de criterio.

::: {.callout-caution collapse="true"}
## Una reflexión sobre los métodos automáticos de selección de modelos

Con el comando `forecast(ets(nacimientos),h=24)` obtenemos una predicción mensual a dos años vista del número de nacimientos en España. Así de simple, solo 31 caracteres. Todo esto gracias a que un algoritmo interno ha estimado los parámetros de múltiples modelos, elegido el mejor modelo de todos y lo ha usado para obtener las predicciones. Podemos afirmar que tenemos las mejores predicciones. Un momento, ¿podemos?

Parémonos a reflexionar sobre lo que hemos hecho o, más bien, lo que el algoritmo ha hecho y a contrastarlo con lo que nosotros queríamos. Por un lado, el algoritmo estima los parámetros de un menú fijo de modelos y para ello usa un criterio de optimización, que por defecto es maximizar la función de verosimilitud; cuando ya tiene estimados todos los modelos, elije el mejor usando el criterio de información de Akaike corregido para muestras pequeñas; y finalmente, nosotros medimos la capacidad predictiva del modelo seleccionado usando el error absoluto porcentual medio. Vaya, resulta que en los procesos de identificación y estimación del mejor modelo se usan dos criterios diferentes, que además no coinciden con nuestro criterio de calidad de las predicciones.

Si consideramos que la calidad de un modelo viene dada por el error absoluto porcentual medio en las predicciones intramuestrales a un periodo vista (lo que hemos decidido llamar MAPE), ¿no deberíamos estimar los parámetros del modelo usando como criterio la minimización del MAPE?, ¿no deberíamos elegir entre varios modelos aquel que presenta un MAPE menor? De esta forma, en todos los pasos del proceso se usa el mismo criterio, que es, además, el criterio que hemos considerado adecuado para valorar la calidad de las predicciones.

Pero no es esto lo que hacemos.

Nada nos garantiza que el modelo estimado y seleccionado por el algoritmo estime las mejores predicciones posibles. Y por *mejores* quiero decir que de entre todos los posibles modelos del menú y todos los posibles valores de sus parámetros, el seleccionado sea el que minimiza nuestro criterio de calidad de las predicciones.

Ahora ya podemos dar respuesta a la pregunta del primer párrafo: no, no podemos afirmar que nuestras predicciones sean las mejores.

Alguien dirá que casi seguro entre las predicciones subóptimas obtenidas por el algoritmo con su extraña mezcla de criterios y las predicciones óptimas de verdad no habrá mucha diferencia. Total, que más da una función de verosimilitud que un criterio de información que una medida del error medio. Pero lo cierto es que no lo sabemos, no tenemos ni idea de la distancia que hay entre lo óptimo y lo subóptimo, y si el coste de equivocarme en las predicciones es alto, puede que incluso una pequeña diferencia sea relevante.

Esta reflexión realizada en el contexto de series temporales y para la función `ets` es aplicable a todos los casos donde dejamos que un algoritmo ya programado elija el mejor modelo, y se basa en el hecho de que rara vez los criterios de estimación y elección que usan los algoritmos coinciden con el concepto de calidad de ajuste que estamos interesados.

A pesar de lo aquí expuesto, como es más cómodo (y rápido) tirar de rutinas ya programadas que escribir nuestro propio código, seguiremos trabajando con modelos subóptimos y obteniendo estimaciones subóptimas, pero diciendo que son las mejores.
:::

\
\

# Ejemplos de aplicación

\

## Recogida de residuos

### Identificación y estimación del mejor modelo {.unnumbered}

Si estimamos el mejor modelo de alisado exponencial para la serie Residuos sin ningún tipo de restricción, nos encontramos:

```{r}
residuosEts <- ets(residuos)
summary(residuosEts) 
```

El modelo estimado es ETS(M,N,N) o "MNN", un modelo sin pendiente ni estacionalidad y con error multiplicativo. Es decir, $y_{t+1} = l_t \cdot (1 + \varepsilon_{t+1})$.

El valor de $\alpha$ técnicamente es 1, indicando que el nivel de la serie varia en el tiempo y que prácticamente estamos usando para las previsiones el método Ingenuo I.

Respecto de la calidad del modelo, el valor de MAPE= $`r round(accuracy(residuosEts)[5],1)`$% evidencia que estamos ante un modelo que se ajusta bien a los datos. MASE= $`r round(accuracy(residuosEts)[6],2)`$ indica que el modelo de alisado exponencial simple reduce en solo un $`r 100 - round(100*accuracy(residuosEts)[6],0)`$% el error del método ingenuo I. Además, el modelo estimado no presenta sesgo.

### Predicción {.unnumbered}

Mediante la función `forecast` podemos predecir la serie Residuos. Por tratarse de un modelo sin pendiente ni estacionalidad, la predicción es constante en el tiempo (véase @fig-residuosETSLibre).

```{r}
#| label: fig-residuosETSLibre
#| fig-cap: "Residuos y predicción a 5 años vista"
residuosEtsPre <- forecast(residuosEts, 
                         h = 5,
                         level = 95)
residuosEtsPre

autoplot(residuosEtsPre,
         xlab = "",
         ylab = "Kg per cápita",
         main = "")
```

### Análisis del residuo {.unnumbered}

El error de un modelo de alisado *contiene* la componente de **Intervención** y el propio término de **Error**. Ver numérica o gráficamente el error permite identificar fácilmente la presencia de valores atípicos (intervención). Obtenemos el error con la función `residuals`.

```{r}
#| label: fig-residuoError
#| fig-cap: "Error + Intervención"
error <- residuals(residuosEts)
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(1995, 2022, 2)) 
```

La @fig-residuoError muestra que aunque algún error supera las dos desviaciones típicas, ninguno puede ser considerado claramente como atípico.

### Validación: error extramuestral a varios periodos vista {.unnumbered}

Vamos a mejorar la estimación de la calidad de las predicciones obteniendo el MAPE para **previsiones extramuestrales a varios periodos vista**. Para ello vamos a reservar, por ejemplo, las últimas 6 observaciones de la serie Residuos y ajustar el modelo con las restantes. Después usaremos este modelo para calcular las predicciones a 6 periodos vista y compararlas con los valores reales de la serie Residuos.

Recuerda, este método para valorar la calidad de las predicciones usa la filosofía del método *Conjunto de entrenamiento/Conjuto de prueba*: el periodo de datos usado en la estimación no se usa como periodo de datos para la validación. Sin embargo, tiene el problema de que el error obtenido es una mezcla de errores de predicción a corto, medio y largo plazo difícil de valorar. Además, los resultados dependen tremendamente del punto de corte temporal seleccionado.

```{r}
# Definimos las observaciones intra y extramuestrales
residuoIntra <- subset(residuos, end = length(residuos) - 6)
residuoExtra <- subset(residuos, start = length(residuos) - 5)

# Estimamos el modelo con todos los datos menos los 6 ultimos
residuoIntraEts <- ets(residuoIntra, model = "MNN")

# Predecimos los 6 años que hemos quitado de la serie y 
# vemos la calidad del ajuste.
residuoExtraPre <- forecast(residuoIntraEts, h = 6)
accuracy(residuoExtraPre, residuoExtra)
```

```{r}
#| echo: false
error.muestral.1 <- round(accuracy(residuoExtraPre, residuoExtra)[1,5], 1)
error.extramuestral.n <- round(accuracy(residuoExtraPre, residuoExtra)[2,5],1)
```

Atendiendo al MAPE se tiene que el error de **previsión a un periodo vista** en el **periodo intramuestral** de **1995 a 2016** es del `r error.muestral.1`%; y el error de **previsión a largo plazo** en el **periodo extramuestral** de **2017 a 2022** es del `r error.extramuestral.n`%. Para el punto de corte elegido, la calidad de las previsiones no se deteriora cuanto nos salimos de las condiciones óptimas.

Un gráfico puede ayudar a entender este proceso de validación. En la @fig-residuosTSTS:

-   La línea de puntos vertical separa el periodo muestral (1995-2016) usado para estimar el modelo, del periodo extramuestral (2017-2022) usado sólo para hacer las previsiones.
-   La serie Residuos aparece como una línea sólida en negro, desde 1995 hasta 2022.
-   La previsión *intra*-muestral (a un periodo vista) de la serie Residuos aparece como una línea azul. Observa la previsión puede ser mayor o menor que la serie, no evidenciándose sesgo.
-   La línea en rojo es la previsión *extra*-muestral a largo plazo: $\hat{y}_{T+h}=l_T$, donde $T=2016$. Observa que casi todas las previsiones están por debajo del valor real de la serie.
-   Al lado de cada previsión se ha indicado el error estimado (MAPE). Para la previsión extramuestral, el error es la media de errores muy bajos (primeras previsiones) y errores muy elevados (últimas previsiones).

Claramente estos resultados dependen del punto de corte seleccionado.

```{r}
#| echo: false
#| label: fig-residuosTSTS
#| fig-cap: "Residuos, predicción intra y extramuestral"
autoplot(residuos, series = "Residuos",
         main="",
         xlab="", 
         ylab="Kg per cápita"
         ) +
  autolayer(fitted(residuoIntraEts), series = "Residuos (ajustada)") + 
  autolayer(residuoExtraPre$mean, series = "Predicción") + 
  geom_vline(xintercept = 2013.5, lty = 2, col = "black") +
  scale_colour_manual(values=c("Residuos"="black",
                               "Residuos (ajustada)"="blue", 
                               "Predicción" = "red")) +
  guides(colour = guide_legend(title = "Series")) +
  annotate("text", x=2006, y=610, label="3.2%", colour = "blue") +
  annotate("text", x=2018, y=490, label="1.9%", colour = "red") +
  theme(legend.position=c(0.02,0.98), legend.justification=c(0,1)) 
```

La presencia de tendencia, primero creciente y luego decreciente, en la serie Residuos puede hacernos pensar que un modelo más adecuado para su ajuste y predicción sería ETS(M,A,N), forzando a que haya pendiente. De hecho, el error de estimación de este modelo es del 2.6%, frente al 2.9% para el modelo ETS(M,N,N). Sin embargo, el error de previsión extramuestral a largo plazo para el modelo ETS(M,A,N) es del 6.5%, frente al 1.9% para el modelo ETS(M,N,N). **Mejor ajuste no implica mejor predicción.** De nuevo, incidir en que claramente estos resultados dependen del punto de corte seleccionado.

\

## Nacimientos

Veamos un segundo ejemplo con la serie Nacimientos (desde el año 2000).

### Identificación y estimación del mejor modelo {.unnumbered}

Si damos total libertad al proceso de selección del mejor modelo, el modelo estimado es ETS(A,A,A), es decir, $y_{t+1} = l_t + b_t + s_{t+1-m} + \varepsilon_{t+1}$.

```{r}
nacimientosEts <- ets(nacimientosb)
summary(nacimientosEts) 
```

El bajo valor de $\beta$ y $\gamma$ indican que ambas, la pendiente y la estacionalidad, varían muy lentamente en el tiempo (véase la @fig-nacimientoscomponentes).

```{r}
#| label: fig-nacimientoscomponentes
#| fig-height: 7
#| fig-cap: "Componentes del modelo óptimo para Nacimientos"
autoplot(nacimientosEts,
         xlab = "Periodo",
         main = "")
```

Respecto de la calidad del modelo, el MAPE de `r round(accuracy(nacimientosEts)[5],1)`% indica que estamos ante un modelo que se ajusta muy bien a los datos; y el valor de MASE igual a `r round(accuracy(nacimientosEts)[6],2)` indica que este modelo reduce en un `r 100 - round(100*accuracy(nacimientosEts)[6],0)`% el error del método ingenuo con estacionalidad, el más sencillo posible. El modelo no tiene sesgo y el valor de ACF1 de `r round(accuracy(nacimientosEts)[7],2)`, inferior a 0.1, indica que el intervalo de confianza de las predicciones está bien calculado.

Podemos ver los últimos valores estimados del nivel, la pendiente y la estacionalidad para interpretarlos. Como el último dato de la serie es diciembre de 2023, los valores del nivel $l$ y la pendiente $b$ mostrados corresponden a ese mes.

```{r}
TT <- nrow(nacimientosEts$states)
nacimientosEts$states[TT,]
```

Febrero es el mes con menor número de nacimientos: nacen `r abs(trunc(nacimientosEts$states[TT,13]))` bebés menos, respecto de la media anual. En octubre es cuando más bebés nacen: `r trunc(nacimientosEts$states[TT,5])` más que la media anual.

### Predicción {.unnumbered}

Si pedimos los valores de predicción tenemos (sólo se muestran los primeros meses):

```{r}
#| eval: false
nacimientosEtsPre <- forecast(nacimientosEts, 
                              h = 24, 
                              level = 95)
nacimientosEtsPre
```

```{r}
#| echo: false
nacimientosEtsPre <- forecast(nacimientosEts, h = 24, level = 95)
forecast(nacimientosEts, h = 5, level = 95)
```

La @fig-nacimientosPrediccion muestra la serie Nacimientos, su predicción a dos años vista y el intervalo de confianza.

```{r}
#| label: fig-nacimientosPrediccion
#| fig-cap: "Nacimientos y predicción"
autoplot(nacimientosEtsPre,
         xlab = "",
         ylab = "Nacimientos",
         main = "")
```

### Análisis del error {.unnumbered}

Se identifica varios valores claramente atípicos --superan las 3 desviaciones típicas-- que corresponden a enero de 2011 y, aproximadamente, nueves después del confinamiento por la pandemia (diciembre de 2020, y febrero y marzo de 2021). Abril de 2008 y diciembre de 2010 son otros candidatos a intervención por superar las 2.5 desviaciones típicas.[^2]

[^2]: Recuerda que el valor de 3 es uno de los posibles y debe ajustarse a las características de la serie y el análisis.

```{r}
#| label: fig-NacimientosError
#| fig-cap: "Error + Intervención"
error <- residuals(nacimientosEts)
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Periodo",
         ylab = "Error",
         main = "") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(2000, 2024, 2)) 

fechas <- format(seq(as.Date("2000-1-1"), as.Date("2023-12-1"), "month"), "%Y-%m")
fechas[abs(error) > 3 * sderror]
```

Un método alternativo para obtener valores atípicos es la prueba de Tukey (véase la píldora *Valores perdidos y valores atípicos*).

```{r}
atipicos <- tsoutliers(error)
fechas[atipicos$index]
```

En este caso solo se identifica como atípico el valor de diciembre de 2020.

### Validación: error extramuestral según horizonte temporal {.unnumbered}

En este ejemplo calcularemos el error extramuestral según el horizonte temporal de previsión, una metodología que ya hemos visto anteriormente.

```{r}
k <- 120                 
h <- 12                  
TT <- length(nacimientosb)
s <- TT - k - h 

mapeAlisado <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(nacimientosb, start = i + 1, end = i + k)
  test.set <-  subset(nacimientosb, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set, model = "AAA", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

errorAlisado <- colMeans(mapeAlisado)
errorAlisado
```

```{r}
#| label: fig-NacimientosErrorRW
#| fig-cap: "Error de predicción según horizonte temporal"
ggplot() +
  geom_line(aes(x = 1:12, y = errorAlisado)) +
  ggtitle("") +
  xlab("Horizonte temporal de predicción") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:12)
```

La @fig-NacimientosErrorRW muestra el error de previsión extramuestral según el horizonte temporal. El error extramuestral a un periodo vista es comparable al error intramuestral (2.2% frente a 2.0%). Aunque el error de previsión aumenta conforme lo hace el horizonte temporal, siempre se mantiene muy bajo. Por ejemplo, en las previsiones a 12 meses vista el error es del 3.4%.

## Demanda eléctrica

Consideremos la serie de consumo eléctrico diario durante el años 2023.

\

### Identificación y estimación del mejor modelo {.unnumbered}

El modelo óptimo sin restricciones es (MAdM) con un valor de $\phi$ cercano al máximo de 0.98, por lo que se solicita el modelo óptimo excluyendo modelos con tendencia amortiguada. 

```{r}
#electricidadEts <- ets(electricidad)
electricidadEts <- ets(electricidad,
                       damped = FALSE)

summary(electricidadEts) 
```

Ahora el mejor modelo no presenta tendencia y tiene error y estacionalidad aditiva, es decir, $y_{t+1} = l_t + s_{t+1-m} + \varepsilon_{t+1}$.

El valor $\gamma = 0$ indica que las estacionalidad se mantiene contante en el tiempo, mientras que el elevado valor de $\alpha$ indica que el nivel de la serie cambia de forma constante. Este cambio de nivel está relacionado con las variaciones en el consumo eléctrico debido a los cambios en la temperatura y el uso de aparatos de climatización. 

Respecto de la calidad del modelo, el MAPE de `r round(accuracy(electricidadEts)[5],1)`% indica que estamos ante un modelo que se ajusta muy bien a los datos; no hay sesgo (MPE es casi cero); y el valor de ACF1, muy bajo, indica que la fórmula usada para el cálculo del intervalo de confianza de las predicciones es válida.

Podemos ver los últimos valores estimados del nivel y la estacionalidad para interpretarlos. Recuerda que los valores de la componente estacional están ordenados alrevés (s1 es domingo y s7 es lunes).

```{r}
TT <- nrow(electricidadEts$states)
electricidadEts$states[TT,]
```

El domingo la demanda eléctrica cae `r abs(round(electricidadEts$states[TT,2], 0))` GWh respecto de la media semanal. Por el contrario, el miércoles es el día de mayor incremento de demanda respecto de la media semanal, `r round(electricidadEts$states[TT,6], 0)` GWh.

### Predicción {.unnumbered}

Si pedimos los valores de predicción para las cuatro semanas siguientes, tenemos (sólo se muestran la primera):

```{r}
#| eval: false
electricidadEtsPre <- forecast(electricidadEts, 
                               h = 28, 
                               level = 95)
electricidadEtsPre
```

```{r}
#| echo: false
electricidadEtsPre <- forecast(electricidadEts, h = 28, level = 95)
forecast(electricidadEts, h = 7, level = 95)
```

La @fig-electricidadPrediccion muestra la serie Demanda eléctrica, su predicción a cuatro semanas vista y el intervalo de confianza.

```{r}
#| label: fig-electricidadPrediccion
#| fig-cap: "Demanda eléctrica y predicción"
autoplot(electricidadEtsPre,
         xlab = "",
         ylab = "GWh",
         main = "")
```

### Análisis del error {.unnumbered}

```{r}
#| label: fig-electricidadError
#| fig-cap: "Error + Intervención"
error <- residuals(electricidadEts)
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "Semana",
         ylab = "Error",
         main = "") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(6, 26, 2)) 

fechas <- format(seq(as.Date("2023-1-1"), as.Date("2023-12-31"), "day"), "%Y-%m-%d")
fechas[abs(error) > 3 * sderror]
```

El la @fig-electricidadError se identifican múltiples días atípicos asociados con un consumo inferior al esperado debido a festividades: Año nuevo, Reyes, Semana Santa (el Viernes Santo fue el 7 de abril), Día del trabajador, Virgen de agosto, Día de la Hispanidad, Todos los Santos, Día de la Constitución y Navidad. El Día de la Inmaculada (8 de diciembre) no aparece por caer en domingo. 

También se observan tres días con un consumo mayor de lo esperado justo después de un festivo, el 7 de enero (tras Reyes), el 8 de abril (Sábado Santo) y el 2 de noviembre (tras Todos los Santos). Aquí la causa no es tanto un incremento inesperado del consumo, como la dinámica del propio método de estimación. Al llegar un día festivo, el método de Alisado falla ofreciendo una predicción más alta de la real y dando lugar a un error negativo. Al día siguiente, el método de Alisado ajusta su predicción a la baja, pero por no ser festivo vuelve a fallar, esta vez ofreciendo una predicción más baja de la real y dando lugar a un error positivo.

Veamos como en este caso la prueba de Tukey identifica las mismas fechas.

```{r}
atipicos <- tsoutliers(error)
fechas[atipicos$index]
```

\
\

# Otras alternativas para ajustar un modelo y predecir

A la hora de ajustar un modelo a una serie y predecir hay que ser un poco imaginativos, dedicarle tiempo y probar cosas. Por ejemplo, podríamos considerar la transformación logarítmica de la serie. O podríamos cambiar el criterio de estimación de los parámetros o el de selección del modelo óptimo.

Yendo un poco más lejos, para una serie mensual (como Nacimientos) dado que el valor de la serie dependerá forzosamente del número de días del mes, podríamos ajustar y predecir el valor medio de la serie por día del mes. Por ejemplo, los nacimientos medios por día: cociente entre los nacimientos de cada mes y el número de días del mes. Esta serie tendrá una componente estacional más suave, al eliminar el efecto de los meses de febrero bisiestos, y tendrá, previsiblemente, un mejor ajuste.

También podemos mezclar varios de los enfoques previos o ser aún más imaginativos.

El siguiente código muestra el MAPE (para previsiones intramuestrales a un periodo vista) para la serie Nacimientos usando varias de estas opciones. Puedes deducir que se está haciendo en cada caso a partir del código. Sería más adecuado usar otro criterio de validación diferente, pero el objetivo de este epígrafe es recalcar que no hay que quedarse con lo inmediato (predecir una serie con las opciones por defecto de las funciones), sino probar y probar.

```{r}
# Serie Nacimientos
accuracy(ets(nacimientos))[5]
accuracy(ets(nacimientos, 
             opt.crit = "mse"))[5]
accuracy(ets(nacimientos, 
             opt.crit = "amse",
             nmse = 4))[5]

# Transformación logarítmica
accuracy(ets(nacimientos, 
             lambda = 0))[5]
accuracy(ets(nacimientos, 
             lambda = 0, 
             opt.crit = "mse"))[5]
accuracy(ets(nacimientos, 
             lambda = 0, 
             opt.crit = "amse",
             nmse = 4))[5]

# Transformación logarítmica insesgada
accuracy(ets(nacimientos, 
             lambda = 0,
             biasadj = TRUE))[5]
accuracy(ets(nacimientos, 
             lambda = 0, 
             biasadj = TRUE,
             opt.crit = "mse"))[5]
accuracy(ets(nacimientos, 
             lambda = 0, 
             biasadj = TRUE,
             opt.crit = "amse",
             nmse = 4))[5]

# Nacimientos por dia
accuracy(ets(nacimientos/monthdays(nacimientos)))[5]
accuracy(ets(nacimientos/monthdays(nacimientos), 
             opt.crit = "mse"))[5]
accuracy(ets(nacimientos/monthdays(nacimientos), 
             opt.crit = "amse",
             nmse = 4))[5]

```

La principal conclusión en este caso es que salirse de la estimación directa sobre la serie original no reduce el error significativamente. Sin embargo, cabe destacar que,

-   El error de estimación de los nacimientos por día es menor que el error obtenido con la serie original de nacimiento. Véanse los tres últimos modelos respecto de los tres primeros.
-   Usar la transformación logarítmica (con o sin predicciones insesgadas) puede mejorar o no la capacidad predictiva del modelo, dependiendo del resto de parámetros. Véanse los modelos 4 a 9 respecto de los modelos 1 a 3.
-   El mejor modelo estima los nacimientos por día y estima los parámetros minimizando la verosimilitud o el error cuadrático medio ("mse"). No siempre el uso directo de la serie ofrece los mejores resultados.

\
\

# Resumen de los comandos utilizados


|Función  |Paquete | Descripción                                           |
|:--------------|:-----------|:-----------------------------------------------------|
| `format`   | base    | Da formato a un objeto de R para mejorar sus impresión |
| `seq`   | base    | Genera secuencias regulares, en particular de fechas de calendiario |
| `fitted`   | stats    | Obtiene las predicciones a un periodo vista intramuestrales |
| `residuals`    |stats   |Obtiene el residuo de un modelo estimado|
| `accuracy` | forecast | Calculo de la precisión del modelo                           |
| `ets`          |forecast  |Estimación de una amplia familia de métodos de alisado exponencial|
| `forecast` | forecast | Predice valores extramuestrales futuros de la serie         |
| `meanf`    | forecast | Predicción por media                                         |
| `naive`    | forecast | Predicción por método ingenuo I                              |
| `rwf`      | forecast | Predicción por tendencia media                               |
| `snaive`   | forecast | Predicción por método ingenuo con estacionalidad             |

\
\
\
\


