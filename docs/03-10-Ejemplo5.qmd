---
title: "Defunciones por Enfermedades Cerebrovasculares"
subtitle: "Procesos ARIMA con estacionalidad"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
toc: true
toc-title: Índice
number-sections: true
bibliography: references.bib
crossref:
  fig-title: Figura
  tbl-title: Tabla
  fig-prefix: Figura
  tbl-prefix: Tabla
---

```{r}
#| label: chunk_setup
#| echo: false
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```


```{r}
#| label: librerias
#| echo: false
library(forecast)
library(ggplot2); theme_set(theme_bw())
library(tseries)
library(lmtest)
library(seasonal)
```

\
\

# Introducción

Consideremos la serie temporal correspondiente al número de defunciones causadas por enfermedades cerebrovasculares, Esta serie está disponible en el Instituto Nacional de Estadística desde enero de 1980 hasta diciembre de 2023, un total de 44 años o 528 meses.

En la descriptiva vimos que la descomposición revelaba la presencia de varios valores atípicos concentrados al inicio de la serie. Por este motivo, para su análisis por modelos Arima vamos a recortar la serie, que empezará el enero de 1990 (véase @fig-ECB).

También hemos visto que para alcanzar la estacionariedad y verificar la hipótesis de ergodicidad es necesario diferenciar la serie tanto en la parte regular como estacional y decidimos usar la transformación logarítmica para linealizar la serie y ganar en interpretabilidad.

```{r}
#| label: fig-ECB
#| fig-cap: "Defunciones causadas por enfermedades cerebrovasculares"
DefEnfCer <- read.csv2("./series/Enfermedades cerebrovasculares.csv", 
                       header = TRUE)

DefEnfCer <- ts(DefEnfCer[,2], 
                start = 1980, 
                freq = 12)

DefEnfCer <- window(DefEnfCer, 
                    start = 1990)

autoplot(DefEnfCer,
         xlab = "",
         ylab = "",
         main = "")
```

\
\

# Identificación

Vamos a identificar los valores de $p$, $q$, $P$ y $Q$. Para ello, analizaremos la FAC y la FACP, y solicitaremos con `auto.arima` y `seas` una identificación automática.

```{r} 
#| label: fig-ECBDisplay
#| fig-cap: "Defunciones anuales por enfermedades cerebrovasculares, FAC y FACP de la serie transformada"
#| fig-height: 5
ggtsdisplay(diff(diff(log(DefEnfCer), lag = 12)), lag = 48)
```

En la parte regular, la FAC muestra que la primera autocorrelación está por encima del IC95 y en la FACP se observa decrecimiento. En la parte estacional, la FAC muestra una autocorrelación significativa en el orden 12 y la FACP muestra decrecimiento. Así, podemos identificar el proceso como $log(DefEnfCer_t) \sim ARIMA_{12}(0,1,1)(0,1,1)$.

Veamos ahora `auto.arima`, al que incluiremos variables ficticias para los cuatro valores atípicos ya identificados cuando aplicamos Alisado exponencial: febrero de 1999, junio de 2003, enero de 2005, y febrero de 2012.

```{r}
d0299 <- 1*(cycle(DefEnfCer) == 2 & trunc(time(DefEnfCer)) == 1999)
d0603 <- 1*(cycle(DefEnfCer) == 6 & trunc(time(DefEnfCer)) == 2003)
d0105 <- 1*(cycle(DefEnfCer) == 1 & trunc(time(DefEnfCer)) == 2005)
d0212 <- 1*(cycle(DefEnfCer) == 2 & trunc(time(DefEnfCer)) == 2012)

auto.arima(DefEnfCer, 
           d = 1, 
           D = 1,
           lambda = 0,
           xreg = cbind(d0299, d0603, d0105, d0212))
```

La función `auto.arima` identifica un complejo proceso $ARIMA_{12}(2,1,2)(1,1,2)$. Por otro lado, la función `seas` identifica un proceso $ARIMA_{12}(1,0,1)(0,1,1)$. El resultado muestra la conveniencia de la transformación logarítmica y una intervenciones en febrero de 2012.

```{r}
summary(seas(DefEnfCer))
```

Vamos a descartar ambas identificaciones y considerar el modelo de las aerolíneas. El AICc para este modelo es solo algo superior al de los modelos sugeridos por `auto.arima` o `seas`. Es decir, $\log(DefEnfCer) \sim ARIMA_{12}(0, 1, 1)(0, 1, 1) + AI$ donde $AI$ recoge las cuatro variables ficticias que afectan un único mes.

\
\

# Estimación 

La siguiente salida muestra el modelo estimado y la @fig-ECBError permite analizar la presencia de más valores extremos.

```{r}
DefEnfCerArima1 <- Arima(DefEnfCer, 
                         order = c(0, 1, 1),  
                         seasonal = c(0, 1, 1),
                         lambda = 0,
                         cbind(d0299, d0603, d0105, d0212))
DefEnfCerArima1
``` 


```{r} 
#| label: fig-ECBError
#| fig-cap: "Error + Intervención"
error <- residuals(DefEnfCerArima1)
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "",
         ylab = "Error",
         main = "") +
  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, 
             colour = c("red", "green", "green", "red"), 
             lty = 2) + 
  scale_x_continuous(breaks= seq(1990, 2024, 2))

fechas <- format(seq(as.Date("1990-01-01"), as.Date("2023-12-01"), "month"), "%Y-%m")
fechas[abs(error) > 3 * sderror]

atipicos <- tsoutliers(error)
fechas[atipicos$index]
```

Se observan tres valores claramente atípicos en mayo de 2001, agosto de 2003 y febrero de 2015. Además, hay otros candidatos a valor extremo, entre los que destacan febrero de 2005, enero de 2015 y julio de 2022. Procederemos a incluirlos en el modelo.

```{r}
d0501 <- 1*(cycle(DefEnfCer) == 5 & trunc(time(DefEnfCer)) == 2001)
d0803 <- 1*(cycle(DefEnfCer) == 8 & trunc(time(DefEnfCer)) == 2003)
d0205 <- 1*(cycle(DefEnfCer) == 2 & trunc(time(DefEnfCer)) == 2005)
d0115 <- 1*(cycle(DefEnfCer) == 1 & trunc(time(DefEnfCer)) == 2015)
d0215 <- 1*(cycle(DefEnfCer) == 2 & trunc(time(DefEnfCer)) == 2015)
d0722 <- 1*(cycle(DefEnfCer) == 7 & trunc(time(DefEnfCer)) == 2022)


DefEnfCerArima2 <- Arima(DefEnfCer, 
                         order = c(0, 1, 1),  
                         seasonal = c(0, 1, 1),
                         lambda = 0,
                         xreg = cbind(d0299, d0501, d0603, 
                                      d0803, d0105, d0205, 
                                      d0212, d0115, d0215, d0722))
DefEnfCerArima2
``` 

Aparentemente las variables de intervención incluidas son significativas.

El análisis gráfico del residuo indica que aún hay candidatos a valores atípicos (véase @fig-ECBError2). Sin embargo, vamos a dar por concluido este proceso.

```{r} 
#| label: fig-ECBError2
#| fig-cap: "Error + Intervención"
error <- residuals(DefEnfCerArima2)
sderror <- sd(error)

autoplot(error, series="Error",
         colour = "black",
         xlab = "",
         ylab = "Error",
         main = "") +
  geom_hline(yintercept = c(-3, -2, 2, 3)*sderror, 
             colour = c("red", "green", "green", "red"), 
             lty = 2) + 
  scale_x_continuous(breaks= seq(1990, 2024, 2)) 

fechas[abs(error) > 3 * sderror]
```

Cuatro de los valores atípicos corresponden al mes de febrero y sus coeficientes estimados toman valores parecidos. También hay dos meses de enero atípicos con similar efecto. Vamos a asumir que la causa que hay detrás del valor anómalo en los meses de febrero es la misma, posiblemente un invierno más frío de lo usual. Lo mismo asumiremos para los valores atípicos en enero. Esto nos permite *agrupar* variables de intervención y simplificar el modelo. 

```{r}
d01aa <- d0105 + d0115
d02aa <- d0299 + d0205 + d0212 + d0215

DefEnfCerArima3 <- Arima(DefEnfCer, 
                         order = c(0, 1, 1),  
                         seasonal = c(0, 1, 1),
                         lambda = 0,
                         xreg = cbind(d01aa, d02aa, 
                                      d0501, d0603, d0803, d0722))
DefEnfCerArima3
``` 

Por último, vemos que todos los coeficientes del modelo son significativos.

```{r}
coeftest(DefEnfCerArima3)
```

\
\

# Validación

### Calidad de ajuste {-}

Analizando los criterios de bondad de ajuste se tiene que el error medio (ME), igual a `r round(accuracy(DefEnfCerArima3)[1],2)`, defunciones es prácticamente cero por lo que no parece que haya sesgo en las predicciones; en media nos equivocamos en `r round(accuracy(DefEnfCerArima3)[2],0)` defunciones (RMSE); y el error porcentual medio es `r round(accuracy(DefEnfCerArima3)[5],1)`%, bajo. Sin embargo, los intervalos de las predicciones no están correctamente calculados.

```{r}
#| eval: false
accuracy(DefEnfCerArima3)
```

```{r}
#| echo: false
round(accuracy(DefEnfCerArima3),2)
```

\

### Incorrelación, Homocedasticidad y Normalidad {-}

Veamos ahora si el residuo es ruido blanco.

```{r}
error <- residuals(DefEnfCerArima3)
Box.test(error, lag = 2,type = "Ljung-Box")
Box.test(error, lag = 24,type = "Ljung-Box")
Box.test(error^2, lag = 2, type = "Ljung-Box")
Box.test(error^2, lag = 24, type = "Ljung-Box")
jarque.bera.test(error) 
```

El error muestra ser incorrelado (al 1%), homocedástico y seguir una distribución normal. 

\
\

# Ecuación del modelo identificado

El modelo estimado es el de las aerolíneas con intervención:
$$(1-L)(1-L^{12})log(DefEnfCer_t) =(1+\theta_1 L)(1 + \theta_{12}L^{12})\varepsilon_t +AI.$$
Como la interpretación de la parte estructural del modelo es ya conocida, vamos a centrar la interpretación en la intervención:

* En los dos meses de enero atípicos, posiblemente por ser más frios, la defunciones fueron 15.3% mayores que las observadas en otros meses de enero. 

* De la misma forma, en los tres meses de febrero atípicos, la defunciones fueron un 20.1% mayores que las observadas en otros meses de febrero.

* En mayo de 2001 hubo un aumento en las defunciones del 11.1% respecto de lo esperado; en junio de 2003 del 16.8%; en agosto de 2003 del 18.0%; y en julio de 2022 del 15.1%.

\
\

# Predicción de las defunciones por enfermedad cerebrovascular

Una vez dado por válido el modelo, podemos pasar a realizar predicciones para los próximos años (véase @fig-ECBPredicción). Como la variables de intervención no son efectos calendario, sus valores previstos serán cero. En concreto, estamos asumiendo que la temperatura en los eneros y febreros de los próximos años no será inusualmente baja.

```{r}
#| label: fig-ECBPredicción
#| fig-cap: "Defunciones (1990-2023) y predicción (2023-2028)"
pDefEnfCerArima3 <- forecast(DefEnfCerArima3, 
                             h = 60,
                             xreg = cbind(rep(0, 60), rep(0, 60), rep(0 ,60), 
                                          rep(0 ,60), rep(0, 60), rep(0, 60)), 
                             level = 95)

autoplot(pDefEnfCerArima3, 
         xlab = "",
         ylab = "Defunciones",
         main = "") +
  scale_x_continuous(breaks= seq(1990, 2028, 4)) 
```

A partir de 2026 se espera que el número de defunciones por enfermedad cerebrovascular caiga por debajo de los 22000 casos.

```{r}
aggregate(pDefEnfCerArima3$mean, FUN = sum)
```

\
\

# Comparación con Alisado Exponencial

El método de Alisado exponencial, aplicado sobre el logaritmo de las defunciones identifica un proceso (A,A,A) con $\alpha=0.301$ y $\beta = \gamma = 0$. La raíz del error cuadrático medio (RMSE) es de 150 defunciones y el error porcentual (MAPE) del 3.8%. Estos valores son superiores a los obtenidos con el modelo Arima (127 defunciones y 3.3%, respectivamente).

```{r}
summary(ets(DefEnfCer, lambda = 0))
```

Vamos a determinar si la aplicación de modelos Arima mejora la calidad de las predicciones lo suficiente como para justificar su uso --frente a los métodos de Alisado, mucho más sencillos. Para ello, aplicaremos la metodología de origen de predicción móvil para estimar la capacidad predictiva del modelo Arima y compararla con el modelo de Alisado. 

```{r}  
k <- 120                   
h <- 12                    
T <- length(DefEnfCer)     
s <- T - k - h               

mapeArima <- matrix(NA, s + 1, h)
mapeAlisado <- matrix(NA, s + 1, h)

for (i in 0:s) {
  train.set <- subset(DefEnfCer, start = i + 1, end = i + k)
  test.set <-  subset(DefEnfCer, start = i + k + 1, end = i + k + h) 
  
  fit <- Arima(train.set, 
               order = c(0, 1, 1),
               seasonal = c(0, 1, 1), 
               lambda = 0)
  
  fcast <- forecast(fit, h = h)
  mapeArima[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, lambda = 0, model = "AAA", damped = FALSE)
  
  fcast<-forecast(fit, h = h)
  mapeAlisado[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}
```

Calculamos los errores medianos para eliminar el impacto de los meses atípicos sobre la precisión en las predicciones.

```{r}  
errorArima <- apply(mapeArima, MARGIN = 2, FUN = median)
errorArima

errorAlisado <- apply(mapeAlisado, MARGIN = 2, FUN = median)
errorAlisado
```

```{r}
#| label: fig-ECBRW
#| fig-cap: "Error de predicción (MAPE) según horizonte temporal"
datos <- data.frame(
  factor = c(rep("Arima", 12), rep("Alisado", 12)),
  x = c(1:12,1:12),
  y = c(errorArima, errorAlisado)
)

ggplot(datos, aes(x = x, y = y,  colour= factor)) + 
  geom_line() +
  ggtitle("") +
  xlab("Horizonte temporal de predicción") +
  ylab("%") +
  scale_x_continuous(breaks= 1:12) +
  labs(colour = "Métodos") + 
  theme(legend.position=c(0.1,0.8)) 
```

La @fig-ECBRW revela que Arima siempre es algo superior a Alisado en calidad de predicciones, pero con un error inferior en promedio de 0.16 puntos porcentuales. Por tanto, la mejora en la precisión no parece justificar la complejidad de los modelos Arima frente a la sencillez de los modelos de Alidado.

La ventaja de Arima reside en su capacidad para estimar el efecto de inviernos más crudos sobre las defunciones por enfermedad cerebrovascular y mejorar las predicciones en estos meses.

\
\
\
\




