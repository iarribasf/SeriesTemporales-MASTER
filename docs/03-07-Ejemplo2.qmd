---
title: "Defunciones por Enfermedades Cerebrovasculares"
subtitle: "Alisado Exponencial"
author: "Iván Arribas (Depto. Análisis Económico. Universitat de València)"
toc: true
toc-title: Índice
number-sections: true
bibliography: references.bib
crossref:
  fig-title: Figura
  tbl-title: Tabla
  fig-prefix: Figura
  tbl-prefix: Tabla
---

```{r}
#| label: chunk_setup
#| echo: false
knitr::opts_chunk$set(warning = FALSE, 
                      message = FALSE, 
                      comment = "",
                      fig.align = "center", 
                      fig.show = "hold",
                      fig.height = 4,
                      fig.width = 8,
                      out.width = "80%") 
```


```{r}
#| label: librerias
#| echo: false
library(forecast)
library(ggplot2); theme_set(theme_bw())
```

\
\

# Introducción

Consideremos la serie temporal correspondiente al número de defunciones causadas por enfermedades cerebrovasculares, Esta serie está disponible en el Instituto Nacional de Estadística desde enero de 1980 hasta diciembre de 2023, un total de 44 años o 528 meses.

En la descriptiva vimos que la descomposición revelaba la presencia de varios valores atípicos concentrados al inicio de la serie. Por este motivo, para el análisis por técnicas de Alisado Exponencial vamos a recortar la serie y considerarla solo desde enero de 1990, 34 años o 408 meses.

La serie presenta tendencia decreciente y estacionalidad de orden 12 en un claro esquema multiplicativo (véase @fig-ECB). Ya vimos que el determinante principal del patrón estacional es la temperatura.

```{r}
#| label: fig-ECB
#| fig-cap: "Defunciones causadas por enfermedades cerebrovasculares"
DefEnfCer <- read.csv2("./series/Enfermedades cerebrovasculares.csv", 
                       header = TRUE)

DefEnfCer <- ts(DefEnfCer[,2], 
                start = 1980, 
                frequency = 12)

DefEnfCer <- window(DefEnfCer, 
                    start = 1990)

autoplot(DefEnfCer,
         xlab = "",
         ylab = "Defunciones",
         main = "") +
  scale_x_continuous(breaks= seq(1990, 2024, 2)) 
```

\
\

# Ajuste por alisado exponencial e interpretación

Vamos a aplicar la metodología de Alisado Exponencial a la serie de defunciones. Si se estima el modelo sin imponer ninguna restricción `ets` identifica como modelo óptimo ETS(M,Ad,M), con un valor de $\phi = 0.98$, en su valor máximo. Por tanto, se opta por solicitar de nuevo el mejor modelo excluyendo aquellos con amortiguamiento.

```{r}
DefEnfCerEts <- ets(DefEnfCer, 
                    damped = FALSE)

summary(DefEnfCerEts) 
```

El modelo estimado no tiene pendiente y tiene estacionalidad y error multiplicativos:
$$y_{t+1} = l_t \cdot s_{t+1-m} \cdot (1 + \varepsilon_{t+1}).$$

El valor de $\alpha$ indica que el nivel de la serie ha ido variando en el tiempo. El valor de $\gamma$ es prácticamente cero e indica que la estacionalidad se mantienen constante en el tiempo (véase @fig-ECBDescomposicion).

```{r}
#| label: fig-ECBDescomposicion
#| fig-cap: "Descomposición por Alisado Exponencial para defunciones por enfermedades cerebrovasculares"
#| fig-height: 7
autoplot(DefEnfCerEts,
         xlab = "",
         main = "")
```

La calidad del ajuste es bastante buena, con un MAPE de 3.9% y un RMSE de 150 defunciones (o 109 si usamos el MAE). Además, según el MASE, el modelo de Alisado supone una mejora del 32% respecto del método ingenuo con estacionalidad, el más sencillo que podríamos aplicar. La ACF1 indica que las estimaciones por intervalo de las previsiones serán correctas, y no hay sesgo.
      
Los últimos valores estimados del nivel y la estacionalidad, que corresponden a diciembre de 2023, nos permiten mostrar gráficamente la componente estacional (@fig-ECBEstacionalidad).

```{r}
#| eval: false
tail(DefEnfCerEts$states, 1)
```

```{r}
#| echo: false
round(tail(DefEnfCerEts$states, 1),2)
```

```{r}
#| label: fig-ECBEstacionalidad 
#| fig-cap: "Componente estacional"
componenteEstacional <- tail(DefEnfCerEts$states, 1)[13:2]

ggplot() +
  geom_line(aes(x = 1:12, y = componenteEstacional)) + 
  geom_hline(yintercept = 1, colour = "blue", lty = 2) +
  ggtitle("") +
  xlab("") +
  ylab("Efecto estacional") +
  scale_x_continuous(breaks= 1:12, 
                     labels = c("Ene", "Feb", "Mar", "Abr", "May", "Jun", 
                                "Jul", "Ago", "Sep", "Oct", "Nov", "Dic")) 
```

El nivel de las defunciones por enfermedades cerebrovasculares en diciembre de 2023 (última observación) es de 1907 casos. La mayor incidencia de las defunciones por enfermedades cerebrovasculares tiene lugar en invierno, en los meses de diciembre a marzo. En concreto, destaca el mes enero con un incremento del 23% (`s12`) en las defunciones por enfermedades cerebrovasculares respecto de la media anual. La incidencia en verano es menor que la media anual, observándose en septiembre un 15% menos de casos (`s4`). El efecto estacional estimado por el método de Alisado es más acusado que el estimado durante la descriptiva de la serie.

\
\

# Predicción

Si pedimos los valores de predicción y su intervalo de confianza al 95% para los próximos tres años, tenemos (numéricamente sólo se muestra el primer año):

```{r}
#| eval: false
DefEnfCerEtsPre <- forecast(DefEnfCerEts, 
                            h = 36, 
                            level = 95)
DefEnfCerEtsPre
```

Recuerda que las fórmulas usadas para el cálculo del intervalo de confianza de las predicciones no son adecuadas.

```{r}
#| echo: false
DefEnfCerEtsPre <- forecast(DefEnfCerEts, 
                            h = 36, 
                            level = 95)
forecast(DefEnfCerEts, 
         h = 12, 
         level = 95)
```

```{r}
#| label: fig-ECBPrediccion
#| fig-cap: "Muertes por enf. cerebrovasculares (1990-2023) y predicción (2024-2026)"
autoplot(DefEnfCerEtsPre,
         xlab = "",
         ylab = "Casos",
         main = "")
```

Las predicciones, acordes con el modelo estimado, no muestran tendencia y su nivel es constante en los tres años de predicción. (véase @fig-ECBPrediccion).

\
\

# Análisis del error

La @fig-ECBError muestra el residuo del modelo. Se aprecian cuatro meses en los que el residuo supera las tres desviaciones típicas porque el número de muertes por enfermedades cerebrovasculares fue muy superior al estimado por el modelo: febrero de 1999, junio 2003, enero de 2005 y febrero de 2012. El error en este último mes, febrero de 2012, es especialmente acusado ---supera las 5 desviaciones típicas y es el único identificado por la prueba de Tukey. Durante ese mes se registraron temperaturas muy bajas en muchas partes del país, incluso algunas nevadas inusuales en zonas donde no era común ver nieve, y se reportaron mínimas récord en varias ciudades españolas. Estas temperaturas extremas causaron un incremento significativo en el número de defunciones por enfermedades cerebrovasculares.


```{r}
#| label: fig-ECBError
#| fig-cap: "Error + Intervención"
error <- residuals(DefEnfCerEts)
sderror <- sd(error)

autoplot(error,
         xlab = "",
         ylab = "Error",
         main = "",
         colour = "black") +
  geom_hline(yintercept = c(-3, -2, 2 ,3)*sderror, 
             colour = c("red", "blue", "blue", "red"), lty = 2) + 
  scale_x_continuous(breaks= seq(1990, 2024, 2)) 

fechas <- format(seq(as.Date("1990-01-01"), as.Date("2023-12-01"), "month"), "%Y-%m")
fechas[abs(error) > 3 * sderror]

atipicos <- tsoutliers(error)
fechas[atipicos$index]
```

\
\

# Validación: origen de predicción móvil

Asumimos que se precisan diez años para hacer una buena estimación, $k=120$, y que el horizonte temporal es un año, $h = 12$ meses. La siguiente rutina permite obtener el MAPE para previsiones con un horizonte temporal desde 1 mes hasta 12 meses.
  
```{r}  
#| label: fig-ECBRW
#| fig-cap: "Error de predicción según horizonte temporal"
k <- 120                 
h <- 12                  
TT <- length(DefEnfCer)  
s <- TT - k - h          

mapeAlisado <- matrix(NA, s + 1, h)
for (i in 0:s) {
  train.set <- subset(DefEnfCer, start = i + 1, end = i + k)
  test.set <-  subset(DefEnfCer, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set, model = "MAM", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
}

errorAlisado <- colMeans(mapeAlisado)
errorAlisado

ggplot() +
  geom_line(aes(x = 1:12, y = errorAlisado)) +
  ggtitle("Error de predicción según horizonte temporal") +
  xlab("Horizonte temporal de predicción") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:12)
```

La @fig-ECBRW muestra que aunque el error depende del horizonte temporal de previsión, se mueve en una banda muy estrecha: entre el 4.1% para previsiones a un mes vista y el 4.7% para previsiones a siete meses vista.

\
\

# Modelos alternativos

¿Podemos reducir el error extramuestral de previsión si cambiamos las opciones por defecto de `ets` o la serie a analizar? La @fig-ECBRW2 muestra el error de previsión extramuestral según el horizonte de previsión para los siguientes modelos (todos sin amortiguamiento y en caso de transformación logarítmica, sin ajuste para insesgadez):

|**Id**  |**Transformación** |**Modelo** |
|:-------|:------------------|:----------|
| 1      |Ninguna            |MNM        |
| 2      |Ninguna            |MAM        |
| 3      |Logaritmo          |ANA        |
| 4      |Logaritmo          |AAA        |
| 5      |Defunciones por día |MNM       |
| 6      |Defunciones por día |MAM       |

En concreto, los comandos utilizados han sido: 

* Modelo 1: `ets(x, model = "MNM", damped = FALSE)`
* Modelo 2: `ets(x, model = "MAM", damped = FALSE)`
* Modelo 3: `ets(x, model = "ANA", lambda = 0, damped = FALSE)`
* Modelo 4: `ets(x, model = "AAA", lambda = 0, damped = FALSE)`
* Modelo 5: `ets(x/monthdays(x), model = "MNM", damped = FALSE)`
* Modelo 6: `ets(x/monthdays(x), model = "MAM", damped = FALSE)`

\

```{r}
#| echo: false
#| label: fig-ECBRW2
#| fig-cap: "Errores de previsión extramuestral. Varios modelos"
k <- 120                 
h <- 12                  
TT <- length(DefEnfCer)  
s <- TT - k - h          

mapeAlisado1 <- matrix(NA, s + 1, h)
mapeAlisado2 <- matrix(NA, s + 1, h)
mapeAlisado3 <- matrix(NA, s + 1, h)
mapeAlisado4 <- matrix(NA, s + 1, h)
mapeAlisado5 <- matrix(NA, s + 1, h)
mapeAlisado6 <- matrix(NA, s + 1, h)

for (i in 0:s) {
  train.set <- subset(DefEnfCer, start = i + 1, end = i + k)
  test.set <-  subset(DefEnfCer, start = i + k + 1, end = i + k + h)
  
  fit <- ets(train.set, model = "MNM", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado1[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, model = "MAM", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado2[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, model = "ANA", lambda = 0, damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado3[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set, model = "AAA", lambda = 0, damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado4[i + 1,] <- 100*abs(test.set - fcast$mean)/test.set
  
  fit <- ets(train.set/monthdays(train.set), model = "MNM", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado5[i + 1,] <- 100*abs(test.set - fcast$mean * monthdays(fcast$mean))/test.set
  
  fit <- ets(train.set/monthdays(train.set), model = "MAM", damped = FALSE)
  fcast<-forecast(fit, h = h)
  mapeAlisado6[i + 1,] <- 100*abs(test.set - fcast$mean * monthdays(fcast$mean))/test.set
}


errorAlisado1 <- colMeans(mapeAlisado1)
errorAlisado2 <- colMeans(mapeAlisado2)
errorAlisado3 <- colMeans(mapeAlisado3)
errorAlisado4 <- colMeans(mapeAlisado4)
errorAlisado5 <- colMeans(mapeAlisado5)
errorAlisado6 <- colMeans(mapeAlisado6)

ggplot() +
  geom_line(aes(x = 1:12, y = errorAlisado1, colour = "Modelo 1")) +
  geom_line(aes(x = 1:12, y = errorAlisado2, colour = "Modelo 2")) + 
  geom_line(aes(x = 1:12, y = errorAlisado3, colour = "Modelo 3")) +
  geom_line(aes(x = 1:12, y = errorAlisado4, colour = "Modelo 4")) +
  geom_line(aes(x = 1:12, y = errorAlisado5, colour = "Modelo 5")) +
  geom_line(aes(x = 1:12, y = errorAlisado6, colour = "Modelo 6")) +
  ggtitle("") +
  xlab("") +
  ylab("MAPE") +
  scale_x_continuous(breaks= 1:12) +
  scale_color_discrete(name = "Modelos")
```

De la @fig-ECBRW2 deducimos que aunque todos los métodos resultan similares en la precisión de las predicciones extramuestrales en el corto plazo, al pasar al medio y largo plazo las diferencias pueden ser significativas: la mayor diferencia entre los modelos se da para la previsión a ocho y nueve meses vista y es de 0.75 puntos porcentuales.

Si queremos entrar en matices:

* Globalmente el modelo que ofrece previsiones más precisas es el modelo 6, donde se ha forzado a que haya pendiente (`model = "MAM`) y se trabaja sobre las defunciones por día. El segundo mejor modelo, el modelo 2, sigue el mismo esquema que el modelo 6 pero sobre la serie original.
* Los modelos que tienen tendencia (modelos 2, 4 y 6) resultan mejores que sus homólogos sin tendencia (modelos 1, 3 y 5, respectivamente).
* El uso de logaritmo no mejora la precisión en las predicciones.

Es decir, tanto la estrategia de predecir la serie de defunciones medias por día (en lugar de la serie original) como la de forzar a que el modelo tenga tendencia, que es lo que se observa gráficamente, mejoran la calidad de las previsiones extramuestrales. La combinación de estas dos estrategias es la óptima.

\
\
\
\

